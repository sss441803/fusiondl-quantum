reading from multiple data folder!**********************************************
Selected signals (determines which signals are used for training):
[q95 safety factor, internal inductance, plasma current, Locked mode amplitude, Normalized Beta, stored energy, Plasma density, Radiated Power Core, Radiated Power Edge, Input Power (beam for d3d), Input Beam Torque, plasma current direction, plasma current target, plasma current error, Electron temperature profile, Electron density profile]
...done
Training on 1724 shots, testing on 857 shots
NO SCALARS ARE USED, ONLY 1D SIGNALS
n_scalars,n_profiles,profile_size= 0 2 64
Classical convolution with channels  2 4
Classical convolution with channels  4 3
InputBlock parameters:  0 2 64 ['c4', 'c3'] 3 10 0.08 2
TCN parameters:  3 1 [5, 5, 5, 5, 5, 5, 5, 5] 5 0.08
Using single GPU..........................................
99 epochs left to go

Training Epoch 0/100 starting at 2021-08-24 21:50:01.585900
[1]  [0/1724] loss: 3.034, ave_loss: 3.034
[2]  [20/1724] loss: 4.010, ave_loss: 3.522
[3]  [40/1724] loss: 4.009, ave_loss: 3.684
[4]  [60/1724] loss: 3.893, ave_loss: 3.737
[5]  [80/1724] loss: 4.027, ave_loss: 3.795
[6]  [100/1724] loss: 3.545, ave_loss: 3.753
[7]  [120/1724] loss: 3.117, ave_loss: 3.662
[8]  [140/1724] loss: 3.952, ave_loss: 3.698
[9]  [160/1724] loss: 3.088, ave_loss: 3.631
[10]  [180/1724] loss: 3.834, ave_loss: 3.651
[11]  [200/1724] loss: 3.856, ave_loss: 3.670
[12]  [220/1724] loss: 3.195, ave_loss: 3.630
[13]  [240/1724] loss: 4.152, ave_loss: 3.670
[14]  [260/1724] loss: 4.008, ave_loss: 3.694
[15]  [280/1724] loss: 3.732, ave_loss: 3.697
[16]  [300/1724] loss: 4.120, ave_loss: 3.723
[17]  [320/1724] loss: 2.280, ave_loss: 3.638
[18]  [340/1724] loss: 4.103, ave_loss: 3.664
[19]  [360/1724] loss: 2.858, ave_loss: 3.622
[20]  [380/1724] loss: 3.013, ave_loss: 3.591
[21]  [400/1724] loss: 3.134, ave_loss: 3.570
[22]  [420/1724] loss: 2.847, ave_loss: 3.537
[23]  [440/1724] loss: 3.132, ave_loss: 3.519
[24]  [460/1724] loss: 3.210, ave_loss: 3.506
[25]  [480/1724] loss: 3.112, ave_loss: 3.490
[26]  [500/1724] loss: 2.674, ave_loss: 3.459
[27]  [520/1724] loss: 3.359, ave_loss: 3.455
[28]  [540/1724] loss: 2.215, ave_loss: 3.411
[29]  [560/1724] loss: 3.246, ave_loss: 3.405
[30]  [580/1724] loss: 2.410, ave_loss: 3.372
[31]  [600/1724] loss: 2.695, ave_loss: 3.350
[32]  [620/1724] loss: 2.349, ave_loss: 3.319
[33]  [640/1724] loss: 2.337, ave_loss: 3.289
[34]  [660/1724] loss: 3.113, ave_loss: 3.284
[35]  [680/1724] loss: 2.650, ave_loss: 3.266
[36]  [700/1724] loss: 3.322, ave_loss: 3.267
[37]  [720/1724] loss: 2.478, ave_loss: 3.246
[38]  [740/1724] loss: 1.970, ave_loss: 3.213
[39]  [760/1724] loss: 3.216, ave_loss: 3.213
[40]  [780/1724] loss: 2.514, ave_loss: 3.195
[41]  [800/1724] loss: 3.293, ave_loss: 3.198
[42]  [820/1724] loss: 2.178, ave_loss: 3.173
[43]  [840/1724] loss: 2.539, ave_loss: 3.159
[44]  [860/1724] loss: 2.049, ave_loss: 3.133
[45]  [880/1724] loss: 2.445, ave_loss: 3.118
[46]  [900/1724] loss: 2.622, ave_loss: 3.107
[47]  [920/1724] loss: 2.343, ave_loss: 3.091
[48]  [940/1724] loss: 2.155, ave_loss: 3.071
[49]  [960/1724] loss: 1.723, ave_loss: 3.044
[50]  [980/1724] loss: 2.925, ave_loss: 3.042
[51]  [1000/1724] loss: 2.419, ave_loss: 3.029
[52]  [1020/1724] loss: 2.352, ave_loss: 3.016
[53]  [1040/1724] loss: 2.633, ave_loss: 3.009
[54]  [1060/1724] loss: 1.995, ave_loss: 2.990
[55]  [1080/1724] loss: 1.792, ave_loss: 2.969
[56]  [1100/1724] loss: 1.880, ave_loss: 2.949
[57]  [1120/1724] loss: 2.052, ave_loss: 2.933
[58]  [1140/1724] loss: 2.778, ave_loss: 2.931
[59]  [1160/1724] loss: 2.006, ave_loss: 2.915
[60]  [1180/1724] loss: 1.833, ave_loss: 2.897
[61]  [1200/1724] loss: 2.059, ave_loss: 2.883
[62]  [1220/1724] loss: 2.093, ave_loss: 2.871
[63]  [1240/1724] loss: 1.917, ave_loss: 2.855
[64]  [1260/1724] loss: 2.212, ave_loss: 2.845
[65]  [1280/1724] loss: 2.189, ave_loss: 2.835
[66]  [1300/1724] loss: 2.234, ave_loss: 2.826
[67]  [1320/1724] loss: 2.310, ave_loss: 2.818
[68]  [1340/1724] loss: 1.817, ave_loss: 2.804
[69]  [1360/1724] loss: 1.655, ave_loss: 2.787
[70]  [1380/1724] loss: 1.745, ave_loss: 2.772
[71]  [1400/1724] loss: 1.965, ave_loss: 2.761
[72]  [1420/1724] loss: 1.734, ave_loss: 2.747
[73]  [1440/1724] loss: 1.826, ave_loss: 2.734
[74]  [1460/1724] loss: 1.695, ave_loss: 2.720
[75]  [1480/1724] loss: 1.845, ave_loss: 2.708
[76]  [1500/1724] loss: 1.911, ave_loss: 2.698
[77]  [1520/1724] loss: 1.755, ave_loss: 2.686
[78]  [1540/1724] loss: 1.527, ave_loss: 2.671
[79]  [1560/1724] loss: 1.687, ave_loss: 2.658
[80]  [1580/1724] loss: 1.843, ave_loss: 2.648
[81]  [1600/1724] loss: 1.453, ave_loss: 2.633
[82]  [1620/1724] loss: 1.736, ave_loss: 2.622
[83]  [1640/1724] loss: 1.490, ave_loss: 2.609
[84]  [1660/1724] loss: 1.978, ave_loss: 2.601
[85]  [1680/1724] loss: 1.599, ave_loss: 2.589
[86]  [1700/1724] loss: 1.622, ave_loss: 2.578
[87]  [1720/1724] loss: 1.340, ave_loss: 2.564
[88]  [1740/1724] loss: 1.318, ave_loss: 2.550

Finished Training finishing at 2021-08-24 21:53:16.986346
printing_out epoch  1.0208816705336428 learning rate: 0.0005153561248318907
0.000499895441086934
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 2.550e+00
Validation Loss: 1.797e+00
Validation ROC: 0.5283
Saving model
97.97911832946636 epochs left to go

Training Epoch 1.0208816705336428/100 starting at 2021-08-24 21:55:32.581222
[1]  [0/1724] loss: 1.628, ave_loss: 1.628
[2]  [20/1724] loss: 1.548, ave_loss: 1.588
[3]  [40/1724] loss: 1.366, ave_loss: 1.514
[4]  [60/1724] loss: 1.223, ave_loss: 1.441
[5]  [80/1724] loss: 1.551, ave_loss: 1.463
[6]  [100/1724] loss: 1.231, ave_loss: 1.425
[7]  [120/1724] loss: 1.352, ave_loss: 1.414
[8]  [140/1724] loss: 1.803, ave_loss: 1.463
[9]  [160/1724] loss: 1.099, ave_loss: 1.423
[10]  [180/1724] loss: 1.443, ave_loss: 1.425
[11]  [200/1724] loss: 1.536, ave_loss: 1.435
[12]  [220/1724] loss: 1.309, ave_loss: 1.424
[13]  [240/1724] loss: 1.456, ave_loss: 1.427
[14]  [260/1724] loss: 1.074, ave_loss: 1.401
[15]  [280/1724] loss: 1.158, ave_loss: 1.385
[16]  [300/1724] loss: 1.270, ave_loss: 1.378
[17]  [320/1724] loss: 1.380, ave_loss: 1.378
[18]  [340/1724] loss: 1.321, ave_loss: 1.375
[19]  [360/1724] loss: 1.201, ave_loss: 1.366
[20]  [380/1724] loss: 0.866, ave_loss: 1.341
[21]  [400/1724] loss: 0.935, ave_loss: 1.322
[22]  [420/1724] loss: 0.973, ave_loss: 1.306
[23]  [440/1724] loss: 1.056, ave_loss: 1.295
[24]  [460/1724] loss: 1.169, ave_loss: 1.290
[25]  [480/1724] loss: 1.106, ave_loss: 1.282
[26]  [500/1724] loss: 1.121, ave_loss: 1.276
[27]  [520/1724] loss: 0.931, ave_loss: 1.263
[28]  [540/1724] loss: 0.844, ave_loss: 1.248
[29]  [560/1724] loss: 1.026, ave_loss: 1.241
[30]  [580/1724] loss: 0.856, ave_loss: 1.228
[31]  [600/1724] loss: 1.103, ave_loss: 1.224
[32]  [620/1724] loss: 1.002, ave_loss: 1.217
[33]  [640/1724] loss: 0.834, ave_loss: 1.205
[34]  [660/1724] loss: 0.924, ave_loss: 1.197
[35]  [680/1724] loss: 0.920, ave_loss: 1.189
[36]  [700/1724] loss: 0.903, ave_loss: 1.181
[37]  [720/1724] loss: 0.870, ave_loss: 1.173
[38]  [740/1724] loss: 0.791, ave_loss: 1.163
[39]  [760/1724] loss: 0.963, ave_loss: 1.158
[40]  [780/1724] loss: 0.819, ave_loss: 1.149
[41]  [800/1724] loss: 1.037, ave_loss: 1.146
[42]  [820/1724] loss: 0.873, ave_loss: 1.140
[43]  [840/1724] loss: 0.930, ave_loss: 1.135
[44]  [860/1724] loss: 0.967, ave_loss: 1.131
[45]  [880/1724] loss: 0.782, ave_loss: 1.123
[46]  [900/1724] loss: 0.958, ave_loss: 1.120
[47]  [920/1724] loss: 0.867, ave_loss: 1.114
[48]  [940/1724] loss: 0.955, ave_loss: 1.111
[49]  [960/1724] loss: 0.928, ave_loss: 1.107
[50]  [980/1724] loss: 0.807, ave_loss: 1.101
[51]  [1000/1724] loss: 0.991, ave_loss: 1.099
[52]  [1020/1724] loss: 0.830, ave_loss: 1.094
[53]  [1040/1724] loss: 0.924, ave_loss: 1.091
[54]  [1060/1724] loss: 0.921, ave_loss: 1.088
[55]  [1080/1724] loss: 0.798, ave_loss: 1.082
[56]  [1100/1724] loss: 1.051, ave_loss: 1.082
[57]  [1120/1724] loss: 0.773, ave_loss: 1.076
[58]  [1140/1724] loss: 0.990, ave_loss: 1.075
[59]  [1160/1724] loss: 0.757, ave_loss: 1.070
[60]  [1180/1724] loss: 1.006, ave_loss: 1.068
[61]  [1200/1724] loss: 0.684, ave_loss: 1.062
[62]  [1220/1724] loss: 0.782, ave_loss: 1.058
[63]  [1240/1724] loss: 0.863, ave_loss: 1.055
[64]  [1260/1724] loss: 0.623, ave_loss: 1.048
[65]  [1280/1724] loss: 0.808, ave_loss: 1.044
[66]  [1300/1724] loss: 0.892, ave_loss: 1.042
[67]  [1320/1724] loss: 0.970, ave_loss: 1.041
[68]  [1340/1724] loss: 0.831, ave_loss: 1.038
[69]  [1360/1724] loss: 0.723, ave_loss: 1.033
[70]  [1380/1724] loss: 1.014, ave_loss: 1.033
[71]  [1400/1724] loss: 1.018, ave_loss: 1.033
[72]  [1420/1724] loss: 0.928, ave_loss: 1.031
[73]  [1440/1724] loss: 0.885, ave_loss: 1.029
[74]  [1460/1724] loss: 0.688, ave_loss: 1.025
[75]  [1480/1724] loss: 0.826, ave_loss: 1.022
[76]  [1500/1724] loss: 0.794, ave_loss: 1.019
[77]  [1520/1724] loss: 1.030, ave_loss: 1.019
[78]  [1540/1724] loss: 0.817, ave_loss: 1.016
[79]  [1560/1724] loss: 0.838, ave_loss: 1.014
[80]  [1580/1724] loss: 0.819, ave_loss: 1.012
[81]  [1600/1724] loss: 0.820, ave_loss: 1.009
[82]  [1620/1724] loss: 0.834, ave_loss: 1.007
[83]  [1640/1724] loss: 0.733, ave_loss: 1.004
[84]  [1660/1724] loss: 0.806, ave_loss: 1.002
[85]  [1680/1724] loss: 0.755, ave_loss: 0.999
[86]  [1700/1724] loss: 0.736, ave_loss: 0.996
[87]  [1720/1724] loss: 0.997, ave_loss: 0.996
[88]  [1740/1724] loss: 0.960, ave_loss: 0.995

Finished Training finishing at 2021-08-24 21:57:39.035216
printing_out epoch  2.0417633410672855 learning rate: 0.0005153561248318907
0.00048489857785432596
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 9.953e-01
Validation Loss: 7.163e-01
Validation ROC: 0.5318
Saving model
96.95823665893272 epochs left to go

Training Epoch 2.0417633410672855/100 starting at 2021-08-24 21:58:05.491479
[1]  [0/1724] loss: 0.724, ave_loss: 0.724
[2]  [20/1724] loss: 0.692, ave_loss: 0.708
[3]  [40/1724] loss: 0.651, ave_loss: 0.689
[4]  [60/1724] loss: 0.723, ave_loss: 0.698
[5]  [80/1724] loss: 0.908, ave_loss: 0.740
[6]  [100/1724] loss: 0.862, ave_loss: 0.760
[7]  [120/1724] loss: 0.806, ave_loss: 0.767
[8]  [140/1724] loss: 0.638, ave_loss: 0.751
[9]  [160/1724] loss: 0.691, ave_loss: 0.744
[10]  [180/1724] loss: 0.724, ave_loss: 0.742
[11]  [200/1724] loss: 0.787, ave_loss: 0.746
[12]  [220/1724] loss: 0.751, ave_loss: 0.746
[13]  [240/1724] loss: 0.788, ave_loss: 0.750
[14]  [260/1724] loss: 0.711, ave_loss: 0.747
[15]  [280/1724] loss: 0.715, ave_loss: 0.745
[16]  [300/1724] loss: 0.871, ave_loss: 0.753
[17]  [320/1724] loss: 0.824, ave_loss: 0.757
[18]  [340/1724] loss: 0.802, ave_loss: 0.759
[19]  [360/1724] loss: 0.900, ave_loss: 0.767
[20]  [380/1724] loss: 0.856, ave_loss: 0.771
[21]  [400/1724] loss: 0.861, ave_loss: 0.775
[22]  [420/1724] loss: 0.675, ave_loss: 0.771
[23]  [440/1724] loss: 0.685, ave_loss: 0.767
[24]  [460/1724] loss: 0.909, ave_loss: 0.773
[25]  [480/1724] loss: 0.840, ave_loss: 0.776
[26]  [500/1724] loss: 0.579, ave_loss: 0.768
[27]  [520/1724] loss: 0.758, ave_loss: 0.768
[28]  [540/1724] loss: 0.658, ave_loss: 0.764
[29]  [560/1724] loss: 0.856, ave_loss: 0.767
[30]  [580/1724] loss: 0.921, ave_loss: 0.772
[31]  [600/1724] loss: 0.812, ave_loss: 0.774
[32]  [620/1724] loss: 0.809, ave_loss: 0.775
[33]  [640/1724] loss: 0.706, ave_loss: 0.773
[34]  [660/1724] loss: 0.781, ave_loss: 0.773
[35]  [680/1724] loss: 0.929, ave_loss: 0.777
[36]  [700/1724] loss: 0.918, ave_loss: 0.781
[37]  [720/1724] loss: 0.838, ave_loss: 0.783
[38]  [740/1724] loss: 0.801, ave_loss: 0.783
[39]  [760/1724] loss: 0.695, ave_loss: 0.781
[40]  [780/1724] loss: 0.634, ave_loss: 0.777
[41]  [800/1724] loss: 0.922, ave_loss: 0.781
[42]  [820/1724] loss: 0.787, ave_loss: 0.781
[43]  [840/1724] loss: 0.868, ave_loss: 0.783
[44]  [860/1724] loss: 0.855, ave_loss: 0.785
[45]  [880/1724] loss: 0.864, ave_loss: 0.786
[46]  [900/1724] loss: 0.624, ave_loss: 0.783
[47]  [920/1724] loss: 0.733, ave_loss: 0.782
[48]  [940/1724] loss: 0.770, ave_loss: 0.782
[49]  [960/1724] loss: 0.762, ave_loss: 0.781
[50]  [980/1724] loss: 0.739, ave_loss: 0.780
[51]  [1000/1724] loss: 0.801, ave_loss: 0.781
[52]  [1020/1724] loss: 0.743, ave_loss: 0.780
[53]  [1040/1724] loss: 0.835, ave_loss: 0.781
[54]  [1060/1724] loss: 0.740, ave_loss: 0.780
[55]  [1080/1724] loss: 0.735, ave_loss: 0.779
[56]  [1100/1724] loss: 0.898, ave_loss: 0.782
[57]  [1120/1724] loss: 0.594, ave_loss: 0.778
[58]  [1140/1724] loss: 0.824, ave_loss: 0.779
[59]  [1160/1724] loss: 0.770, ave_loss: 0.779
[60]  [1180/1724] loss: 0.769, ave_loss: 0.779
[61]  [1200/1724] loss: 0.702, ave_loss: 0.777
[62]  [1220/1724] loss: 0.687, ave_loss: 0.776
[63]  [1240/1724] loss: 0.751, ave_loss: 0.776
[64]  [1260/1724] loss: 0.681, ave_loss: 0.774
[65]  [1280/1724] loss: 0.697, ave_loss: 0.773
[66]  [1300/1724] loss: 0.691, ave_loss: 0.772
[67]  [1320/1724] loss: 0.621, ave_loss: 0.769
[68]  [1340/1724] loss: 0.834, ave_loss: 0.770
[69]  [1360/1724] loss: 0.801, ave_loss: 0.771
[70]  [1380/1724] loss: 0.638, ave_loss: 0.769
[71]  [1400/1724] loss: 0.853, ave_loss: 0.770
[72]  [1420/1724] loss: 0.938, ave_loss: 0.772
[73]  [1440/1724] loss: 0.705, ave_loss: 0.772
[74]  [1460/1724] loss: 0.731, ave_loss: 0.771
[75]  [1480/1724] loss: 0.679, ave_loss: 0.770
[76]  [1500/1724] loss: 0.640, ave_loss: 0.768
[77]  [1520/1724] loss: 0.690, ave_loss: 0.767
[78]  [1540/1724] loss: 0.882, ave_loss: 0.769
[79]  [1560/1724] loss: 0.842, ave_loss: 0.769
[80]  [1580/1724] loss: 0.787, ave_loss: 0.770
[81]  [1600/1724] loss: 0.890, ave_loss: 0.771
[82]  [1620/1724] loss: 0.873, ave_loss: 0.772
[83]  [1640/1724] loss: 0.690, ave_loss: 0.771
[84]  [1660/1724] loss: 0.730, ave_loss: 0.771
[85]  [1680/1724] loss: 0.648, ave_loss: 0.769
[86]  [1700/1724] loss: 0.790, ave_loss: 0.770
[87]  [1720/1724] loss: 0.717, ave_loss: 0.769
[88]  [1740/1724] loss: 0.749, ave_loss: 0.769

Finished Training finishing at 2021-08-24 21:59:49.829814
printing_out epoch  3.062645011600928 learning rate: 0.0005153561248318907
0.00047035162051869614
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.689e-01
Validation Loss: 6.668e-01
Validation ROC: 0.5342
Saving model
95.93735498839908 epochs left to go

Training Epoch 3.062645011600928/100 starting at 2021-08-24 22:00:16.191967
[1]  [0/1724] loss: 0.646, ave_loss: 0.646
[2]  [20/1724] loss: 0.702, ave_loss: 0.674
[3]  [40/1724] loss: 0.664, ave_loss: 0.671
[4]  [60/1724] loss: 1.010, ave_loss: 0.755
[5]  [80/1724] loss: 0.727, ave_loss: 0.750
[6]  [100/1724] loss: 0.739, ave_loss: 0.748
[7]  [120/1724] loss: 0.557, ave_loss: 0.721
[8]  [140/1724] loss: 0.703, ave_loss: 0.718
[9]  [160/1724] loss: 0.800, ave_loss: 0.728
[10]  [180/1724] loss: 0.738, ave_loss: 0.729
[11]  [200/1724] loss: 0.805, ave_loss: 0.736
[12]  [220/1724] loss: 0.688, ave_loss: 0.732
[13]  [240/1724] loss: 0.912, ave_loss: 0.745
[14]  [260/1724] loss: 0.788, ave_loss: 0.749
[15]  [280/1724] loss: 0.730, ave_loss: 0.747
[16]  [300/1724] loss: 0.782, ave_loss: 0.749
[17]  [320/1724] loss: 0.668, ave_loss: 0.745
[18]  [340/1724] loss: 0.759, ave_loss: 0.745
[19]  [360/1724] loss: 0.707, ave_loss: 0.743
[20]  [380/1724] loss: 0.741, ave_loss: 0.743
[21]  [400/1724] loss: 0.903, ave_loss: 0.751
[22]  [420/1724] loss: 0.646, ave_loss: 0.746
[23]  [440/1724] loss: 0.727, ave_loss: 0.745
[24]  [460/1724] loss: 0.785, ave_loss: 0.747
[25]  [480/1724] loss: 0.659, ave_loss: 0.743
[26]  [500/1724] loss: 0.779, ave_loss: 0.745
[27]  [520/1724] loss: 0.745, ave_loss: 0.745
[28]  [540/1724] loss: 0.887, ave_loss: 0.750
[29]  [560/1724] loss: 0.780, ave_loss: 0.751
[30]  [580/1724] loss: 0.719, ave_loss: 0.750
[31]  [600/1724] loss: 0.718, ave_loss: 0.749
[32]  [620/1724] loss: 0.877, ave_loss: 0.753
[33]  [640/1724] loss: 0.697, ave_loss: 0.751
[34]  [660/1724] loss: 0.632, ave_loss: 0.748
[35]  [680/1724] loss: 0.706, ave_loss: 0.746
[36]  [700/1724] loss: 0.807, ave_loss: 0.748
[37]  [720/1724] loss: 0.660, ave_loss: 0.746
[38]  [740/1724] loss: 0.771, ave_loss: 0.746
[39]  [760/1724] loss: 0.753, ave_loss: 0.747
[40]  [780/1724] loss: 0.740, ave_loss: 0.746
[41]  [800/1724] loss: 0.798, ave_loss: 0.748
[42]  [820/1724] loss: 0.719, ave_loss: 0.747
[43]  [840/1724] loss: 0.694, ave_loss: 0.746
[44]  [860/1724] loss: 0.826, ave_loss: 0.748
[45]  [880/1724] loss: 0.696, ave_loss: 0.746
[46]  [900/1724] loss: 0.748, ave_loss: 0.747
[47]  [920/1724] loss: 0.741, ave_loss: 0.746
[48]  [940/1724] loss: 0.944, ave_loss: 0.751
[49]  [960/1724] loss: 0.847, ave_loss: 0.752
[50]  [980/1724] loss: 0.657, ave_loss: 0.751
[51]  [1000/1724] loss: 0.627, ave_loss: 0.748
[52]  [1020/1724] loss: 0.573, ave_loss: 0.745
[53]  [1040/1724] loss: 0.757, ave_loss: 0.745
[54]  [1060/1724] loss: 0.566, ave_loss: 0.742
[55]  [1080/1724] loss: 0.660, ave_loss: 0.740
[56]  [1100/1724] loss: 0.621, ave_loss: 0.738
[57]  [1120/1724] loss: 0.810, ave_loss: 0.739
[58]  [1140/1724] loss: 0.768, ave_loss: 0.740
[59]  [1160/1724] loss: 0.684, ave_loss: 0.739
[60]  [1180/1724] loss: 0.934, ave_loss: 0.742
[61]  [1200/1724] loss: 0.727, ave_loss: 0.742
[62]  [1220/1724] loss: 0.741, ave_loss: 0.742
[63]  [1240/1724] loss: 0.695, ave_loss: 0.741
[64]  [1260/1724] loss: 0.683, ave_loss: 0.740
[65]  [1280/1724] loss: 0.670, ave_loss: 0.739
[66]  [1300/1724] loss: 0.737, ave_loss: 0.739
[67]  [1320/1724] loss: 0.677, ave_loss: 0.738
[68]  [1340/1724] loss: 0.647, ave_loss: 0.737
[69]  [1360/1724] loss: 0.873, ave_loss: 0.739
[70]  [1380/1724] loss: 0.681, ave_loss: 0.738
[71]  [1400/1724] loss: 0.582, ave_loss: 0.736
[72]  [1420/1724] loss: 0.695, ave_loss: 0.735
[73]  [1440/1724] loss: 0.609, ave_loss: 0.734
[74]  [1460/1724] loss: 0.779, ave_loss: 0.734
[75]  [1480/1724] loss: 0.849, ave_loss: 0.736
[76]  [1500/1724] loss: 0.905, ave_loss: 0.738
[77]  [1520/1724] loss: 0.751, ave_loss: 0.738
[78]  [1540/1724] loss: 0.742, ave_loss: 0.738
[79]  [1560/1724] loss: 0.750, ave_loss: 0.738
[80]  [1580/1724] loss: 0.886, ave_loss: 0.740
[81]  [1600/1724] loss: 0.757, ave_loss: 0.740
[82]  [1620/1724] loss: 0.765, ave_loss: 0.741
[83]  [1640/1724] loss: 0.735, ave_loss: 0.741
[84]  [1660/1724] loss: 0.708, ave_loss: 0.740
[85]  [1680/1724] loss: 0.775, ave_loss: 0.741
[86]  [1700/1724] loss: 0.637, ave_loss: 0.739
[87]  [1720/1724] loss: 0.718, ave_loss: 0.739
[88]  [1740/1724] loss: 0.533, ave_loss: 0.737

Finished Training finishing at 2021-08-24 22:02:12.119582
printing_out epoch  4.083526682134571 learning rate: 0.0005153561248318907
0.00045624107190313527
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.368e-01
Validation Loss: 6.372e-01
Validation ROC: 0.5318
No improvement, still saving model
94.91647331786542 epochs left to go

Training Epoch 4.083526682134571/100 starting at 2021-08-24 22:02:39.363993
[1]  [0/1724] loss: 0.686, ave_loss: 0.686
[2]  [20/1724] loss: 0.963, ave_loss: 0.825
[3]  [40/1724] loss: 0.759, ave_loss: 0.803
[4]  [60/1724] loss: 0.647, ave_loss: 0.764
[5]  [80/1724] loss: 0.806, ave_loss: 0.772
[6]  [100/1724] loss: 0.864, ave_loss: 0.787
[7]  [120/1724] loss: 0.692, ave_loss: 0.774
[8]  [140/1724] loss: 0.777, ave_loss: 0.774
[9]  [160/1724] loss: 0.697, ave_loss: 0.766
[10]  [180/1724] loss: 0.822, ave_loss: 0.771
[11]  [200/1724] loss: 0.797, ave_loss: 0.774
[12]  [220/1724] loss: 0.995, ave_loss: 0.792
[13]  [240/1724] loss: 0.739, ave_loss: 0.788
[14]  [260/1724] loss: 0.605, ave_loss: 0.775
[15]  [280/1724] loss: 0.679, ave_loss: 0.768
[16]  [300/1724] loss: 0.864, ave_loss: 0.774
[17]  [320/1724] loss: 0.660, ave_loss: 0.768
[18]  [340/1724] loss: 0.670, ave_loss: 0.762
[19]  [360/1724] loss: 0.701, ave_loss: 0.759
[20]  [380/1724] loss: 0.664, ave_loss: 0.754
[21]  [400/1724] loss: 0.702, ave_loss: 0.752
[22]  [420/1724] loss: 0.639, ave_loss: 0.747
[23]  [440/1724] loss: 0.827, ave_loss: 0.750
[24]  [460/1724] loss: 0.780, ave_loss: 0.751
[25]  [480/1724] loss: 0.717, ave_loss: 0.750
[26]  [500/1724] loss: 0.684, ave_loss: 0.747
[27]  [520/1724] loss: 0.640, ave_loss: 0.743
[28]  [540/1724] loss: 0.853, ave_loss: 0.747
[29]  [560/1724] loss: 0.804, ave_loss: 0.749
[30]  [580/1724] loss: 0.633, ave_loss: 0.745
[31]  [600/1724] loss: 0.669, ave_loss: 0.743
[32]  [620/1724] loss: 0.631, ave_loss: 0.739
[33]  [640/1724] loss: 0.622, ave_loss: 0.736
[34]  [660/1724] loss: 0.664, ave_loss: 0.734
[35]  [680/1724] loss: 0.710, ave_loss: 0.733
[36]  [700/1724] loss: 0.792, ave_loss: 0.735
[37]  [720/1724] loss: 0.597, ave_loss: 0.731
[38]  [740/1724] loss: 0.794, ave_loss: 0.733
[39]  [760/1724] loss: 0.817, ave_loss: 0.735
[40]  [780/1724] loss: 0.857, ave_loss: 0.738
[41]  [800/1724] loss: 0.719, ave_loss: 0.737
[42]  [820/1724] loss: 0.842, ave_loss: 0.740
[43]  [840/1724] loss: 0.672, ave_loss: 0.738
[44]  [860/1724] loss: 0.683, ave_loss: 0.737
[45]  [880/1724] loss: 0.631, ave_loss: 0.735
[46]  [900/1724] loss: 0.683, ave_loss: 0.734
[47]  [920/1724] loss: 0.598, ave_loss: 0.731
[48]  [940/1724] loss: 0.728, ave_loss: 0.731
[49]  [960/1724] loss: 0.649, ave_loss: 0.729
[50]  [980/1724] loss: 0.668, ave_loss: 0.728
[51]  [1000/1724] loss: 0.607, ave_loss: 0.725
[52]  [1020/1724] loss: 0.836, ave_loss: 0.728
[53]  [1040/1724] loss: 0.743, ave_loss: 0.728
[54]  [1060/1724] loss: 0.726, ave_loss: 0.728
[55]  [1080/1724] loss: 0.741, ave_loss: 0.728
[56]  [1100/1724] loss: 0.623, ave_loss: 0.726
[57]  [1120/1724] loss: 0.663, ave_loss: 0.725
[58]  [1140/1724] loss: 0.578, ave_loss: 0.723
[59]  [1160/1724] loss: 0.879, ave_loss: 0.725
[60]  [1180/1724] loss: 0.849, ave_loss: 0.727
[61]  [1200/1724] loss: 0.611, ave_loss: 0.725
[62]  [1220/1724] loss: 0.857, ave_loss: 0.727
[63]  [1240/1724] loss: 0.841, ave_loss: 0.729
[64]  [1260/1724] loss: 0.745, ave_loss: 0.730
[65]  [1280/1724] loss: 0.658, ave_loss: 0.728
[66]  [1300/1724] loss: 0.739, ave_loss: 0.729
[67]  [1320/1724] loss: 0.788, ave_loss: 0.729
[68]  [1340/1724] loss: 0.654, ave_loss: 0.728
[69]  [1360/1724] loss: 0.587, ave_loss: 0.726
[70]  [1380/1724] loss: 0.621, ave_loss: 0.725
[71]  [1400/1724] loss: 0.683, ave_loss: 0.724
[72]  [1420/1724] loss: 0.783, ave_loss: 0.725
[73]  [1440/1724] loss: 0.710, ave_loss: 0.725
[74]  [1460/1724] loss: 0.789, ave_loss: 0.726
[75]  [1480/1724] loss: 0.755, ave_loss: 0.726
[76]  [1500/1724] loss: 0.751, ave_loss: 0.726
[77]  [1520/1724] loss: 0.667, ave_loss: 0.726
[78]  [1540/1724] loss: 0.760, ave_loss: 0.726
[79]  [1560/1724] loss: 0.655, ave_loss: 0.725
[80]  [1580/1724] loss: 0.752, ave_loss: 0.726
[81]  [1600/1724] loss: 0.640, ave_loss: 0.724
[82]  [1620/1724] loss: 0.676, ave_loss: 0.724
[83]  [1640/1724] loss: 0.884, ave_loss: 0.726
[84]  [1660/1724] loss: 0.711, ave_loss: 0.726
[85]  [1680/1724] loss: 0.698, ave_loss: 0.725
[86]  [1700/1724] loss: 0.704, ave_loss: 0.725
[87]  [1720/1724] loss: 0.636, ave_loss: 0.724
[88]  [1740/1724] loss: 0.651, ave_loss: 0.723

Finished Training finishing at 2021-08-24 22:04:29.909951
printing_out epoch  5.104408352668213 learning rate: 0.0005153561248318907
0.0004425538397460412
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.232e-01
Validation Loss: 6.077e-01
Validation ROC: 0.5328
No improvement, still saving model
93.89559164733178 epochs left to go

Training Epoch 5.104408352668213/100 starting at 2021-08-24 22:04:58.048452
[1]  [0/1724] loss: 0.829, ave_loss: 0.829
[2]  [20/1724] loss: 0.578, ave_loss: 0.703
[3]  [40/1724] loss: 0.692, ave_loss: 0.700
[4]  [60/1724] loss: 0.569, ave_loss: 0.667
[5]  [80/1724] loss: 0.758, ave_loss: 0.685
[6]  [100/1724] loss: 0.987, ave_loss: 0.735
[7]  [120/1724] loss: 0.720, ave_loss: 0.733
[8]  [140/1724] loss: 0.776, ave_loss: 0.739
[9]  [160/1724] loss: 0.619, ave_loss: 0.725
[10]  [180/1724] loss: 0.663, ave_loss: 0.719
[11]  [200/1724] loss: 0.782, ave_loss: 0.725
[12]  [220/1724] loss: 0.574, ave_loss: 0.712
[13]  [240/1724] loss: 0.752, ave_loss: 0.715
[14]  [260/1724] loss: 0.833, ave_loss: 0.724
[15]  [280/1724] loss: 0.563, ave_loss: 0.713
[16]  [300/1724] loss: 0.587, ave_loss: 0.705
[17]  [320/1724] loss: 0.680, ave_loss: 0.704
[18]  [340/1724] loss: 0.894, ave_loss: 0.714
[19]  [360/1724] loss: 0.675, ave_loss: 0.712
[20]  [380/1724] loss: 0.623, ave_loss: 0.708
[21]  [400/1724] loss: 0.847, ave_loss: 0.714
[22]  [420/1724] loss: 0.772, ave_loss: 0.717
[23]  [440/1724] loss: 0.736, ave_loss: 0.718
[24]  [460/1724] loss: 0.613, ave_loss: 0.713
[25]  [480/1724] loss: 0.930, ave_loss: 0.722
[26]  [500/1724] loss: 0.853, ave_loss: 0.727
[27]  [520/1724] loss: 0.840, ave_loss: 0.731
[28]  [540/1724] loss: 0.731, ave_loss: 0.731
[29]  [560/1724] loss: 0.832, ave_loss: 0.735
[30]  [580/1724] loss: 0.778, ave_loss: 0.736
[31]  [600/1724] loss: 0.776, ave_loss: 0.737
[32]  [620/1724] loss: 0.706, ave_loss: 0.736
[33]  [640/1724] loss: 0.706, ave_loss: 0.736
[34]  [660/1724] loss: 0.818, ave_loss: 0.738
[35]  [680/1724] loss: 0.603, ave_loss: 0.734
[36]  [700/1724] loss: 0.691, ave_loss: 0.733
[37]  [720/1724] loss: 0.742, ave_loss: 0.733
[38]  [740/1724] loss: 0.749, ave_loss: 0.734
[39]  [760/1724] loss: 0.672, ave_loss: 0.732
[40]  [780/1724] loss: 0.712, ave_loss: 0.732
[41]  [800/1724] loss: 0.599, ave_loss: 0.728
[42]  [820/1724] loss: 0.778, ave_loss: 0.730
[43]  [840/1724] loss: 0.787, ave_loss: 0.731
[44]  [860/1724] loss: 0.680, ave_loss: 0.730
[45]  [880/1724] loss: 0.581, ave_loss: 0.726
[46]  [900/1724] loss: 0.760, ave_loss: 0.727
[47]  [920/1724] loss: 0.720, ave_loss: 0.727
[48]  [940/1724] loss: 0.691, ave_loss: 0.726
[49]  [960/1724] loss: 0.831, ave_loss: 0.728
[50]  [980/1724] loss: 0.741, ave_loss: 0.729
[51]  [1000/1724] loss: 0.616, ave_loss: 0.726
[52]  [1020/1724] loss: 0.637, ave_loss: 0.725
[53]  [1040/1724] loss: 0.581, ave_loss: 0.722
[54]  [1060/1724] loss: 0.688, ave_loss: 0.721
[55]  [1080/1724] loss: 0.778, ave_loss: 0.722
[56]  [1100/1724] loss: 0.764, ave_loss: 0.723
[57]  [1120/1724] loss: 0.708, ave_loss: 0.723
[58]  [1140/1724] loss: 0.679, ave_loss: 0.722
[59]  [1160/1724] loss: 0.731, ave_loss: 0.722
[60]  [1180/1724] loss: 0.741, ave_loss: 0.723
[61]  [1200/1724] loss: 0.708, ave_loss: 0.722
[62]  [1220/1724] loss: 0.710, ave_loss: 0.722
[63]  [1240/1724] loss: 0.675, ave_loss: 0.721
[64]  [1260/1724] loss: 0.646, ave_loss: 0.720
[65]  [1280/1724] loss: 0.695, ave_loss: 0.720
[66]  [1300/1724] loss: 0.673, ave_loss: 0.719
[67]  [1320/1724] loss: 0.541, ave_loss: 0.716
[68]  [1340/1724] loss: 0.668, ave_loss: 0.716
[69]  [1360/1724] loss: 0.603, ave_loss: 0.714
[70]  [1380/1724] loss: 0.702, ave_loss: 0.714
[71]  [1400/1724] loss: 0.640, ave_loss: 0.713
[72]  [1420/1724] loss: 0.754, ave_loss: 0.713
[73]  [1440/1724] loss: 0.674, ave_loss: 0.713
[74]  [1460/1724] loss: 0.630, ave_loss: 0.712
[75]  [1480/1724] loss: 0.657, ave_loss: 0.711
[76]  [1500/1724] loss: 0.777, ave_loss: 0.712
[77]  [1520/1724] loss: 0.699, ave_loss: 0.712
[78]  [1540/1724] loss: 0.736, ave_loss: 0.712
[79]  [1560/1724] loss: 0.624, ave_loss: 0.711
[80]  [1580/1724] loss: 0.722, ave_loss: 0.711
[81]  [1600/1724] loss: 0.754, ave_loss: 0.712
[82]  [1620/1724] loss: 0.653, ave_loss: 0.711
[83]  [1640/1724] loss: 0.670, ave_loss: 0.710
[84]  [1660/1724] loss: 0.738, ave_loss: 0.711
[85]  [1680/1724] loss: 0.719, ave_loss: 0.711
[86]  [1700/1724] loss: 0.694, ave_loss: 0.711
[87]  [1720/1724] loss: 0.526, ave_loss: 0.709
[88]  [1740/1724] loss: 0.853, ave_loss: 0.710

Finished Training finishing at 2021-08-24 22:06:53.500670
printing_out epoch  6.125290023201856 learning rate: 0.0005153561248318907
0.00042927722455365994
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.102e-01
Validation Loss: 6.031e-01
Validation ROC: 0.5334
No improvement, still saving model
92.87470997679814 epochs left to go

Training Epoch 6.125290023201856/100 starting at 2021-08-24 22:08:54.027747
[1]  [0/1724] loss: 0.735, ave_loss: 0.735
[2]  [20/1724] loss: 0.559, ave_loss: 0.647
[3]  [40/1724] loss: 0.733, ave_loss: 0.676
[4]  [60/1724] loss: 0.858, ave_loss: 0.721
[5]  [80/1724] loss: 0.851, ave_loss: 0.747
[6]  [100/1724] loss: 0.744, ave_loss: 0.747
[7]  [120/1724] loss: 0.582, ave_loss: 0.723
[8]  [140/1724] loss: 0.733, ave_loss: 0.724
[9]  [160/1724] loss: 0.713, ave_loss: 0.723
[10]  [180/1724] loss: 0.602, ave_loss: 0.711
[11]  [200/1724] loss: 0.562, ave_loss: 0.697
[12]  [220/1724] loss: 0.604, ave_loss: 0.690
[13]  [240/1724] loss: 0.721, ave_loss: 0.692
[14]  [260/1724] loss: 0.679, ave_loss: 0.691
[15]  [280/1724] loss: 0.754, ave_loss: 0.695
[16]  [300/1724] loss: 0.685, ave_loss: 0.695
[17]  [320/1724] loss: 0.649, ave_loss: 0.692
[18]  [340/1724] loss: 0.645, ave_loss: 0.689
[19]  [360/1724] loss: 0.717, ave_loss: 0.691
[20]  [380/1724] loss: 0.779, ave_loss: 0.695
[21]  [400/1724] loss: 0.673, ave_loss: 0.694
[22]  [420/1724] loss: 0.595, ave_loss: 0.690
[23]  [440/1724] loss: 0.623, ave_loss: 0.687
[24]  [460/1724] loss: 0.677, ave_loss: 0.686
[25]  [480/1724] loss: 0.666, ave_loss: 0.686
[26]  [500/1724] loss: 0.661, ave_loss: 0.685
[27]  [520/1724] loss: 0.605, ave_loss: 0.682
[28]  [540/1724] loss: 0.744, ave_loss: 0.684
[29]  [560/1724] loss: 0.723, ave_loss: 0.685
[30]  [580/1724] loss: 0.701, ave_loss: 0.686
[31]  [600/1724] loss: 0.595, ave_loss: 0.683
[32]  [620/1724] loss: 0.627, ave_loss: 0.681
[33]  [640/1724] loss: 0.551, ave_loss: 0.677
[34]  [660/1724] loss: 0.748, ave_loss: 0.679
[35]  [680/1724] loss: 0.593, ave_loss: 0.677
[36]  [700/1724] loss: 0.696, ave_loss: 0.677
[37]  [720/1724] loss: 0.680, ave_loss: 0.677
[38]  [740/1724] loss: 0.651, ave_loss: 0.677
[39]  [760/1724] loss: 0.617, ave_loss: 0.675
[40]  [780/1724] loss: 0.741, ave_loss: 0.677
[41]  [800/1724] loss: 0.667, ave_loss: 0.676
[42]  [820/1724] loss: 0.669, ave_loss: 0.676
[43]  [840/1724] loss: 0.675, ave_loss: 0.676
[44]  [860/1724] loss: 0.635, ave_loss: 0.675
[45]  [880/1724] loss: 0.954, ave_loss: 0.682
[46]  [900/1724] loss: 0.652, ave_loss: 0.681
[47]  [920/1724] loss: 0.862, ave_loss: 0.685
[48]  [940/1724] loss: 0.616, ave_loss: 0.683
[49]  [960/1724] loss: 0.748, ave_loss: 0.685
[50]  [980/1724] loss: 0.559, ave_loss: 0.682
[51]  [1000/1724] loss: 0.652, ave_loss: 0.682
[52]  [1020/1724] loss: 0.603, ave_loss: 0.680
[53]  [1040/1724] loss: 0.695, ave_loss: 0.680
[54]  [1060/1724] loss: 0.631, ave_loss: 0.679
[55]  [1080/1724] loss: 0.619, ave_loss: 0.678
[56]  [1100/1724] loss: 0.661, ave_loss: 0.678
[57]  [1120/1724] loss: 0.534, ave_loss: 0.675
[58]  [1140/1724] loss: 0.806, ave_loss: 0.678
[59]  [1160/1724] loss: 0.687, ave_loss: 0.678
[60]  [1180/1724] loss: 0.635, ave_loss: 0.677
[61]  [1200/1724] loss: 0.722, ave_loss: 0.678
[62]  [1220/1724] loss: 0.747, ave_loss: 0.679
[63]  [1240/1724] loss: 0.568, ave_loss: 0.677
[64]  [1260/1724] loss: 0.679, ave_loss: 0.677
[65]  [1280/1724] loss: 0.715, ave_loss: 0.678
[66]  [1300/1724] loss: 0.691, ave_loss: 0.678
[67]  [1320/1724] loss: 0.601, ave_loss: 0.677
[68]  [1340/1724] loss: 0.858, ave_loss: 0.680
[69]  [1360/1724] loss: 0.651, ave_loss: 0.679
[70]  [1380/1724] loss: 0.575, ave_loss: 0.678
[71]  [1400/1724] loss: 0.672, ave_loss: 0.678
[72]  [1420/1724] loss: 0.717, ave_loss: 0.678
[73]  [1440/1724] loss: 0.679, ave_loss: 0.678
[74]  [1460/1724] loss: 0.812, ave_loss: 0.680
[75]  [1480/1724] loss: 0.833, ave_loss: 0.682
[76]  [1500/1724] loss: 0.914, ave_loss: 0.685
[77]  [1520/1724] loss: 0.861, ave_loss: 0.687
[78]  [1540/1724] loss: 0.724, ave_loss: 0.688
[79]  [1560/1724] loss: 0.618, ave_loss: 0.687
[80]  [1580/1724] loss: 0.781, ave_loss: 0.688
[81]  [1600/1724] loss: 0.689, ave_loss: 0.688
[82]  [1620/1724] loss: 0.665, ave_loss: 0.688
[83]  [1640/1724] loss: 0.698, ave_loss: 0.688
[84]  [1660/1724] loss: 0.708, ave_loss: 0.688
[85]  [1680/1724] loss: 0.796, ave_loss: 0.689
[86]  [1700/1724] loss: 0.663, ave_loss: 0.689
[87]  [1720/1724] loss: 0.581, ave_loss: 0.688
[88]  [1740/1724] loss: 0.626, ave_loss: 0.687

Finished Training finishing at 2021-08-24 22:10:53.187705
printing_out epoch  7.146171693735499 learning rate: 0.0005153561248318907
0.0004163989078170501
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.872e-01
Validation Loss: 6.313e-01
Validation ROC: 0.5330
No improvement, still saving model
91.8538283062645 epochs left to go

Training Epoch 7.146171693735499/100 starting at 2021-08-24 22:11:21.284390
[1]  [0/1724] loss: 0.617, ave_loss: 0.617
[2]  [20/1724] loss: 0.606, ave_loss: 0.611
[3]  [40/1724] loss: 0.792, ave_loss: 0.672
[4]  [60/1724] loss: 0.669, ave_loss: 0.671
[5]  [80/1724] loss: 0.628, ave_loss: 0.662
[6]  [100/1724] loss: 0.597, ave_loss: 0.651
[7]  [120/1724] loss: 0.610, ave_loss: 0.645
[8]  [140/1724] loss: 0.661, ave_loss: 0.647
[9]  [160/1724] loss: 0.661, ave_loss: 0.649
[10]  [180/1724] loss: 0.629, ave_loss: 0.647
[11]  [200/1724] loss: 0.579, ave_loss: 0.641
[12]  [220/1724] loss: 0.742, ave_loss: 0.649
[13]  [240/1724] loss: 0.671, ave_loss: 0.651
[14]  [260/1724] loss: 0.843, ave_loss: 0.665
[15]  [280/1724] loss: 0.828, ave_loss: 0.675
[16]  [300/1724] loss: 0.578, ave_loss: 0.669
[17]  [320/1724] loss: 0.856, ave_loss: 0.680
[18]  [340/1724] loss: 0.733, ave_loss: 0.683
[19]  [360/1724] loss: 0.679, ave_loss: 0.683
[20]  [380/1724] loss: 0.586, ave_loss: 0.678
[21]  [400/1724] loss: 0.611, ave_loss: 0.675
[22]  [420/1724] loss: 0.635, ave_loss: 0.673
[23]  [440/1724] loss: 0.789, ave_loss: 0.678
[24]  [460/1724] loss: 0.760, ave_loss: 0.682
[25]  [480/1724] loss: 0.775, ave_loss: 0.685
[26]  [500/1724] loss: 0.827, ave_loss: 0.691
[27]  [520/1724] loss: 0.778, ave_loss: 0.694
[28]  [540/1724] loss: 0.600, ave_loss: 0.691
[29]  [560/1724] loss: 0.645, ave_loss: 0.689
[30]  [580/1724] loss: 0.660, ave_loss: 0.688
[31]  [600/1724] loss: 0.728, ave_loss: 0.689
[32]  [620/1724] loss: 0.675, ave_loss: 0.689
[33]  [640/1724] loss: 0.729, ave_loss: 0.690
[34]  [660/1724] loss: 0.760, ave_loss: 0.692
[35]  [680/1724] loss: 0.647, ave_loss: 0.691
[36]  [700/1724] loss: 0.692, ave_loss: 0.691
[37]  [720/1724] loss: 0.622, ave_loss: 0.689
[38]  [740/1724] loss: 0.585, ave_loss: 0.686
[39]  [760/1724] loss: 0.608, ave_loss: 0.684
[40]  [780/1724] loss: 0.678, ave_loss: 0.684
[41]  [800/1724] loss: 0.750, ave_loss: 0.686
[42]  [820/1724] loss: 0.762, ave_loss: 0.688
[43]  [840/1724] loss: 0.611, ave_loss: 0.686
[44]  [860/1724] loss: 0.674, ave_loss: 0.686
[45]  [880/1724] loss: 0.694, ave_loss: 0.686
[46]  [900/1724] loss: 0.657, ave_loss: 0.685
[47]  [920/1724] loss: 0.687, ave_loss: 0.685
[48]  [940/1724] loss: 0.773, ave_loss: 0.687
[49]  [960/1724] loss: 0.732, ave_loss: 0.688
[50]  [980/1724] loss: 0.698, ave_loss: 0.688
[51]  [1000/1724] loss: 0.673, ave_loss: 0.688
[52]  [1020/1724] loss: 0.603, ave_loss: 0.686
[53]  [1040/1724] loss: 0.748, ave_loss: 0.687
[54]  [1060/1724] loss: 0.808, ave_loss: 0.690
[55]  [1080/1724] loss: 0.746, ave_loss: 0.691
[56]  [1100/1724] loss: 0.599, ave_loss: 0.689
[57]  [1120/1724] loss: 0.801, ave_loss: 0.691
[58]  [1140/1724] loss: 0.739, ave_loss: 0.692
[59]  [1160/1724] loss: 0.805, ave_loss: 0.694
[60]  [1180/1724] loss: 0.802, ave_loss: 0.695
[61]  [1200/1724] loss: 0.729, ave_loss: 0.696
[62]  [1220/1724] loss: 0.758, ave_loss: 0.697
[63]  [1240/1724] loss: 0.576, ave_loss: 0.695
[64]  [1260/1724] loss: 0.655, ave_loss: 0.694
[65]  [1280/1724] loss: 0.716, ave_loss: 0.695
[66]  [1300/1724] loss: 0.661, ave_loss: 0.694
[67]  [1320/1724] loss: 0.740, ave_loss: 0.695
[68]  [1340/1724] loss: 0.612, ave_loss: 0.694
[69]  [1360/1724] loss: 0.629, ave_loss: 0.693
[70]  [1380/1724] loss: 0.634, ave_loss: 0.692
[71]  [1400/1724] loss: 0.724, ave_loss: 0.692
[72]  [1420/1724] loss: 0.626, ave_loss: 0.691
[73]  [1440/1724] loss: 0.626, ave_loss: 0.691
[74]  [1460/1724] loss: 0.719, ave_loss: 0.691
[75]  [1480/1724] loss: 0.669, ave_loss: 0.691
[76]  [1500/1724] loss: 0.634, ave_loss: 0.690
[77]  [1520/1724] loss: 0.648, ave_loss: 0.689
[78]  [1540/1724] loss: 0.566, ave_loss: 0.688
[79]  [1560/1724] loss: 0.652, ave_loss: 0.687
[80]  [1580/1724] loss: 0.603, ave_loss: 0.686
[81]  [1600/1724] loss: 0.653, ave_loss: 0.686
[82]  [1620/1724] loss: 0.709, ave_loss: 0.686
[83]  [1640/1724] loss: 0.704, ave_loss: 0.686
[84]  [1660/1724] loss: 0.654, ave_loss: 0.686
[85]  [1680/1724] loss: 0.686, ave_loss: 0.686
[86]  [1700/1724] loss: 0.639, ave_loss: 0.685
[87]  [1720/1724] loss: 0.731, ave_loss: 0.686
[88]  [1740/1724] loss: 0.579, ave_loss: 0.685

Finished Training finishing at 2021-08-24 22:13:19.028013
printing_out epoch  8.167053364269142 learning rate: 0.0005153561248318907
0.0004039069405825386
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.848e-01
Validation Loss: 5.718e-01
Validation ROC: 0.5327
No improvement, still saving model
90.83294663573086 epochs left to go

Training Epoch 8.167053364269142/100 starting at 2021-08-24 22:13:45.583442
[1]  [0/1724] loss: 0.862, ave_loss: 0.862
[2]  [20/1724] loss: 0.738, ave_loss: 0.800
[3]  [40/1724] loss: 0.636, ave_loss: 0.745
[4]  [60/1724] loss: 0.706, ave_loss: 0.735
[5]  [80/1724] loss: 0.827, ave_loss: 0.753
[6]  [100/1724] loss: 0.653, ave_loss: 0.737
[7]  [120/1724] loss: 0.583, ave_loss: 0.715
[8]  [140/1724] loss: 0.732, ave_loss: 0.717
[9]  [160/1724] loss: 0.823, ave_loss: 0.729
[10]  [180/1724] loss: 0.671, ave_loss: 0.723
[11]  [200/1724] loss: 0.640, ave_loss: 0.715
[12]  [220/1724] loss: 0.662, ave_loss: 0.711
[13]  [240/1724] loss: 0.792, ave_loss: 0.717
[14]  [260/1724] loss: 0.532, ave_loss: 0.704
[15]  [280/1724] loss: 0.661, ave_loss: 0.701
[16]  [300/1724] loss: 0.674, ave_loss: 0.699
[17]  [320/1724] loss: 0.651, ave_loss: 0.697
[18]  [340/1724] loss: 0.859, ave_loss: 0.706
[19]  [360/1724] loss: 0.468, ave_loss: 0.693
[20]  [380/1724] loss: 0.746, ave_loss: 0.696
[21]  [400/1724] loss: 0.718, ave_loss: 0.697
[22]  [420/1724] loss: 0.582, ave_loss: 0.692
[23]  [440/1724] loss: 0.828, ave_loss: 0.697
[24]  [460/1724] loss: 0.832, ave_loss: 0.703
[25]  [480/1724] loss: 0.766, ave_loss: 0.706
[26]  [500/1724] loss: 0.678, ave_loss: 0.705
[27]  [520/1724] loss: 0.733, ave_loss: 0.706
[28]  [540/1724] loss: 0.722, ave_loss: 0.706
[29]  [560/1724] loss: 0.765, ave_loss: 0.708
[30]  [580/1724] loss: 0.671, ave_loss: 0.707
[31]  [600/1724] loss: 0.793, ave_loss: 0.710
[32]  [620/1724] loss: 0.658, ave_loss: 0.708
[33]  [640/1724] loss: 0.599, ave_loss: 0.705
[34]  [660/1724] loss: 0.637, ave_loss: 0.703
[35]  [680/1724] loss: 0.766, ave_loss: 0.705
[36]  [700/1724] loss: 0.716, ave_loss: 0.705
[37]  [720/1724] loss: 0.702, ave_loss: 0.705
[38]  [740/1724] loss: 0.735, ave_loss: 0.706
[39]  [760/1724] loss: 0.583, ave_loss: 0.702
[40]  [780/1724] loss: 0.831, ave_loss: 0.706
[41]  [800/1724] loss: 0.643, ave_loss: 0.704
[42]  [820/1724] loss: 0.714, ave_loss: 0.704
[43]  [840/1724] loss: 0.807, ave_loss: 0.707
[44]  [860/1724] loss: 0.593, ave_loss: 0.704
[45]  [880/1724] loss: 0.681, ave_loss: 0.704
[46]  [900/1724] loss: 0.642, ave_loss: 0.702
[47]  [920/1724] loss: 0.656, ave_loss: 0.701
[48]  [940/1724] loss: 0.666, ave_loss: 0.701
[49]  [960/1724] loss: 0.661, ave_loss: 0.700
[50]  [980/1724] loss: 0.651, ave_loss: 0.699
[51]  [1000/1724] loss: 0.754, ave_loss: 0.700
[52]  [1020/1724] loss: 0.709, ave_loss: 0.700
[53]  [1040/1724] loss: 0.591, ave_loss: 0.698
[54]  [1060/1724] loss: 0.657, ave_loss: 0.697
[55]  [1080/1724] loss: 0.504, ave_loss: 0.694
[56]  [1100/1724] loss: 0.742, ave_loss: 0.695
[57]  [1120/1724] loss: 0.673, ave_loss: 0.694
[58]  [1140/1724] loss: 0.582, ave_loss: 0.692
[59]  [1160/1724] loss: 0.817, ave_loss: 0.694
[60]  [1180/1724] loss: 0.745, ave_loss: 0.695
[61]  [1200/1724] loss: 0.811, ave_loss: 0.697
[62]  [1220/1724] loss: 0.819, ave_loss: 0.699
[63]  [1240/1724] loss: 0.615, ave_loss: 0.698
[64]  [1260/1724] loss: 0.550, ave_loss: 0.695
[65]  [1280/1724] loss: 0.711, ave_loss: 0.696
[66]  [1300/1724] loss: 0.698, ave_loss: 0.696
[67]  [1320/1724] loss: 0.688, ave_loss: 0.696
[68]  [1340/1724] loss: 0.741, ave_loss: 0.696
[69]  [1360/1724] loss: 0.596, ave_loss: 0.695
[70]  [1380/1724] loss: 0.644, ave_loss: 0.694
[71]  [1400/1724] loss: 0.640, ave_loss: 0.693
[72]  [1420/1724] loss: 0.578, ave_loss: 0.692
[73]  [1440/1724] loss: 0.671, ave_loss: 0.692
[74]  [1460/1724] loss: 0.672, ave_loss: 0.691
[75]  [1480/1724] loss: 0.648, ave_loss: 0.691
[76]  [1500/1724] loss: 0.638, ave_loss: 0.690
[77]  [1520/1724] loss: 0.646, ave_loss: 0.689
[78]  [1540/1724] loss: 0.916, ave_loss: 0.692
[79]  [1560/1724] loss: 0.866, ave_loss: 0.694
[80]  [1580/1724] loss: 0.566, ave_loss: 0.693
[81]  [1600/1724] loss: 0.598, ave_loss: 0.692
[82]  [1620/1724] loss: 0.580, ave_loss: 0.690
[83]  [1640/1724] loss: 0.737, ave_loss: 0.691
[84]  [1660/1724] loss: 0.609, ave_loss: 0.690
[85]  [1680/1724] loss: 0.578, ave_loss: 0.689
[86]  [1700/1724] loss: 0.725, ave_loss: 0.689
[87]  [1720/1724] loss: 0.731, ave_loss: 0.690
[88]  [1740/1724] loss: 0.698, ave_loss: 0.690

Finished Training finishing at 2021-08-24 22:15:22.488302
printing_out epoch  9.187935034802784 learning rate: 0.0005153561248318907
0.00039178973236506245
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.896e-01
Validation Loss: 5.664e-01
Validation ROC: 0.5312
No improvement, still saving model
89.81206496519721 epochs left to go

Training Epoch 9.187935034802784/100 starting at 2021-08-24 22:16:08.179664
[1]  [0/1724] loss: 0.725, ave_loss: 0.725
[2]  [20/1724] loss: 0.684, ave_loss: 0.705
[3]  [40/1724] loss: 0.525, ave_loss: 0.645
[4]  [60/1724] loss: 0.701, ave_loss: 0.659
[5]  [80/1724] loss: 0.737, ave_loss: 0.674
[6]  [100/1724] loss: 0.817, ave_loss: 0.698
[7]  [120/1724] loss: 0.795, ave_loss: 0.712
[8]  [140/1724] loss: 0.772, ave_loss: 0.719
[9]  [160/1724] loss: 0.589, ave_loss: 0.705
[10]  [180/1724] loss: 0.752, ave_loss: 0.710
[11]  [200/1724] loss: 0.634, ave_loss: 0.703
[12]  [220/1724] loss: 0.626, ave_loss: 0.696
[13]  [240/1724] loss: 0.754, ave_loss: 0.701
[14]  [260/1724] loss: 0.889, ave_loss: 0.714
[15]  [280/1724] loss: 0.846, ave_loss: 0.723
[16]  [300/1724] loss: 0.730, ave_loss: 0.723
[17]  [320/1724] loss: 0.701, ave_loss: 0.722
[18]  [340/1724] loss: 0.523, ave_loss: 0.711
[19]  [360/1724] loss: 0.666, ave_loss: 0.709
[20]  [380/1724] loss: 0.693, ave_loss: 0.708
[21]  [400/1724] loss: 0.664, ave_loss: 0.706
[22]  [420/1724] loss: 0.610, ave_loss: 0.701
[23]  [440/1724] loss: 0.677, ave_loss: 0.700
[24]  [460/1724] loss: 0.582, ave_loss: 0.695
[25]  [480/1724] loss: 0.628, ave_loss: 0.693
[26]  [500/1724] loss: 0.660, ave_loss: 0.692
[27]  [520/1724] loss: 0.755, ave_loss: 0.694
[28]  [540/1724] loss: 0.807, ave_loss: 0.698
[29]  [560/1724] loss: 0.679, ave_loss: 0.697
[30]  [580/1724] loss: 0.610, ave_loss: 0.694
[31]  [600/1724] loss: 0.675, ave_loss: 0.694
[32]  [620/1724] loss: 0.743, ave_loss: 0.695
[33]  [640/1724] loss: 0.667, ave_loss: 0.694
[34]  [660/1724] loss: 0.638, ave_loss: 0.693
[35]  [680/1724] loss: 0.630, ave_loss: 0.691
[36]  [700/1724] loss: 0.562, ave_loss: 0.687
[37]  [720/1724] loss: 0.639, ave_loss: 0.686
[38]  [740/1724] loss: 0.754, ave_loss: 0.688
[39]  [760/1724] loss: 0.619, ave_loss: 0.686
[40]  [780/1724] loss: 0.668, ave_loss: 0.686
[41]  [800/1724] loss: 0.613, ave_loss: 0.684
[42]  [820/1724] loss: 0.617, ave_loss: 0.682
[43]  [840/1724] loss: 0.557, ave_loss: 0.679
[44]  [860/1724] loss: 0.634, ave_loss: 0.678
[45]  [880/1724] loss: 0.647, ave_loss: 0.678
[46]  [900/1724] loss: 0.681, ave_loss: 0.678
[47]  [920/1724] loss: 0.688, ave_loss: 0.678
[48]  [940/1724] loss: 0.821, ave_loss: 0.681
[49]  [960/1724] loss: 0.691, ave_loss: 0.681
[50]  [980/1724] loss: 0.649, ave_loss: 0.681
[51]  [1000/1724] loss: 0.920, ave_loss: 0.685
[52]  [1020/1724] loss: 0.627, ave_loss: 0.684
[53]  [1040/1724] loss: 0.821, ave_loss: 0.687
[54]  [1060/1724] loss: 0.748, ave_loss: 0.688
[55]  [1080/1724] loss: 0.541, ave_loss: 0.685
[56]  [1100/1724] loss: 0.733, ave_loss: 0.686
[57]  [1120/1724] loss: 0.670, ave_loss: 0.686
[58]  [1140/1724] loss: 0.658, ave_loss: 0.685
[59]  [1160/1724] loss: 0.760, ave_loss: 0.686
[60]  [1180/1724] loss: 0.701, ave_loss: 0.687
[61]  [1200/1724] loss: 0.632, ave_loss: 0.686
[62]  [1220/1724] loss: 0.674, ave_loss: 0.686
[63]  [1240/1724] loss: 0.705, ave_loss: 0.686
[64]  [1260/1724] loss: 0.558, ave_loss: 0.684
[65]  [1280/1724] loss: 0.745, ave_loss: 0.685
[66]  [1300/1724] loss: 0.865, ave_loss: 0.688
[67]  [1320/1724] loss: 0.689, ave_loss: 0.688
[68]  [1340/1724] loss: 0.895, ave_loss: 0.691
[69]  [1360/1724] loss: 0.553, ave_loss: 0.689
[70]  [1380/1724] loss: 0.643, ave_loss: 0.688
[71]  [1400/1724] loss: 0.584, ave_loss: 0.687
[72]  [1420/1724] loss: 0.686, ave_loss: 0.687
[73]  [1440/1724] loss: 0.708, ave_loss: 0.687
[74]  [1460/1724] loss: 0.649, ave_loss: 0.686
[75]  [1480/1724] loss: 0.726, ave_loss: 0.687
[76]  [1500/1724] loss: 0.592, ave_loss: 0.686
[77]  [1520/1724] loss: 0.660, ave_loss: 0.685
[78]  [1540/1724] loss: 0.740, ave_loss: 0.686
[79]  [1560/1724] loss: 0.704, ave_loss: 0.686
[80]  [1580/1724] loss: 0.833, ave_loss: 0.688
[81]  [1600/1724] loss: 0.762, ave_loss: 0.689
[82]  [1620/1724] loss: 0.671, ave_loss: 0.689
[83]  [1640/1724] loss: 0.679, ave_loss: 0.689
[84]  [1660/1724] loss: 0.612, ave_loss: 0.688
[85]  [1680/1724] loss: 0.700, ave_loss: 0.688
[86]  [1700/1724] loss: 0.691, ave_loss: 0.688
[87]  [1720/1724] loss: 0.776, ave_loss: 0.689
[88]  [1740/1724] loss: 0.705, ave_loss: 0.689

Finished Training finishing at 2021-08-24 22:18:05.821381
printing_out epoch  10.208816705336426 learning rate: 0.0005153561248318907
0.0003800360403941106
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.891e-01
Validation Loss: 5.872e-01
Validation ROC: 0.5341
No improvement, still saving model
88.79118329466357 epochs left to go

Training Epoch 10.208816705336426/100 starting at 2021-08-24 22:18:41.519455
[1]  [0/1724] loss: 0.697, ave_loss: 0.697
[2]  [20/1724] loss: 0.682, ave_loss: 0.689
[3]  [40/1724] loss: 0.614, ave_loss: 0.664
[4]  [60/1724] loss: 0.743, ave_loss: 0.684
[5]  [80/1724] loss: 0.762, ave_loss: 0.699
[6]  [100/1724] loss: 0.659, ave_loss: 0.693
[7]  [120/1724] loss: 0.603, ave_loss: 0.680
[8]  [140/1724] loss: 0.622, ave_loss: 0.673
[9]  [160/1724] loss: 0.640, ave_loss: 0.669
[10]  [180/1724] loss: 0.669, ave_loss: 0.669
[11]  [200/1724] loss: 0.660, ave_loss: 0.668
[12]  [220/1724] loss: 0.723, ave_loss: 0.673
[13]  [240/1724] loss: 0.647, ave_loss: 0.671
[14]  [260/1724] loss: 0.608, ave_loss: 0.666
[15]  [280/1724] loss: 0.644, ave_loss: 0.665
[16]  [300/1724] loss: 0.627, ave_loss: 0.662
[17]  [320/1724] loss: 0.695, ave_loss: 0.664
[18]  [340/1724] loss: 0.808, ave_loss: 0.672
[19]  [360/1724] loss: 0.616, ave_loss: 0.669
[20]  [380/1724] loss: 0.683, ave_loss: 0.670
[21]  [400/1724] loss: 0.777, ave_loss: 0.675
[22]  [420/1724] loss: 0.562, ave_loss: 0.670
[23]  [440/1724] loss: 0.525, ave_loss: 0.664
[24]  [460/1724] loss: 0.690, ave_loss: 0.665
[25]  [480/1724] loss: 0.588, ave_loss: 0.662
[26]  [500/1724] loss: 0.584, ave_loss: 0.659
[27]  [520/1724] loss: 0.806, ave_loss: 0.664
[28]  [540/1724] loss: 0.638, ave_loss: 0.663
[29]  [560/1724] loss: 0.604, ave_loss: 0.661
[30]  [580/1724] loss: 0.765, ave_loss: 0.665
[31]  [600/1724] loss: 0.705, ave_loss: 0.666
[32]  [620/1724] loss: 0.485, ave_loss: 0.660
[33]  [640/1724] loss: 0.620, ave_loss: 0.659
[34]  [660/1724] loss: 0.796, ave_loss: 0.663
[35]  [680/1724] loss: 0.573, ave_loss: 0.661
[36]  [700/1724] loss: 0.590, ave_loss: 0.659
[37]  [720/1724] loss: 0.775, ave_loss: 0.662
[38]  [740/1724] loss: 0.639, ave_loss: 0.661
[39]  [760/1724] loss: 0.626, ave_loss: 0.660
[40]  [780/1724] loss: 0.774, ave_loss: 0.663
[41]  [800/1724] loss: 0.665, ave_loss: 0.663
[42]  [820/1724] loss: 0.546, ave_loss: 0.660
[43]  [840/1724] loss: 0.606, ave_loss: 0.659
[44]  [860/1724] loss: 0.530, ave_loss: 0.656
[45]  [880/1724] loss: 0.806, ave_loss: 0.659
[46]  [900/1724] loss: 0.584, ave_loss: 0.658
[47]  [920/1724] loss: 0.546, ave_loss: 0.655
[48]  [940/1724] loss: 0.721, ave_loss: 0.657
[49]  [960/1724] loss: 0.617, ave_loss: 0.656
[50]  [980/1724] loss: 0.582, ave_loss: 0.654
[51]  [1000/1724] loss: 0.552, ave_loss: 0.652
[52]  [1020/1724] loss: 0.705, ave_loss: 0.653
[53]  [1040/1724] loss: 0.801, ave_loss: 0.656
[54]  [1060/1724] loss: 0.769, ave_loss: 0.658
[55]  [1080/1724] loss: 0.568, ave_loss: 0.657
[56]  [1100/1724] loss: 0.586, ave_loss: 0.655
[57]  [1120/1724] loss: 0.665, ave_loss: 0.656
[58]  [1140/1724] loss: 0.849, ave_loss: 0.659
[59]  [1160/1724] loss: 0.795, ave_loss: 0.661
[60]  [1180/1724] loss: 0.725, ave_loss: 0.662
[61]  [1200/1724] loss: 0.587, ave_loss: 0.661
[62]  [1220/1724] loss: 0.807, ave_loss: 0.663
[63]  [1240/1724] loss: 0.651, ave_loss: 0.663
[64]  [1260/1724] loss: 0.656, ave_loss: 0.663
[65]  [1280/1724] loss: 0.809, ave_loss: 0.665
[66]  [1300/1724] loss: 0.667, ave_loss: 0.665
[67]  [1320/1724] loss: 0.750, ave_loss: 0.667
[68]  [1340/1724] loss: 0.732, ave_loss: 0.668
[69]  [1360/1724] loss: 0.556, ave_loss: 0.666
[70]  [1380/1724] loss: 0.625, ave_loss: 0.665
[71]  [1400/1724] loss: 0.622, ave_loss: 0.665
[72]  [1420/1724] loss: 0.731, ave_loss: 0.666
[73]  [1440/1724] loss: 0.763, ave_loss: 0.667
[74]  [1460/1724] loss: 0.627, ave_loss: 0.667
[75]  [1480/1724] loss: 0.710, ave_loss: 0.667
[76]  [1500/1724] loss: 0.681, ave_loss: 0.667
[77]  [1520/1724] loss: 0.720, ave_loss: 0.668
[78]  [1540/1724] loss: 0.626, ave_loss: 0.667
[79]  [1560/1724] loss: 0.692, ave_loss: 0.668
[80]  [1580/1724] loss: 0.675, ave_loss: 0.668
[81]  [1600/1724] loss: 0.572, ave_loss: 0.667
[82]  [1620/1724] loss: 0.585, ave_loss: 0.666
[83]  [1640/1724] loss: 0.674, ave_loss: 0.666
[84]  [1660/1724] loss: 0.556, ave_loss: 0.664
[85]  [1680/1724] loss: 0.661, ave_loss: 0.664
[86]  [1700/1724] loss: 0.698, ave_loss: 0.665
[87]  [1720/1724] loss: 0.805, ave_loss: 0.666
[88]  [1740/1724] loss: 0.598, ave_loss: 0.666

Finished Training finishing at 2021-08-24 22:20:37.828614
printing_out epoch  11.22969837587007 learning rate: 0.00046850556802899155
0.0004544504009881218
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.656e-01
Validation Loss: 5.628e-01
Validation ROC: 0.5293
No improvement, still saving model
87.77030162412993 epochs left to go

Training Epoch 11.22969837587007/100 starting at 2021-08-24 22:22:09.409819
[1]  [0/1724] loss: 0.676, ave_loss: 0.676
[2]  [20/1724] loss: 0.701, ave_loss: 0.689
[3]  [40/1724] loss: 0.673, ave_loss: 0.683
[4]  [60/1724] loss: 0.732, ave_loss: 0.695
[5]  [80/1724] loss: 0.600, ave_loss: 0.676
[6]  [100/1724] loss: 0.778, ave_loss: 0.693
[7]  [120/1724] loss: 0.636, ave_loss: 0.685
[8]  [140/1724] loss: 0.725, ave_loss: 0.690
[9]  [160/1724] loss: 0.621, ave_loss: 0.682
[10]  [180/1724] loss: 0.777, ave_loss: 0.692
[11]  [200/1724] loss: 0.515, ave_loss: 0.676
[12]  [220/1724] loss: 0.704, ave_loss: 0.678
[13]  [240/1724] loss: 0.603, ave_loss: 0.672
[14]  [260/1724] loss: 0.682, ave_loss: 0.673
[15]  [280/1724] loss: 0.730, ave_loss: 0.677
[16]  [300/1724] loss: 0.593, ave_loss: 0.672
[17]  [320/1724] loss: 0.842, ave_loss: 0.682
[18]  [340/1724] loss: 0.628, ave_loss: 0.679
[19]  [360/1724] loss: 0.692, ave_loss: 0.679
[20]  [380/1724] loss: 0.711, ave_loss: 0.681
[21]  [400/1724] loss: 0.673, ave_loss: 0.681
[22]  [420/1724] loss: 0.531, ave_loss: 0.674
[23]  [440/1724] loss: 0.631, ave_loss: 0.672
[24]  [460/1724] loss: 0.628, ave_loss: 0.670
[25]  [480/1724] loss: 0.594, ave_loss: 0.667
[26]  [500/1724] loss: 0.706, ave_loss: 0.669
[27]  [520/1724] loss: 0.572, ave_loss: 0.665
[28]  [540/1724] loss: 0.881, ave_loss: 0.673
[29]  [560/1724] loss: 0.617, ave_loss: 0.671
[30]  [580/1724] loss: 0.794, ave_loss: 0.675
[31]  [600/1724] loss: 0.689, ave_loss: 0.675
[32]  [620/1724] loss: 0.637, ave_loss: 0.674
[33]  [640/1724] loss: 0.721, ave_loss: 0.676
[34]  [660/1724] loss: 0.669, ave_loss: 0.675
[35]  [680/1724] loss: 0.666, ave_loss: 0.675
[36]  [700/1724] loss: 0.723, ave_loss: 0.676
[37]  [720/1724] loss: 0.639, ave_loss: 0.675
[38]  [740/1724] loss: 0.719, ave_loss: 0.676
[39]  [760/1724] loss: 0.609, ave_loss: 0.675
[40]  [780/1724] loss: 0.660, ave_loss: 0.674
[41]  [800/1724] loss: 0.629, ave_loss: 0.673
[42]  [820/1724] loss: 0.665, ave_loss: 0.673
[43]  [840/1724] loss: 0.714, ave_loss: 0.674
[44]  [860/1724] loss: 0.705, ave_loss: 0.675
[45]  [880/1724] loss: 0.671, ave_loss: 0.675
[46]  [900/1724] loss: 0.658, ave_loss: 0.674
[47]  [920/1724] loss: 0.722, ave_loss: 0.675
[48]  [940/1724] loss: 0.553, ave_loss: 0.673
[49]  [960/1724] loss: 0.697, ave_loss: 0.673
[50]  [980/1724] loss: 0.664, ave_loss: 0.673
[51]  [1000/1724] loss: 0.622, ave_loss: 0.672
[52]  [1020/1724] loss: 0.487, ave_loss: 0.669
[53]  [1040/1724] loss: 0.675, ave_loss: 0.669
[54]  [1060/1724] loss: 0.749, ave_loss: 0.670
[55]  [1080/1724] loss: 0.838, ave_loss: 0.673
[56]  [1100/1724] loss: 0.600, ave_loss: 0.672
[57]  [1120/1724] loss: 0.637, ave_loss: 0.671
[58]  [1140/1724] loss: 0.771, ave_loss: 0.673
[59]  [1160/1724] loss: 0.621, ave_loss: 0.672
[60]  [1180/1724] loss: 0.609, ave_loss: 0.671
[61]  [1200/1724] loss: 0.693, ave_loss: 0.671
[62]  [1220/1724] loss: 0.591, ave_loss: 0.670
[63]  [1240/1724] loss: 0.778, ave_loss: 0.672
[64]  [1260/1724] loss: 0.757, ave_loss: 0.673
[65]  [1280/1724] loss: 0.705, ave_loss: 0.674
[66]  [1300/1724] loss: 0.619, ave_loss: 0.673
[67]  [1320/1724] loss: 0.658, ave_loss: 0.673
[68]  [1340/1724] loss: 0.622, ave_loss: 0.672
[69]  [1360/1724] loss: 0.542, ave_loss: 0.670
[70]  [1380/1724] loss: 0.713, ave_loss: 0.671
[71]  [1400/1724] loss: 0.664, ave_loss: 0.670
[72]  [1420/1724] loss: 0.643, ave_loss: 0.670
[73]  [1440/1724] loss: 0.662, ave_loss: 0.670
[74]  [1460/1724] loss: 0.514, ave_loss: 0.668
[75]  [1480/1724] loss: 0.611, ave_loss: 0.667
[76]  [1500/1724] loss: 0.585, ave_loss: 0.666
[77]  [1520/1724] loss: 0.617, ave_loss: 0.665
[78]  [1540/1724] loss: 0.527, ave_loss: 0.664
[79]  [1560/1724] loss: 0.604, ave_loss: 0.663
[80]  [1580/1724] loss: 0.699, ave_loss: 0.663
[81]  [1600/1724] loss: 0.616, ave_loss: 0.663
[82]  [1620/1724] loss: 0.736, ave_loss: 0.664
[83]  [1640/1724] loss: 0.606, ave_loss: 0.663
[84]  [1660/1724] loss: 0.790, ave_loss: 0.664
[85]  [1680/1724] loss: 0.675, ave_loss: 0.665
[86]  [1700/1724] loss: 0.828, ave_loss: 0.666
[87]  [1720/1724] loss: 0.774, ave_loss: 0.668
[88]  [1740/1724] loss: 0.871, ave_loss: 0.670

Finished Training finishing at 2021-08-24 22:24:19.124724
printing_out epoch  12.250580046403712 learning rate: 0.00042591415275362865
0.0004131367281710198
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.700e-01
Validation Loss: 5.595e-01
Validation ROC: 0.5174
No improvement, still saving model
86.74941995359629 epochs left to go

Training Epoch 12.250580046403712/100 starting at 2021-08-24 22:24:47.980561
[1]  [0/1724] loss: 0.463, ave_loss: 0.463
[2]  [20/1724] loss: 0.555, ave_loss: 0.509
[3]  [40/1724] loss: 0.836, ave_loss: 0.618
[4]  [60/1724] loss: 0.686, ave_loss: 0.635
[5]  [80/1724] loss: 0.486, ave_loss: 0.605
[6]  [100/1724] loss: 0.630, ave_loss: 0.609
[7]  [120/1724] loss: 0.660, ave_loss: 0.617
[8]  [140/1724] loss: 0.628, ave_loss: 0.618
[9]  [160/1724] loss: 0.706, ave_loss: 0.628
[10]  [180/1724] loss: 0.698, ave_loss: 0.635
[11]  [200/1724] loss: 0.558, ave_loss: 0.628
[12]  [220/1724] loss: 0.673, ave_loss: 0.632
[13]  [240/1724] loss: 0.680, ave_loss: 0.635
[14]  [260/1724] loss: 0.661, ave_loss: 0.637
[15]  [280/1724] loss: 0.681, ave_loss: 0.640
[16]  [300/1724] loss: 0.676, ave_loss: 0.642
[17]  [320/1724] loss: 0.591, ave_loss: 0.639
[18]  [340/1724] loss: 0.648, ave_loss: 0.640
[19]  [360/1724] loss: 0.904, ave_loss: 0.654
[20]  [380/1724] loss: 0.687, ave_loss: 0.655
[21]  [400/1724] loss: 0.722, ave_loss: 0.659
[22]  [420/1724] loss: 0.591, ave_loss: 0.655
[23]  [440/1724] loss: 0.691, ave_loss: 0.657
[24]  [460/1724] loss: 0.632, ave_loss: 0.656
[25]  [480/1724] loss: 0.647, ave_loss: 0.656
[26]  [500/1724] loss: 0.640, ave_loss: 0.655
[27]  [520/1724] loss: 0.671, ave_loss: 0.656
[28]  [540/1724] loss: 0.538, ave_loss: 0.651
[29]  [560/1724] loss: 0.657, ave_loss: 0.652
[30]  [580/1724] loss: 0.649, ave_loss: 0.651
[31]  [600/1724] loss: 0.525, ave_loss: 0.647
[32]  [620/1724] loss: 0.631, ave_loss: 0.647
[33]  [640/1724] loss: 0.529, ave_loss: 0.643
[34]  [660/1724] loss: 0.498, ave_loss: 0.639
[35]  [680/1724] loss: 0.538, ave_loss: 0.636
[36]  [700/1724] loss: 0.720, ave_loss: 0.638
[37]  [720/1724] loss: 0.542, ave_loss: 0.636
[38]  [740/1724] loss: 0.678, ave_loss: 0.637
[39]  [760/1724] loss: 0.604, ave_loss: 0.636
[40]  [780/1724] loss: 0.739, ave_loss: 0.639
[41]  [800/1724] loss: 0.561, ave_loss: 0.637
[42]  [820/1724] loss: 0.688, ave_loss: 0.638
[43]  [840/1724] loss: 0.597, ave_loss: 0.637
[44]  [860/1724] loss: 0.741, ave_loss: 0.639
[45]  [880/1724] loss: 0.628, ave_loss: 0.639
[46]  [900/1724] loss: 0.520, ave_loss: 0.637
[47]  [920/1724] loss: 0.635, ave_loss: 0.637
[48]  [940/1724] loss: 0.709, ave_loss: 0.638
[49]  [960/1724] loss: 0.734, ave_loss: 0.640
[50]  [980/1724] loss: 0.578, ave_loss: 0.639
[51]  [1000/1724] loss: 0.514, ave_loss: 0.636
[52]  [1020/1724] loss: 0.758, ave_loss: 0.639
[53]  [1040/1724] loss: 0.690, ave_loss: 0.640
[54]  [1060/1724] loss: 0.738, ave_loss: 0.641
[55]  [1080/1724] loss: 0.660, ave_loss: 0.642
[56]  [1100/1724] loss: 0.515, ave_loss: 0.640
[57]  [1120/1724] loss: 0.701, ave_loss: 0.641
[58]  [1140/1724] loss: 0.744, ave_loss: 0.642
[59]  [1160/1724] loss: 0.624, ave_loss: 0.642
[60]  [1180/1724] loss: 0.488, ave_loss: 0.640
[61]  [1200/1724] loss: 0.750, ave_loss: 0.641
[62]  [1220/1724] loss: 0.706, ave_loss: 0.642
[63]  [1240/1724] loss: 0.849, ave_loss: 0.646
[64]  [1260/1724] loss: 0.651, ave_loss: 0.646
[65]  [1280/1724] loss: 0.648, ave_loss: 0.646
[66]  [1300/1724] loss: 0.647, ave_loss: 0.646
[67]  [1320/1724] loss: 0.659, ave_loss: 0.646
[68]  [1340/1724] loss: 0.575, ave_loss: 0.645
[69]  [1360/1724] loss: 0.803, ave_loss: 0.647
[70]  [1380/1724] loss: 0.732, ave_loss: 0.648
[71]  [1400/1724] loss: 0.835, ave_loss: 0.651
[72]  [1420/1724] loss: 0.761, ave_loss: 0.653
[73]  [1440/1724] loss: 0.657, ave_loss: 0.653
[74]  [1460/1724] loss: 0.619, ave_loss: 0.652
[75]  [1480/1724] loss: 0.882, ave_loss: 0.655
[76]  [1500/1724] loss: 0.667, ave_loss: 0.655
[77]  [1520/1724] loss: 0.734, ave_loss: 0.656
[78]  [1540/1724] loss: 0.703, ave_loss: 0.657
[79]  [1560/1724] loss: 0.763, ave_loss: 0.658
[80]  [1580/1724] loss: 0.561, ave_loss: 0.657
[81]  [1600/1724] loss: 0.697, ave_loss: 0.658
[82]  [1620/1724] loss: 0.804, ave_loss: 0.659
[83]  [1640/1724] loss: 0.711, ave_loss: 0.660
[84]  [1660/1724] loss: 0.581, ave_loss: 0.659
[85]  [1680/1724] loss: 0.554, ave_loss: 0.658
[86]  [1700/1724] loss: 0.678, ave_loss: 0.658
[87]  [1720/1724] loss: 0.699, ave_loss: 0.659
[88]  [1740/1724] loss: 0.684, ave_loss: 0.659

Finished Training finishing at 2021-08-24 22:26:41.245858
printing_out epoch  13.271461716937354 learning rate: 0.00038719468432148055
0.0003755788437918361
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.589e-01
Validation Loss: 6.289e-01
Validation ROC: 0.4589
No improvement, still saving model
85.72853828306265 epochs left to go

Training Epoch 13.271461716937354/100 starting at 2021-08-24 22:27:04.091532
[1]  [0/1724] loss: 0.754, ave_loss: 0.754
[2]  [20/1724] loss: 0.630, ave_loss: 0.692
[3]  [40/1724] loss: 0.624, ave_loss: 0.669
[4]  [60/1724] loss: 0.691, ave_loss: 0.675
[5]  [80/1724] loss: 0.683, ave_loss: 0.676
[6]  [100/1724] loss: 0.650, ave_loss: 0.672
[7]  [120/1724] loss: 0.650, ave_loss: 0.669
[8]  [140/1724] loss: 0.603, ave_loss: 0.661
[9]  [160/1724] loss: 0.632, ave_loss: 0.658
[10]  [180/1724] loss: 0.732, ave_loss: 0.665
[11]  [200/1724] loss: 0.775, ave_loss: 0.675
[12]  [220/1724] loss: 0.720, ave_loss: 0.679
[13]  [240/1724] loss: 0.621, ave_loss: 0.674
[14]  [260/1724] loss: 0.785, ave_loss: 0.682
[15]  [280/1724] loss: 0.653, ave_loss: 0.680
[16]  [300/1724] loss: 0.649, ave_loss: 0.678
[17]  [320/1724] loss: 0.694, ave_loss: 0.679
[18]  [340/1724] loss: 0.604, ave_loss: 0.675
[19]  [360/1724] loss: 0.687, ave_loss: 0.676
[20]  [380/1724] loss: 0.685, ave_loss: 0.676
[21]  [400/1724] loss: 0.672, ave_loss: 0.676
[22]  [420/1724] loss: 0.582, ave_loss: 0.672
[23]  [440/1724] loss: 0.745, ave_loss: 0.675
[24]  [460/1724] loss: 0.705, ave_loss: 0.676
[25]  [480/1724] loss: 0.665, ave_loss: 0.676
[26]  [500/1724] loss: 0.666, ave_loss: 0.675
[27]  [520/1724] loss: 0.613, ave_loss: 0.673
[28]  [540/1724] loss: 0.619, ave_loss: 0.671
[29]  [560/1724] loss: 0.599, ave_loss: 0.669
[30]  [580/1724] loss: 0.754, ave_loss: 0.671
[31]  [600/1724] loss: 0.701, ave_loss: 0.672
[32]  [620/1724] loss: 0.602, ave_loss: 0.670
[33]  [640/1724] loss: 0.501, ave_loss: 0.665
[34]  [660/1724] loss: 0.793, ave_loss: 0.669
[35]  [680/1724] loss: 0.673, ave_loss: 0.669
[36]  [700/1724] loss: 0.505, ave_loss: 0.664
[37]  [720/1724] loss: 0.656, ave_loss: 0.664
[38]  [740/1724] loss: 0.578, ave_loss: 0.662
[39]  [760/1724] loss: 0.685, ave_loss: 0.662
[40]  [780/1724] loss: 0.751, ave_loss: 0.665
[41]  [800/1724] loss: 0.683, ave_loss: 0.665
[42]  [820/1724] loss: 0.584, ave_loss: 0.663
[43]  [840/1724] loss: 0.656, ave_loss: 0.663
[44]  [860/1724] loss: 0.577, ave_loss: 0.661
[45]  [880/1724] loss: 0.683, ave_loss: 0.662
[46]  [900/1724] loss: 0.677, ave_loss: 0.662
[47]  [920/1724] loss: 0.652, ave_loss: 0.662
[48]  [940/1724] loss: 0.562, ave_loss: 0.660
[49]  [960/1724] loss: 0.762, ave_loss: 0.662
[50]  [980/1724] loss: 0.686, ave_loss: 0.662
[51]  [1000/1724] loss: 0.722, ave_loss: 0.663
[52]  [1020/1724] loss: 0.741, ave_loss: 0.665
[53]  [1040/1724] loss: 0.672, ave_loss: 0.665
[54]  [1060/1724] loss: 0.568, ave_loss: 0.663
[55]  [1080/1724] loss: 0.527, ave_loss: 0.661
[56]  [1100/1724] loss: 0.765, ave_loss: 0.663
[57]  [1120/1724] loss: 0.511, ave_loss: 0.660
[58]  [1140/1724] loss: 0.792, ave_loss: 0.662
[59]  [1160/1724] loss: 0.485, ave_loss: 0.659
[60]  [1180/1724] loss: 0.654, ave_loss: 0.659
[61]  [1200/1724] loss: 0.683, ave_loss: 0.660
[62]  [1220/1724] loss: 0.705, ave_loss: 0.660
[63]  [1240/1724] loss: 0.642, ave_loss: 0.660
[64]  [1260/1724] loss: 0.598, ave_loss: 0.659
[65]  [1280/1724] loss: 0.787, ave_loss: 0.661
[66]  [1300/1724] loss: 0.551, ave_loss: 0.659
[67]  [1320/1724] loss: 0.718, ave_loss: 0.660
[68]  [1340/1724] loss: 0.697, ave_loss: 0.661
[69]  [1360/1724] loss: 0.663, ave_loss: 0.661
[70]  [1380/1724] loss: 0.719, ave_loss: 0.662
[71]  [1400/1724] loss: 0.558, ave_loss: 0.660
[72]  [1420/1724] loss: 0.608, ave_loss: 0.659
[73]  [1440/1724] loss: 0.522, ave_loss: 0.658
[74]  [1460/1724] loss: 0.623, ave_loss: 0.657
[75]  [1480/1724] loss: 0.704, ave_loss: 0.658
[76]  [1500/1724] loss: 0.576, ave_loss: 0.657
[77]  [1520/1724] loss: 0.516, ave_loss: 0.655
[78]  [1540/1724] loss: 0.613, ave_loss: 0.654
[79]  [1560/1724] loss: 0.580, ave_loss: 0.653
[80]  [1580/1724] loss: 0.677, ave_loss: 0.654
[81]  [1600/1724] loss: 0.581, ave_loss: 0.653
[82]  [1620/1724] loss: 0.575, ave_loss: 0.652
[83]  [1640/1724] loss: 0.677, ave_loss: 0.652
[84]  [1660/1724] loss: 0.605, ave_loss: 0.651
[85]  [1680/1724] loss: 0.749, ave_loss: 0.653
[86]  [1700/1724] loss: 0.627, ave_loss: 0.652
[87]  [1720/1724] loss: 0.718, ave_loss: 0.653
[88]  [1740/1724] loss: 0.716, ave_loss: 0.654

Finished Training finishing at 2021-08-24 22:28:46.035519
printing_out epoch  14.292343387470998 learning rate: 0.0003519951675649823
0.00034143531253803285
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.538e-01
Validation Loss: 5.680e-01
Validation ROC: 0.4631
No improvement, still saving model
84.70765661252901 epochs left to go

Training Epoch 14.292343387470998/100 starting at 2021-08-24 22:29:22.707903
[1]  [0/1724] loss: 0.841, ave_loss: 0.841
[2]  [20/1724] loss: 0.552, ave_loss: 0.697
[3]  [40/1724] loss: 0.565, ave_loss: 0.653
[4]  [60/1724] loss: 0.602, ave_loss: 0.640
[5]  [80/1724] loss: 0.703, ave_loss: 0.653
[6]  [100/1724] loss: 0.538, ave_loss: 0.634
[7]  [120/1724] loss: 0.635, ave_loss: 0.634
[8]  [140/1724] loss: 0.491, ave_loss: 0.616
[9]  [160/1724] loss: 0.723, ave_loss: 0.628
[10]  [180/1724] loss: 0.570, ave_loss: 0.622
[11]  [200/1724] loss: 0.628, ave_loss: 0.623
[12]  [220/1724] loss: 0.811, ave_loss: 0.638
[13]  [240/1724] loss: 0.674, ave_loss: 0.641
[14]  [260/1724] loss: 0.604, ave_loss: 0.638
[15]  [280/1724] loss: 0.720, ave_loss: 0.644
[16]  [300/1724] loss: 0.757, ave_loss: 0.651
[17]  [320/1724] loss: 0.648, ave_loss: 0.651
[18]  [340/1724] loss: 0.719, ave_loss: 0.655
[19]  [360/1724] loss: 0.704, ave_loss: 0.657
[20]  [380/1724] loss: 0.599, ave_loss: 0.654
[21]  [400/1724] loss: 0.630, ave_loss: 0.653
[22]  [420/1724] loss: 0.576, ave_loss: 0.650
[23]  [440/1724] loss: 0.555, ave_loss: 0.645
[24]  [460/1724] loss: 0.785, ave_loss: 0.651
[25]  [480/1724] loss: 0.651, ave_loss: 0.651
[26]  [500/1724] loss: 0.637, ave_loss: 0.651
[27]  [520/1724] loss: 0.676, ave_loss: 0.652
[28]  [540/1724] loss: 0.595, ave_loss: 0.650
[29]  [560/1724] loss: 0.674, ave_loss: 0.650
[30]  [580/1724] loss: 0.799, ave_loss: 0.655
[31]  [600/1724] loss: 0.484, ave_loss: 0.650
[32]  [620/1724] loss: 0.678, ave_loss: 0.651
[33]  [640/1724] loss: 0.599, ave_loss: 0.649
[34]  [660/1724] loss: 0.549, ave_loss: 0.646
[35]  [680/1724] loss: 0.761, ave_loss: 0.650
[36]  [700/1724] loss: 0.691, ave_loss: 0.651
[37]  [720/1724] loss: 0.730, ave_loss: 0.653
[38]  [740/1724] loss: 0.635, ave_loss: 0.652
[39]  [760/1724] loss: 0.789, ave_loss: 0.656
[40]  [780/1724] loss: 0.632, ave_loss: 0.655
[41]  [800/1724] loss: 0.635, ave_loss: 0.655
[42]  [820/1724] loss: 0.687, ave_loss: 0.656
[43]  [840/1724] loss: 0.625, ave_loss: 0.655
[44]  [860/1724] loss: 0.764, ave_loss: 0.657
[45]  [880/1724] loss: 0.701, ave_loss: 0.658
[46]  [900/1724] loss: 0.643, ave_loss: 0.658
[47]  [920/1724] loss: 0.702, ave_loss: 0.659
[48]  [940/1724] loss: 0.698, ave_loss: 0.660
[49]  [960/1724] loss: 0.598, ave_loss: 0.658
[50]  [980/1724] loss: 0.663, ave_loss: 0.659
[51]  [1000/1724] loss: 0.640, ave_loss: 0.658
[52]  [1020/1724] loss: 0.620, ave_loss: 0.657
[53]  [1040/1724] loss: 0.561, ave_loss: 0.656
[54]  [1060/1724] loss: 0.724, ave_loss: 0.657
[55]  [1080/1724] loss: 0.640, ave_loss: 0.657
[56]  [1100/1724] loss: 0.682, ave_loss: 0.657
[57]  [1120/1724] loss: 0.691, ave_loss: 0.658
[58]  [1140/1724] loss: 0.658, ave_loss: 0.658
[59]  [1160/1724] loss: 0.562, ave_loss: 0.656
[60]  [1180/1724] loss: 0.592, ave_loss: 0.655
[61]  [1200/1724] loss: 0.712, ave_loss: 0.656
[62]  [1220/1724] loss: 0.649, ave_loss: 0.656
[63]  [1240/1724] loss: 0.582, ave_loss: 0.655
[64]  [1260/1724] loss: 0.685, ave_loss: 0.655
[65]  [1280/1724] loss: 0.836, ave_loss: 0.658
[66]  [1300/1724] loss: 0.747, ave_loss: 0.659
[67]  [1320/1724] loss: 0.700, ave_loss: 0.660
[68]  [1340/1724] loss: 0.573, ave_loss: 0.659
[69]  [1360/1724] loss: 0.700, ave_loss: 0.659
[70]  [1380/1724] loss: 0.766, ave_loss: 0.661
[71]  [1400/1724] loss: 0.685, ave_loss: 0.661
[72]  [1420/1724] loss: 0.690, ave_loss: 0.661
[73]  [1440/1724] loss: 0.535, ave_loss: 0.660
[74]  [1460/1724] loss: 0.580, ave_loss: 0.659
[75]  [1480/1724] loss: 0.594, ave_loss: 0.658
[76]  [1500/1724] loss: 0.575, ave_loss: 0.657
[77]  [1520/1724] loss: 0.667, ave_loss: 0.657
[78]  [1540/1724] loss: 0.539, ave_loss: 0.655
[79]  [1560/1724] loss: 0.766, ave_loss: 0.657
[80]  [1580/1724] loss: 0.635, ave_loss: 0.656
[81]  [1600/1724] loss: 0.626, ave_loss: 0.656
[82]  [1620/1724] loss: 0.626, ave_loss: 0.656
[83]  [1640/1724] loss: 0.650, ave_loss: 0.656
[84]  [1660/1724] loss: 0.699, ave_loss: 0.656
[85]  [1680/1724] loss: 0.745, ave_loss: 0.657
[86]  [1700/1724] loss: 0.659, ave_loss: 0.657
[87]  [1720/1724] loss: 0.585, ave_loss: 0.656
[88]  [1740/1724] loss: 0.708, ave_loss: 0.657

Finished Training finishing at 2021-08-24 22:31:08.846482
printing_out epoch  15.31322505800464 learning rate: 0.0003199956068772566
0.0003103957386709389
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.570e-01
Validation Loss: 5.589e-01
Validation ROC: 0.4475
No improvement, still saving model
83.68677494199537 epochs left to go

Training Epoch 15.31322505800464/100 starting at 2021-08-24 22:31:42.260716
[1]  [0/1724] loss: 0.617, ave_loss: 0.617
[2]  [20/1724] loss: 0.744, ave_loss: 0.680
[3]  [40/1724] loss: 0.626, ave_loss: 0.662
[4]  [60/1724] loss: 0.682, ave_loss: 0.667
[5]  [80/1724] loss: 0.634, ave_loss: 0.660
[6]  [100/1724] loss: 0.540, ave_loss: 0.640
[7]  [120/1724] loss: 0.834, ave_loss: 0.668
[8]  [140/1724] loss: 0.613, ave_loss: 0.661
[9]  [160/1724] loss: 0.720, ave_loss: 0.668
[10]  [180/1724] loss: 0.641, ave_loss: 0.665
[11]  [200/1724] loss: 0.572, ave_loss: 0.657
[12]  [220/1724] loss: 0.826, ave_loss: 0.671
[13]  [240/1724] loss: 0.673, ave_loss: 0.671
[14]  [260/1724] loss: 0.586, ave_loss: 0.665
[15]  [280/1724] loss: 0.542, ave_loss: 0.657
[16]  [300/1724] loss: 0.597, ave_loss: 0.653
[17]  [320/1724] loss: 0.567, ave_loss: 0.648
[18]  [340/1724] loss: 0.745, ave_loss: 0.653
[19]  [360/1724] loss: 0.585, ave_loss: 0.650
[20]  [380/1724] loss: 0.760, ave_loss: 0.655
[21]  [400/1724] loss: 0.555, ave_loss: 0.650
[22]  [420/1724] loss: 0.722, ave_loss: 0.654
[23]  [440/1724] loss: 0.707, ave_loss: 0.656
[24]  [460/1724] loss: 0.611, ave_loss: 0.654
[25]  [480/1724] loss: 0.664, ave_loss: 0.655
[26]  [500/1724] loss: 0.768, ave_loss: 0.659
[27]  [520/1724] loss: 0.600, ave_loss: 0.657
[28]  [540/1724] loss: 0.687, ave_loss: 0.658
[29]  [560/1724] loss: 0.784, ave_loss: 0.662
[30]  [580/1724] loss: 0.780, ave_loss: 0.666
[31]  [600/1724] loss: 0.723, ave_loss: 0.668
[32]  [620/1724] loss: 0.562, ave_loss: 0.665
[33]  [640/1724] loss: 0.560, ave_loss: 0.661
[34]  [660/1724] loss: 0.540, ave_loss: 0.658
[35]  [680/1724] loss: 0.662, ave_loss: 0.658
[36]  [700/1724] loss: 0.750, ave_loss: 0.660
[37]  [720/1724] loss: 0.534, ave_loss: 0.657
[38]  [740/1724] loss: 0.745, ave_loss: 0.659
[39]  [760/1724] loss: 0.738, ave_loss: 0.661
[40]  [780/1724] loss: 0.667, ave_loss: 0.662
[41]  [800/1724] loss: 0.495, ave_loss: 0.657
[42]  [820/1724] loss: 0.647, ave_loss: 0.657
[43]  [840/1724] loss: 0.593, ave_loss: 0.656
[44]  [860/1724] loss: 0.728, ave_loss: 0.657
[45]  [880/1724] loss: 0.668, ave_loss: 0.658
[46]  [900/1724] loss: 0.604, ave_loss: 0.656
[47]  [920/1724] loss: 0.614, ave_loss: 0.656
[48]  [940/1724] loss: 0.715, ave_loss: 0.657
[49]  [960/1724] loss: 0.620, ave_loss: 0.656
[50]  [980/1724] loss: 0.645, ave_loss: 0.656
[51]  [1000/1724] loss: 0.759, ave_loss: 0.658
[52]  [1020/1724] loss: 0.704, ave_loss: 0.659
[53]  [1040/1724] loss: 0.724, ave_loss: 0.660
[54]  [1060/1724] loss: 0.636, ave_loss: 0.659
[55]  [1080/1724] loss: 0.587, ave_loss: 0.658
[56]  [1100/1724] loss: 0.673, ave_loss: 0.658
[57]  [1120/1724] loss: 0.667, ave_loss: 0.659
[58]  [1140/1724] loss: 0.590, ave_loss: 0.657
[59]  [1160/1724] loss: 0.536, ave_loss: 0.655
[60]  [1180/1724] loss: 0.671, ave_loss: 0.656
[61]  [1200/1724] loss: 0.624, ave_loss: 0.655
[62]  [1220/1724] loss: 0.547, ave_loss: 0.653
[63]  [1240/1724] loss: 0.534, ave_loss: 0.651
[64]  [1260/1724] loss: 0.636, ave_loss: 0.651
[65]  [1280/1724] loss: 0.572, ave_loss: 0.650
[66]  [1300/1724] loss: 0.602, ave_loss: 0.649
[67]  [1320/1724] loss: 0.667, ave_loss: 0.650
[68]  [1340/1724] loss: 0.418, ave_loss: 0.646
[69]  [1360/1724] loss: 0.642, ave_loss: 0.646
[70]  [1380/1724] loss: 0.601, ave_loss: 0.645
[71]  [1400/1724] loss: 0.727, ave_loss: 0.647
[72]  [1420/1724] loss: 0.583, ave_loss: 0.646
[73]  [1440/1724] loss: 0.785, ave_loss: 0.648
[74]  [1460/1724] loss: 0.574, ave_loss: 0.647
[75]  [1480/1724] loss: 0.619, ave_loss: 0.646
[76]  [1500/1724] loss: 0.601, ave_loss: 0.646
[77]  [1520/1724] loss: 0.592, ave_loss: 0.645
[78]  [1540/1724] loss: 0.749, ave_loss: 0.646
[79]  [1560/1724] loss: 0.797, ave_loss: 0.648
[80]  [1580/1724] loss: 0.596, ave_loss: 0.648
[81]  [1600/1724] loss: 0.667, ave_loss: 0.648
[82]  [1620/1724] loss: 0.754, ave_loss: 0.649
[83]  [1640/1724] loss: 0.605, ave_loss: 0.649
[84]  [1660/1724] loss: 0.543, ave_loss: 0.647
[85]  [1680/1724] loss: 0.626, ave_loss: 0.647
[86]  [1700/1724] loss: 0.562, ave_loss: 0.646
[87]  [1720/1724] loss: 0.622, ave_loss: 0.646
[88]  [1740/1724] loss: 0.460, ave_loss: 0.644

Finished Training finishing at 2021-08-24 22:33:37.260507
printing_out epoch  16.334106728538284 learning rate: 0.00029090509716114235
0.0002821779442463081
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.437e-01
Validation Loss: 5.584e-01
Validation ROC: 0.4309
No improvement, still saving model
82.66589327146171 epochs left to go

Training Epoch 16.334106728538284/100 starting at 2021-08-24 22:35:00.452703
[1]  [0/1724] loss: 0.694, ave_loss: 0.694
[2]  [20/1724] loss: 0.574, ave_loss: 0.634
[3]  [40/1724] loss: 0.706, ave_loss: 0.658
[4]  [60/1724] loss: 0.727, ave_loss: 0.675
[5]  [80/1724] loss: 0.658, ave_loss: 0.672
[6]  [100/1724] loss: 0.667, ave_loss: 0.671
[7]  [120/1724] loss: 0.450, ave_loss: 0.640
[8]  [140/1724] loss: 0.771, ave_loss: 0.656
[9]  [160/1724] loss: 0.740, ave_loss: 0.665
[10]  [180/1724] loss: 0.695, ave_loss: 0.668
[11]  [200/1724] loss: 0.551, ave_loss: 0.658
[12]  [220/1724] loss: 0.765, ave_loss: 0.666
[13]  [240/1724] loss: 0.592, ave_loss: 0.661
[14]  [260/1724] loss: 0.629, ave_loss: 0.658
[15]  [280/1724] loss: 0.695, ave_loss: 0.661
[16]  [300/1724] loss: 0.684, ave_loss: 0.662
[17]  [320/1724] loss: 0.621, ave_loss: 0.660
[18]  [340/1724] loss: 0.639, ave_loss: 0.659
[19]  [360/1724] loss: 0.689, ave_loss: 0.660
[20]  [380/1724] loss: 0.809, ave_loss: 0.668
[21]  [400/1724] loss: 0.704, ave_loss: 0.670
[22]  [420/1724] loss: 0.661, ave_loss: 0.669
[23]  [440/1724] loss: 0.739, ave_loss: 0.672
[24]  [460/1724] loss: 0.536, ave_loss: 0.666
[25]  [480/1724] loss: 0.762, ave_loss: 0.670
[26]  [500/1724] loss: 0.630, ave_loss: 0.669
[27]  [520/1724] loss: 0.704, ave_loss: 0.670
[28]  [540/1724] loss: 0.644, ave_loss: 0.669
[29]  [560/1724] loss: 0.740, ave_loss: 0.672
[30]  [580/1724] loss: 0.706, ave_loss: 0.673
[31]  [600/1724] loss: 0.562, ave_loss: 0.669
[32]  [620/1724] loss: 0.610, ave_loss: 0.667
[33]  [640/1724] loss: 0.608, ave_loss: 0.665
[34]  [660/1724] loss: 0.685, ave_loss: 0.666
[35]  [680/1724] loss: 0.702, ave_loss: 0.667
[36]  [700/1724] loss: 0.603, ave_loss: 0.665
[37]  [720/1724] loss: 0.697, ave_loss: 0.666
[38]  [740/1724] loss: 0.686, ave_loss: 0.667
[39]  [760/1724] loss: 0.517, ave_loss: 0.663
[40]  [780/1724] loss: 0.603, ave_loss: 0.661
[41]  [800/1724] loss: 0.702, ave_loss: 0.662
[42]  [820/1724] loss: 0.773, ave_loss: 0.665
[43]  [840/1724] loss: 0.715, ave_loss: 0.666
[44]  [860/1724] loss: 0.668, ave_loss: 0.666
[45]  [880/1724] loss: 0.653, ave_loss: 0.666
[46]  [900/1724] loss: 0.622, ave_loss: 0.665
[47]  [920/1724] loss: 0.668, ave_loss: 0.665
[48]  [940/1724] loss: 0.606, ave_loss: 0.664
[49]  [960/1724] loss: 0.626, ave_loss: 0.663
[50]  [980/1724] loss: 0.671, ave_loss: 0.663
[51]  [1000/1724] loss: 0.651, ave_loss: 0.663
[52]  [1020/1724] loss: 0.599, ave_loss: 0.662
[53]  [1040/1724] loss: 0.638, ave_loss: 0.661
[54]  [1060/1724] loss: 0.599, ave_loss: 0.660
[55]  [1080/1724] loss: 0.652, ave_loss: 0.660
[56]  [1100/1724] loss: 0.613, ave_loss: 0.659
[57]  [1120/1724] loss: 0.662, ave_loss: 0.659
[58]  [1140/1724] loss: 0.570, ave_loss: 0.658
[59]  [1160/1724] loss: 0.590, ave_loss: 0.656
[60]  [1180/1724] loss: 0.750, ave_loss: 0.658
[61]  [1200/1724] loss: 0.624, ave_loss: 0.657
[62]  [1220/1724] loss: 0.626, ave_loss: 0.657
[63]  [1240/1724] loss: 0.611, ave_loss: 0.656
[64]  [1260/1724] loss: 0.599, ave_loss: 0.655
[65]  [1280/1724] loss: 0.843, ave_loss: 0.658
[66]  [1300/1724] loss: 0.680, ave_loss: 0.659
[67]  [1320/1724] loss: 0.857, ave_loss: 0.662
[68]  [1340/1724] loss: 0.807, ave_loss: 0.664
[69]  [1360/1724] loss: 0.634, ave_loss: 0.663
[70]  [1380/1724] loss: 0.663, ave_loss: 0.663
[71]  [1400/1724] loss: 0.697, ave_loss: 0.664
[72]  [1420/1724] loss: 0.589, ave_loss: 0.663
[73]  [1440/1724] loss: 0.571, ave_loss: 0.661
[74]  [1460/1724] loss: 0.635, ave_loss: 0.661
[75]  [1480/1724] loss: 0.653, ave_loss: 0.661
[76]  [1500/1724] loss: 0.638, ave_loss: 0.661
[77]  [1520/1724] loss: 0.650, ave_loss: 0.661
[78]  [1540/1724] loss: 0.635, ave_loss: 0.660
[79]  [1560/1724] loss: 0.578, ave_loss: 0.659
[80]  [1580/1724] loss: 0.722, ave_loss: 0.660
[81]  [1600/1724] loss: 0.798, ave_loss: 0.662
[82]  [1620/1724] loss: 0.622, ave_loss: 0.661
[83]  [1640/1724] loss: 0.630, ave_loss: 0.661
[84]  [1660/1724] loss: 0.731, ave_loss: 0.662
[85]  [1680/1724] loss: 0.645, ave_loss: 0.661
[86]  [1700/1724] loss: 0.681, ave_loss: 0.662
[87]  [1720/1724] loss: 0.666, ave_loss: 0.662
[88]  [1740/1724] loss: 0.664, ave_loss: 0.662

Finished Training finishing at 2021-08-24 22:37:00.758273
printing_out epoch  17.354988399071924 learning rate: 0.00026445917923740214
0.0002565254038602801
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.617e-01
Validation Loss: 5.734e-01
Validation ROC: 0.4169
No improvement, still saving model
81.64501160092807 epochs left to go

Training Epoch 17.354988399071924/100 starting at 2021-08-24 22:37:34.343030
[1]  [0/1724] loss: 0.670, ave_loss: 0.670
[2]  [20/1724] loss: 0.652, ave_loss: 0.661
[3]  [40/1724] loss: 0.815, ave_loss: 0.712
[4]  [60/1724] loss: 0.628, ave_loss: 0.691
[5]  [80/1724] loss: 0.603, ave_loss: 0.674
[6]  [100/1724] loss: 0.553, ave_loss: 0.654
[7]  [120/1724] loss: 0.648, ave_loss: 0.653
[8]  [140/1724] loss: 0.643, ave_loss: 0.651
[9]  [160/1724] loss: 0.718, ave_loss: 0.659
[10]  [180/1724] loss: 0.688, ave_loss: 0.662
[11]  [200/1724] loss: 0.573, ave_loss: 0.654
[12]  [220/1724] loss: 0.912, ave_loss: 0.675
[13]  [240/1724] loss: 0.731, ave_loss: 0.680
[14]  [260/1724] loss: 0.608, ave_loss: 0.674
[15]  [280/1724] loss: 0.593, ave_loss: 0.669
[16]  [300/1724] loss: 0.575, ave_loss: 0.663
[17]  [320/1724] loss: 0.657, ave_loss: 0.663
[18]  [340/1724] loss: 0.536, ave_loss: 0.656
[19]  [360/1724] loss: 0.592, ave_loss: 0.652
[20]  [380/1724] loss: 0.665, ave_loss: 0.653
[21]  [400/1724] loss: 0.580, ave_loss: 0.650
[22]  [420/1724] loss: 0.646, ave_loss: 0.649
[23]  [440/1724] loss: 0.565, ave_loss: 0.646
[24]  [460/1724] loss: 0.712, ave_loss: 0.649
[25]  [480/1724] loss: 0.735, ave_loss: 0.652
[26]  [500/1724] loss: 0.623, ave_loss: 0.651
[27]  [520/1724] loss: 0.771, ave_loss: 0.655
[28]  [540/1724] loss: 0.662, ave_loss: 0.656
[29]  [560/1724] loss: 0.604, ave_loss: 0.654
[30]  [580/1724] loss: 0.830, ave_loss: 0.660
[31]  [600/1724] loss: 0.742, ave_loss: 0.662
[32]  [620/1724] loss: 0.735, ave_loss: 0.665
[33]  [640/1724] loss: 0.655, ave_loss: 0.664
[34]  [660/1724] loss: 0.685, ave_loss: 0.665
[35]  [680/1724] loss: 0.626, ave_loss: 0.664
[36]  [700/1724] loss: 0.582, ave_loss: 0.662
[37]  [720/1724] loss: 0.592, ave_loss: 0.660
[38]  [740/1724] loss: 0.491, ave_loss: 0.655
[39]  [760/1724] loss: 0.690, ave_loss: 0.656
[40]  [780/1724] loss: 0.590, ave_loss: 0.654
[41]  [800/1724] loss: 0.654, ave_loss: 0.654
[42]  [820/1724] loss: 0.733, ave_loss: 0.656
[43]  [840/1724] loss: 0.574, ave_loss: 0.654
[44]  [860/1724] loss: 0.610, ave_loss: 0.653
[45]  [880/1724] loss: 0.649, ave_loss: 0.653
[46]  [900/1724] loss: 0.695, ave_loss: 0.654
[47]  [920/1724] loss: 0.603, ave_loss: 0.653
[48]  [940/1724] loss: 0.661, ave_loss: 0.653
[49]  [960/1724] loss: 0.645, ave_loss: 0.653
[50]  [980/1724] loss: 0.606, ave_loss: 0.652
[51]  [1000/1724] loss: 0.697, ave_loss: 0.653
[52]  [1020/1724] loss: 0.557, ave_loss: 0.651
[53]  [1040/1724] loss: 0.783, ave_loss: 0.654
[54]  [1060/1724] loss: 0.752, ave_loss: 0.655
[55]  [1080/1724] loss: 0.784, ave_loss: 0.658
[56]  [1100/1724] loss: 0.727, ave_loss: 0.659
[57]  [1120/1724] loss: 0.674, ave_loss: 0.659
[58]  [1140/1724] loss: 0.666, ave_loss: 0.659
[59]  [1160/1724] loss: 0.737, ave_loss: 0.661
[60]  [1180/1724] loss: 0.630, ave_loss: 0.660
[61]  [1200/1724] loss: 0.628, ave_loss: 0.660
[62]  [1220/1724] loss: 0.662, ave_loss: 0.660
[63]  [1240/1724] loss: 0.705, ave_loss: 0.660
[64]  [1260/1724] loss: 0.615, ave_loss: 0.660
[65]  [1280/1724] loss: 0.629, ave_loss: 0.659
[66]  [1300/1724] loss: 0.710, ave_loss: 0.660
[67]  [1320/1724] loss: 0.563, ave_loss: 0.659
[68]  [1340/1724] loss: 0.670, ave_loss: 0.659
[69]  [1360/1724] loss: 0.679, ave_loss: 0.659
[70]  [1380/1724] loss: 0.595, ave_loss: 0.658
[71]  [1400/1724] loss: 0.557, ave_loss: 0.657
[72]  [1420/1724] loss: 0.687, ave_loss: 0.657
[73]  [1440/1724] loss: 0.560, ave_loss: 0.656
[74]  [1460/1724] loss: 0.547, ave_loss: 0.654
[75]  [1480/1724] loss: 0.643, ave_loss: 0.654
[76]  [1500/1724] loss: 0.604, ave_loss: 0.653
[77]  [1520/1724] loss: 0.517, ave_loss: 0.652
[78]  [1540/1724] loss: 0.608, ave_loss: 0.651
[79]  [1560/1724] loss: 0.732, ave_loss: 0.652
[80]  [1580/1724] loss: 0.550, ave_loss: 0.651
[81]  [1600/1724] loss: 0.455, ave_loss: 0.648
[82]  [1620/1724] loss: 0.749, ave_loss: 0.650
[83]  [1640/1724] loss: 0.666, ave_loss: 0.650
[84]  [1660/1724] loss: 0.716, ave_loss: 0.651
[85]  [1680/1724] loss: 0.633, ave_loss: 0.650
[86]  [1700/1724] loss: 0.581, ave_loss: 0.650
[87]  [1720/1724] loss: 0.565, ave_loss: 0.649
[88]  [1740/1724] loss: 0.589, ave_loss: 0.648

Finished Training finishing at 2021-08-24 22:39:33.699594
printing_out epoch  18.37587006960557 learning rate: 0.00024041743567036557
0.0002332049126002546
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.480e-01
Validation Loss: 5.600e-01
Validation ROC: 0.4095
No improvement, still saving model
80.62412993039443 epochs left to go

Training Epoch 18.37587006960557/100 starting at 2021-08-24 22:40:08.705107
[1]  [0/1724] loss: 0.500, ave_loss: 0.500
[2]  [20/1724] loss: 0.690, ave_loss: 0.595
[3]  [40/1724] loss: 0.591, ave_loss: 0.594
[4]  [60/1724] loss: 0.625, ave_loss: 0.601
[5]  [80/1724] loss: 0.601, ave_loss: 0.601
[6]  [100/1724] loss: 0.667, ave_loss: 0.612
[7]  [120/1724] loss: 0.681, ave_loss: 0.622
[8]  [140/1724] loss: 0.735, ave_loss: 0.636
[9]  [160/1724] loss: 0.592, ave_loss: 0.631
[10]  [180/1724] loss: 0.670, ave_loss: 0.635
[11]  [200/1724] loss: 0.703, ave_loss: 0.641
[12]  [220/1724] loss: 0.714, ave_loss: 0.647
[13]  [240/1724] loss: 0.749, ave_loss: 0.655
[14]  [260/1724] loss: 0.591, ave_loss: 0.651
[15]  [280/1724] loss: 0.753, ave_loss: 0.657
[16]  [300/1724] loss: 0.586, ave_loss: 0.653
[17]  [320/1724] loss: 0.715, ave_loss: 0.657
[18]  [340/1724] loss: 0.682, ave_loss: 0.658
[19]  [360/1724] loss: 0.692, ave_loss: 0.660
[20]  [380/1724] loss: 0.750, ave_loss: 0.664
[21]  [400/1724] loss: 0.862, ave_loss: 0.674
[22]  [420/1724] loss: 0.675, ave_loss: 0.674
[23]  [440/1724] loss: 0.658, ave_loss: 0.673
[24]  [460/1724] loss: 0.613, ave_loss: 0.671
[25]  [480/1724] loss: 0.599, ave_loss: 0.668
[26]  [500/1724] loss: 0.567, ave_loss: 0.664
[27]  [520/1724] loss: 0.686, ave_loss: 0.665
[28]  [540/1724] loss: 0.735, ave_loss: 0.667
[29]  [560/1724] loss: 0.596, ave_loss: 0.665
[30]  [580/1724] loss: 0.661, ave_loss: 0.665
[31]  [600/1724] loss: 0.671, ave_loss: 0.665
[32]  [620/1724] loss: 0.675, ave_loss: 0.665
[33]  [640/1724] loss: 0.725, ave_loss: 0.667
[34]  [660/1724] loss: 0.636, ave_loss: 0.666
[35]  [680/1724] loss: 0.710, ave_loss: 0.667
[36]  [700/1724] loss: 0.663, ave_loss: 0.667
[37]  [720/1724] loss: 0.671, ave_loss: 0.667
[38]  [740/1724] loss: 0.588, ave_loss: 0.665
[39]  [760/1724] loss: 0.612, ave_loss: 0.664
[40]  [780/1724] loss: 0.646, ave_loss: 0.663
[41]  [800/1724] loss: 0.602, ave_loss: 0.662
[42]  [820/1724] loss: 0.632, ave_loss: 0.661
[43]  [840/1724] loss: 0.582, ave_loss: 0.659
[44]  [860/1724] loss: 0.631, ave_loss: 0.659
[45]  [880/1724] loss: 0.686, ave_loss: 0.659
[46]  [900/1724] loss: 0.721, ave_loss: 0.661
[47]  [920/1724] loss: 0.602, ave_loss: 0.659
[48]  [940/1724] loss: 0.618, ave_loss: 0.658
[49]  [960/1724] loss: 0.703, ave_loss: 0.659
[50]  [980/1724] loss: 0.647, ave_loss: 0.659
[51]  [1000/1724] loss: 0.613, ave_loss: 0.658
[52]  [1020/1724] loss: 0.627, ave_loss: 0.658
[53]  [1040/1724] loss: 0.780, ave_loss: 0.660
[54]  [1060/1724] loss: 0.516, ave_loss: 0.657
[55]  [1080/1724] loss: 0.723, ave_loss: 0.658
[56]  [1100/1724] loss: 0.551, ave_loss: 0.657
[57]  [1120/1724] loss: 0.597, ave_loss: 0.656
[58]  [1140/1724] loss: 0.661, ave_loss: 0.656
[59]  [1160/1724] loss: 0.844, ave_loss: 0.659
[60]  [1180/1724] loss: 0.623, ave_loss: 0.658
[61]  [1200/1724] loss: 0.817, ave_loss: 0.661
[62]  [1220/1724] loss: 0.568, ave_loss: 0.659
[63]  [1240/1724] loss: 0.582, ave_loss: 0.658
[64]  [1260/1724] loss: 0.614, ave_loss: 0.657
[65]  [1280/1724] loss: 0.722, ave_loss: 0.658
[66]  [1300/1724] loss: 0.656, ave_loss: 0.658
[67]  [1320/1724] loss: 0.725, ave_loss: 0.659
[68]  [1340/1724] loss: 0.717, ave_loss: 0.660
[69]  [1360/1724] loss: 0.606, ave_loss: 0.659
[70]  [1380/1724] loss: 0.596, ave_loss: 0.659
[71]  [1400/1724] loss: 0.683, ave_loss: 0.659
[72]  [1420/1724] loss: 0.616, ave_loss: 0.658
[73]  [1440/1724] loss: 0.675, ave_loss: 0.658
[74]  [1460/1724] loss: 0.633, ave_loss: 0.658
[75]  [1480/1724] loss: 0.606, ave_loss: 0.657
[76]  [1500/1724] loss: 0.640, ave_loss: 0.657
[77]  [1520/1724] loss: 0.543, ave_loss: 0.656
[78]  [1540/1724] loss: 0.572, ave_loss: 0.655
[79]  [1560/1724] loss: 0.571, ave_loss: 0.654
[80]  [1580/1724] loss: 0.641, ave_loss: 0.653
[81]  [1600/1724] loss: 0.659, ave_loss: 0.654
[82]  [1620/1724] loss: 0.618, ave_loss: 0.653
[83]  [1640/1724] loss: 0.539, ave_loss: 0.652
[84]  [1660/1724] loss: 0.794, ave_loss: 0.653
[85]  [1680/1724] loss: 0.616, ave_loss: 0.653
[86]  [1700/1724] loss: 0.599, ave_loss: 0.652
[87]  [1720/1724] loss: 0.727, ave_loss: 0.653
[88]  [1740/1724] loss: 0.759, ave_loss: 0.654

Finished Training finishing at 2021-08-24 22:42:16.903234
printing_out epoch  19.396751740139212 learning rate: 0.00021856130515487778
0.00021200446600023144
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.544e-01
Validation Loss: 5.666e-01
Validation ROC: 0.3997
No improvement, still saving model
79.60324825986079 epochs left to go

Training Epoch 19.396751740139212/100 starting at 2021-08-24 22:43:29.261521
[1]  [0/1724] loss: 0.598, ave_loss: 0.598
[2]  [20/1724] loss: 0.629, ave_loss: 0.613
[3]  [40/1724] loss: 0.680, ave_loss: 0.636
[4]  [60/1724] loss: 0.712, ave_loss: 0.655
[5]  [80/1724] loss: 0.582, ave_loss: 0.640
[6]  [100/1724] loss: 0.494, ave_loss: 0.616
[7]  [120/1724] loss: 0.665, ave_loss: 0.623
[8]  [140/1724] loss: 0.742, ave_loss: 0.638
[9]  [160/1724] loss: 0.785, ave_loss: 0.654
[10]  [180/1724] loss: 0.582, ave_loss: 0.647
[11]  [200/1724] loss: 0.651, ave_loss: 0.647
[12]  [220/1724] loss: 0.651, ave_loss: 0.648
[13]  [240/1724] loss: 0.704, ave_loss: 0.652
[14]  [260/1724] loss: 0.704, ave_loss: 0.656
[15]  [280/1724] loss: 0.571, ave_loss: 0.650
[16]  [300/1724] loss: 0.736, ave_loss: 0.655
[17]  [320/1724] loss: 0.525, ave_loss: 0.648
[18]  [340/1724] loss: 0.723, ave_loss: 0.652
[19]  [360/1724] loss: 0.601, ave_loss: 0.649
[20]  [380/1724] loss: 0.649, ave_loss: 0.649
[21]  [400/1724] loss: 0.530, ave_loss: 0.644
[22]  [420/1724] loss: 0.547, ave_loss: 0.639
[23]  [440/1724] loss: 0.687, ave_loss: 0.641
[24]  [460/1724] loss: 0.689, ave_loss: 0.643
[25]  [480/1724] loss: 0.723, ave_loss: 0.646
[26]  [500/1724] loss: 0.678, ave_loss: 0.648
[27]  [520/1724] loss: 0.603, ave_loss: 0.646
[28]  [540/1724] loss: 0.606, ave_loss: 0.645
[29]  [560/1724] loss: 0.570, ave_loss: 0.642
[30]  [580/1724] loss: 0.576, ave_loss: 0.640
[31]  [600/1724] loss: 0.717, ave_loss: 0.642
[32]  [620/1724] loss: 0.702, ave_loss: 0.644
[33]  [640/1724] loss: 0.585, ave_loss: 0.642
[34]  [660/1724] loss: 0.644, ave_loss: 0.642
[35]  [680/1724] loss: 0.622, ave_loss: 0.642
[36]  [700/1724] loss: 0.712, ave_loss: 0.644
[37]  [720/1724] loss: 0.583, ave_loss: 0.642
[38]  [740/1724] loss: 0.566, ave_loss: 0.640
[39]  [760/1724] loss: 0.650, ave_loss: 0.640
[40]  [780/1724] loss: 0.650, ave_loss: 0.641
[41]  [800/1724] loss: 0.608, ave_loss: 0.640
[42]  [820/1724] loss: 0.637, ave_loss: 0.640
[43]  [840/1724] loss: 0.645, ave_loss: 0.640
[44]  [860/1724] loss: 0.687, ave_loss: 0.641
[45]  [880/1724] loss: 0.595, ave_loss: 0.640
[46]  [900/1724] loss: 0.725, ave_loss: 0.642
[47]  [920/1724] loss: 0.620, ave_loss: 0.641
[48]  [940/1724] loss: 0.646, ave_loss: 0.641
[49]  [960/1724] loss: 0.622, ave_loss: 0.641
[50]  [980/1724] loss: 0.606, ave_loss: 0.640
[51]  [1000/1724] loss: 0.616, ave_loss: 0.640
[52]  [1020/1724] loss: 0.691, ave_loss: 0.641
[53]  [1040/1724] loss: 0.607, ave_loss: 0.640
[54]  [1060/1724] loss: 0.615, ave_loss: 0.640
[55]  [1080/1724] loss: 0.726, ave_loss: 0.641
[56]  [1100/1724] loss: 0.765, ave_loss: 0.644
[57]  [1120/1724] loss: 0.575, ave_loss: 0.642
[58]  [1140/1724] loss: 0.753, ave_loss: 0.644
[59]  [1160/1724] loss: 0.461, ave_loss: 0.641
[60]  [1180/1724] loss: 0.682, ave_loss: 0.642
[61]  [1200/1724] loss: 0.746, ave_loss: 0.644
[62]  [1220/1724] loss: 0.623, ave_loss: 0.643
[63]  [1240/1724] loss: 0.742, ave_loss: 0.645
[64]  [1260/1724] loss: 0.676, ave_loss: 0.645
[65]  [1280/1724] loss: 0.561, ave_loss: 0.644
[66]  [1300/1724] loss: 0.739, ave_loss: 0.645
[67]  [1320/1724] loss: 0.526, ave_loss: 0.644
[68]  [1340/1724] loss: 0.668, ave_loss: 0.644
[69]  [1360/1724] loss: 0.628, ave_loss: 0.644
[70]  [1380/1724] loss: 0.556, ave_loss: 0.642
[71]  [1400/1724] loss: 0.716, ave_loss: 0.644
[72]  [1420/1724] loss: 0.562, ave_loss: 0.642
[73]  [1440/1724] loss: 0.525, ave_loss: 0.641
[74]  [1460/1724] loss: 0.564, ave_loss: 0.640
[75]  [1480/1724] loss: 0.684, ave_loss: 0.640
[76]  [1500/1724] loss: 0.482, ave_loss: 0.638
[77]  [1520/1724] loss: 0.753, ave_loss: 0.640
[78]  [1540/1724] loss: 0.778, ave_loss: 0.642
[79]  [1560/1724] loss: 0.775, ave_loss: 0.643
[80]  [1580/1724] loss: 0.705, ave_loss: 0.644
[81]  [1600/1724] loss: 0.584, ave_loss: 0.643
[82]  [1620/1724] loss: 0.621, ave_loss: 0.643
[83]  [1640/1724] loss: 0.789, ave_loss: 0.645
[84]  [1660/1724] loss: 0.636, ave_loss: 0.645
[85]  [1680/1724] loss: 0.614, ave_loss: 0.644
[86]  [1700/1724] loss: 0.677, ave_loss: 0.645
[87]  [1720/1724] loss: 0.704, ave_loss: 0.645
[88]  [1740/1724] loss: 0.626, ave_loss: 0.645

Finished Training finishing at 2021-08-24 22:45:32.270416
printing_out epoch  20.417633410672853 learning rate: 0.00019869209559534342
0.00019273133272748312
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.451e-01
Validation Loss: 5.614e-01
Validation ROC: 0.3945
No improvement, still saving model
78.58236658932715 epochs left to go

Training Epoch 20.417633410672853/100 starting at 2021-08-24 22:46:07.719075
[1]  [0/1724] loss: 0.712, ave_loss: 0.712
[2]  [20/1724] loss: 0.678, ave_loss: 0.695
[3]  [40/1724] loss: 0.722, ave_loss: 0.704
[4]  [60/1724] loss: 0.783, ave_loss: 0.724
[5]  [80/1724] loss: 0.610, ave_loss: 0.701
[6]  [100/1724] loss: 0.639, ave_loss: 0.691
[7]  [120/1724] loss: 0.723, ave_loss: 0.695
[8]  [140/1724] loss: 0.528, ave_loss: 0.674
[9]  [160/1724] loss: 0.630, ave_loss: 0.669
[10]  [180/1724] loss: 0.604, ave_loss: 0.663
[11]  [200/1724] loss: 0.689, ave_loss: 0.665
[12]  [220/1724] loss: 0.788, ave_loss: 0.676
[13]  [240/1724] loss: 0.691, ave_loss: 0.677
[14]  [260/1724] loss: 0.645, ave_loss: 0.674
[15]  [280/1724] loss: 0.588, ave_loss: 0.669
[16]  [300/1724] loss: 0.544, ave_loss: 0.661
[17]  [320/1724] loss: 0.589, ave_loss: 0.657
[18]  [340/1724] loss: 0.617, ave_loss: 0.654
[19]  [360/1724] loss: 0.604, ave_loss: 0.652
[20]  [380/1724] loss: 0.614, ave_loss: 0.650
[21]  [400/1724] loss: 0.588, ave_loss: 0.647
[22]  [420/1724] loss: 0.577, ave_loss: 0.644
[23]  [440/1724] loss: 0.716, ave_loss: 0.647
[24]  [460/1724] loss: 0.597, ave_loss: 0.645
[25]  [480/1724] loss: 0.544, ave_loss: 0.641
[26]  [500/1724] loss: 0.594, ave_loss: 0.639
[27]  [520/1724] loss: 0.710, ave_loss: 0.642
[28]  [540/1724] loss: 0.679, ave_loss: 0.643
[29]  [560/1724] loss: 0.644, ave_loss: 0.643
[30]  [580/1724] loss: 0.574, ave_loss: 0.641
[31]  [600/1724] loss: 0.610, ave_loss: 0.640
[32]  [620/1724] loss: 0.612, ave_loss: 0.639
[33]  [640/1724] loss: 0.596, ave_loss: 0.638
[34]  [660/1724] loss: 0.678, ave_loss: 0.639
[35]  [680/1724] loss: 0.750, ave_loss: 0.642
[36]  [700/1724] loss: 0.564, ave_loss: 0.640
[37]  [720/1724] loss: 0.605, ave_loss: 0.639
[38]  [740/1724] loss: 0.650, ave_loss: 0.639
[39]  [760/1724] loss: 0.751, ave_loss: 0.642
[40]  [780/1724] loss: 0.702, ave_loss: 0.643
[41]  [800/1724] loss: 0.603, ave_loss: 0.643
[42]  [820/1724] loss: 0.643, ave_loss: 0.643
[43]  [840/1724] loss: 0.665, ave_loss: 0.643
[44]  [860/1724] loss: 0.602, ave_loss: 0.642
[45]  [880/1724] loss: 0.666, ave_loss: 0.643
[46]  [900/1724] loss: 0.715, ave_loss: 0.644
[47]  [920/1724] loss: 0.731, ave_loss: 0.646
[48]  [940/1724] loss: 0.687, ave_loss: 0.647
[49]  [960/1724] loss: 0.746, ave_loss: 0.649
[50]  [980/1724] loss: 0.787, ave_loss: 0.652
[51]  [1000/1724] loss: 0.648, ave_loss: 0.652
[52]  [1020/1724] loss: 0.806, ave_loss: 0.655
[53]  [1040/1724] loss: 0.624, ave_loss: 0.654
[54]  [1060/1724] loss: 0.797, ave_loss: 0.657
[55]  [1080/1724] loss: 0.739, ave_loss: 0.658
[56]  [1100/1724] loss: 0.608, ave_loss: 0.657
[57]  [1120/1724] loss: 0.569, ave_loss: 0.656
[58]  [1140/1724] loss: 0.680, ave_loss: 0.656
[59]  [1160/1724] loss: 0.620, ave_loss: 0.656
[60]  [1180/1724] loss: 0.701, ave_loss: 0.656
[61]  [1200/1724] loss: 0.624, ave_loss: 0.656
[62]  [1220/1724] loss: 0.590, ave_loss: 0.655
[63]  [1240/1724] loss: 0.682, ave_loss: 0.655
[64]  [1260/1724] loss: 0.729, ave_loss: 0.656
[65]  [1280/1724] loss: 0.660, ave_loss: 0.656
[66]  [1300/1724] loss: 0.787, ave_loss: 0.658
[67]  [1320/1724] loss: 0.698, ave_loss: 0.659
[68]  [1340/1724] loss: 0.545, ave_loss: 0.657
[69]  [1360/1724] loss: 0.665, ave_loss: 0.657
[70]  [1380/1724] loss: 0.648, ave_loss: 0.657
[71]  [1400/1724] loss: 0.675, ave_loss: 0.657
[72]  [1420/1724] loss: 0.674, ave_loss: 0.658
[73]  [1440/1724] loss: 0.624, ave_loss: 0.657
[74]  [1460/1724] loss: 0.742, ave_loss: 0.658
[75]  [1480/1724] loss: 0.550, ave_loss: 0.657
[76]  [1500/1724] loss: 0.669, ave_loss: 0.657
[77]  [1520/1724] loss: 0.694, ave_loss: 0.658
[78]  [1540/1724] loss: 0.684, ave_loss: 0.658
[79]  [1560/1724] loss: 0.760, ave_loss: 0.659
[80]  [1580/1724] loss: 0.718, ave_loss: 0.660
[81]  [1600/1724] loss: 0.741, ave_loss: 0.661
[82]  [1620/1724] loss: 0.589, ave_loss: 0.660
[83]  [1640/1724] loss: 0.733, ave_loss: 0.661
[84]  [1660/1724] loss: 0.595, ave_loss: 0.660
[85]  [1680/1724] loss: 0.682, ave_loss: 0.660
[86]  [1700/1724] loss: 0.567, ave_loss: 0.659
[87]  [1720/1724] loss: 0.647, ave_loss: 0.659
[88]  [1740/1724] loss: 0.681, ave_loss: 0.659

Finished Training finishing at 2021-08-24 22:48:03.105588
printing_out epoch  21.438515081206496 learning rate: 0.00018062917781394856
0.0001752103024795301
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.595e-01
Validation Loss: 5.931e-01
Validation ROC: 0.3826
No improvement, still saving model
77.5614849187935 epochs left to go

Training Epoch 21.438515081206496/100 starting at 2021-08-24 22:49:38.539212
[1]  [0/1724] loss: 0.684, ave_loss: 0.684
[2]  [20/1724] loss: 0.748, ave_loss: 0.716
[3]  [40/1724] loss: 0.537, ave_loss: 0.656
[4]  [60/1724] loss: 0.625, ave_loss: 0.649
[5]  [80/1724] loss: 0.625, ave_loss: 0.644
[6]  [100/1724] loss: 0.712, ave_loss: 0.655
[7]  [120/1724] loss: 0.649, ave_loss: 0.654
[8]  [140/1724] loss: 0.655, ave_loss: 0.654
[9]  [160/1724] loss: 0.713, ave_loss: 0.661
[10]  [180/1724] loss: 0.662, ave_loss: 0.661
[11]  [200/1724] loss: 0.667, ave_loss: 0.662
[12]  [220/1724] loss: 0.565, ave_loss: 0.653
[13]  [240/1724] loss: 0.566, ave_loss: 0.647
[14]  [260/1724] loss: 0.618, ave_loss: 0.645
[15]  [280/1724] loss: 0.640, ave_loss: 0.644
[16]  [300/1724] loss: 0.646, ave_loss: 0.644
[17]  [320/1724] loss: 0.645, ave_loss: 0.645
[18]  [340/1724] loss: 0.518, ave_loss: 0.637
[19]  [360/1724] loss: 0.644, ave_loss: 0.638
[20]  [380/1724] loss: 0.790, ave_loss: 0.645
[21]  [400/1724] loss: 0.624, ave_loss: 0.644
[22]  [420/1724] loss: 0.614, ave_loss: 0.643
[23]  [440/1724] loss: 0.656, ave_loss: 0.644
[24]  [460/1724] loss: 0.737, ave_loss: 0.647
[25]  [480/1724] loss: 0.659, ave_loss: 0.648
[26]  [500/1724] loss: 0.643, ave_loss: 0.648
[27]  [520/1724] loss: 0.708, ave_loss: 0.650
[28]  [540/1724] loss: 0.603, ave_loss: 0.648
[29]  [560/1724] loss: 0.672, ave_loss: 0.649
[30]  [580/1724] loss: 0.578, ave_loss: 0.647
[31]  [600/1724] loss: 0.648, ave_loss: 0.647
[32]  [620/1724] loss: 0.546, ave_loss: 0.644
[33]  [640/1724] loss: 0.675, ave_loss: 0.645
[34]  [660/1724] loss: 0.633, ave_loss: 0.644
[35]  [680/1724] loss: 0.710, ave_loss: 0.646
[36]  [700/1724] loss: 0.571, ave_loss: 0.644
[37]  [720/1724] loss: 0.577, ave_loss: 0.642
[38]  [740/1724] loss: 0.643, ave_loss: 0.642
[39]  [760/1724] loss: 0.649, ave_loss: 0.642
[40]  [780/1724] loss: 0.550, ave_loss: 0.640
[41]  [800/1724] loss: 0.792, ave_loss: 0.644
[42]  [820/1724] loss: 0.775, ave_loss: 0.647
[43]  [840/1724] loss: 0.568, ave_loss: 0.645
[44]  [860/1724] loss: 0.587, ave_loss: 0.644
[45]  [880/1724] loss: 0.661, ave_loss: 0.644
[46]  [900/1724] loss: 0.740, ave_loss: 0.646
[47]  [920/1724] loss: 0.578, ave_loss: 0.645
[48]  [940/1724] loss: 0.654, ave_loss: 0.645
[49]  [960/1724] loss: 0.631, ave_loss: 0.645
[50]  [980/1724] loss: 0.643, ave_loss: 0.645
[51]  [1000/1724] loss: 0.631, ave_loss: 0.644
[52]  [1020/1724] loss: 0.710, ave_loss: 0.646
[53]  [1040/1724] loss: 0.756, ave_loss: 0.648
[54]  [1060/1724] loss: 0.514, ave_loss: 0.645
[55]  [1080/1724] loss: 0.654, ave_loss: 0.645
[56]  [1100/1724] loss: 0.553, ave_loss: 0.644
[57]  [1120/1724] loss: 0.748, ave_loss: 0.646
[58]  [1140/1724] loss: 0.557, ave_loss: 0.644
[59]  [1160/1724] loss: 0.633, ave_loss: 0.644
[60]  [1180/1724] loss: 0.589, ave_loss: 0.643
[61]  [1200/1724] loss: 0.701, ave_loss: 0.644
[62]  [1220/1724] loss: 0.621, ave_loss: 0.644
[63]  [1240/1724] loss: 0.735, ave_loss: 0.645
[64]  [1260/1724] loss: 0.643, ave_loss: 0.645
[65]  [1280/1724] loss: 0.583, ave_loss: 0.644
[66]  [1300/1724] loss: 0.796, ave_loss: 0.646
[67]  [1320/1724] loss: 0.710, ave_loss: 0.647
[68]  [1340/1724] loss: 0.569, ave_loss: 0.646
[69]  [1360/1724] loss: 0.738, ave_loss: 0.648
[70]  [1380/1724] loss: 0.813, ave_loss: 0.650
[71]  [1400/1724] loss: 0.643, ave_loss: 0.650
[72]  [1420/1724] loss: 0.684, ave_loss: 0.650
[73]  [1440/1724] loss: 0.638, ave_loss: 0.650
[74]  [1460/1724] loss: 0.682, ave_loss: 0.651
[75]  [1480/1724] loss: 0.768, ave_loss: 0.652
[76]  [1500/1724] loss: 0.539, ave_loss: 0.651
[77]  [1520/1724] loss: 0.852, ave_loss: 0.653
[78]  [1540/1724] loss: 0.897, ave_loss: 0.656
[79]  [1560/1724] loss: 0.684, ave_loss: 0.657
[80]  [1580/1724] loss: 0.615, ave_loss: 0.656
[81]  [1600/1724] loss: 0.699, ave_loss: 0.657
[82]  [1620/1724] loss: 0.662, ave_loss: 0.657
[83]  [1640/1724] loss: 0.618, ave_loss: 0.656
[84]  [1660/1724] loss: 0.776, ave_loss: 0.658
[85]  [1680/1724] loss: 0.543, ave_loss: 0.656
[86]  [1700/1724] loss: 0.550, ave_loss: 0.655
[87]  [1720/1724] loss: 0.570, ave_loss: 0.654
[88]  [1740/1724] loss: 0.634, ave_loss: 0.654

Finished Training finishing at 2021-08-24 22:51:48.052797
printing_out epoch  22.45939675174014 learning rate: 0.00016420834346722596
0.00015928209316320917
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.540e-01
Validation Loss: 5.841e-01
Validation ROC: 0.3811
No improvement, still saving model
76.54060324825986 epochs left to go

Training Epoch 22.45939675174014/100 starting at 2021-08-24 22:52:18.938579
[1]  [0/1724] loss: 0.641, ave_loss: 0.641
[2]  [20/1724] loss: 0.696, ave_loss: 0.668
[3]  [40/1724] loss: 0.556, ave_loss: 0.631
[4]  [60/1724] loss: 0.628, ave_loss: 0.630
[5]  [80/1724] loss: 0.680, ave_loss: 0.640
[6]  [100/1724] loss: 0.523, ave_loss: 0.621
[7]  [120/1724] loss: 0.750, ave_loss: 0.639
[8]  [140/1724] loss: 0.692, ave_loss: 0.646
[9]  [160/1724] loss: 0.625, ave_loss: 0.643
[10]  [180/1724] loss: 0.604, ave_loss: 0.639
[11]  [200/1724] loss: 0.576, ave_loss: 0.634
[12]  [220/1724] loss: 0.619, ave_loss: 0.632
[13]  [240/1724] loss: 0.652, ave_loss: 0.634
[14]  [260/1724] loss: 0.694, ave_loss: 0.638
[15]  [280/1724] loss: 0.620, ave_loss: 0.637
[16]  [300/1724] loss: 0.760, ave_loss: 0.645
[17]  [320/1724] loss: 0.563, ave_loss: 0.640
[18]  [340/1724] loss: 0.781, ave_loss: 0.648
[19]  [360/1724] loss: 0.716, ave_loss: 0.651
[20]  [380/1724] loss: 0.745, ave_loss: 0.656
[21]  [400/1724] loss: 0.737, ave_loss: 0.660
[22]  [420/1724] loss: 0.738, ave_loss: 0.663
[23]  [440/1724] loss: 0.667, ave_loss: 0.664
[24]  [460/1724] loss: 0.604, ave_loss: 0.661
[25]  [480/1724] loss: 0.560, ave_loss: 0.657
[26]  [500/1724] loss: 0.666, ave_loss: 0.657
[27]  [520/1724] loss: 0.669, ave_loss: 0.658
[28]  [540/1724] loss: 0.688, ave_loss: 0.659
[29]  [560/1724] loss: 0.716, ave_loss: 0.661
[30]  [580/1724] loss: 0.635, ave_loss: 0.660
[31]  [600/1724] loss: 0.734, ave_loss: 0.662
[32]  [620/1724] loss: 0.675, ave_loss: 0.663
[33]  [640/1724] loss: 0.697, ave_loss: 0.664
[34]  [660/1724] loss: 0.581, ave_loss: 0.661
[35]  [680/1724] loss: 0.686, ave_loss: 0.662
[36]  [700/1724] loss: 0.545, ave_loss: 0.659
[37]  [720/1724] loss: 0.550, ave_loss: 0.656
[38]  [740/1724] loss: 0.629, ave_loss: 0.655
[39]  [760/1724] loss: 0.758, ave_loss: 0.658
[40]  [780/1724] loss: 0.612, ave_loss: 0.657
[41]  [800/1724] loss: 0.665, ave_loss: 0.657
[42]  [820/1724] loss: 0.710, ave_loss: 0.658
[43]  [840/1724] loss: 0.562, ave_loss: 0.656
[44]  [860/1724] loss: 0.582, ave_loss: 0.654
[45]  [880/1724] loss: 0.644, ave_loss: 0.654
[46]  [900/1724] loss: 0.637, ave_loss: 0.654
[47]  [920/1724] loss: 0.629, ave_loss: 0.653
[48]  [940/1724] loss: 0.635, ave_loss: 0.653
[49]  [960/1724] loss: 0.702, ave_loss: 0.654
[50]  [980/1724] loss: 0.559, ave_loss: 0.652
[51]  [1000/1724] loss: 0.489, ave_loss: 0.649
[52]  [1020/1724] loss: 0.604, ave_loss: 0.648
[53]  [1040/1724] loss: 0.605, ave_loss: 0.647
[54]  [1060/1724] loss: 0.655, ave_loss: 0.647
[55]  [1080/1724] loss: 0.601, ave_loss: 0.646
[56]  [1100/1724] loss: 0.715, ave_loss: 0.648
[57]  [1120/1724] loss: 0.650, ave_loss: 0.648
[58]  [1140/1724] loss: 0.622, ave_loss: 0.647
[59]  [1160/1724] loss: 0.508, ave_loss: 0.645
[60]  [1180/1724] loss: 0.609, ave_loss: 0.644
[61]  [1200/1724] loss: 0.564, ave_loss: 0.643
[62]  [1220/1724] loss: 0.607, ave_loss: 0.642
[63]  [1240/1724] loss: 0.598, ave_loss: 0.642
[64]  [1260/1724] loss: 0.565, ave_loss: 0.640
[65]  [1280/1724] loss: 0.743, ave_loss: 0.642
[66]  [1300/1724] loss: 0.657, ave_loss: 0.642
[67]  [1320/1724] loss: 0.673, ave_loss: 0.643
[68]  [1340/1724] loss: 0.559, ave_loss: 0.641
[69]  [1360/1724] loss: 0.544, ave_loss: 0.640
[70]  [1380/1724] loss: 0.552, ave_loss: 0.639
[71]  [1400/1724] loss: 0.620, ave_loss: 0.638
[72]  [1420/1724] loss: 0.761, ave_loss: 0.640
[73]  [1440/1724] loss: 0.621, ave_loss: 0.640
[74]  [1460/1724] loss: 0.686, ave_loss: 0.641
[75]  [1480/1724] loss: 0.704, ave_loss: 0.641
[76]  [1500/1724] loss: 0.583, ave_loss: 0.641
[77]  [1520/1724] loss: 0.630, ave_loss: 0.640
[78]  [1540/1724] loss: 0.653, ave_loss: 0.641
[79]  [1560/1724] loss: 0.552, ave_loss: 0.640
[80]  [1580/1724] loss: 0.582, ave_loss: 0.639
[81]  [1600/1724] loss: 0.477, ave_loss: 0.637
[82]  [1620/1724] loss: 0.692, ave_loss: 0.637
[83]  [1640/1724] loss: 0.736, ave_loss: 0.639
[84]  [1660/1724] loss: 0.694, ave_loss: 0.639
[85]  [1680/1724] loss: 0.567, ave_loss: 0.638
[86]  [1700/1724] loss: 0.627, ave_loss: 0.638
[87]  [1720/1724] loss: 0.652, ave_loss: 0.638
[88]  [1740/1724] loss: 0.607, ave_loss: 0.638

Finished Training finishing at 2021-08-24 22:54:20.317861
printing_out epoch  23.48027842227378 learning rate: 0.0001492803122429327
0.0001448019028756447
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.381e-01
Validation Loss: 5.565e-01
Validation ROC: 0.3875
No improvement, still saving model
75.51972157772622 epochs left to go

Training Epoch 23.48027842227378/100 starting at 2021-08-24 22:54:52.212745
[1]  [0/1724] loss: 0.665, ave_loss: 0.665
[2]  [20/1724] loss: 0.710, ave_loss: 0.688
[3]  [40/1724] loss: 0.737, ave_loss: 0.704
[4]  [60/1724] loss: 0.653, ave_loss: 0.691
[5]  [80/1724] loss: 0.609, ave_loss: 0.675
[6]  [100/1724] loss: 0.685, ave_loss: 0.677
[7]  [120/1724] loss: 0.537, ave_loss: 0.657
[8]  [140/1724] loss: 0.670, ave_loss: 0.658
[9]  [160/1724] loss: 0.656, ave_loss: 0.658
[10]  [180/1724] loss: 0.622, ave_loss: 0.655
[11]  [200/1724] loss: 0.651, ave_loss: 0.654
[12]  [220/1724] loss: 0.628, ave_loss: 0.652
[13]  [240/1724] loss: 0.652, ave_loss: 0.652
[14]  [260/1724] loss: 0.605, ave_loss: 0.649
[15]  [280/1724] loss: 0.808, ave_loss: 0.659
[16]  [300/1724] loss: 0.646, ave_loss: 0.658
[17]  [320/1724] loss: 0.657, ave_loss: 0.658
[18]  [340/1724] loss: 0.492, ave_loss: 0.649
[19]  [360/1724] loss: 0.623, ave_loss: 0.648
[20]  [380/1724] loss: 0.546, ave_loss: 0.643
[21]  [400/1724] loss: 0.688, ave_loss: 0.645
[22]  [420/1724] loss: 0.806, ave_loss: 0.652
[23]  [440/1724] loss: 0.682, ave_loss: 0.653
[24]  [460/1724] loss: 0.679, ave_loss: 0.654
[25]  [480/1724] loss: 0.779, ave_loss: 0.659
[26]  [500/1724] loss: 0.673, ave_loss: 0.660
[27]  [520/1724] loss: 0.597, ave_loss: 0.658
[28]  [540/1724] loss: 0.709, ave_loss: 0.659
[29]  [560/1724] loss: 0.736, ave_loss: 0.662
[30]  [580/1724] loss: 0.655, ave_loss: 0.662
[31]  [600/1724] loss: 0.755, ave_loss: 0.665
[32]  [620/1724] loss: 0.568, ave_loss: 0.662
[33]  [640/1724] loss: 0.613, ave_loss: 0.660
[34]  [660/1724] loss: 0.626, ave_loss: 0.659
[35]  [680/1724] loss: 0.700, ave_loss: 0.661
[36]  [700/1724] loss: 0.710, ave_loss: 0.662
[37]  [720/1724] loss: 0.577, ave_loss: 0.660
[38]  [740/1724] loss: 0.726, ave_loss: 0.661
[39]  [760/1724] loss: 0.648, ave_loss: 0.661
[40]  [780/1724] loss: 0.545, ave_loss: 0.658
[41]  [800/1724] loss: 0.617, ave_loss: 0.657
[42]  [820/1724] loss: 0.680, ave_loss: 0.658
[43]  [840/1724] loss: 0.655, ave_loss: 0.658
[44]  [860/1724] loss: 0.645, ave_loss: 0.657
[45]  [880/1724] loss: 0.681, ave_loss: 0.658
[46]  [900/1724] loss: 0.739, ave_loss: 0.660
[47]  [920/1724] loss: 0.562, ave_loss: 0.658
[48]  [940/1724] loss: 0.658, ave_loss: 0.658
[49]  [960/1724] loss: 0.778, ave_loss: 0.660

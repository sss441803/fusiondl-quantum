reading from multiple data folder!**********************************************
Selected signals (determines which signals are used for training):
[q95 safety factor, internal inductance, plasma current, Locked mode amplitude, Normalized Beta, stored energy, Plasma density, Radiated Power Core, Radiated Power Edge, Input Power (beam for d3d), Input Beam Torque, plasma current direction, plasma current target, plasma current error, Electron temperature profile, Electron density profile]
...done
Training on 1724 shots, testing on 857 shots
n_scalars,n_profiles,profile_size= 14 2 64
Classical convolution with channels  2 4
Classical convolution with channels  4 4
Classical convolution with channels  4 3
Classical convolution with channels  3 2
InputBlock parameters:  14 2 64 ['c4', 'c4', 'c3', 'c2'] 4 10 0.08 2
TCN parameters:  17 1 [20, 20, 20, 20, 20] 11 0.08
Using single GPU..........................................
99 epochs left to go

Training Epoch 0/100 starting at 2021-08-21 09:40:17.573083
[1]  [0/1724] loss: 1.809, ave_loss: 1.809
[2]  [20/1724] loss: 2.507, ave_loss: 2.158
[3]  [40/1724] loss: 2.405, ave_loss: 2.240
[4]  [60/1724] loss: 2.265, ave_loss: 2.246
[5]  [80/1724] loss: 2.143, ave_loss: 2.226
[6]  [100/1724] loss: 1.688, ave_loss: 2.136
[7]  [120/1724] loss: 1.310, ave_loss: 2.018
[8]  [140/1724] loss: 1.452, ave_loss: 1.947
[9]  [160/1724] loss: 0.837, ave_loss: 1.824
[10]  [180/1724] loss: 1.060, ave_loss: 1.748
[11]  [200/1724] loss: 0.720, ave_loss: 1.654
[12]  [220/1724] loss: 1.421, ave_loss: 1.635
[13]  [240/1724] loss: 0.879, ave_loss: 1.577
[14]  [260/1724] loss: 0.686, ave_loss: 1.513
[15]  [280/1724] loss: 0.763, ave_loss: 1.463
[16]  [300/1724] loss: 0.601, ave_loss: 1.409
[17]  [320/1724] loss: 0.722, ave_loss: 1.369
[18]  [340/1724] loss: 0.846, ave_loss: 1.340
[19]  [360/1724] loss: 0.740, ave_loss: 1.308
[20]  [380/1724] loss: 0.662, ave_loss: 1.276
[21]  [400/1724] loss: 0.837, ave_loss: 1.255
[22]  [420/1724] loss: 0.675, ave_loss: 1.229
[23]  [440/1724] loss: 0.776, ave_loss: 1.209
[24]  [460/1724] loss: 0.784, ave_loss: 1.191
[25]  [480/1724] loss: 0.832, ave_loss: 1.177
[26]  [500/1724] loss: 0.783, ave_loss: 1.162
[27]  [520/1724] loss: 0.642, ave_loss: 1.142
[28]  [540/1724] loss: 0.685, ave_loss: 1.126
[29]  [560/1724] loss: 0.671, ave_loss: 1.110
[30]  [580/1724] loss: 0.669, ave_loss: 1.096
[31]  [600/1724] loss: 0.681, ave_loss: 1.082
[32]  [620/1724] loss: 0.702, ave_loss: 1.070
[33]  [640/1724] loss: 0.648, ave_loss: 1.058
[34]  [660/1724] loss: 0.530, ave_loss: 1.042
[35]  [680/1724] loss: 0.795, ave_loss: 1.035
[36]  [700/1724] loss: 0.503, ave_loss: 1.020
[37]  [720/1724] loss: 0.640, ave_loss: 1.010
[38]  [740/1724] loss: 0.619, ave_loss: 1.000
[39]  [760/1724] loss: 0.406, ave_loss: 0.984
[40]  [780/1724] loss: 0.702, ave_loss: 0.977
[41]  [800/1724] loss: 0.351, ave_loss: 0.962
[42]  [820/1724] loss: 0.741, ave_loss: 0.957
[43]  [840/1724] loss: 0.589, ave_loss: 0.948
[44]  [860/1724] loss: 0.787, ave_loss: 0.945
[45]  [880/1724] loss: 0.530, ave_loss: 0.935
[46]  [900/1724] loss: 0.731, ave_loss: 0.931
[47]  [920/1724] loss: 0.532, ave_loss: 0.922
[48]  [940/1724] loss: 0.522, ave_loss: 0.914
[49]  [960/1724] loss: 0.639, ave_loss: 0.909
[50]  [980/1724] loss: 0.713, ave_loss: 0.905
[51]  [1000/1724] loss: 0.644, ave_loss: 0.900
[52]  [1020/1724] loss: 0.515, ave_loss: 0.892
[53]  [1040/1724] loss: 0.490, ave_loss: 0.885
[54]  [1060/1724] loss: 0.593, ave_loss: 0.879
[55]  [1080/1724] loss: 0.809, ave_loss: 0.878
[56]  [1100/1724] loss: 0.642, ave_loss: 0.874
[57]  [1120/1724] loss: 0.547, ave_loss: 0.868
[58]  [1140/1724] loss: 0.507, ave_loss: 0.862
[59]  [1160/1724] loss: 0.545, ave_loss: 0.856
[60]  [1180/1724] loss: 0.576, ave_loss: 0.852
[61]  [1200/1724] loss: 0.482, ave_loss: 0.846
[62]  [1220/1724] loss: 0.529, ave_loss: 0.840
[63]  [1240/1724] loss: 0.574, ave_loss: 0.836
[64]  [1260/1724] loss: 0.581, ave_loss: 0.832
[65]  [1280/1724] loss: 0.473, ave_loss: 0.827
[66]  [1300/1724] loss: 0.467, ave_loss: 0.821
[67]  [1320/1724] loss: 0.480, ave_loss: 0.816
[68]  [1340/1724] loss: 0.667, ave_loss: 0.814
[69]  [1360/1724] loss: 0.711, ave_loss: 0.812
[70]  [1380/1724] loss: 0.586, ave_loss: 0.809
[71]  [1400/1724] loss: 0.624, ave_loss: 0.807
[72]  [1420/1724] loss: 0.535, ave_loss: 0.803
[73]  [1440/1724] loss: 0.572, ave_loss: 0.800
[74]  [1460/1724] loss: 0.537, ave_loss: 0.796
[75]  [1480/1724] loss: 0.485, ave_loss: 0.792
[76]  [1500/1724] loss: 0.595, ave_loss: 0.789
[77]  [1520/1724] loss: 0.560, ave_loss: 0.786
[78]  [1540/1724] loss: 0.549, ave_loss: 0.783
[79]  [1560/1724] loss: 0.447, ave_loss: 0.779
[80]  [1580/1724] loss: 0.442, ave_loss: 0.775
[81]  [1600/1724] loss: 0.675, ave_loss: 0.774
[82]  [1620/1724] loss: 0.482, ave_loss: 0.770
[83]  [1640/1724] loss: 0.447, ave_loss: 0.766
[84]  [1660/1724] loss: 0.480, ave_loss: 0.763
[85]  [1680/1724] loss: 0.683, ave_loss: 0.762
[86]  [1700/1724] loss: 0.440, ave_loss: 0.758
[87]  [1720/1724] loss: 0.705, ave_loss: 0.757
[88]  [1740/1724] loss: 0.626, ave_loss: 0.756

Finished Training finishing at 2021-08-21 09:44:03.703316
printing_out epoch  1.0208816705336428 learning rate: 0.0005153561248318907
0.000499895441086934
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.560e-01
Validation Loss: 8.944e+04
Validation ROC: 0.7112
Saving model
97.97911832946636 epochs left to go

Training Epoch 1.0208816705336428/100 starting at 2021-08-21 09:46:12.150940
[1]  [0/1724] loss: 0.762, ave_loss: 0.762
[2]  [20/1724] loss: 0.675, ave_loss: 0.718
[3]  [40/1724] loss: 0.580, ave_loss: 0.672
[4]  [60/1724] loss: 0.503, ave_loss: 0.630
[5]  [80/1724] loss: 0.490, ave_loss: 0.602
[6]  [100/1724] loss: 0.560, ave_loss: 0.595
[7]  [120/1724] loss: 0.522, ave_loss: 0.584
[8]  [140/1724] loss: 0.452, ave_loss: 0.568
[9]  [160/1724] loss: 0.398, ave_loss: 0.549
[10]  [180/1724] loss: 0.405, ave_loss: 0.535
[11]  [200/1724] loss: 0.377, ave_loss: 0.520
[12]  [220/1724] loss: 0.557, ave_loss: 0.523
[13]  [240/1724] loss: 0.394, ave_loss: 0.513
[14]  [260/1724] loss: 0.619, ave_loss: 0.521
[15]  [280/1724] loss: 0.471, ave_loss: 0.518
[16]  [300/1724] loss: 0.656, ave_loss: 0.526
[17]  [320/1724] loss: 0.514, ave_loss: 0.526
[18]  [340/1724] loss: 0.477, ave_loss: 0.523
[19]  [360/1724] loss: 0.540, ave_loss: 0.524
[20]  [380/1724] loss: 0.465, ave_loss: 0.521
[21]  [400/1724] loss: 0.600, ave_loss: 0.525
[22]  [420/1724] loss: 0.483, ave_loss: 0.523
[23]  [440/1724] loss: 0.518, ave_loss: 0.522
[24]  [460/1724] loss: 0.450, ave_loss: 0.519
[25]  [480/1724] loss: 0.615, ave_loss: 0.523
[26]  [500/1724] loss: 0.717, ave_loss: 0.531
[27]  [520/1724] loss: 0.618, ave_loss: 0.534
[28]  [540/1724] loss: 0.389, ave_loss: 0.529
[29]  [560/1724] loss: 0.506, ave_loss: 0.528
[30]  [580/1724] loss: 0.429, ave_loss: 0.525
[31]  [600/1724] loss: 0.370, ave_loss: 0.520
[32]  [620/1724] loss: 0.535, ave_loss: 0.520
[33]  [640/1724] loss: 0.531, ave_loss: 0.521
[34]  [660/1724] loss: 0.614, ave_loss: 0.523
[35]  [680/1724] loss: 0.527, ave_loss: 0.523
[36]  [700/1724] loss: 0.482, ave_loss: 0.522
[37]  [720/1724] loss: 0.561, ave_loss: 0.523
[38]  [740/1724] loss: 0.531, ave_loss: 0.523
[39]  [760/1724] loss: 0.514, ave_loss: 0.523
[40]  [780/1724] loss: 0.509, ave_loss: 0.523
[41]  [800/1724] loss: 0.473, ave_loss: 0.522
[42]  [820/1724] loss: 0.465, ave_loss: 0.520
[43]  [840/1724] loss: 0.419, ave_loss: 0.518
[44]  [860/1724] loss: 0.446, ave_loss: 0.516
[45]  [880/1724] loss: 0.501, ave_loss: 0.516
[46]  [900/1724] loss: 0.432, ave_loss: 0.514
[47]  [920/1724] loss: 0.473, ave_loss: 0.513
[48]  [940/1724] loss: 0.535, ave_loss: 0.514
[49]  [960/1724] loss: 0.592, ave_loss: 0.515
[50]  [980/1724] loss: 0.462, ave_loss: 0.514
[51]  [1000/1724] loss: 0.426, ave_loss: 0.512
[52]  [1020/1724] loss: 0.448, ave_loss: 0.511
[53]  [1040/1724] loss: 0.487, ave_loss: 0.511
[54]  [1060/1724] loss: 0.567, ave_loss: 0.512
[55]  [1080/1724] loss: 0.536, ave_loss: 0.512
[56]  [1100/1724] loss: 0.461, ave_loss: 0.511
[57]  [1120/1724] loss: 0.530, ave_loss: 0.512
[58]  [1140/1724] loss: 0.481, ave_loss: 0.511
[59]  [1160/1724] loss: 0.475, ave_loss: 0.511
[60]  [1180/1724] loss: 0.498, ave_loss: 0.510
[61]  [1200/1724] loss: 0.426, ave_loss: 0.509
[62]  [1220/1724] loss: 0.579, ave_loss: 0.510
[63]  [1240/1724] loss: 0.629, ave_loss: 0.512
[64]  [1260/1724] loss: 0.418, ave_loss: 0.511
[65]  [1280/1724] loss: 0.461, ave_loss: 0.510
[66]  [1300/1724] loss: 0.689, ave_loss: 0.512
[67]  [1320/1724] loss: 0.625, ave_loss: 0.514
[68]  [1340/1724] loss: 0.464, ave_loss: 0.513
[69]  [1360/1724] loss: 0.504, ave_loss: 0.513
[70]  [1380/1724] loss: 0.741, ave_loss: 0.517
[71]  [1400/1724] loss: 0.332, ave_loss: 0.514
[72]  [1420/1724] loss: 0.468, ave_loss: 0.513
[73]  [1440/1724] loss: 0.623, ave_loss: 0.515
[74]  [1460/1724] loss: 0.504, ave_loss: 0.515
[75]  [1480/1724] loss: 0.436, ave_loss: 0.514
[76]  [1500/1724] loss: 0.441, ave_loss: 0.513
[77]  [1520/1724] loss: 0.454, ave_loss: 0.512
[78]  [1540/1724] loss: 0.639, ave_loss: 0.514
[79]  [1560/1724] loss: 0.427, ave_loss: 0.512
[80]  [1580/1724] loss: 0.509, ave_loss: 0.512
[81]  [1600/1724] loss: 0.529, ave_loss: 0.513
[82]  [1620/1724] loss: 0.397, ave_loss: 0.511
[83]  [1640/1724] loss: 0.412, ave_loss: 0.510
[84]  [1660/1724] loss: 0.516, ave_loss: 0.510
[85]  [1680/1724] loss: 0.405, ave_loss: 0.509
[86]  [1700/1724] loss: 0.439, ave_loss: 0.508
[87]  [1720/1724] loss: 0.577, ave_loss: 0.509
[88]  [1740/1724] loss: 0.612, ave_loss: 0.510

Finished Training finishing at 2021-08-21 09:48:34.883961
printing_out epoch  2.0417633410672855 learning rate: 0.0005153561248318907
0.00048489857785432596
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 5.100e-01
Validation Loss: 9.245e+04
Validation ROC: 0.7292
Saving model
96.95823665893272 epochs left to go

Training Epoch 2.0417633410672855/100 starting at 2021-08-21 09:49:02.787344
[1]  [0/1724] loss: 0.588, ave_loss: 0.588
[2]  [20/1724] loss: 0.499, ave_loss: 0.543
[3]  [40/1724] loss: 0.473, ave_loss: 0.520
[4]  [60/1724] loss: 0.560, ave_loss: 0.530
[5]  [80/1724] loss: 0.506, ave_loss: 0.525
[6]  [100/1724] loss: 0.437, ave_loss: 0.510
[7]  [120/1724] loss: 0.471, ave_loss: 0.505
[8]  [140/1724] loss: 0.489, ave_loss: 0.503
[9]  [160/1724] loss: 0.566, ave_loss: 0.510
[10]  [180/1724] loss: 0.493, ave_loss: 0.508
[11]  [200/1724] loss: 0.484, ave_loss: 0.506
[12]  [220/1724] loss: 0.425, ave_loss: 0.499
[13]  [240/1724] loss: 0.525, ave_loss: 0.501
[14]  [260/1724] loss: 0.520, ave_loss: 0.503
[15]  [280/1724] loss: 0.588, ave_loss: 0.508
[16]  [300/1724] loss: 0.476, ave_loss: 0.506
[17]  [320/1724] loss: 0.398, ave_loss: 0.500
[18]  [340/1724] loss: 0.557, ave_loss: 0.503
[19]  [360/1724] loss: 0.462, ave_loss: 0.501
[20]  [380/1724] loss: 0.470, ave_loss: 0.499
[21]  [400/1724] loss: 0.512, ave_loss: 0.500
[22]  [420/1724] loss: 0.563, ave_loss: 0.503
[23]  [440/1724] loss: 0.405, ave_loss: 0.499
[24]  [460/1724] loss: 0.411, ave_loss: 0.495
[25]  [480/1724] loss: 0.428, ave_loss: 0.492
[26]  [500/1724] loss: 0.477, ave_loss: 0.492
[27]  [520/1724] loss: 0.469, ave_loss: 0.491
[28]  [540/1724] loss: 0.401, ave_loss: 0.488
[29]  [560/1724] loss: 0.647, ave_loss: 0.493
[30]  [580/1724] loss: 0.433, ave_loss: 0.491
[31]  [600/1724] loss: 0.546, ave_loss: 0.493
[32]  [620/1724] loss: 0.524, ave_loss: 0.494
[33]  [640/1724] loss: 0.451, ave_loss: 0.493
[34]  [660/1724] loss: 0.430, ave_loss: 0.491
[35]  [680/1724] loss: 0.489, ave_loss: 0.491
[36]  [700/1724] loss: 0.542, ave_loss: 0.492
[37]  [720/1724] loss: 0.380, ave_loss: 0.489
[38]  [740/1724] loss: 0.443, ave_loss: 0.488
[39]  [760/1724] loss: 0.461, ave_loss: 0.487
[40]  [780/1724] loss: 0.507, ave_loss: 0.488
[41]  [800/1724] loss: 0.548, ave_loss: 0.489
[42]  [820/1724] loss: 0.463, ave_loss: 0.489
[43]  [840/1724] loss: 0.462, ave_loss: 0.488
[44]  [860/1724] loss: 0.697, ave_loss: 0.493
[45]  [880/1724] loss: 0.454, ave_loss: 0.492
[46]  [900/1724] loss: 0.351, ave_loss: 0.489
[47]  [920/1724] loss: 0.481, ave_loss: 0.489
[48]  [940/1724] loss: 0.380, ave_loss: 0.486
[49]  [960/1724] loss: 0.467, ave_loss: 0.486
[50]  [980/1724] loss: 0.450, ave_loss: 0.485
[51]  [1000/1724] loss: 0.491, ave_loss: 0.485
[52]  [1020/1724] loss: 0.572, ave_loss: 0.487
[53]  [1040/1724] loss: 0.354, ave_loss: 0.485
[54]  [1060/1724] loss: 0.527, ave_loss: 0.485
[55]  [1080/1724] loss: 0.524, ave_loss: 0.486
[56]  [1100/1724] loss: 0.533, ave_loss: 0.487
[57]  [1120/1724] loss: 0.445, ave_loss: 0.486
[58]  [1140/1724] loss: 0.492, ave_loss: 0.486
[59]  [1160/1724] loss: 0.466, ave_loss: 0.486
[60]  [1180/1724] loss: 0.456, ave_loss: 0.485
[61]  [1200/1724] loss: 0.439, ave_loss: 0.485
[62]  [1220/1724] loss: 0.541, ave_loss: 0.486
[63]  [1240/1724] loss: 0.530, ave_loss: 0.486
[64]  [1260/1724] loss: 0.449, ave_loss: 0.486
[65]  [1280/1724] loss: 0.531, ave_loss: 0.486
[66]  [1300/1724] loss: 0.605, ave_loss: 0.488
[67]  [1320/1724] loss: 0.427, ave_loss: 0.487
[68]  [1340/1724] loss: 0.542, ave_loss: 0.488
[69]  [1360/1724] loss: 0.499, ave_loss: 0.488
[70]  [1380/1724] loss: 0.516, ave_loss: 0.489
[71]  [1400/1724] loss: 0.529, ave_loss: 0.489
[72]  [1420/1724] loss: 0.522, ave_loss: 0.490
[73]  [1440/1724] loss: 0.449, ave_loss: 0.489
[74]  [1460/1724] loss: 0.531, ave_loss: 0.490
[75]  [1480/1724] loss: 0.454, ave_loss: 0.489
[76]  [1500/1724] loss: 0.447, ave_loss: 0.489
[77]  [1520/1724] loss: 0.512, ave_loss: 0.489
[78]  [1540/1724] loss: 0.490, ave_loss: 0.489
[79]  [1560/1724] loss: 0.560, ave_loss: 0.490
[80]  [1580/1724] loss: 0.620, ave_loss: 0.491
[81]  [1600/1724] loss: 0.517, ave_loss: 0.492
[82]  [1620/1724] loss: 0.308, ave_loss: 0.490
[83]  [1640/1724] loss: 0.506, ave_loss: 0.490
[84]  [1660/1724] loss: 0.678, ave_loss: 0.492
[85]  [1680/1724] loss: 0.493, ave_loss: 0.492
[86]  [1700/1724] loss: 0.483, ave_loss: 0.492
[87]  [1720/1724] loss: 0.524, ave_loss: 0.492
[88]  [1740/1724] loss: 0.490, ave_loss: 0.492

Finished Training finishing at 2021-08-21 09:51:16.111311
printing_out epoch  3.062645011600928 learning rate: 0.0005153561248318907
0.00047035162051869614
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.922e-01
Validation Loss: 1.071e+05
Validation ROC: 0.7266
No improvement, still saving model
95.93735498839908 epochs left to go

Training Epoch 3.062645011600928/100 starting at 2021-08-21 09:51:43.691074
[1]  [0/1724] loss: 0.504, ave_loss: 0.504
[2]  [20/1724] loss: 0.436, ave_loss: 0.470
[3]  [40/1724] loss: 0.477, ave_loss: 0.472
[4]  [60/1724] loss: 0.592, ave_loss: 0.502
[5]  [80/1724] loss: 0.586, ave_loss: 0.519
[6]  [100/1724] loss: 0.517, ave_loss: 0.518
[7]  [120/1724] loss: 0.521, ave_loss: 0.519
[8]  [140/1724] loss: 0.446, ave_loss: 0.510
[9]  [160/1724] loss: 0.820, ave_loss: 0.544
[10]  [180/1724] loss: 0.524, ave_loss: 0.542
[11]  [200/1724] loss: 0.670, ave_loss: 0.554
[12]  [220/1724] loss: 0.605, ave_loss: 0.558
[13]  [240/1724] loss: 0.577, ave_loss: 0.560
[14]  [260/1724] loss: 0.476, ave_loss: 0.554
[15]  [280/1724] loss: 0.399, ave_loss: 0.543
[16]  [300/1724] loss: 0.465, ave_loss: 0.538
[17]  [320/1724] loss: 0.793, ave_loss: 0.553
[18]  [340/1724] loss: 0.769, ave_loss: 0.565
[19]  [360/1724] loss: 0.507, ave_loss: 0.562
[20]  [380/1724] loss: 0.570, ave_loss: 0.563
[21]  [400/1724] loss: 0.458, ave_loss: 0.558
[22]  [420/1724] loss: 0.554, ave_loss: 0.558
[23]  [440/1724] loss: 0.509, ave_loss: 0.555
[24]  [460/1724] loss: 0.539, ave_loss: 0.555
[25]  [480/1724] loss: 0.470, ave_loss: 0.551
[26]  [500/1724] loss: 0.655, ave_loss: 0.555
[27]  [520/1724] loss: 0.343, ave_loss: 0.547
[28]  [540/1724] loss: 0.527, ave_loss: 0.547
[29]  [560/1724] loss: 0.802, ave_loss: 0.556
[30]  [580/1724] loss: 0.527, ave_loss: 0.555
[31]  [600/1724] loss: 0.420, ave_loss: 0.550
[32]  [620/1724] loss: 0.465, ave_loss: 0.548
[33]  [640/1724] loss: 0.548, ave_loss: 0.548
[34]  [660/1724] loss: 0.634, ave_loss: 0.550
[35]  [680/1724] loss: 0.484, ave_loss: 0.548
[36]  [700/1724] loss: 0.445, ave_loss: 0.545
[37]  [720/1724] loss: 0.734, ave_loss: 0.550
[38]  [740/1724] loss: 0.535, ave_loss: 0.550
[39]  [760/1724] loss: 0.433, ave_loss: 0.547
[40]  [780/1724] loss: 0.560, ave_loss: 0.547
[41]  [800/1724] loss: 0.459, ave_loss: 0.545
[42]  [820/1724] loss: 0.396, ave_loss: 0.542
[43]  [840/1724] loss: 0.355, ave_loss: 0.537
[44]  [860/1724] loss: 0.622, ave_loss: 0.539
[45]  [880/1724] loss: 0.437, ave_loss: 0.537
[46]  [900/1724] loss: 0.383, ave_loss: 0.534
[47]  [920/1724] loss: 0.542, ave_loss: 0.534
[48]  [940/1724] loss: 0.491, ave_loss: 0.533
[49]  [960/1724] loss: 0.418, ave_loss: 0.531
[50]  [980/1724] loss: 0.459, ave_loss: 0.529
[51]  [1000/1724] loss: 0.585, ave_loss: 0.530
[52]  [1020/1724] loss: 0.484, ave_loss: 0.529
[53]  [1040/1724] loss: 0.494, ave_loss: 0.529
[54]  [1060/1724] loss: 0.416, ave_loss: 0.527
[55]  [1080/1724] loss: 0.473, ave_loss: 0.526
[56]  [1100/1724] loss: 0.517, ave_loss: 0.526
[57]  [1120/1724] loss: 0.535, ave_loss: 0.526
[58]  [1140/1724] loss: 0.312, ave_loss: 0.522
[59]  [1160/1724] loss: 0.406, ave_loss: 0.520
[60]  [1180/1724] loss: 0.609, ave_loss: 0.522
[61]  [1200/1724] loss: 0.435, ave_loss: 0.520
[62]  [1220/1724] loss: 0.537, ave_loss: 0.520
[63]  [1240/1724] loss: 0.421, ave_loss: 0.519
[64]  [1260/1724] loss: 0.431, ave_loss: 0.517
[65]  [1280/1724] loss: 0.452, ave_loss: 0.516
[66]  [1300/1724] loss: 0.604, ave_loss: 0.518
[67]  [1320/1724] loss: 0.394, ave_loss: 0.516
[68]  [1340/1724] loss: 0.548, ave_loss: 0.516
[69]  [1360/1724] loss: 0.446, ave_loss: 0.515
[70]  [1380/1724] loss: 0.488, ave_loss: 0.515
[71]  [1400/1724] loss: 0.325, ave_loss: 0.512
[72]  [1420/1724] loss: 0.498, ave_loss: 0.512
[73]  [1440/1724] loss: 0.361, ave_loss: 0.510
[74]  [1460/1724] loss: 0.457, ave_loss: 0.509
[75]  [1480/1724] loss: 0.565, ave_loss: 0.510
[76]  [1500/1724] loss: 0.588, ave_loss: 0.511
[77]  [1520/1724] loss: 0.676, ave_loss: 0.513
[78]  [1540/1724] loss: 0.419, ave_loss: 0.512
[79]  [1560/1724] loss: 0.456, ave_loss: 0.511
[80]  [1580/1724] loss: 0.297, ave_loss: 0.509
[81]  [1600/1724] loss: 0.462, ave_loss: 0.508
[82]  [1620/1724] loss: 0.520, ave_loss: 0.508
[83]  [1640/1724] loss: 0.578, ave_loss: 0.509
[84]  [1660/1724] loss: 0.374, ave_loss: 0.507
[85]  [1680/1724] loss: 0.426, ave_loss: 0.506
[86]  [1700/1724] loss: 0.520, ave_loss: 0.507
[87]  [1720/1724] loss: 0.343, ave_loss: 0.505
[88]  [1740/1724] loss: 0.335, ave_loss: 0.503

Finished Training finishing at 2021-08-21 09:54:00.320072
printing_out epoch  4.083526682134571 learning rate: 0.0005153561248318907
0.00045624107190313527
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 5.028e-01
Validation Loss: 1.431e+05
Validation ROC: 0.7439
Saving model
94.91647331786542 epochs left to go

Training Epoch 4.083526682134571/100 starting at 2021-08-21 09:54:33.614114
[1]  [0/1724] loss: 0.471, ave_loss: 0.471
[2]  [20/1724] loss: 0.529, ave_loss: 0.500
[3]  [40/1724] loss: 0.378, ave_loss: 0.459
[4]  [60/1724] loss: 0.405, ave_loss: 0.446
[5]  [80/1724] loss: 0.520, ave_loss: 0.461
[6]  [100/1724] loss: 0.372, ave_loss: 0.446
[7]  [120/1724] loss: 0.446, ave_loss: 0.446
[8]  [140/1724] loss: 0.589, ave_loss: 0.464
[9]  [160/1724] loss: 0.393, ave_loss: 0.456
[10]  [180/1724] loss: 0.348, ave_loss: 0.445
[11]  [200/1724] loss: 0.420, ave_loss: 0.443
[12]  [220/1724] loss: 0.462, ave_loss: 0.445
[13]  [240/1724] loss: 0.499, ave_loss: 0.449
[14]  [260/1724] loss: 0.539, ave_loss: 0.455
[15]  [280/1724] loss: 0.582, ave_loss: 0.464
[16]  [300/1724] loss: 0.367, ave_loss: 0.458
[17]  [320/1724] loss: 0.478, ave_loss: 0.459
[18]  [340/1724] loss: 0.453, ave_loss: 0.458
[19]  [360/1724] loss: 0.380, ave_loss: 0.454
[20]  [380/1724] loss: 0.652, ave_loss: 0.464
[21]  [400/1724] loss: 0.640, ave_loss: 0.473
[22]  [420/1724] loss: 0.423, ave_loss: 0.470
[23]  [440/1724] loss: 0.541, ave_loss: 0.473
[24]  [460/1724] loss: 0.596, ave_loss: 0.479
[25]  [480/1724] loss: 0.521, ave_loss: 0.480
[26]  [500/1724] loss: 0.464, ave_loss: 0.480
[27]  [520/1724] loss: 0.463, ave_loss: 0.479
[28]  [540/1724] loss: 0.403, ave_loss: 0.476
[29]  [560/1724] loss: 0.458, ave_loss: 0.476
[30]  [580/1724] loss: 0.437, ave_loss: 0.474
[31]  [600/1724] loss: 0.481, ave_loss: 0.475
[32]  [620/1724] loss: 0.355, ave_loss: 0.471
[33]  [640/1724] loss: 0.345, ave_loss: 0.467
[34]  [660/1724] loss: 0.567, ave_loss: 0.470
[35]  [680/1724] loss: 0.364, ave_loss: 0.467
[36]  [700/1724] loss: 0.483, ave_loss: 0.467
[37]  [720/1724] loss: 0.374, ave_loss: 0.465
[38]  [740/1724] loss: 0.395, ave_loss: 0.463
[39]  [760/1724] loss: 0.472, ave_loss: 0.463
[40]  [780/1724] loss: 0.588, ave_loss: 0.466
[41]  [800/1724] loss: 0.462, ave_loss: 0.466
[42]  [820/1724] loss: 0.441, ave_loss: 0.466
[43]  [840/1724] loss: 0.623, ave_loss: 0.469
[44]  [860/1724] loss: 0.378, ave_loss: 0.467
[45]  [880/1724] loss: 0.384, ave_loss: 0.465
[46]  [900/1724] loss: 0.410, ave_loss: 0.464
[47]  [920/1724] loss: 0.413, ave_loss: 0.463
[48]  [940/1724] loss: 0.448, ave_loss: 0.463
[49]  [960/1724] loss: 0.370, ave_loss: 0.461
[50]  [980/1724] loss: 0.444, ave_loss: 0.461
[51]  [1000/1724] loss: 0.368, ave_loss: 0.459
[52]  [1020/1724] loss: 0.729, ave_loss: 0.464
[53]  [1040/1724] loss: 0.681, ave_loss: 0.468
[54]  [1060/1724] loss: 0.549, ave_loss: 0.470
[55]  [1080/1724] loss: 0.478, ave_loss: 0.470
[56]  [1100/1724] loss: 0.317, ave_loss: 0.467
[57]  [1120/1724] loss: 0.427, ave_loss: 0.466
[58]  [1140/1724] loss: 0.429, ave_loss: 0.466
[59]  [1160/1724] loss: 0.402, ave_loss: 0.465
[60]  [1180/1724] loss: 0.555, ave_loss: 0.466
[61]  [1200/1724] loss: 0.422, ave_loss: 0.465
[62]  [1220/1724] loss: 0.497, ave_loss: 0.466
[63]  [1240/1724] loss: 0.419, ave_loss: 0.465
[64]  [1260/1724] loss: 0.508, ave_loss: 0.466
[65]  [1280/1724] loss: 0.340, ave_loss: 0.464
[66]  [1300/1724] loss: 0.620, ave_loss: 0.466
[67]  [1320/1724] loss: 0.522, ave_loss: 0.467
[68]  [1340/1724] loss: 0.401, ave_loss: 0.466
[69]  [1360/1724] loss: 0.448, ave_loss: 0.466
[70]  [1380/1724] loss: 0.373, ave_loss: 0.464
[71]  [1400/1724] loss: 0.441, ave_loss: 0.464
[72]  [1420/1724] loss: 0.438, ave_loss: 0.464
[73]  [1440/1724] loss: 0.467, ave_loss: 0.464
[74]  [1460/1724] loss: 0.505, ave_loss: 0.464
[75]  [1480/1724] loss: 0.297, ave_loss: 0.462
[76]  [1500/1724] loss: 0.414, ave_loss: 0.462
[77]  [1520/1724] loss: 0.353, ave_loss: 0.460
[78]  [1540/1724] loss: 0.370, ave_loss: 0.459
[79]  [1560/1724] loss: 0.490, ave_loss: 0.459
[80]  [1580/1724] loss: 0.579, ave_loss: 0.461
[81]  [1600/1724] loss: 0.479, ave_loss: 0.461
[82]  [1620/1724] loss: 0.458, ave_loss: 0.461
[83]  [1640/1724] loss: 0.391, ave_loss: 0.460
[84]  [1660/1724] loss: 0.483, ave_loss: 0.460
[85]  [1680/1724] loss: 0.393, ave_loss: 0.460
[86]  [1700/1724] loss: 0.352, ave_loss: 0.458
[87]  [1720/1724] loss: 0.427, ave_loss: 0.458
[88]  [1740/1724] loss: 0.537, ave_loss: 0.459

Finished Training finishing at 2021-08-21 09:56:42.894933
printing_out epoch  5.104408352668213 learning rate: 0.0005153561248318907
0.0004425538397460412
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.589e-01
Validation Loss: 1.518e+05
Validation ROC: 0.7302
No improvement, still saving model
93.89559164733178 epochs left to go

Training Epoch 5.104408352668213/100 starting at 2021-08-21 09:57:27.222218
[1]  [0/1724] loss: 0.489, ave_loss: 0.489
[2]  [20/1724] loss: 0.384, ave_loss: 0.436
[3]  [40/1724] loss: 0.553, ave_loss: 0.475
[4]  [60/1724] loss: 0.413, ave_loss: 0.460
[5]  [80/1724] loss: 0.510, ave_loss: 0.470
[6]  [100/1724] loss: 0.440, ave_loss: 0.465
[7]  [120/1724] loss: 0.394, ave_loss: 0.455
[8]  [140/1724] loss: 0.430, ave_loss: 0.452
[9]  [160/1724] loss: 0.398, ave_loss: 0.446
[10]  [180/1724] loss: 0.447, ave_loss: 0.446
[11]  [200/1724] loss: 0.267, ave_loss: 0.429
[12]  [220/1724] loss: 0.312, ave_loss: 0.420
[13]  [240/1724] loss: 0.426, ave_loss: 0.420
[14]  [260/1724] loss: 0.424, ave_loss: 0.420
[15]  [280/1724] loss: 0.515, ave_loss: 0.427
[16]  [300/1724] loss: 0.311, ave_loss: 0.419
[17]  [320/1724] loss: 0.507, ave_loss: 0.425
[18]  [340/1724] loss: 0.602, ave_loss: 0.434
[19]  [360/1724] loss: 0.474, ave_loss: 0.437
[20]  [380/1724] loss: 0.434, ave_loss: 0.436
[21]  [400/1724] loss: 0.421, ave_loss: 0.436
[22]  [420/1724] loss: 0.423, ave_loss: 0.435
[23]  [440/1724] loss: 0.372, ave_loss: 0.432
[24]  [460/1724] loss: 0.535, ave_loss: 0.437
[25]  [480/1724] loss: 0.418, ave_loss: 0.436
[26]  [500/1724] loss: 0.490, ave_loss: 0.438
[27]  [520/1724] loss: 0.333, ave_loss: 0.434
[28]  [540/1724] loss: 0.743, ave_loss: 0.445
[29]  [560/1724] loss: 0.547, ave_loss: 0.449
[30]  [580/1724] loss: 0.400, ave_loss: 0.447
[31]  [600/1724] loss: 0.521, ave_loss: 0.449
[32]  [620/1724] loss: 0.450, ave_loss: 0.449
[33]  [640/1724] loss: 0.392, ave_loss: 0.448
[34]  [660/1724] loss: 0.438, ave_loss: 0.447
[35]  [680/1724] loss: 0.394, ave_loss: 0.446
[36]  [700/1724] loss: 0.461, ave_loss: 0.446
[37]  [720/1724] loss: 0.535, ave_loss: 0.449
[38]  [740/1724] loss: 0.521, ave_loss: 0.451
[39]  [760/1724] loss: 0.628, ave_loss: 0.455
[40]  [780/1724] loss: 0.542, ave_loss: 0.457
[41]  [800/1724] loss: 0.378, ave_loss: 0.455
[42]  [820/1724] loss: 0.414, ave_loss: 0.454
[43]  [840/1724] loss: 0.441, ave_loss: 0.454
[44]  [860/1724] loss: 0.412, ave_loss: 0.453
[45]  [880/1724] loss: 0.478, ave_loss: 0.454
[46]  [900/1724] loss: 0.506, ave_loss: 0.455
[47]  [920/1724] loss: 0.422, ave_loss: 0.454
[48]  [940/1724] loss: 0.460, ave_loss: 0.454
[49]  [960/1724] loss: 0.691, ave_loss: 0.459
[50]  [980/1724] loss: 0.523, ave_loss: 0.460
[51]  [1000/1724] loss: 0.574, ave_loss: 0.463
[52]  [1020/1724] loss: 0.369, ave_loss: 0.461
[53]  [1040/1724] loss: 0.356, ave_loss: 0.459
[54]  [1060/1724] loss: 0.448, ave_loss: 0.459
[55]  [1080/1724] loss: 0.361, ave_loss: 0.457
[56]  [1100/1724] loss: 0.503, ave_loss: 0.458
[57]  [1120/1724] loss: 0.473, ave_loss: 0.458
[58]  [1140/1724] loss: 0.630, ave_loss: 0.461
[59]  [1160/1724] loss: 0.513, ave_loss: 0.462
[60]  [1180/1724] loss: 0.391, ave_loss: 0.461
[61]  [1200/1724] loss: 0.394, ave_loss: 0.459
[62]  [1220/1724] loss: 0.495, ave_loss: 0.460
[63]  [1240/1724] loss: 0.357, ave_loss: 0.458
[64]  [1260/1724] loss: 0.482, ave_loss: 0.459
[65]  [1280/1724] loss: 0.522, ave_loss: 0.460
[66]  [1300/1724] loss: 0.480, ave_loss: 0.460
[67]  [1320/1724] loss: 0.495, ave_loss: 0.461
[68]  [1340/1724] loss: 0.422, ave_loss: 0.460
[69]  [1360/1724] loss: 0.334, ave_loss: 0.458
[70]  [1380/1724] loss: 0.417, ave_loss: 0.458
[71]  [1400/1724] loss: 0.456, ave_loss: 0.458
[72]  [1420/1724] loss: 0.350, ave_loss: 0.456
[73]  [1440/1724] loss: 0.362, ave_loss: 0.455
[74]  [1460/1724] loss: 0.398, ave_loss: 0.454
[75]  [1480/1724] loss: 0.504, ave_loss: 0.455
[76]  [1500/1724] loss: 0.545, ave_loss: 0.456
[77]  [1520/1724] loss: 0.271, ave_loss: 0.453
[78]  [1540/1724] loss: 0.465, ave_loss: 0.454
[79]  [1560/1724] loss: 0.467, ave_loss: 0.454
[80]  [1580/1724] loss: 0.484, ave_loss: 0.454
[81]  [1600/1724] loss: 0.456, ave_loss: 0.454
[82]  [1620/1724] loss: 0.551, ave_loss: 0.455
[83]  [1640/1724] loss: 0.593, ave_loss: 0.457
[84]  [1660/1724] loss: 0.438, ave_loss: 0.457
[85]  [1680/1724] loss: 0.377, ave_loss: 0.456
[86]  [1700/1724] loss: 0.397, ave_loss: 0.455
[87]  [1720/1724] loss: 0.450, ave_loss: 0.455
[88]  [1740/1724] loss: 0.537, ave_loss: 0.456

Finished Training finishing at 2021-08-21 09:59:31.195652
printing_out epoch  6.125290023201856 learning rate: 0.0005153561248318907
0.00042927722455365994
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.560e-01
Validation Loss: 1.693e+05
Validation ROC: 0.7292
No improvement, still saving model
92.87470997679814 epochs left to go

Training Epoch 6.125290023201856/100 starting at 2021-08-21 10:01:16.229945
[1]  [0/1724] loss: 0.541, ave_loss: 0.541
[2]  [20/1724] loss: 0.318, ave_loss: 0.429
[3]  [40/1724] loss: 0.322, ave_loss: 0.394
[4]  [60/1724] loss: 0.463, ave_loss: 0.411
[5]  [80/1724] loss: 0.455, ave_loss: 0.420
[6]  [100/1724] loss: 0.381, ave_loss: 0.413
[7]  [120/1724] loss: 0.459, ave_loss: 0.420
[8]  [140/1724] loss: 0.442, ave_loss: 0.423
[9]  [160/1724] loss: 0.445, ave_loss: 0.425
[10]  [180/1724] loss: 0.528, ave_loss: 0.435
[11]  [200/1724] loss: 0.508, ave_loss: 0.442
[12]  [220/1724] loss: 0.367, ave_loss: 0.436
[13]  [240/1724] loss: 0.367, ave_loss: 0.430
[14]  [260/1724] loss: 0.447, ave_loss: 0.432
[15]  [280/1724] loss: 0.574, ave_loss: 0.441
[16]  [300/1724] loss: 0.311, ave_loss: 0.433
[17]  [320/1724] loss: 0.323, ave_loss: 0.426
[18]  [340/1724] loss: 0.489, ave_loss: 0.430
[19]  [360/1724] loss: 0.625, ave_loss: 0.440
[20]  [380/1724] loss: 0.428, ave_loss: 0.440
[21]  [400/1724] loss: 0.425, ave_loss: 0.439
[22]  [420/1724] loss: 0.417, ave_loss: 0.438
[23]  [440/1724] loss: 0.404, ave_loss: 0.436
[24]  [460/1724] loss: 0.621, ave_loss: 0.444
[25]  [480/1724] loss: 0.379, ave_loss: 0.442
[26]  [500/1724] loss: 0.389, ave_loss: 0.439
[27]  [520/1724] loss: 0.590, ave_loss: 0.445
[28]  [540/1724] loss: 0.424, ave_loss: 0.444
[29]  [560/1724] loss: 0.506, ave_loss: 0.446
[30]  [580/1724] loss: 0.580, ave_loss: 0.451
[31]  [600/1724] loss: 0.576, ave_loss: 0.455
[32]  [620/1724] loss: 0.466, ave_loss: 0.455
[33]  [640/1724] loss: 0.414, ave_loss: 0.454
[34]  [660/1724] loss: 0.418, ave_loss: 0.453
[35]  [680/1724] loss: 0.396, ave_loss: 0.451
[36]  [700/1724] loss: 0.540, ave_loss: 0.454
[37]  [720/1724] loss: 0.527, ave_loss: 0.456
[38]  [740/1724] loss: 0.512, ave_loss: 0.457
[39]  [760/1724] loss: 0.378, ave_loss: 0.455
[40]  [780/1724] loss: 0.444, ave_loss: 0.455
[41]  [800/1724] loss: 0.365, ave_loss: 0.453
[42]  [820/1724] loss: 0.514, ave_loss: 0.454
[43]  [840/1724] loss: 0.388, ave_loss: 0.453
[44]  [860/1724] loss: 0.433, ave_loss: 0.452
[45]  [880/1724] loss: 0.444, ave_loss: 0.452
[46]  [900/1724] loss: 0.467, ave_loss: 0.452
[47]  [920/1724] loss: 0.333, ave_loss: 0.450
[48]  [940/1724] loss: 0.535, ave_loss: 0.452
[49]  [960/1724] loss: 0.426, ave_loss: 0.451
[50]  [980/1724] loss: 0.511, ave_loss: 0.452
[51]  [1000/1724] loss: 0.402, ave_loss: 0.451
[52]  [1020/1724] loss: 0.363, ave_loss: 0.450
[53]  [1040/1724] loss: 0.348, ave_loss: 0.448
[54]  [1060/1724] loss: 0.513, ave_loss: 0.449
[55]  [1080/1724] loss: 0.394, ave_loss: 0.448
[56]  [1100/1724] loss: 0.422, ave_loss: 0.447
[57]  [1120/1724] loss: 0.477, ave_loss: 0.448
[58]  [1140/1724] loss: 0.670, ave_loss: 0.452
[59]  [1160/1724] loss: 0.539, ave_loss: 0.453
[60]  [1180/1724] loss: 0.488, ave_loss: 0.454
[61]  [1200/1724] loss: 0.426, ave_loss: 0.453
[62]  [1220/1724] loss: 0.374, ave_loss: 0.452
[63]  [1240/1724] loss: 0.348, ave_loss: 0.450
[64]  [1260/1724] loss: 0.537, ave_loss: 0.452
[65]  [1280/1724] loss: 0.425, ave_loss: 0.451
[66]  [1300/1724] loss: 0.512, ave_loss: 0.452
[67]  [1320/1724] loss: 0.353, ave_loss: 0.451
[68]  [1340/1724] loss: 0.451, ave_loss: 0.451
[69]  [1360/1724] loss: 0.414, ave_loss: 0.450
[70]  [1380/1724] loss: 0.503, ave_loss: 0.451
[71]  [1400/1724] loss: 0.455, ave_loss: 0.451
[72]  [1420/1724] loss: 0.528, ave_loss: 0.452
[73]  [1440/1724] loss: 0.487, ave_loss: 0.453
[74]  [1460/1724] loss: 0.604, ave_loss: 0.455
[75]  [1480/1724] loss: 0.632, ave_loss: 0.457
[76]  [1500/1724] loss: 0.419, ave_loss: 0.457
[77]  [1520/1724] loss: 0.352, ave_loss: 0.455
[78]  [1540/1724] loss: 0.389, ave_loss: 0.454
[79]  [1560/1724] loss: 0.289, ave_loss: 0.452
[80]  [1580/1724] loss: 0.567, ave_loss: 0.454
[81]  [1600/1724] loss: 0.470, ave_loss: 0.454
[82]  [1620/1724] loss: 0.505, ave_loss: 0.455
[83]  [1640/1724] loss: 0.415, ave_loss: 0.454
[84]  [1660/1724] loss: 0.289, ave_loss: 0.452
[85]  [1680/1724] loss: 0.505, ave_loss: 0.453
[86]  [1700/1724] loss: 0.479, ave_loss: 0.453
[87]  [1720/1724] loss: 0.602, ave_loss: 0.455
[88]  [1740/1724] loss: 0.688, ave_loss: 0.457

Finished Training finishing at 2021-08-21 10:03:24.628882
printing_out epoch  7.146171693735499 learning rate: 0.0005153561248318907
0.0004163989078170501
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.574e-01
Validation Loss: 1.728e+05
Validation ROC: 0.7321
No improvement, still saving model
91.8538283062645 epochs left to go

Training Epoch 7.146171693735499/100 starting at 2021-08-21 10:03:55.802459
[1]  [0/1724] loss: 0.425, ave_loss: 0.425
[2]  [20/1724] loss: 0.362, ave_loss: 0.394
[3]  [40/1724] loss: 0.591, ave_loss: 0.460
[4]  [60/1724] loss: 0.522, ave_loss: 0.475
[5]  [80/1724] loss: 0.384, ave_loss: 0.457
[6]  [100/1724] loss: 0.465, ave_loss: 0.458
[7]  [120/1724] loss: 0.240, ave_loss: 0.427
[8]  [140/1724] loss: 0.443, ave_loss: 0.429
[9]  [160/1724] loss: 0.569, ave_loss: 0.445
[10]  [180/1724] loss: 0.452, ave_loss: 0.445
[11]  [200/1724] loss: 0.514, ave_loss: 0.452
[12]  [220/1724] loss: 0.522, ave_loss: 0.458
[13]  [240/1724] loss: 0.425, ave_loss: 0.455
[14]  [260/1724] loss: 0.450, ave_loss: 0.455
[15]  [280/1724] loss: 0.436, ave_loss: 0.454
[16]  [300/1724] loss: 0.533, ave_loss: 0.458
[17]  [320/1724] loss: 0.559, ave_loss: 0.464
[18]  [340/1724] loss: 0.494, ave_loss: 0.466
[19]  [360/1724] loss: 0.456, ave_loss: 0.466
[20]  [380/1724] loss: 0.568, ave_loss: 0.471
[21]  [400/1724] loss: 0.430, ave_loss: 0.469
[22]  [420/1724] loss: 0.484, ave_loss: 0.469
[23]  [440/1724] loss: 0.533, ave_loss: 0.472
[24]  [460/1724] loss: 0.358, ave_loss: 0.467
[25]  [480/1724] loss: 0.417, ave_loss: 0.465
[26]  [500/1724] loss: 0.445, ave_loss: 0.465
[27]  [520/1724] loss: 0.414, ave_loss: 0.463
[28]  [540/1724] loss: 0.330, ave_loss: 0.458
[29]  [560/1724] loss: 0.403, ave_loss: 0.456
[30]  [580/1724] loss: 0.505, ave_loss: 0.458
[31]  [600/1724] loss: 0.571, ave_loss: 0.461
[32]  [620/1724] loss: 0.309, ave_loss: 0.457
[33]  [640/1724] loss: 0.465, ave_loss: 0.457
[34]  [660/1724] loss: 0.337, ave_loss: 0.453
[35]  [680/1724] loss: 0.409, ave_loss: 0.452
[36]  [700/1724] loss: 0.591, ave_loss: 0.456
[37]  [720/1724] loss: 0.528, ave_loss: 0.458
[38]  [740/1724] loss: 0.452, ave_loss: 0.458
[39]  [760/1724] loss: 0.265, ave_loss: 0.453
[40]  [780/1724] loss: 0.398, ave_loss: 0.451
[41]  [800/1724] loss: 0.341, ave_loss: 0.449
[42]  [820/1724] loss: 0.373, ave_loss: 0.447
[43]  [840/1724] loss: 0.431, ave_loss: 0.447
[44]  [860/1724] loss: 0.428, ave_loss: 0.446
[45]  [880/1724] loss: 0.448, ave_loss: 0.446
[46]  [900/1724] loss: 0.366, ave_loss: 0.444
[47]  [920/1724] loss: 0.459, ave_loss: 0.445
[48]  [940/1724] loss: 0.431, ave_loss: 0.444
[49]  [960/1724] loss: 0.629, ave_loss: 0.448
[50]  [980/1724] loss: 0.339, ave_loss: 0.446
[51]  [1000/1724] loss: 0.427, ave_loss: 0.446
[52]  [1020/1724] loss: 0.571, ave_loss: 0.448
[53]  [1040/1724] loss: 0.423, ave_loss: 0.448
[54]  [1060/1724] loss: 0.482, ave_loss: 0.448
[55]  [1080/1724] loss: 0.577, ave_loss: 0.451
[56]  [1100/1724] loss: 0.379, ave_loss: 0.449
[57]  [1120/1724] loss: 0.682, ave_loss: 0.453
[58]  [1140/1724] loss: 0.454, ave_loss: 0.453
[59]  [1160/1724] loss: 0.409, ave_loss: 0.453
[60]  [1180/1724] loss: 0.346, ave_loss: 0.451
[61]  [1200/1724] loss: 0.384, ave_loss: 0.450
[62]  [1220/1724] loss: 0.436, ave_loss: 0.450
[63]  [1240/1724] loss: 0.380, ave_loss: 0.448
[64]  [1260/1724] loss: 0.504, ave_loss: 0.449
[65]  [1280/1724] loss: 0.484, ave_loss: 0.450
[66]  [1300/1724] loss: 0.473, ave_loss: 0.450
[67]  [1320/1724] loss: 0.459, ave_loss: 0.450
[68]  [1340/1724] loss: 0.392, ave_loss: 0.449
[69]  [1360/1724] loss: 0.280, ave_loss: 0.447
[70]  [1380/1724] loss: 0.319, ave_loss: 0.445
[71]  [1400/1724] loss: 0.533, ave_loss: 0.446
[72]  [1420/1724] loss: 0.526, ave_loss: 0.448
[73]  [1440/1724] loss: 0.387, ave_loss: 0.447
[74]  [1460/1724] loss: 0.435, ave_loss: 0.447
[75]  [1480/1724] loss: 0.402, ave_loss: 0.446
[76]  [1500/1724] loss: 0.392, ave_loss: 0.445
[77]  [1520/1724] loss: 0.578, ave_loss: 0.447
[78]  [1540/1724] loss: 0.485, ave_loss: 0.447
[79]  [1560/1724] loss: 0.433, ave_loss: 0.447
[80]  [1580/1724] loss: 0.367, ave_loss: 0.446
[81]  [1600/1724] loss: 0.526, ave_loss: 0.447
[82]  [1620/1724] loss: 0.407, ave_loss: 0.447
[83]  [1640/1724] loss: 0.459, ave_loss: 0.447
[84]  [1660/1724] loss: 0.432, ave_loss: 0.447
[85]  [1680/1724] loss: 0.316, ave_loss: 0.445
[86]  [1700/1724] loss: 0.526, ave_loss: 0.446
[87]  [1720/1724] loss: 0.391, ave_loss: 0.445
[88]  [1740/1724] loss: 0.421, ave_loss: 0.445

Finished Training finishing at 2021-08-21 10:05:55.670447
printing_out epoch  8.167053364269142 learning rate: 0.0005153561248318907
0.0004039069405825386
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.452e-01
Validation Loss: 1.762e+05
Validation ROC: 0.7288
No improvement, still saving model
90.83294663573086 epochs left to go

Training Epoch 8.167053364269142/100 starting at 2021-08-21 10:06:23.113729
[1]  [0/1724] loss: 0.319, ave_loss: 0.319
[2]  [20/1724] loss: 0.461, ave_loss: 0.390
[3]  [40/1724] loss: 0.405, ave_loss: 0.395
[4]  [60/1724] loss: 0.301, ave_loss: 0.372
[5]  [80/1724] loss: 0.440, ave_loss: 0.385
[6]  [100/1724] loss: 0.572, ave_loss: 0.416
[7]  [120/1724] loss: 0.381, ave_loss: 0.411
[8]  [140/1724] loss: 0.453, ave_loss: 0.417
[9]  [160/1724] loss: 0.400, ave_loss: 0.415
[10]  [180/1724] loss: 0.399, ave_loss: 0.413
[11]  [200/1724] loss: 0.261, ave_loss: 0.399
[12]  [220/1724] loss: 0.520, ave_loss: 0.409
[13]  [240/1724] loss: 0.363, ave_loss: 0.406
[14]  [260/1724] loss: 0.563, ave_loss: 0.417
[15]  [280/1724] loss: 0.358, ave_loss: 0.413
[16]  [300/1724] loss: 0.375, ave_loss: 0.411
[17]  [320/1724] loss: 0.275, ave_loss: 0.403
[18]  [340/1724] loss: 0.514, ave_loss: 0.409
[19]  [360/1724] loss: 0.379, ave_loss: 0.407
[20]  [380/1724] loss: 0.392, ave_loss: 0.407
[21]  [400/1724] loss: 0.353, ave_loss: 0.404
[22]  [420/1724] loss: 0.334, ave_loss: 0.401
[23]  [440/1724] loss: 0.417, ave_loss: 0.401
[24]  [460/1724] loss: 0.412, ave_loss: 0.402
[25]  [480/1724] loss: 0.369, ave_loss: 0.401
[26]  [500/1724] loss: 0.339, ave_loss: 0.398
[27]  [520/1724] loss: 0.474, ave_loss: 0.401
[28]  [540/1724] loss: 0.364, ave_loss: 0.400
[29]  [560/1724] loss: 0.382, ave_loss: 0.399
[30]  [580/1724] loss: 0.314, ave_loss: 0.396
[31]  [600/1724] loss: 0.519, ave_loss: 0.400
[32]  [620/1724] loss: 0.426, ave_loss: 0.401
[33]  [640/1724] loss: 0.388, ave_loss: 0.401
[34]  [660/1724] loss: 0.395, ave_loss: 0.400
[35]  [680/1724] loss: 0.452, ave_loss: 0.402
[36]  [700/1724] loss: 0.294, ave_loss: 0.399
[37]  [720/1724] loss: 0.319, ave_loss: 0.397
[38]  [740/1724] loss: 0.439, ave_loss: 0.398
[39]  [760/1724] loss: 0.207, ave_loss: 0.393
[40]  [780/1724] loss: 0.447, ave_loss: 0.394
[41]  [800/1724] loss: 0.414, ave_loss: 0.395
[42]  [820/1724] loss: 0.387, ave_loss: 0.395
[43]  [840/1724] loss: 0.230, ave_loss: 0.391
[44]  [860/1724] loss: 0.325, ave_loss: 0.389
[45]  [880/1724] loss: 0.488, ave_loss: 0.391
[46]  [900/1724] loss: 0.264, ave_loss: 0.389
[47]  [920/1724] loss: 0.466, ave_loss: 0.390
[48]  [940/1724] loss: 0.352, ave_loss: 0.390
[49]  [960/1724] loss: 0.390, ave_loss: 0.390
[50]  [980/1724] loss: 0.322, ave_loss: 0.388
[51]  [1000/1724] loss: 0.555, ave_loss: 0.391
[52]  [1020/1724] loss: 0.391, ave_loss: 0.391
[53]  [1040/1724] loss: 0.462, ave_loss: 0.393
[54]  [1060/1724] loss: 0.469, ave_loss: 0.394
[55]  [1080/1724] loss: 0.333, ave_loss: 0.393
[56]  [1100/1724] loss: 0.369, ave_loss: 0.393
[57]  [1120/1724] loss: 0.373, ave_loss: 0.392
[58]  [1140/1724] loss: 0.517, ave_loss: 0.395
[59]  [1160/1724] loss: 0.612, ave_loss: 0.398
[60]  [1180/1724] loss: 0.461, ave_loss: 0.399
[61]  [1200/1724] loss: 0.433, ave_loss: 0.400
[62]  [1220/1724] loss: 0.669, ave_loss: 0.404
[63]  [1240/1724] loss: 0.531, ave_loss: 0.406
[64]  [1260/1724] loss: 0.471, ave_loss: 0.407
[65]  [1280/1724] loss: 0.429, ave_loss: 0.408
[66]  [1300/1724] loss: 0.491, ave_loss: 0.409
[67]  [1320/1724] loss: 0.409, ave_loss: 0.409
[68]  [1340/1724] loss: 0.476, ave_loss: 0.410
[69]  [1360/1724] loss: 0.412, ave_loss: 0.410
[70]  [1380/1724] loss: 0.352, ave_loss: 0.409
[71]  [1400/1724] loss: 0.541, ave_loss: 0.411
[72]  [1420/1724] loss: 0.438, ave_loss: 0.411
[73]  [1440/1724] loss: 0.464, ave_loss: 0.412
[74]  [1460/1724] loss: 0.535, ave_loss: 0.414
[75]  [1480/1724] loss: 0.480, ave_loss: 0.415
[76]  [1500/1724] loss: 0.452, ave_loss: 0.415
[77]  [1520/1724] loss: 0.404, ave_loss: 0.415
[78]  [1540/1724] loss: 0.472, ave_loss: 0.416
[79]  [1560/1724] loss: 0.535, ave_loss: 0.417
[80]  [1580/1724] loss: 0.489, ave_loss: 0.418
[81]  [1600/1724] loss: 0.330, ave_loss: 0.417
[82]  [1620/1724] loss: 0.323, ave_loss: 0.416
[83]  [1640/1724] loss: 0.551, ave_loss: 0.417
[84]  [1660/1724] loss: 0.547, ave_loss: 0.419
[85]  [1680/1724] loss: 0.499, ave_loss: 0.420
[86]  [1700/1724] loss: 0.514, ave_loss: 0.421
[87]  [1720/1724] loss: 0.313, ave_loss: 0.420
[88]  [1740/1724] loss: 0.453, ave_loss: 0.420

Finished Training finishing at 2021-08-21 10:08:18.453136
printing_out epoch  9.187935034802784 learning rate: 0.0005153561248318907
0.00039178973236506245
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.201e-01
Validation Loss: 1.947e+05
Validation ROC: 0.7336
No improvement, still saving model
89.81206496519721 epochs left to go

Training Epoch 9.187935034802784/100 starting at 2021-08-21 10:09:02.662345
[1]  [0/1724] loss: 0.586, ave_loss: 0.586
[2]  [20/1724] loss: 0.417, ave_loss: 0.501
[3]  [40/1724] loss: 0.424, ave_loss: 0.475
[4]  [60/1724] loss: 0.494, ave_loss: 0.480
[5]  [80/1724] loss: 0.441, ave_loss: 0.472
[6]  [100/1724] loss: 0.373, ave_loss: 0.456
[7]  [120/1724] loss: 0.441, ave_loss: 0.454
[8]  [140/1724] loss: 0.413, ave_loss: 0.449
[9]  [160/1724] loss: 0.607, ave_loss: 0.466
[10]  [180/1724] loss: 0.285, ave_loss: 0.448
[11]  [200/1724] loss: 0.416, ave_loss: 0.445
[12]  [220/1724] loss: 0.293, ave_loss: 0.433
[13]  [240/1724] loss: 0.311, ave_loss: 0.423
[14]  [260/1724] loss: 0.555, ave_loss: 0.433
[15]  [280/1724] loss: 0.499, ave_loss: 0.437
[16]  [300/1724] loss: 0.350, ave_loss: 0.432
[17]  [320/1724] loss: 0.631, ave_loss: 0.443
[18]  [340/1724] loss: 0.513, ave_loss: 0.447
[19]  [360/1724] loss: 0.507, ave_loss: 0.450
[20]  [380/1724] loss: 0.524, ave_loss: 0.454
[21]  [400/1724] loss: 0.346, ave_loss: 0.449
[22]  [420/1724] loss: 0.355, ave_loss: 0.445
[23]  [440/1724] loss: 0.453, ave_loss: 0.445
[24]  [460/1724] loss: 0.513, ave_loss: 0.448
[25]  [480/1724] loss: 0.541, ave_loss: 0.452
[26]  [500/1724] loss: 0.433, ave_loss: 0.451
[27]  [520/1724] loss: 0.567, ave_loss: 0.455
[28]  [540/1724] loss: 0.434, ave_loss: 0.454
[29]  [560/1724] loss: 0.370, ave_loss: 0.451
[30]  [580/1724] loss: 0.479, ave_loss: 0.452
[31]  [600/1724] loss: 0.417, ave_loss: 0.451
[32]  [620/1724] loss: 0.517, ave_loss: 0.453
[33]  [640/1724] loss: 0.532, ave_loss: 0.456
[34]  [660/1724] loss: 0.466, ave_loss: 0.456
[35]  [680/1724] loss: 0.519, ave_loss: 0.458
[36]  [700/1724] loss: 0.325, ave_loss: 0.454
[37]  [720/1724] loss: 0.378, ave_loss: 0.452
[38]  [740/1724] loss: 0.509, ave_loss: 0.454
[39]  [760/1724] loss: 0.571, ave_loss: 0.457
[40]  [780/1724] loss: 0.468, ave_loss: 0.457
[41]  [800/1724] loss: 0.288, ave_loss: 0.453
[42]  [820/1724] loss: 0.436, ave_loss: 0.452
[43]  [840/1724] loss: 0.357, ave_loss: 0.450
[44]  [860/1724] loss: 0.422, ave_loss: 0.449
[45]  [880/1724] loss: 0.475, ave_loss: 0.450
[46]  [900/1724] loss: 0.535, ave_loss: 0.452
[47]  [920/1724] loss: 0.477, ave_loss: 0.452
[48]  [940/1724] loss: 0.473, ave_loss: 0.453
[49]  [960/1724] loss: 0.489, ave_loss: 0.454
[50]  [980/1724] loss: 0.361, ave_loss: 0.452
[51]  [1000/1724] loss: 0.400, ave_loss: 0.451
[52]  [1020/1724] loss: 0.514, ave_loss: 0.452
[53]  [1040/1724] loss: 0.396, ave_loss: 0.451
[54]  [1060/1724] loss: 0.553, ave_loss: 0.453
[55]  [1080/1724] loss: 0.531, ave_loss: 0.454
[56]  [1100/1724] loss: 0.302, ave_loss: 0.451
[57]  [1120/1724] loss: 0.465, ave_loss: 0.452
[58]  [1140/1724] loss: 0.416, ave_loss: 0.451
[59]  [1160/1724] loss: 0.420, ave_loss: 0.451
[60]  [1180/1724] loss: 0.565, ave_loss: 0.452
[61]  [1200/1724] loss: 0.562, ave_loss: 0.454
[62]  [1220/1724] loss: 0.343, ave_loss: 0.452
[63]  [1240/1724] loss: 0.442, ave_loss: 0.452
[64]  [1260/1724] loss: 0.325, ave_loss: 0.450
[65]  [1280/1724] loss: 0.470, ave_loss: 0.451
[66]  [1300/1724] loss: 0.432, ave_loss: 0.450
[67]  [1320/1724] loss: 0.330, ave_loss: 0.449
[68]  [1340/1724] loss: 0.442, ave_loss: 0.448
[69]  [1360/1724] loss: 0.472, ave_loss: 0.449
[70]  [1380/1724] loss: 0.436, ave_loss: 0.449
[71]  [1400/1724] loss: 0.563, ave_loss: 0.450
[72]  [1420/1724] loss: 0.455, ave_loss: 0.450
[73]  [1440/1724] loss: 0.374, ave_loss: 0.449
[74]  [1460/1724] loss: 0.396, ave_loss: 0.449
[75]  [1480/1724] loss: 0.411, ave_loss: 0.448
[76]  [1500/1724] loss: 0.382, ave_loss: 0.447
[77]  [1520/1724] loss: 0.407, ave_loss: 0.447
[78]  [1540/1724] loss: 0.370, ave_loss: 0.446
[79]  [1560/1724] loss: 0.373, ave_loss: 0.445
[80]  [1580/1724] loss: 0.438, ave_loss: 0.445
[81]  [1600/1724] loss: 0.497, ave_loss: 0.445
[82]  [1620/1724] loss: 0.386, ave_loss: 0.445
[83]  [1640/1724] loss: 0.328, ave_loss: 0.443
[84]  [1660/1724] loss: 0.437, ave_loss: 0.443
[85]  [1680/1724] loss: 0.368, ave_loss: 0.442
[86]  [1700/1724] loss: 0.383, ave_loss: 0.442
[87]  [1720/1724] loss: 0.547, ave_loss: 0.443
[88]  [1740/1724] loss: 0.448, ave_loss: 0.443

Finished Training finishing at 2021-08-21 10:11:02.151744
printing_out epoch  10.208816705336426 learning rate: 0.0005153561248318907
0.0003800360403941106
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.428e-01
Validation Loss: 1.592e+05
Validation ROC: 0.7383
No improvement, still saving model
88.79118329466357 epochs left to go

Training Epoch 10.208816705336426/100 starting at 2021-08-21 10:11:45.691963
[1]  [0/1724] loss: 0.535, ave_loss: 0.535
[2]  [20/1724] loss: 0.528, ave_loss: 0.531
[3]  [40/1724] loss: 0.498, ave_loss: 0.520
[4]  [60/1724] loss: 0.577, ave_loss: 0.535
[5]  [80/1724] loss: 0.356, ave_loss: 0.499
[6]  [100/1724] loss: 0.379, ave_loss: 0.479
[7]  [120/1724] loss: 0.428, ave_loss: 0.472
[8]  [140/1724] loss: 0.265, ave_loss: 0.446
[9]  [160/1724] loss: 0.436, ave_loss: 0.445
[10]  [180/1724] loss: 0.571, ave_loss: 0.457
[11]  [200/1724] loss: 0.428, ave_loss: 0.455
[12]  [220/1724] loss: 0.378, ave_loss: 0.448
[13]  [240/1724] loss: 0.405, ave_loss: 0.445
[14]  [260/1724] loss: 0.397, ave_loss: 0.442
[15]  [280/1724] loss: 0.319, ave_loss: 0.433
[16]  [300/1724] loss: 0.373, ave_loss: 0.430
[17]  [320/1724] loss: 0.489, ave_loss: 0.433
[18]  [340/1724] loss: 0.545, ave_loss: 0.439
[19]  [360/1724] loss: 0.373, ave_loss: 0.436
[20]  [380/1724] loss: 0.377, ave_loss: 0.433
[21]  [400/1724] loss: 0.502, ave_loss: 0.436
[22]  [420/1724] loss: 0.358, ave_loss: 0.433
[23]  [440/1724] loss: 0.413, ave_loss: 0.432
[24]  [460/1724] loss: 0.399, ave_loss: 0.430
[25]  [480/1724] loss: 0.519, ave_loss: 0.434
[26]  [500/1724] loss: 0.397, ave_loss: 0.433
[27]  [520/1724] loss: 0.598, ave_loss: 0.439
[28]  [540/1724] loss: 0.460, ave_loss: 0.440
[29]  [560/1724] loss: 0.396, ave_loss: 0.438
[30]  [580/1724] loss: 0.312, ave_loss: 0.434
[31]  [600/1724] loss: 0.359, ave_loss: 0.431
[32]  [620/1724] loss: 0.397, ave_loss: 0.430
[33]  [640/1724] loss: 0.594, ave_loss: 0.435
[34]  [660/1724] loss: 0.414, ave_loss: 0.435
[35]  [680/1724] loss: 0.465, ave_loss: 0.436
[36]  [700/1724] loss: 0.487, ave_loss: 0.437
[37]  [720/1724] loss: 0.501, ave_loss: 0.439
[38]  [740/1724] loss: 0.393, ave_loss: 0.438
[39]  [760/1724] loss: 0.456, ave_loss: 0.438
[40]  [780/1724] loss: 0.437, ave_loss: 0.438
[41]  [800/1724] loss: 0.431, ave_loss: 0.438
[42]  [820/1724] loss: 0.479, ave_loss: 0.439
[43]  [840/1724] loss: 0.272, ave_loss: 0.435
[44]  [860/1724] loss: 0.265, ave_loss: 0.431
[45]  [880/1724] loss: 0.448, ave_loss: 0.431
[46]  [900/1724] loss: 0.360, ave_loss: 0.430
[47]  [920/1724] loss: 0.454, ave_loss: 0.430
[48]  [940/1724] loss: 0.445, ave_loss: 0.431
[49]  [960/1724] loss: 0.376, ave_loss: 0.430
[50]  [980/1724] loss: 0.523, ave_loss: 0.431
[51]  [1000/1724] loss: 0.277, ave_loss: 0.428
[52]  [1020/1724] loss: 0.484, ave_loss: 0.430
[53]  [1040/1724] loss: 0.379, ave_loss: 0.429
[54]  [1060/1724] loss: 0.583, ave_loss: 0.431
[55]  [1080/1724] loss: 0.528, ave_loss: 0.433
[56]  [1100/1724] loss: 0.329, ave_loss: 0.431
[57]  [1120/1724] loss: 0.387, ave_loss: 0.431
[58]  [1140/1724] loss: 0.456, ave_loss: 0.431
[59]  [1160/1724] loss: 0.446, ave_loss: 0.431
[60]  [1180/1724] loss: 0.462, ave_loss: 0.432
[61]  [1200/1724] loss: 0.265, ave_loss: 0.429
[62]  [1220/1724] loss: 0.344, ave_loss: 0.428
[63]  [1240/1724] loss: 0.480, ave_loss: 0.428
[64]  [1260/1724] loss: 0.602, ave_loss: 0.431
[65]  [1280/1724] loss: 0.510, ave_loss: 0.432
[66]  [1300/1724] loss: 0.347, ave_loss: 0.431
[67]  [1320/1724] loss: 0.392, ave_loss: 0.431
[68]  [1340/1724] loss: 0.456, ave_loss: 0.431
[69]  [1360/1724] loss: 0.369, ave_loss: 0.430
[70]  [1380/1724] loss: 0.461, ave_loss: 0.430
[71]  [1400/1724] loss: 0.420, ave_loss: 0.430
[72]  [1420/1724] loss: 0.422, ave_loss: 0.430
[73]  [1440/1724] loss: 0.503, ave_loss: 0.431
[74]  [1460/1724] loss: 0.384, ave_loss: 0.431
[75]  [1480/1724] loss: 0.376, ave_loss: 0.430
[76]  [1500/1724] loss: 0.405, ave_loss: 0.429
[77]  [1520/1724] loss: 0.395, ave_loss: 0.429
[78]  [1540/1724] loss: 0.325, ave_loss: 0.428
[79]  [1560/1724] loss: 0.405, ave_loss: 0.427
[80]  [1580/1724] loss: 0.377, ave_loss: 0.427
[81]  [1600/1724] loss: 0.491, ave_loss: 0.428
[82]  [1620/1724] loss: 0.501, ave_loss: 0.428
[83]  [1640/1724] loss: 0.674, ave_loss: 0.431
[84]  [1660/1724] loss: 0.497, ave_loss: 0.432
[85]  [1680/1724] loss: 0.367, ave_loss: 0.431
[86]  [1700/1724] loss: 0.392, ave_loss: 0.431
[87]  [1720/1724] loss: 0.521, ave_loss: 0.432
[88]  [1740/1724] loss: 0.387, ave_loss: 0.431

Finished Training finishing at 2021-08-21 10:13:53.651978
printing_out epoch  11.22969837587007 learning rate: 0.00046850556802899155
0.0004544504009881218
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.315e-01
Validation Loss: 1.649e+05
Validation ROC: 0.7231
No improvement, still saving model
87.77030162412993 epochs left to go

Training Epoch 11.22969837587007/100 starting at 2021-08-21 10:15:20.906960
[1]  [0/1724] loss: 0.605, ave_loss: 0.605
[2]  [20/1724] loss: 0.487, ave_loss: 0.546
[3]  [40/1724] loss: 0.319, ave_loss: 0.470
[4]  [60/1724] loss: 0.416, ave_loss: 0.456
[5]  [80/1724] loss: 0.356, ave_loss: 0.436
[6]  [100/1724] loss: 0.547, ave_loss: 0.455
[7]  [120/1724] loss: 0.439, ave_loss: 0.452
[8]  [140/1724] loss: 0.513, ave_loss: 0.460
[9]  [160/1724] loss: 0.350, ave_loss: 0.448
[10]  [180/1724] loss: 0.442, ave_loss: 0.447
[11]  [200/1724] loss: 0.412, ave_loss: 0.444
[12]  [220/1724] loss: 0.326, ave_loss: 0.434
[13]  [240/1724] loss: 0.387, ave_loss: 0.431
[14]  [260/1724] loss: 0.485, ave_loss: 0.434
[15]  [280/1724] loss: 0.326, ave_loss: 0.427
[16]  [300/1724] loss: 0.353, ave_loss: 0.423
[17]  [320/1724] loss: 0.516, ave_loss: 0.428
[18]  [340/1724] loss: 0.441, ave_loss: 0.429
[19]  [360/1724] loss: 0.311, ave_loss: 0.423
[20]  [380/1724] loss: 0.286, ave_loss: 0.416
[21]  [400/1724] loss: 0.292, ave_loss: 0.410
[22]  [420/1724] loss: 0.427, ave_loss: 0.411
[23]  [440/1724] loss: 0.461, ave_loss: 0.413
[24]  [460/1724] loss: 0.439, ave_loss: 0.414
[25]  [480/1724] loss: 0.292, ave_loss: 0.409
[26]  [500/1724] loss: 0.436, ave_loss: 0.410
[27]  [520/1724] loss: 0.329, ave_loss: 0.407
[28]  [540/1724] loss: 0.427, ave_loss: 0.408
[29]  [560/1724] loss: 0.418, ave_loss: 0.408
[30]  [580/1724] loss: 0.442, ave_loss: 0.409
[31]  [600/1724] loss: 0.548, ave_loss: 0.414
[32]  [620/1724] loss: 0.302, ave_loss: 0.410
[33]  [640/1724] loss: 0.318, ave_loss: 0.407
[34]  [660/1724] loss: 0.518, ave_loss: 0.411
[35]  [680/1724] loss: 0.397, ave_loss: 0.410
[36]  [700/1724] loss: 0.548, ave_loss: 0.414
[37]  [720/1724] loss: 0.490, ave_loss: 0.416
[38]  [740/1724] loss: 0.458, ave_loss: 0.417
[39]  [760/1724] loss: 0.346, ave_loss: 0.415
[40]  [780/1724] loss: 0.302, ave_loss: 0.413
[41]  [800/1724] loss: 0.312, ave_loss: 0.410
[42]  [820/1724] loss: 0.473, ave_loss: 0.412
[43]  [840/1724] loss: 0.549, ave_loss: 0.415
[44]  [860/1724] loss: 0.596, ave_loss: 0.419
[45]  [880/1724] loss: 0.416, ave_loss: 0.419
[46]  [900/1724] loss: 0.404, ave_loss: 0.419
[47]  [920/1724] loss: 0.433, ave_loss: 0.419
[48]  [940/1724] loss: 0.381, ave_loss: 0.418
[49]  [960/1724] loss: 0.355, ave_loss: 0.417
[50]  [980/1724] loss: 0.373, ave_loss: 0.416
[51]  [1000/1724] loss: 0.531, ave_loss: 0.418
[52]  [1020/1724] loss: 0.464, ave_loss: 0.419
[53]  [1040/1724] loss: 0.444, ave_loss: 0.420
[54]  [1060/1724] loss: 0.371, ave_loss: 0.419
[55]  [1080/1724] loss: 0.455, ave_loss: 0.419
[56]  [1100/1724] loss: 0.351, ave_loss: 0.418
[57]  [1120/1724] loss: 0.354, ave_loss: 0.417
[58]  [1140/1724] loss: 0.491, ave_loss: 0.418
[59]  [1160/1724] loss: 0.345, ave_loss: 0.417
[60]  [1180/1724] loss: 0.281, ave_loss: 0.415
[61]  [1200/1724] loss: 0.437, ave_loss: 0.415
[62]  [1220/1724] loss: 0.308, ave_loss: 0.413
[63]  [1240/1724] loss: 0.424, ave_loss: 0.414
[64]  [1260/1724] loss: 0.442, ave_loss: 0.414
[65]  [1280/1724] loss: 0.522, ave_loss: 0.416
[66]  [1300/1724] loss: 0.328, ave_loss: 0.414
[67]  [1320/1724] loss: 0.386, ave_loss: 0.414
[68]  [1340/1724] loss: 0.326, ave_loss: 0.413
[69]  [1360/1724] loss: 0.266, ave_loss: 0.410
[70]  [1380/1724] loss: 0.412, ave_loss: 0.410
[71]  [1400/1724] loss: 0.370, ave_loss: 0.410
[72]  [1420/1724] loss: 0.339, ave_loss: 0.409
[73]  [1440/1724] loss: 0.509, ave_loss: 0.410
[74]  [1460/1724] loss: 0.280, ave_loss: 0.409
[75]  [1480/1724] loss: 0.337, ave_loss: 0.408
[76]  [1500/1724] loss: 0.443, ave_loss: 0.408
[77]  [1520/1724] loss: 0.429, ave_loss: 0.408
[78]  [1540/1724] loss: 0.346, ave_loss: 0.408
[79]  [1560/1724] loss: 0.457, ave_loss: 0.408
[80]  [1580/1724] loss: 0.528, ave_loss: 0.410
[81]  [1600/1724] loss: 0.524, ave_loss: 0.411
[82]  [1620/1724] loss: 0.474, ave_loss: 0.412
[83]  [1640/1724] loss: 0.425, ave_loss: 0.412
[84]  [1660/1724] loss: 0.323, ave_loss: 0.411
[85]  [1680/1724] loss: 0.382, ave_loss: 0.411
[86]  [1700/1724] loss: 0.527, ave_loss: 0.412
[87]  [1720/1724] loss: 0.660, ave_loss: 0.415
[88]  [1740/1724] loss: 0.387, ave_loss: 0.414

Finished Training finishing at 2021-08-21 10:17:26.723549
printing_out epoch  12.250580046403712 learning rate: 0.00042591415275362865
0.0004131367281710198
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.145e-01
Validation Loss: 1.182e+05
Validation ROC: 0.7253
No improvement, still saving model
86.74941995359629 epochs left to go

Training Epoch 12.250580046403712/100 starting at 2021-08-21 10:17:57.940250
[1]  [0/1724] loss: 1.013, ave_loss: 1.013
[2]  [20/1724] loss: 0.439, ave_loss: 0.726
[3]  [40/1724] loss: 0.326, ave_loss: 0.593
[4]  [60/1724] loss: 0.330, ave_loss: 0.527
[5]  [80/1724] loss: 0.376, ave_loss: 0.497
[6]  [100/1724] loss: 0.469, ave_loss: 0.492
[7]  [120/1724] loss: 0.337, ave_loss: 0.470
[8]  [140/1724] loss: 0.348, ave_loss: 0.455
[9]  [160/1724] loss: 0.499, ave_loss: 0.460
[10]  [180/1724] loss: 0.571, ave_loss: 0.471
[11]  [200/1724] loss: 0.350, ave_loss: 0.460
[12]  [220/1724] loss: 0.497, ave_loss: 0.463
[13]  [240/1724] loss: 0.466, ave_loss: 0.463
[14]  [260/1724] loss: 0.379, ave_loss: 0.457
[15]  [280/1724] loss: 0.501, ave_loss: 0.460
[16]  [300/1724] loss: 0.368, ave_loss: 0.454
[17]  [320/1724] loss: 0.438, ave_loss: 0.453
[18]  [340/1724] loss: 0.389, ave_loss: 0.450
[19]  [360/1724] loss: 0.512, ave_loss: 0.453
[20]  [380/1724] loss: 0.335, ave_loss: 0.447
[21]  [400/1724] loss: 0.415, ave_loss: 0.446
[22]  [420/1724] loss: 0.332, ave_loss: 0.440
[23]  [440/1724] loss: 0.286, ave_loss: 0.434
[24]  [460/1724] loss: 0.300, ave_loss: 0.428
[25]  [480/1724] loss: 0.357, ave_loss: 0.425
[26]  [500/1724] loss: 0.575, ave_loss: 0.431
[27]  [520/1724] loss: 0.422, ave_loss: 0.431
[28]  [540/1724] loss: 0.622, ave_loss: 0.438
[29]  [560/1724] loss: 0.332, ave_loss: 0.434
[30]  [580/1724] loss: 0.633, ave_loss: 0.441
[31]  [600/1724] loss: 0.592, ave_loss: 0.445
[32]  [620/1724] loss: 0.366, ave_loss: 0.443
[33]  [640/1724] loss: 0.341, ave_loss: 0.440
[34]  [660/1724] loss: 0.230, ave_loss: 0.434
[35]  [680/1724] loss: 0.424, ave_loss: 0.433
[36]  [700/1724] loss: 0.470, ave_loss: 0.434
[37]  [720/1724] loss: 0.270, ave_loss: 0.430
[38]  [740/1724] loss: 0.603, ave_loss: 0.435
[39]  [760/1724] loss: 0.491, ave_loss: 0.436
[40]  [780/1724] loss: 0.440, ave_loss: 0.436
[41]  [800/1724] loss: 0.351, ave_loss: 0.434
[42]  [820/1724] loss: 0.358, ave_loss: 0.432
[43]  [840/1724] loss: 0.356, ave_loss: 0.430
[44]  [860/1724] loss: 0.529, ave_loss: 0.433
[45]  [880/1724] loss: 0.471, ave_loss: 0.434
[46]  [900/1724] loss: 0.463, ave_loss: 0.434
[47]  [920/1724] loss: 0.494, ave_loss: 0.435
[48]  [940/1724] loss: 0.386, ave_loss: 0.434
[49]  [960/1724] loss: 0.416, ave_loss: 0.434
[50]  [980/1724] loss: 0.353, ave_loss: 0.432
[51]  [1000/1724] loss: 0.395, ave_loss: 0.432
[52]  [1020/1724] loss: 0.423, ave_loss: 0.431
[53]  [1040/1724] loss: 0.486, ave_loss: 0.433
[54]  [1060/1724] loss: 0.443, ave_loss: 0.433
[55]  [1080/1724] loss: 0.464, ave_loss: 0.433
[56]  [1100/1724] loss: 0.535, ave_loss: 0.435
[57]  [1120/1724] loss: 0.381, ave_loss: 0.434
[58]  [1140/1724] loss: 0.403, ave_loss: 0.434
[59]  [1160/1724] loss: 0.350, ave_loss: 0.432
[60]  [1180/1724] loss: 0.306, ave_loss: 0.430
[61]  [1200/1724] loss: 0.358, ave_loss: 0.429
[62]  [1220/1724] loss: 0.411, ave_loss: 0.429
[63]  [1240/1724] loss: 0.490, ave_loss: 0.430
[64]  [1260/1724] loss: 0.455, ave_loss: 0.430
[65]  [1280/1724] loss: 0.311, ave_loss: 0.428
[66]  [1300/1724] loss: 0.376, ave_loss: 0.427
[67]  [1320/1724] loss: 0.496, ave_loss: 0.428
[68]  [1340/1724] loss: 0.398, ave_loss: 0.428
[69]  [1360/1724] loss: 0.424, ave_loss: 0.428
[70]  [1380/1724] loss: 0.424, ave_loss: 0.428
[71]  [1400/1724] loss: 0.529, ave_loss: 0.429
[72]  [1420/1724] loss: 0.448, ave_loss: 0.430
[73]  [1440/1724] loss: 0.419, ave_loss: 0.429
[74]  [1460/1724] loss: 0.288, ave_loss: 0.427
[75]  [1480/1724] loss: 0.575, ave_loss: 0.429
[76]  [1500/1724] loss: 0.394, ave_loss: 0.429
[77]  [1520/1724] loss: 0.392, ave_loss: 0.429
[78]  [1540/1724] loss: 0.268, ave_loss: 0.426
[79]  [1560/1724] loss: 0.314, ave_loss: 0.425
[80]  [1580/1724] loss: 0.432, ave_loss: 0.425
[81]  [1600/1724] loss: 0.282, ave_loss: 0.423
[82]  [1620/1724] loss: 0.330, ave_loss: 0.422
[83]  [1640/1724] loss: 0.305, ave_loss: 0.421
[84]  [1660/1724] loss: 0.379, ave_loss: 0.420
[85]  [1680/1724] loss: 0.468, ave_loss: 0.421
[86]  [1700/1724] loss: 0.466, ave_loss: 0.421
[87]  [1720/1724] loss: 0.303, ave_loss: 0.420
[88]  [1740/1724] loss: 0.518, ave_loss: 0.421

Finished Training finishing at 2021-08-21 10:19:57.820820
printing_out epoch  13.271461716937354 learning rate: 0.00038719468432148055
0.0003755788437918361
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.211e-01
Validation Loss: 1.393e+05
Validation ROC: 0.7306
No improvement, still saving model
85.72853828306265 epochs left to go

Training Epoch 13.271461716937354/100 starting at 2021-08-21 10:20:26.182933
[1]  [0/1724] loss: 0.514, ave_loss: 0.514
[2]  [20/1724] loss: 0.196, ave_loss: 0.355
[3]  [40/1724] loss: 0.239, ave_loss: 0.317
[4]  [60/1724] loss: 0.567, ave_loss: 0.379
[5]  [80/1724] loss: 0.427, ave_loss: 0.389
[6]  [100/1724] loss: 0.408, ave_loss: 0.392
[7]  [120/1724] loss: 0.515, ave_loss: 0.410
[8]  [140/1724] loss: 0.515, ave_loss: 0.423
[9]  [160/1724] loss: 0.440, ave_loss: 0.425
[10]  [180/1724] loss: 0.477, ave_loss: 0.430
[11]  [200/1724] loss: 0.594, ave_loss: 0.445
[12]  [220/1724] loss: 0.384, ave_loss: 0.440
[13]  [240/1724] loss: 0.359, ave_loss: 0.434
[14]  [260/1724] loss: 0.516, ave_loss: 0.439
[15]  [280/1724] loss: 0.355, ave_loss: 0.434
[16]  [300/1724] loss: 0.436, ave_loss: 0.434
[17]  [320/1724] loss: 0.521, ave_loss: 0.439
[18]  [340/1724] loss: 0.358, ave_loss: 0.434
[19]  [360/1724] loss: 0.453, ave_loss: 0.435
[20]  [380/1724] loss: 0.443, ave_loss: 0.436
[21]  [400/1724] loss: 0.290, ave_loss: 0.429
[22]  [420/1724] loss: 0.360, ave_loss: 0.426
[23]  [440/1724] loss: 0.375, ave_loss: 0.424
[24]  [460/1724] loss: 0.490, ave_loss: 0.426
[25]  [480/1724] loss: 0.480, ave_loss: 0.428
[26]  [500/1724] loss: 0.406, ave_loss: 0.428
[27]  [520/1724] loss: 0.540, ave_loss: 0.432
[28]  [540/1724] loss: 0.335, ave_loss: 0.428
[29]  [560/1724] loss: 0.363, ave_loss: 0.426
[30]  [580/1724] loss: 0.501, ave_loss: 0.429
[31]  [600/1724] loss: 0.505, ave_loss: 0.431
[32]  [620/1724] loss: 0.273, ave_loss: 0.426
[33]  [640/1724] loss: 0.377, ave_loss: 0.425
[34]  [660/1724] loss: 0.468, ave_loss: 0.426
[35]  [680/1724] loss: 0.262, ave_loss: 0.421
[36]  [700/1724] loss: 0.397, ave_loss: 0.420
[37]  [720/1724] loss: 0.524, ave_loss: 0.423
[38]  [740/1724] loss: 0.509, ave_loss: 0.426
[39]  [760/1724] loss: 0.557, ave_loss: 0.429
[40]  [780/1724] loss: 0.309, ave_loss: 0.426
[41]  [800/1724] loss: 0.358, ave_loss: 0.424
[42]  [820/1724] loss: 0.354, ave_loss: 0.423
[43]  [840/1724] loss: 0.462, ave_loss: 0.423
[44]  [860/1724] loss: 0.337, ave_loss: 0.422
[45]  [880/1724] loss: 0.418, ave_loss: 0.421
[46]  [900/1724] loss: 0.390, ave_loss: 0.421
[47]  [920/1724] loss: 0.318, ave_loss: 0.419
[48]  [940/1724] loss: 0.416, ave_loss: 0.419
[49]  [960/1724] loss: 0.547, ave_loss: 0.421
[50]  [980/1724] loss: 0.411, ave_loss: 0.421
[51]  [1000/1724] loss: 0.435, ave_loss: 0.421
[52]  [1020/1724] loss: 0.453, ave_loss: 0.422
[53]  [1040/1724] loss: 0.417, ave_loss: 0.422
[54]  [1060/1724] loss: 0.328, ave_loss: 0.420
[55]  [1080/1724] loss: 0.388, ave_loss: 0.419
[56]  [1100/1724] loss: 0.673, ave_loss: 0.424
[57]  [1120/1724] loss: 0.366, ave_loss: 0.423
[58]  [1140/1724] loss: 0.511, ave_loss: 0.424
[59]  [1160/1724] loss: 0.288, ave_loss: 0.422
[60]  [1180/1724] loss: 0.509, ave_loss: 0.424
[61]  [1200/1724] loss: 0.488, ave_loss: 0.425
[62]  [1220/1724] loss: 0.337, ave_loss: 0.423
[63]  [1240/1724] loss: 0.416, ave_loss: 0.423
[64]  [1260/1724] loss: 0.341, ave_loss: 0.422
[65]  [1280/1724] loss: 0.408, ave_loss: 0.422
[66]  [1300/1724] loss: 0.466, ave_loss: 0.422
[67]  [1320/1724] loss: 0.496, ave_loss: 0.423
[68]  [1340/1724] loss: 0.415, ave_loss: 0.423
[69]  [1360/1724] loss: 0.298, ave_loss: 0.421
[70]  [1380/1724] loss: 0.303, ave_loss: 0.420
[71]  [1400/1724] loss: 0.330, ave_loss: 0.419
[72]  [1420/1724] loss: 0.422, ave_loss: 0.419
[73]  [1440/1724] loss: 0.299, ave_loss: 0.417
[74]  [1460/1724] loss: 0.413, ave_loss: 0.417
[75]  [1480/1724] loss: 0.497, ave_loss: 0.418
[76]  [1500/1724] loss: 0.290, ave_loss: 0.416
[77]  [1520/1724] loss: 0.254, ave_loss: 0.414
[78]  [1540/1724] loss: 0.448, ave_loss: 0.415
[79]  [1560/1724] loss: 0.568, ave_loss: 0.417
[80]  [1580/1724] loss: 0.376, ave_loss: 0.416
[81]  [1600/1724] loss: 0.519, ave_loss: 0.417
[82]  [1620/1724] loss: 0.252, ave_loss: 0.415
[83]  [1640/1724] loss: 0.497, ave_loss: 0.416
[84]  [1660/1724] loss: 0.441, ave_loss: 0.417
[85]  [1680/1724] loss: 0.404, ave_loss: 0.416
[86]  [1700/1724] loss: 0.328, ave_loss: 0.415
[87]  [1720/1724] loss: 0.429, ave_loss: 0.416
[88]  [1740/1724] loss: 0.564, ave_loss: 0.417

Finished Training finishing at 2021-08-21 10:22:32.471606
printing_out epoch  14.292343387470998 learning rate: 0.0003519951675649823
0.00034143531253803285
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.172e-01
Validation Loss: 9.844e+04
Validation ROC: 0.7241
No improvement, still saving model
84.70765661252901 epochs left to go

Training Epoch 14.292343387470998/100 starting at 2021-08-21 10:23:26.428411
[1]  [0/1724] loss: 0.567, ave_loss: 0.567
[2]  [20/1724] loss: 0.498, ave_loss: 0.532
[3]  [40/1724] loss: 0.429, ave_loss: 0.498
[4]  [60/1724] loss: 0.396, ave_loss: 0.472
[5]  [80/1724] loss: 0.403, ave_loss: 0.459
[6]  [100/1724] loss: 0.488, ave_loss: 0.463
[7]  [120/1724] loss: 0.571, ave_loss: 0.479
[8]  [140/1724] loss: 0.262, ave_loss: 0.452
[9]  [160/1724] loss: 0.420, ave_loss: 0.448
[10]  [180/1724] loss: 0.384, ave_loss: 0.442
[11]  [200/1724] loss: 0.450, ave_loss: 0.443
[12]  [220/1724] loss: 0.459, ave_loss: 0.444
[13]  [240/1724] loss: 0.480, ave_loss: 0.447
[14]  [260/1724] loss: 0.371, ave_loss: 0.441
[15]  [280/1724] loss: 0.375, ave_loss: 0.437
[16]  [300/1724] loss: 0.414, ave_loss: 0.435
[17]  [320/1724] loss: 0.349, ave_loss: 0.430
[18]  [340/1724] loss: 0.444, ave_loss: 0.431
[19]  [360/1724] loss: 0.494, ave_loss: 0.434
[20]  [380/1724] loss: 0.343, ave_loss: 0.430
[21]  [400/1724] loss: 0.464, ave_loss: 0.432
[22]  [420/1724] loss: 0.473, ave_loss: 0.433
[23]  [440/1724] loss: 0.434, ave_loss: 0.433
[24]  [460/1724] loss: 0.339, ave_loss: 0.430
[25]  [480/1724] loss: 0.411, ave_loss: 0.429
[26]  [500/1724] loss: 0.539, ave_loss: 0.433
[27]  [520/1724] loss: 0.386, ave_loss: 0.431
[28]  [540/1724] loss: 0.296, ave_loss: 0.426
[29]  [560/1724] loss: 0.469, ave_loss: 0.428
[30]  [580/1724] loss: 0.407, ave_loss: 0.427
[31]  [600/1724] loss: 0.290, ave_loss: 0.423
[32]  [620/1724] loss: 0.256, ave_loss: 0.418
[33]  [640/1724] loss: 0.366, ave_loss: 0.416
[34]  [660/1724] loss: 0.342, ave_loss: 0.414
[35]  [680/1724] loss: 0.316, ave_loss: 0.411
[36]  [700/1724] loss: 0.457, ave_loss: 0.412
[37]  [720/1724] loss: 0.511, ave_loss: 0.415
[38]  [740/1724] loss: 0.466, ave_loss: 0.416
[39]  [760/1724] loss: 0.401, ave_loss: 0.416
[40]  [780/1724] loss: 0.335, ave_loss: 0.414
[41]  [800/1724] loss: 0.519, ave_loss: 0.416
[42]  [820/1724] loss: 0.432, ave_loss: 0.417
[43]  [840/1724] loss: 0.313, ave_loss: 0.414
[44]  [860/1724] loss: 0.525, ave_loss: 0.417
[45]  [880/1724] loss: 0.558, ave_loss: 0.420
[46]  [900/1724] loss: 0.363, ave_loss: 0.419
[47]  [920/1724] loss: 0.563, ave_loss: 0.422
[48]  [940/1724] loss: 0.468, ave_loss: 0.423
[49]  [960/1724] loss: 0.388, ave_loss: 0.422
[50]  [980/1724] loss: 0.412, ave_loss: 0.422
[51]  [1000/1724] loss: 0.370, ave_loss: 0.421
[52]  [1020/1724] loss: 0.359, ave_loss: 0.420
[53]  [1040/1724] loss: 0.338, ave_loss: 0.418
[54]  [1060/1724] loss: 0.394, ave_loss: 0.418
[55]  [1080/1724] loss: 0.357, ave_loss: 0.417
[56]  [1100/1724] loss: 0.457, ave_loss: 0.417
[57]  [1120/1724] loss: 0.339, ave_loss: 0.416
[58]  [1140/1724] loss: 0.523, ave_loss: 0.418
[59]  [1160/1724] loss: 0.305, ave_loss: 0.416
[60]  [1180/1724] loss: 0.310, ave_loss: 0.414
[61]  [1200/1724] loss: 0.401, ave_loss: 0.414
[62]  [1220/1724] loss: 0.361, ave_loss: 0.413
[63]  [1240/1724] loss: 0.312, ave_loss: 0.411
[64]  [1260/1724] loss: 0.389, ave_loss: 0.411
[65]  [1280/1724] loss: 0.467, ave_loss: 0.412
[66]  [1300/1724] loss: 0.507, ave_loss: 0.413
[67]  [1320/1724] loss: 0.441, ave_loss: 0.414
[68]  [1340/1724] loss: 0.408, ave_loss: 0.414
[69]  [1360/1724] loss: 0.438, ave_loss: 0.414
[70]  [1380/1724] loss: 0.442, ave_loss: 0.415
[71]  [1400/1724] loss: 0.405, ave_loss: 0.414
[72]  [1420/1724] loss: 0.308, ave_loss: 0.413
[73]  [1440/1724] loss: 0.415, ave_loss: 0.413
[74]  [1460/1724] loss: 0.337, ave_loss: 0.412
[75]  [1480/1724] loss: 0.352, ave_loss: 0.411
[76]  [1500/1724] loss: 0.367, ave_loss: 0.411
[77]  [1520/1724] loss: 0.296, ave_loss: 0.409
[78]  [1540/1724] loss: 0.288, ave_loss: 0.407
[79]  [1560/1724] loss: 0.492, ave_loss: 0.409
[80]  [1580/1724] loss: 0.388, ave_loss: 0.408
[81]  [1600/1724] loss: 0.332, ave_loss: 0.407
[82]  [1620/1724] loss: 0.448, ave_loss: 0.408
[83]  [1640/1724] loss: 0.383, ave_loss: 0.408
[84]  [1660/1724] loss: 0.281, ave_loss: 0.406
[85]  [1680/1724] loss: 0.439, ave_loss: 0.406
[86]  [1700/1724] loss: 0.452, ave_loss: 0.407
[87]  [1720/1724] loss: 0.405, ave_loss: 0.407
[88]  [1740/1724] loss: 0.462, ave_loss: 0.408

Finished Training finishing at 2021-08-21 10:25:29.510670
printing_out epoch  15.31322505800464 learning rate: 0.0003199956068772566
0.0003103957386709389
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.076e-01
Validation Loss: 8.961e+04
Validation ROC: 0.7268
No improvement, still saving model
83.68677494199537 epochs left to go

Training Epoch 15.31322505800464/100 starting at 2021-08-21 10:26:19.935532
[1]  [0/1724] loss: 0.707, ave_loss: 0.707
[2]  [20/1724] loss: 0.442, ave_loss: 0.575
[3]  [40/1724] loss: 0.487, ave_loss: 0.545
[4]  [60/1724] loss: 0.505, ave_loss: 0.535
[5]  [80/1724] loss: 0.461, ave_loss: 0.520
[6]  [100/1724] loss: 0.403, ave_loss: 0.501
[7]  [120/1724] loss: 0.530, ave_loss: 0.505
[8]  [140/1724] loss: 0.423, ave_loss: 0.495
[9]  [160/1724] loss: 0.318, ave_loss: 0.475
[10]  [180/1724] loss: 0.372, ave_loss: 0.465
[11]  [200/1724] loss: 0.448, ave_loss: 0.463
[12]  [220/1724] loss: 0.275, ave_loss: 0.448
[13]  [240/1724] loss: 0.557, ave_loss: 0.456
[14]  [260/1724] loss: 0.384, ave_loss: 0.451
[15]  [280/1724] loss: 0.413, ave_loss: 0.448
[16]  [300/1724] loss: 0.289, ave_loss: 0.438
[17]  [320/1724] loss: 0.330, ave_loss: 0.432
[18]  [340/1724] loss: 0.481, ave_loss: 0.435
[19]  [360/1724] loss: 0.381, ave_loss: 0.432
[20]  [380/1724] loss: 0.453, ave_loss: 0.433
[21]  [400/1724] loss: 0.394, ave_loss: 0.431
[22]  [420/1724] loss: 0.490, ave_loss: 0.434
[23]  [440/1724] loss: 0.392, ave_loss: 0.432
[24]  [460/1724] loss: 0.495, ave_loss: 0.435
[25]  [480/1724] loss: 0.455, ave_loss: 0.435
[26]  [500/1724] loss: 0.379, ave_loss: 0.433
[27]  [520/1724] loss: 0.519, ave_loss: 0.436
[28]  [540/1724] loss: 0.413, ave_loss: 0.436
[29]  [560/1724] loss: 0.429, ave_loss: 0.435
[30]  [580/1724] loss: 0.631, ave_loss: 0.442
[31]  [600/1724] loss: 0.361, ave_loss: 0.439
[32]  [620/1724] loss: 0.365, ave_loss: 0.437
[33]  [640/1724] loss: 0.379, ave_loss: 0.435
[34]  [660/1724] loss: 0.387, ave_loss: 0.434
[35]  [680/1724] loss: 0.412, ave_loss: 0.433
[36]  [700/1724] loss: 0.352, ave_loss: 0.431
[37]  [720/1724] loss: 0.408, ave_loss: 0.430
[38]  [740/1724] loss: 0.414, ave_loss: 0.430
[39]  [760/1724] loss: 0.429, ave_loss: 0.430
[40]  [780/1724] loss: 0.491, ave_loss: 0.431
[41]  [800/1724] loss: 0.394, ave_loss: 0.430
[42]  [820/1724] loss: 0.419, ave_loss: 0.430
[43]  [840/1724] loss: 0.411, ave_loss: 0.430
[44]  [860/1724] loss: 0.402, ave_loss: 0.429
[45]  [880/1724] loss: 0.316, ave_loss: 0.427
[46]  [900/1724] loss: 0.443, ave_loss: 0.427
[47]  [920/1724] loss: 0.350, ave_loss: 0.425
[48]  [940/1724] loss: 0.476, ave_loss: 0.426
[49]  [960/1724] loss: 0.359, ave_loss: 0.425
[50]  [980/1724] loss: 0.495, ave_loss: 0.426
[51]  [1000/1724] loss: 0.465, ave_loss: 0.427
[52]  [1020/1724] loss: 0.318, ave_loss: 0.425
[53]  [1040/1724] loss: 0.276, ave_loss: 0.422
[54]  [1060/1724] loss: 0.421, ave_loss: 0.422
[55]  [1080/1724] loss: 0.358, ave_loss: 0.421
[56]  [1100/1724] loss: 0.461, ave_loss: 0.422
[57]  [1120/1724] loss: 0.575, ave_loss: 0.424
[58]  [1140/1724] loss: 0.350, ave_loss: 0.423
[59]  [1160/1724] loss: 0.331, ave_loss: 0.422
[60]  [1180/1724] loss: 0.366, ave_loss: 0.421
[61]  [1200/1724] loss: 0.417, ave_loss: 0.421
[62]  [1220/1724] loss: 0.277, ave_loss: 0.418
[63]  [1240/1724] loss: 0.233, ave_loss: 0.415
[64]  [1260/1724] loss: 0.396, ave_loss: 0.415
[65]  [1280/1724] loss: 0.355, ave_loss: 0.414
[66]  [1300/1724] loss: 0.432, ave_loss: 0.414
[67]  [1320/1724] loss: 0.420, ave_loss: 0.414
[68]  [1340/1724] loss: 0.334, ave_loss: 0.413
[69]  [1360/1724] loss: 0.363, ave_loss: 0.413
[70]  [1380/1724] loss: 0.322, ave_loss: 0.411
[71]  [1400/1724] loss: 0.322, ave_loss: 0.410
[72]  [1420/1724] loss: 0.421, ave_loss: 0.410
[73]  [1440/1724] loss: 0.419, ave_loss: 0.410
[74]  [1460/1724] loss: 0.476, ave_loss: 0.411
[75]  [1480/1724] loss: 0.376, ave_loss: 0.411
[76]  [1500/1724] loss: 0.382, ave_loss: 0.410
[77]  [1520/1724] loss: 0.266, ave_loss: 0.408
[78]  [1540/1724] loss: 0.354, ave_loss: 0.408
[79]  [1560/1724] loss: 0.331, ave_loss: 0.407
[80]  [1580/1724] loss: 0.365, ave_loss: 0.406
[81]  [1600/1724] loss: 0.341, ave_loss: 0.405
[82]  [1620/1724] loss: 0.524, ave_loss: 0.407
[83]  [1640/1724] loss: 0.333, ave_loss: 0.406
[84]  [1660/1724] loss: 0.334, ave_loss: 0.405
[85]  [1680/1724] loss: 0.410, ave_loss: 0.405
[86]  [1700/1724] loss: 0.396, ave_loss: 0.405
[87]  [1720/1724] loss: 0.414, ave_loss: 0.405
[88]  [1740/1724] loss: 0.381, ave_loss: 0.405

Finished Training finishing at 2021-08-21 10:28:32.446397
printing_out epoch  16.334106728538284 learning rate: 0.00029090509716114235
0.0002821779442463081
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.049e-01
Validation Loss: 7.817e+04
Validation ROC: 0.7456
Saving model
82.66589327146171 epochs left to go

Training Epoch 16.334106728538284/100 starting at 2021-08-21 10:30:48.032555
[1]  [0/1724] loss: 0.641, ave_loss: 0.641
[2]  [20/1724] loss: 0.243, ave_loss: 0.442
[3]  [40/1724] loss: 0.462, ave_loss: 0.449
[4]  [60/1724] loss: 0.436, ave_loss: 0.445
[5]  [80/1724] loss: 0.320, ave_loss: 0.420
[6]  [100/1724] loss: 0.548, ave_loss: 0.442
[7]  [120/1724] loss: 0.471, ave_loss: 0.446
[8]  [140/1724] loss: 0.311, ave_loss: 0.429
[9]  [160/1724] loss: 0.520, ave_loss: 0.439
[10]  [180/1724] loss: 0.449, ave_loss: 0.440
[11]  [200/1724] loss: 0.412, ave_loss: 0.438
[12]  [220/1724] loss: 0.396, ave_loss: 0.434
[13]  [240/1724] loss: 0.404, ave_loss: 0.432
[14]  [260/1724] loss: 0.399, ave_loss: 0.429
[15]  [280/1724] loss: 0.391, ave_loss: 0.427
[16]  [300/1724] loss: 0.552, ave_loss: 0.435
[17]  [320/1724] loss: 0.495, ave_loss: 0.438
[18]  [340/1724] loss: 0.544, ave_loss: 0.444
[19]  [360/1724] loss: 0.349, ave_loss: 0.439
[20]  [380/1724] loss: 0.528, ave_loss: 0.443
[21]  [400/1724] loss: 0.363, ave_loss: 0.440
[22]  [420/1724] loss: 0.363, ave_loss: 0.436
[23]  [440/1724] loss: 0.369, ave_loss: 0.433
[24]  [460/1724] loss: 0.290, ave_loss: 0.427
[25]  [480/1724] loss: 0.498, ave_loss: 0.430
[26]  [500/1724] loss: 0.612, ave_loss: 0.437
[27]  [520/1724] loss: 0.475, ave_loss: 0.439
[28]  [540/1724] loss: 0.328, ave_loss: 0.435
[29]  [560/1724] loss: 0.392, ave_loss: 0.433
[30]  [580/1724] loss: 0.570, ave_loss: 0.438
[31]  [600/1724] loss: 0.342, ave_loss: 0.435
[32]  [620/1724] loss: 0.349, ave_loss: 0.432
[33]  [640/1724] loss: 0.406, ave_loss: 0.431
[34]  [660/1724] loss: 0.342, ave_loss: 0.428
[35]  [680/1724] loss: 0.522, ave_loss: 0.431
[36]  [700/1724] loss: 0.256, ave_loss: 0.426
[37]  [720/1724] loss: 0.312, ave_loss: 0.423
[38]  [740/1724] loss: 0.298, ave_loss: 0.420
[39]  [760/1724] loss: 0.371, ave_loss: 0.419
[40]  [780/1724] loss: 0.371, ave_loss: 0.417
[41]  [800/1724] loss: 0.438, ave_loss: 0.418
[42]  [820/1724] loss: 0.383, ave_loss: 0.417
[43]  [840/1724] loss: 0.257, ave_loss: 0.413
[44]  [860/1724] loss: 0.417, ave_loss: 0.413
[45]  [880/1724] loss: 0.346, ave_loss: 0.412
[46]  [900/1724] loss: 0.260, ave_loss: 0.409
[47]  [920/1724] loss: 0.505, ave_loss: 0.411
[48]  [940/1724] loss: 0.302, ave_loss: 0.408
[49]  [960/1724] loss: 0.437, ave_loss: 0.409
[50]  [980/1724] loss: 0.329, ave_loss: 0.407
[51]  [1000/1724] loss: 0.319, ave_loss: 0.406
[52]  [1020/1724] loss: 0.508, ave_loss: 0.408
[53]  [1040/1724] loss: 0.255, ave_loss: 0.405
[54]  [1060/1724] loss: 0.383, ave_loss: 0.404
[55]  [1080/1724] loss: 0.488, ave_loss: 0.406
[56]  [1100/1724] loss: 0.231, ave_loss: 0.403
[57]  [1120/1724] loss: 0.407, ave_loss: 0.403
[58]  [1140/1724] loss: 0.292, ave_loss: 0.401
[59]  [1160/1724] loss: 0.384, ave_loss: 0.401
[60]  [1180/1724] loss: 0.356, ave_loss: 0.400
[61]  [1200/1724] loss: 0.302, ave_loss: 0.398
[62]  [1220/1724] loss: 0.320, ave_loss: 0.397
[63]  [1240/1724] loss: 0.315, ave_loss: 0.396
[64]  [1260/1724] loss: 0.281, ave_loss: 0.394
[65]  [1280/1724] loss: 0.469, ave_loss: 0.395
[66]  [1300/1724] loss: 0.314, ave_loss: 0.394
[67]  [1320/1724] loss: 0.573, ave_loss: 0.397
[68]  [1340/1724] loss: 0.374, ave_loss: 0.396
[69]  [1360/1724] loss: 0.304, ave_loss: 0.395
[70]  [1380/1724] loss: 0.509, ave_loss: 0.397
[71]  [1400/1724] loss: 0.546, ave_loss: 0.399
[72]  [1420/1724] loss: 0.311, ave_loss: 0.397
[73]  [1440/1724] loss: 0.488, ave_loss: 0.399
[74]  [1460/1724] loss: 0.507, ave_loss: 0.400
[75]  [1480/1724] loss: 0.443, ave_loss: 0.401
[76]  [1500/1724] loss: 0.469, ave_loss: 0.402
[77]  [1520/1724] loss: 0.408, ave_loss: 0.402
[78]  [1540/1724] loss: 0.379, ave_loss: 0.401
[79]  [1560/1724] loss: 0.446, ave_loss: 0.402
[80]  [1580/1724] loss: 0.505, ave_loss: 0.403
[81]  [1600/1724] loss: 0.385, ave_loss: 0.403
[82]  [1620/1724] loss: 0.370, ave_loss: 0.403
[83]  [1640/1724] loss: 0.392, ave_loss: 0.402
[84]  [1660/1724] loss: 0.378, ave_loss: 0.402
[85]  [1680/1724] loss: 0.476, ave_loss: 0.403
[86]  [1700/1724] loss: 0.463, ave_loss: 0.404
[87]  [1720/1724] loss: 0.361, ave_loss: 0.403
[88]  [1740/1724] loss: 0.399, ave_loss: 0.403

Finished Training finishing at 2021-08-21 10:32:51.505637
printing_out epoch  17.354988399071924 learning rate: 0.00029090509716114235
0.00027371260591891884
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.032e-01
Validation Loss: 7.859e+04
Validation ROC: 0.7464
Saving model
81.64501160092807 epochs left to go

Training Epoch 17.354988399071924/100 starting at 2021-08-21 10:33:20.744800
[1]  [0/1724] loss: 0.478, ave_loss: 0.478
[2]  [20/1724] loss: 0.391, ave_loss: 0.435
[3]  [40/1724] loss: 0.420, ave_loss: 0.430
[4]  [60/1724] loss: 0.444, ave_loss: 0.433
[5]  [80/1724] loss: 0.425, ave_loss: 0.432
[6]  [100/1724] loss: 0.391, ave_loss: 0.425
[7]  [120/1724] loss: 0.413, ave_loss: 0.423
[8]  [140/1724] loss: 0.414, ave_loss: 0.422
[9]  [160/1724] loss: 0.437, ave_loss: 0.424
[10]  [180/1724] loss: 0.328, ave_loss: 0.414
[11]  [200/1724] loss: 0.315, ave_loss: 0.405
[12]  [220/1724] loss: 0.354, ave_loss: 0.401
[13]  [240/1724] loss: 0.545, ave_loss: 0.412
[14]  [260/1724] loss: 0.382, ave_loss: 0.410
[15]  [280/1724] loss: 0.434, ave_loss: 0.411
[16]  [300/1724] loss: 0.395, ave_loss: 0.410
[17]  [320/1724] loss: 0.430, ave_loss: 0.411
[18]  [340/1724] loss: 0.357, ave_loss: 0.408
[19]  [360/1724] loss: 0.465, ave_loss: 0.411
[20]  [380/1724] loss: 0.368, ave_loss: 0.409
[21]  [400/1724] loss: 0.367, ave_loss: 0.407
[22]  [420/1724] loss: 0.338, ave_loss: 0.404
[23]  [440/1724] loss: 0.361, ave_loss: 0.402
[24]  [460/1724] loss: 0.489, ave_loss: 0.406
[25]  [480/1724] loss: 0.405, ave_loss: 0.406
[26]  [500/1724] loss: 0.367, ave_loss: 0.404
[27]  [520/1724] loss: 0.471, ave_loss: 0.407
[28]  [540/1724] loss: 0.480, ave_loss: 0.409
[29]  [560/1724] loss: 0.320, ave_loss: 0.406
[30]  [580/1724] loss: 0.424, ave_loss: 0.407
[31]  [600/1724] loss: 0.395, ave_loss: 0.406
[32]  [620/1724] loss: 0.396, ave_loss: 0.406
[33]  [640/1724] loss: 0.356, ave_loss: 0.405
[34]  [660/1724] loss: 0.567, ave_loss: 0.409
[35]  [680/1724] loss: 0.318, ave_loss: 0.407
[36]  [700/1724] loss: 0.356, ave_loss: 0.405
[37]  [720/1724] loss: 0.301, ave_loss: 0.403
[38]  [740/1724] loss: 0.407, ave_loss: 0.403
[39]  [760/1724] loss: 0.346, ave_loss: 0.401
[40]  [780/1724] loss: 0.362, ave_loss: 0.400
[41]  [800/1724] loss: 0.273, ave_loss: 0.397
[42]  [820/1724] loss: 0.343, ave_loss: 0.396
[43]  [840/1724] loss: 0.337, ave_loss: 0.394
[44]  [860/1724] loss: 0.337, ave_loss: 0.393
[45]  [880/1724] loss: 0.369, ave_loss: 0.393
[46]  [900/1724] loss: 0.588, ave_loss: 0.397
[47]  [920/1724] loss: 0.506, ave_loss: 0.399
[48]  [940/1724] loss: 0.405, ave_loss: 0.399
[49]  [960/1724] loss: 0.437, ave_loss: 0.400
[50]  [980/1724] loss: 0.349, ave_loss: 0.399
[51]  [1000/1724] loss: 0.365, ave_loss: 0.398
[52]  [1020/1724] loss: 0.315, ave_loss: 0.397
[53]  [1040/1724] loss: 0.370, ave_loss: 0.396
[54]  [1060/1724] loss: 0.325, ave_loss: 0.395
[55]  [1080/1724] loss: 0.402, ave_loss: 0.395
[56]  [1100/1724] loss: 0.555, ave_loss: 0.398
[57]  [1120/1724] loss: 0.388, ave_loss: 0.398
[58]  [1140/1724] loss: 0.763, ave_loss: 0.404
[59]  [1160/1724] loss: 0.495, ave_loss: 0.406
[60]  [1180/1724] loss: 0.490, ave_loss: 0.407
[61]  [1200/1724] loss: 0.409, ave_loss: 0.407
[62]  [1220/1724] loss: 0.264, ave_loss: 0.405
[63]  [1240/1724] loss: 0.296, ave_loss: 0.403
[64]  [1260/1724] loss: 0.362, ave_loss: 0.402
[65]  [1280/1724] loss: 0.499, ave_loss: 0.404
[66]  [1300/1724] loss: 0.322, ave_loss: 0.403
[67]  [1320/1724] loss: 0.297, ave_loss: 0.401
[68]  [1340/1724] loss: 0.301, ave_loss: 0.400
[69]  [1360/1724] loss: 0.336, ave_loss: 0.399
[70]  [1380/1724] loss: 0.348, ave_loss: 0.398
[71]  [1400/1724] loss: 0.296, ave_loss: 0.396
[72]  [1420/1724] loss: 0.306, ave_loss: 0.395
[73]  [1440/1724] loss: 0.330, ave_loss: 0.394
[74]  [1460/1724] loss: 0.286, ave_loss: 0.393
[75]  [1480/1724] loss: 0.415, ave_loss: 0.393
[76]  [1500/1724] loss: 0.345, ave_loss: 0.393
[77]  [1520/1724] loss: 0.360, ave_loss: 0.392
[78]  [1540/1724] loss: 0.400, ave_loss: 0.392
[79]  [1560/1724] loss: 0.399, ave_loss: 0.392
[80]  [1580/1724] loss: 0.479, ave_loss: 0.393
[81]  [1600/1724] loss: 0.174, ave_loss: 0.391
[82]  [1620/1724] loss: 0.621, ave_loss: 0.393
[83]  [1640/1724] loss: 0.346, ave_loss: 0.393
[84]  [1660/1724] loss: 0.573, ave_loss: 0.395
[85]  [1680/1724] loss: 0.357, ave_loss: 0.395
[86]  [1700/1724] loss: 0.444, ave_loss: 0.395
[87]  [1720/1724] loss: 0.333, ave_loss: 0.394
[88]  [1740/1724] loss: 0.345, ave_loss: 0.394

Finished Training finishing at 2021-08-21 10:35:21.270145
printing_out epoch  18.37587006960557 learning rate: 0.00029090509716114235
0.00026550122774135124
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.939e-01
Validation Loss: 6.414e+04
Validation ROC: 0.7314
No improvement, still saving model
80.62412993039443 epochs left to go

Training Epoch 18.37587006960557/100 starting at 2021-08-21 10:35:54.450176
[1]  [0/1724] loss: 0.647, ave_loss: 0.647
[2]  [20/1724] loss: 0.460, ave_loss: 0.554
[3]  [40/1724] loss: 0.374, ave_loss: 0.494
[4]  [60/1724] loss: 0.370, ave_loss: 0.463
[5]  [80/1724] loss: 0.310, ave_loss: 0.432
[6]  [100/1724] loss: 0.374, ave_loss: 0.423
[7]  [120/1724] loss: 0.464, ave_loss: 0.429
[8]  [140/1724] loss: 0.379, ave_loss: 0.422
[9]  [160/1724] loss: 0.356, ave_loss: 0.415
[10]  [180/1724] loss: 0.386, ave_loss: 0.412
[11]  [200/1724] loss: 0.368, ave_loss: 0.408
[12]  [220/1724] loss: 0.410, ave_loss: 0.408
[13]  [240/1724] loss: 0.356, ave_loss: 0.404
[14]  [260/1724] loss: 0.330, ave_loss: 0.399
[15]  [280/1724] loss: 0.377, ave_loss: 0.397
[16]  [300/1724] loss: 0.278, ave_loss: 0.390
[17]  [320/1724] loss: 0.384, ave_loss: 0.390
[18]  [340/1724] loss: 0.513, ave_loss: 0.396
[19]  [360/1724] loss: 0.328, ave_loss: 0.393
[20]  [380/1724] loss: 0.386, ave_loss: 0.392
[21]  [400/1724] loss: 0.647, ave_loss: 0.405
[22]  [420/1724] loss: 0.407, ave_loss: 0.405
[23]  [440/1724] loss: 0.551, ave_loss: 0.411
[24]  [460/1724] loss: 0.316, ave_loss: 0.407
[25]  [480/1724] loss: 0.324, ave_loss: 0.404
[26]  [500/1724] loss: 0.422, ave_loss: 0.404
[27]  [520/1724] loss: 0.578, ave_loss: 0.411
[28]  [540/1724] loss: 0.389, ave_loss: 0.410
[29]  [560/1724] loss: 0.353, ave_loss: 0.408
[30]  [580/1724] loss: 0.555, ave_loss: 0.413
[31]  [600/1724] loss: 0.311, ave_loss: 0.410
[32]  [620/1724] loss: 0.327, ave_loss: 0.407
[33]  [640/1724] loss: 0.506, ave_loss: 0.410
[34]  [660/1724] loss: 0.289, ave_loss: 0.407
[35]  [680/1724] loss: 0.388, ave_loss: 0.406
[36]  [700/1724] loss: 0.370, ave_loss: 0.405
[37]  [720/1724] loss: 0.445, ave_loss: 0.406
[38]  [740/1724] loss: 0.347, ave_loss: 0.405
[39]  [760/1724] loss: 0.434, ave_loss: 0.405
[40]  [780/1724] loss: 0.376, ave_loss: 0.405
[41]  [800/1724] loss: 0.417, ave_loss: 0.405
[42]  [820/1724] loss: 0.266, ave_loss: 0.402
[43]  [840/1724] loss: 0.253, ave_loss: 0.398
[44]  [860/1724] loss: 0.278, ave_loss: 0.395
[45]  [880/1724] loss: 0.526, ave_loss: 0.398
[46]  [900/1724] loss: 0.336, ave_loss: 0.397
[47]  [920/1724] loss: 0.498, ave_loss: 0.399
[48]  [940/1724] loss: 0.309, ave_loss: 0.397
[49]  [960/1724] loss: 0.398, ave_loss: 0.397
[50]  [980/1724] loss: 0.306, ave_loss: 0.395
[51]  [1000/1724] loss: 0.477, ave_loss: 0.397
[52]  [1020/1724] loss: 0.351, ave_loss: 0.396
[53]  [1040/1724] loss: 0.566, ave_loss: 0.399
[54]  [1060/1724] loss: 0.252, ave_loss: 0.397
[55]  [1080/1724] loss: 0.450, ave_loss: 0.398
[56]  [1100/1724] loss: 0.294, ave_loss: 0.396
[57]  [1120/1724] loss: 0.336, ave_loss: 0.395
[58]  [1140/1724] loss: 0.453, ave_loss: 0.396
[59]  [1160/1724] loss: 0.561, ave_loss: 0.398
[60]  [1180/1724] loss: 0.370, ave_loss: 0.398
[61]  [1200/1724] loss: 0.479, ave_loss: 0.399
[62]  [1220/1724] loss: 0.360, ave_loss: 0.399
[63]  [1240/1724] loss: 0.294, ave_loss: 0.397
[64]  [1260/1724] loss: 0.426, ave_loss: 0.397
[65]  [1280/1724] loss: 0.343, ave_loss: 0.397
[66]  [1300/1724] loss: 0.467, ave_loss: 0.398
[67]  [1320/1724] loss: 0.508, ave_loss: 0.399
[68]  [1340/1724] loss: 0.302, ave_loss: 0.398
[69]  [1360/1724] loss: 0.343, ave_loss: 0.397
[70]  [1380/1724] loss: 0.290, ave_loss: 0.396
[71]  [1400/1724] loss: 0.381, ave_loss: 0.395
[72]  [1420/1724] loss: 0.351, ave_loss: 0.395
[73]  [1440/1724] loss: 0.367, ave_loss: 0.394
[74]  [1460/1724] loss: 0.313, ave_loss: 0.393
[75]  [1480/1724] loss: 0.301, ave_loss: 0.392
[76]  [1500/1724] loss: 0.388, ave_loss: 0.392
[77]  [1520/1724] loss: 0.301, ave_loss: 0.391
[78]  [1540/1724] loss: 0.526, ave_loss: 0.393
[79]  [1560/1724] loss: 0.292, ave_loss: 0.391
[80]  [1580/1724] loss: 0.476, ave_loss: 0.392
[81]  [1600/1724] loss: 0.453, ave_loss: 0.393
[82]  [1620/1724] loss: 0.432, ave_loss: 0.394
[83]  [1640/1724] loss: 0.239, ave_loss: 0.392
[84]  [1660/1724] loss: 0.713, ave_loss: 0.396
[85]  [1680/1724] loss: 0.328, ave_loss: 0.395
[86]  [1700/1724] loss: 0.288, ave_loss: 0.394
[87]  [1720/1724] loss: 0.314, ave_loss: 0.393
[88]  [1740/1724] loss: 0.354, ave_loss: 0.392

Finished Training finishing at 2021-08-21 10:38:01.346179
printing_out epoch  19.396751740139212 learning rate: 0.00026445917923740214
0.0002565254038602801
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.922e-01
Validation Loss: 5.573e+04
Validation ROC: 0.7390
No improvement, still saving model
79.60324825986079 epochs left to go

Training Epoch 19.396751740139212/100 starting at 2021-08-21 10:38:53.583054
[1]  [0/1724] loss: 0.402, ave_loss: 0.402
[2]  [20/1724] loss: 0.430, ave_loss: 0.416
[3]  [40/1724] loss: 0.267, ave_loss: 0.366
[4]  [60/1724] loss: 0.536, ave_loss: 0.409
[5]  [80/1724] loss: 0.190, ave_loss: 0.365
[6]  [100/1724] loss: 0.303, ave_loss: 0.355
[7]  [120/1724] loss: 0.417, ave_loss: 0.364
[8]  [140/1724] loss: 0.386, ave_loss: 0.367
[9]  [160/1724] loss: 0.433, ave_loss: 0.374
[10]  [180/1724] loss: 0.361, ave_loss: 0.373
[11]  [200/1724] loss: 0.461, ave_loss: 0.381
[12]  [220/1724] loss: 0.330, ave_loss: 0.376
[13]  [240/1724] loss: 0.387, ave_loss: 0.377
[14]  [260/1724] loss: 0.269, ave_loss: 0.370
[15]  [280/1724] loss: 0.377, ave_loss: 0.370
[16]  [300/1724] loss: 0.449, ave_loss: 0.375
[17]  [320/1724] loss: 0.204, ave_loss: 0.365
[18]  [340/1724] loss: 0.298, ave_loss: 0.361
[19]  [360/1724] loss: 0.469, ave_loss: 0.367
[20]  [380/1724] loss: 0.352, ave_loss: 0.366
[21]  [400/1724] loss: 0.346, ave_loss: 0.365
[22]  [420/1724] loss: 0.327, ave_loss: 0.363
[23]  [440/1724] loss: 0.458, ave_loss: 0.368
[24]  [460/1724] loss: 0.698, ave_loss: 0.381
[25]  [480/1724] loss: 0.470, ave_loss: 0.385
[26]  [500/1724] loss: 0.276, ave_loss: 0.381
[27]  [520/1724] loss: 0.241, ave_loss: 0.375
[28]  [540/1724] loss: 0.322, ave_loss: 0.374
[29]  [560/1724] loss: 0.518, ave_loss: 0.379
[30]  [580/1724] loss: 0.300, ave_loss: 0.376
[31]  [600/1724] loss: 0.525, ave_loss: 0.381
[32]  [620/1724] loss: 0.606, ave_loss: 0.388
[33]  [640/1724] loss: 0.367, ave_loss: 0.387
[34]  [660/1724] loss: 0.299, ave_loss: 0.385
[35]  [680/1724] loss: 0.434, ave_loss: 0.386
[36]  [700/1724] loss: 0.333, ave_loss: 0.384
[37]  [720/1724] loss: 0.284, ave_loss: 0.382
[38]  [740/1724] loss: 0.379, ave_loss: 0.382
[39]  [760/1724] loss: 0.357, ave_loss: 0.381
[40]  [780/1724] loss: 0.362, ave_loss: 0.381
[41]  [800/1724] loss: 0.446, ave_loss: 0.382
[42]  [820/1724] loss: 0.403, ave_loss: 0.383
[43]  [840/1724] loss: 0.394, ave_loss: 0.383
[44]  [860/1724] loss: 0.633, ave_loss: 0.389
[45]  [880/1724] loss: 0.358, ave_loss: 0.388
[46]  [900/1724] loss: 0.524, ave_loss: 0.391
[47]  [920/1724] loss: 0.373, ave_loss: 0.390
[48]  [940/1724] loss: 0.374, ave_loss: 0.390
[49]  [960/1724] loss: 0.235, ave_loss: 0.387
[50]  [980/1724] loss: 0.328, ave_loss: 0.386
[51]  [1000/1724] loss: 0.362, ave_loss: 0.385
[52]  [1020/1724] loss: 0.421, ave_loss: 0.386
[53]  [1040/1724] loss: 0.446, ave_loss: 0.387
[54]  [1060/1724] loss: 0.384, ave_loss: 0.387
[55]  [1080/1724] loss: 0.375, ave_loss: 0.387
[56]  [1100/1724] loss: 0.412, ave_loss: 0.387
[57]  [1120/1724] loss: 0.488, ave_loss: 0.389
[58]  [1140/1724] loss: 0.390, ave_loss: 0.389
[59]  [1160/1724] loss: 0.450, ave_loss: 0.390
[60]  [1180/1724] loss: 0.346, ave_loss: 0.389
[61]  [1200/1724] loss: 0.364, ave_loss: 0.389
[62]  [1220/1724] loss: 0.278, ave_loss: 0.387
[63]  [1240/1724] loss: 0.320, ave_loss: 0.386
[64]  [1260/1724] loss: 0.406, ave_loss: 0.386
[65]  [1280/1724] loss: 0.406, ave_loss: 0.387
[66]  [1300/1724] loss: 0.273, ave_loss: 0.385
[67]  [1320/1724] loss: 0.362, ave_loss: 0.385
[68]  [1340/1724] loss: 0.510, ave_loss: 0.387
[69]  [1360/1724] loss: 0.419, ave_loss: 0.387
[70]  [1380/1724] loss: 0.367, ave_loss: 0.387
[71]  [1400/1724] loss: 0.346, ave_loss: 0.386
[72]  [1420/1724] loss: 0.342, ave_loss: 0.386
[73]  [1440/1724] loss: 0.255, ave_loss: 0.384
[74]  [1460/1724] loss: 0.218, ave_loss: 0.381
[75]  [1480/1724] loss: 0.301, ave_loss: 0.380
[76]  [1500/1724] loss: 0.304, ave_loss: 0.379
[77]  [1520/1724] loss: 0.302, ave_loss: 0.378
[78]  [1540/1724] loss: 0.491, ave_loss: 0.380
[79]  [1560/1724] loss: 0.595, ave_loss: 0.383
[80]  [1580/1724] loss: 0.399, ave_loss: 0.383
[81]  [1600/1724] loss: 0.273, ave_loss: 0.381
[82]  [1620/1724] loss: 0.317, ave_loss: 0.381
[83]  [1640/1724] loss: 0.498, ave_loss: 0.382
[84]  [1660/1724] loss: 0.351, ave_loss: 0.382
[85]  [1680/1724] loss: 0.369, ave_loss: 0.382
[86]  [1700/1724] loss: 0.557, ave_loss: 0.384
[87]  [1720/1724] loss: 0.587, ave_loss: 0.386
[88]  [1740/1724] loss: 0.425, ave_loss: 0.386

Finished Training finishing at 2021-08-21 10:40:59.270472
printing_out epoch  20.417633410672853 learning rate: 0.00024041743567036557
0.0002332049126002546
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.863e-01
Validation Loss: 5.063e+04
Validation ROC: 0.7344
No improvement, still saving model
78.58236658932715 epochs left to go

Training Epoch 20.417633410672853/100 starting at 2021-08-21 10:41:40.691040
[1]  [0/1724] loss: 0.438, ave_loss: 0.438
[2]  [20/1724] loss: 0.352, ave_loss: 0.395
[3]  [40/1724] loss: 0.370, ave_loss: 0.387
[4]  [60/1724] loss: 0.470, ave_loss: 0.408
[5]  [80/1724] loss: 0.317, ave_loss: 0.390
[6]  [100/1724] loss: 0.389, ave_loss: 0.390
[7]  [120/1724] loss: 0.506, ave_loss: 0.406
[8]  [140/1724] loss: 0.258, ave_loss: 0.388
[9]  [160/1724] loss: 0.533, ave_loss: 0.404
[10]  [180/1724] loss: 0.333, ave_loss: 0.397
[11]  [200/1724] loss: 0.312, ave_loss: 0.389
[12]  [220/1724] loss: 0.555, ave_loss: 0.403
[13]  [240/1724] loss: 0.499, ave_loss: 0.410
[14]  [260/1724] loss: 0.378, ave_loss: 0.408
[15]  [280/1724] loss: 0.351, ave_loss: 0.404
[16]  [300/1724] loss: 0.306, ave_loss: 0.398
[17]  [320/1724] loss: 0.438, ave_loss: 0.400
[18]  [340/1724] loss: 0.440, ave_loss: 0.403
[19]  [360/1724] loss: 0.419, ave_loss: 0.403
[20]  [380/1724] loss: 0.347, ave_loss: 0.401
[21]  [400/1724] loss: 0.277, ave_loss: 0.395
[22]  [420/1724] loss: 0.398, ave_loss: 0.395
[23]  [440/1724] loss: 0.456, ave_loss: 0.398
[24]  [460/1724] loss: 0.448, ave_loss: 0.400
[25]  [480/1724] loss: 0.258, ave_loss: 0.394
[26]  [500/1724] loss: 0.445, ave_loss: 0.396
[27]  [520/1724] loss: 0.335, ave_loss: 0.394
[28]  [540/1724] loss: 0.517, ave_loss: 0.398
[29]  [560/1724] loss: 0.472, ave_loss: 0.401
[30]  [580/1724] loss: 0.327, ave_loss: 0.398
[31]  [600/1724] loss: 0.376, ave_loss: 0.397
[32]  [620/1724] loss: 0.464, ave_loss: 0.400
[33]  [640/1724] loss: 0.416, ave_loss: 0.400
[34]  [660/1724] loss: 0.304, ave_loss: 0.397
[35]  [680/1724] loss: 0.361, ave_loss: 0.396
[36]  [700/1724] loss: 0.341, ave_loss: 0.395
[37]  [720/1724] loss: 0.314, ave_loss: 0.392
[38]  [740/1724] loss: 0.363, ave_loss: 0.392
[39]  [760/1724] loss: 0.487, ave_loss: 0.394
[40]  [780/1724] loss: 0.423, ave_loss: 0.395
[41]  [800/1724] loss: 0.340, ave_loss: 0.394
[42]  [820/1724] loss: 0.396, ave_loss: 0.394
[43]  [840/1724] loss: 0.286, ave_loss: 0.391
[44]  [860/1724] loss: 0.269, ave_loss: 0.388
[45]  [880/1724] loss: 0.355, ave_loss: 0.388
[46]  [900/1724] loss: 0.458, ave_loss: 0.389
[47]  [920/1724] loss: 0.340, ave_loss: 0.388
[48]  [940/1724] loss: 0.341, ave_loss: 0.387
[49]  [960/1724] loss: 0.437, ave_loss: 0.388
[50]  [980/1724] loss: 0.566, ave_loss: 0.392
[51]  [1000/1724] loss: 0.381, ave_loss: 0.391
[52]  [1020/1724] loss: 0.568, ave_loss: 0.395
[53]  [1040/1724] loss: 0.282, ave_loss: 0.393
[54]  [1060/1724] loss: 0.593, ave_loss: 0.396
[55]  [1080/1724] loss: 0.417, ave_loss: 0.397
[56]  [1100/1724] loss: 0.365, ave_loss: 0.396
[57]  [1120/1724] loss: 0.476, ave_loss: 0.398
[58]  [1140/1724] loss: 0.410, ave_loss: 0.398
[59]  [1160/1724] loss: 0.417, ave_loss: 0.398
[60]  [1180/1724] loss: 0.424, ave_loss: 0.399
[61]  [1200/1724] loss: 0.366, ave_loss: 0.398
[62]  [1220/1724] loss: 0.289, ave_loss: 0.396
[63]  [1240/1724] loss: 0.414, ave_loss: 0.397
[64]  [1260/1724] loss: 0.379, ave_loss: 0.396
[65]  [1280/1724] loss: 0.261, ave_loss: 0.394
[66]  [1300/1724] loss: 0.429, ave_loss: 0.395
[67]  [1320/1724] loss: 0.371, ave_loss: 0.394
[68]  [1340/1724] loss: 0.339, ave_loss: 0.394
[69]  [1360/1724] loss: 0.297, ave_loss: 0.392
[70]  [1380/1724] loss: 0.263, ave_loss: 0.390
[71]  [1400/1724] loss: 0.521, ave_loss: 0.392
[72]  [1420/1724] loss: 0.350, ave_loss: 0.392
[73]  [1440/1724] loss: 0.395, ave_loss: 0.392
[74]  [1460/1724] loss: 0.351, ave_loss: 0.391
[75]  [1480/1724] loss: 0.408, ave_loss: 0.391
[76]  [1500/1724] loss: 0.374, ave_loss: 0.391
[77]  [1520/1724] loss: 0.315, ave_loss: 0.390
[78]  [1540/1724] loss: 0.462, ave_loss: 0.391
[79]  [1560/1724] loss: 0.418, ave_loss: 0.391
[80]  [1580/1724] loss: 0.300, ave_loss: 0.390
[81]  [1600/1724] loss: 0.482, ave_loss: 0.391
[82]  [1620/1724] loss: 0.371, ave_loss: 0.391
[83]  [1640/1724] loss: 0.423, ave_loss: 0.391
[84]  [1660/1724] loss: 0.417, ave_loss: 0.392
[85]  [1680/1724] loss: 0.360, ave_loss: 0.391
[86]  [1700/1724] loss: 0.298, ave_loss: 0.390
[87]  [1720/1724] loss: 0.355, ave_loss: 0.390
[88]  [1740/1724] loss: 0.391, ave_loss: 0.390

Finished Training finishing at 2021-08-21 10:43:41.057938
printing_out epoch  21.438515081206496 learning rate: 0.00021856130515487778
0.00021200446600023144
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.899e-01
Validation Loss: 4.582e+04
Validation ROC: 0.7657
Saving model
77.5614849187935 epochs left to go

Training Epoch 21.438515081206496/100 starting at 2021-08-21 10:45:14.553069
[1]  [0/1724] loss: 0.392, ave_loss: 0.392
[2]  [20/1724] loss: 0.458, ave_loss: 0.425
[3]  [40/1724] loss: 0.277, ave_loss: 0.376
[4]  [60/1724] loss: 0.487, ave_loss: 0.403
[5]  [80/1724] loss: 0.434, ave_loss: 0.409
[6]  [100/1724] loss: 0.375, ave_loss: 0.404
[7]  [120/1724] loss: 0.210, ave_loss: 0.376
[8]  [140/1724] loss: 0.352, ave_loss: 0.373
[9]  [160/1724] loss: 0.396, ave_loss: 0.376
[10]  [180/1724] loss: 0.554, ave_loss: 0.393
[11]  [200/1724] loss: 0.298, ave_loss: 0.385
[12]  [220/1724] loss: 0.308, ave_loss: 0.378
[13]  [240/1724] loss: 0.424, ave_loss: 0.382
[14]  [260/1724] loss: 0.250, ave_loss: 0.372
[15]  [280/1724] loss: 0.307, ave_loss: 0.368
[16]  [300/1724] loss: 0.340, ave_loss: 0.366
[17]  [320/1724] loss: 0.340, ave_loss: 0.365
[18]  [340/1724] loss: 0.480, ave_loss: 0.371
[19]  [360/1724] loss: 0.339, ave_loss: 0.369
[20]  [380/1724] loss: 0.523, ave_loss: 0.377
[21]  [400/1724] loss: 0.499, ave_loss: 0.383
[22]  [420/1724] loss: 0.413, ave_loss: 0.384
[23]  [440/1724] loss: 0.382, ave_loss: 0.384
[24]  [460/1724] loss: 0.436, ave_loss: 0.386
[25]  [480/1724] loss: 0.337, ave_loss: 0.384
[26]  [500/1724] loss: 0.402, ave_loss: 0.385
[27]  [520/1724] loss: 0.365, ave_loss: 0.384
[28]  [540/1724] loss: 0.343, ave_loss: 0.383
[29]  [560/1724] loss: 0.399, ave_loss: 0.383
[30]  [580/1724] loss: 0.428, ave_loss: 0.385
[31]  [600/1724] loss: 0.459, ave_loss: 0.387
[32]  [620/1724] loss: 0.287, ave_loss: 0.384
[33]  [640/1724] loss: 0.349, ave_loss: 0.383
[34]  [660/1724] loss: 0.379, ave_loss: 0.383
[35]  [680/1724] loss: 0.288, ave_loss: 0.380
[36]  [700/1724] loss: 0.438, ave_loss: 0.382
[37]  [720/1724] loss: 0.421, ave_loss: 0.383
[38]  [740/1724] loss: 0.294, ave_loss: 0.381
[39]  [760/1724] loss: 0.343, ave_loss: 0.380
[40]  [780/1724] loss: 0.245, ave_loss: 0.376
[41]  [800/1724] loss: 0.386, ave_loss: 0.377
[42]  [820/1724] loss: 0.338, ave_loss: 0.376
[43]  [840/1724] loss: 0.512, ave_loss: 0.379
[44]  [860/1724] loss: 0.433, ave_loss: 0.380
[45]  [880/1724] loss: 0.578, ave_loss: 0.384
[46]  [900/1724] loss: 0.435, ave_loss: 0.385
[47]  [920/1724] loss: 0.551, ave_loss: 0.389
[48]  [940/1724] loss: 0.276, ave_loss: 0.387
[49]  [960/1724] loss: 0.324, ave_loss: 0.385
[50]  [980/1724] loss: 0.379, ave_loss: 0.385
[51]  [1000/1724] loss: 0.613, ave_loss: 0.390
[52]  [1020/1724] loss: 0.388, ave_loss: 0.390
[53]  [1040/1724] loss: 0.500, ave_loss: 0.392
[54]  [1060/1724] loss: 0.193, ave_loss: 0.388
[55]  [1080/1724] loss: 0.407, ave_loss: 0.388
[56]  [1100/1724] loss: 0.317, ave_loss: 0.387
[57]  [1120/1724] loss: 0.316, ave_loss: 0.386
[58]  [1140/1724] loss: 0.431, ave_loss: 0.387
[59]  [1160/1724] loss: 0.320, ave_loss: 0.386
[60]  [1180/1724] loss: 0.384, ave_loss: 0.386
[61]  [1200/1724] loss: 0.352, ave_loss: 0.385
[62]  [1220/1724] loss: 0.394, ave_loss: 0.385
[63]  [1240/1724] loss: 0.384, ave_loss: 0.385
[64]  [1260/1724] loss: 0.306, ave_loss: 0.384
[65]  [1280/1724] loss: 0.307, ave_loss: 0.383
[66]  [1300/1724] loss: 0.383, ave_loss: 0.383
[67]  [1320/1724] loss: 0.544, ave_loss: 0.385
[68]  [1340/1724] loss: 0.383, ave_loss: 0.385
[69]  [1360/1724] loss: 0.383, ave_loss: 0.385
[70]  [1380/1724] loss: 0.405, ave_loss: 0.385
[71]  [1400/1724] loss: 0.327, ave_loss: 0.385
[72]  [1420/1724] loss: 0.370, ave_loss: 0.384
[73]  [1440/1724] loss: 0.312, ave_loss: 0.383
[74]  [1460/1724] loss: 0.400, ave_loss: 0.384
[75]  [1480/1724] loss: 0.359, ave_loss: 0.383
[76]  [1500/1724] loss: 0.398, ave_loss: 0.383
[77]  [1520/1724] loss: 0.336, ave_loss: 0.383
[78]  [1540/1724] loss: 0.302, ave_loss: 0.382
[79]  [1560/1724] loss: 0.214, ave_loss: 0.380
[80]  [1580/1724] loss: 0.486, ave_loss: 0.381
[81]  [1600/1724] loss: 0.276, ave_loss: 0.380
[82]  [1620/1724] loss: 0.420, ave_loss: 0.380
[83]  [1640/1724] loss: 0.382, ave_loss: 0.380
[84]  [1660/1724] loss: 0.469, ave_loss: 0.381
[85]  [1680/1724] loss: 0.389, ave_loss: 0.381
[86]  [1700/1724] loss: 0.304, ave_loss: 0.380
[87]  [1720/1724] loss: 0.344, ave_loss: 0.380
[88]  [1740/1724] loss: 0.306, ave_loss: 0.379

Finished Training finishing at 2021-08-21 10:47:21.104450
printing_out epoch  22.45939675174014 learning rate: 0.00021856130515487778
0.0002056443320202245
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.792e-01
Validation Loss: 4.156e+04
Validation ROC: 0.7555
No improvement, still saving model
76.54060324825986 epochs left to go

Training Epoch 22.45939675174014/100 starting at 2021-08-21 10:47:54.088920
[1]  [0/1724] loss: 0.285, ave_loss: 0.285
[2]  [20/1724] loss: 0.437, ave_loss: 0.361
[3]  [40/1724] loss: 0.311, ave_loss: 0.345
[4]  [60/1724] loss: 0.316, ave_loss: 0.337
[5]  [80/1724] loss: 0.510, ave_loss: 0.372
[6]  [100/1724] loss: 0.331, ave_loss: 0.365
[7]  [120/1724] loss: 0.479, ave_loss: 0.381
[8]  [140/1724] loss: 0.337, ave_loss: 0.376
[9]  [160/1724] loss: 0.212, ave_loss: 0.358
[10]  [180/1724] loss: 0.396, ave_loss: 0.362
[11]  [200/1724] loss: 0.446, ave_loss: 0.369
[12]  [220/1724] loss: 0.324, ave_loss: 0.365
[13]  [240/1724] loss: 0.250, ave_loss: 0.357
[14]  [260/1724] loss: 0.374, ave_loss: 0.358
[15]  [280/1724] loss: 0.387, ave_loss: 0.360
[16]  [300/1724] loss: 0.442, ave_loss: 0.365
[17]  [320/1724] loss: 0.251, ave_loss: 0.358
[18]  [340/1724] loss: 0.512, ave_loss: 0.367
[19]  [360/1724] loss: 0.475, ave_loss: 0.372
[20]  [380/1724] loss: 0.549, ave_loss: 0.381
[21]  [400/1724] loss: 0.447, ave_loss: 0.384
[22]  [420/1724] loss: 0.359, ave_loss: 0.383
[23]  [440/1724] loss: 0.466, ave_loss: 0.387
[24]  [460/1724] loss: 0.418, ave_loss: 0.388
[25]  [480/1724] loss: 0.380, ave_loss: 0.388
[26]  [500/1724] loss: 0.496, ave_loss: 0.392
[27]  [520/1724] loss: 0.361, ave_loss: 0.391
[28]  [540/1724] loss: 0.381, ave_loss: 0.390
[29]  [560/1724] loss: 0.435, ave_loss: 0.392
[30]  [580/1724] loss: 0.396, ave_loss: 0.392
[31]  [600/1724] loss: 0.418, ave_loss: 0.393
[32]  [620/1724] loss: 0.488, ave_loss: 0.396
[33]  [640/1724] loss: 0.317, ave_loss: 0.394
[34]  [660/1724] loss: 0.406, ave_loss: 0.394
[35]  [680/1724] loss: 0.370, ave_loss: 0.393
[36]  [700/1724] loss: 0.335, ave_loss: 0.392
[37]  [720/1724] loss: 0.314, ave_loss: 0.389
[38]  [740/1724] loss: 0.446, ave_loss: 0.391
[39]  [760/1724] loss: 0.451, ave_loss: 0.393
[40]  [780/1724] loss: 0.369, ave_loss: 0.392
[41]  [800/1724] loss: 0.611, ave_loss: 0.397
[42]  [820/1724] loss: 0.443, ave_loss: 0.398
[43]  [840/1724] loss: 0.376, ave_loss: 0.398
[44]  [860/1724] loss: 0.298, ave_loss: 0.396
[45]  [880/1724] loss: 0.284, ave_loss: 0.393
[46]  [900/1724] loss: 0.396, ave_loss: 0.393
[47]  [920/1724] loss: 0.242, ave_loss: 0.390
[48]  [940/1724] loss: 0.424, ave_loss: 0.391
[49]  [960/1724] loss: 0.396, ave_loss: 0.391
[50]  [980/1724] loss: 0.415, ave_loss: 0.391
[51]  [1000/1724] loss: 0.406, ave_loss: 0.392
[52]  [1020/1724] loss: 0.490, ave_loss: 0.393
[53]  [1040/1724] loss: 0.379, ave_loss: 0.393
[54]  [1060/1724] loss: 0.431, ave_loss: 0.394
[55]  [1080/1724] loss: 0.387, ave_loss: 0.394
[56]  [1100/1724] loss: 0.452, ave_loss: 0.395
[57]  [1120/1724] loss: 0.423, ave_loss: 0.395
[58]  [1140/1724] loss: 0.444, ave_loss: 0.396
[59]  [1160/1724] loss: 0.293, ave_loss: 0.394
[60]  [1180/1724] loss: 0.434, ave_loss: 0.395
[61]  [1200/1724] loss: 0.405, ave_loss: 0.395
[62]  [1220/1724] loss: 0.261, ave_loss: 0.393
[63]  [1240/1724] loss: 0.401, ave_loss: 0.393
[64]  [1260/1724] loss: 0.313, ave_loss: 0.392
[65]  [1280/1724] loss: 0.420, ave_loss: 0.392
[66]  [1300/1724] loss: 0.453, ave_loss: 0.393
[67]  [1320/1724] loss: 0.416, ave_loss: 0.394
[68]  [1340/1724] loss: 0.483, ave_loss: 0.395
[69]  [1360/1724] loss: 0.410, ave_loss: 0.395
[70]  [1380/1724] loss: 0.393, ave_loss: 0.395
[71]  [1400/1724] loss: 0.511, ave_loss: 0.397
[72]  [1420/1724] loss: 0.330, ave_loss: 0.396
[73]  [1440/1724] loss: 0.406, ave_loss: 0.396
[74]  [1460/1724] loss: 0.458, ave_loss: 0.397
[75]  [1480/1724] loss: 0.456, ave_loss: 0.398
[76]  [1500/1724] loss: 0.425, ave_loss: 0.398
[77]  [1520/1724] loss: 0.450, ave_loss: 0.399
[78]  [1540/1724] loss: 0.277, ave_loss: 0.397
[79]  [1560/1724] loss: 0.357, ave_loss: 0.397
[80]  [1580/1724] loss: 0.367, ave_loss: 0.396
[81]  [1600/1724] loss: 0.237, ave_loss: 0.394
[82]  [1620/1724] loss: 0.379, ave_loss: 0.394
[83]  [1640/1724] loss: 0.329, ave_loss: 0.393
[84]  [1660/1724] loss: 0.364, ave_loss: 0.393
[85]  [1680/1724] loss: 0.380, ave_loss: 0.393
[86]  [1700/1724] loss: 0.498, ave_loss: 0.394
[87]  [1720/1724] loss: 0.454, ave_loss: 0.395
[88]  [1740/1724] loss: 0.320, ave_loss: 0.394

Finished Training finishing at 2021-08-21 10:50:02.084250
printing_out epoch  23.48027842227378 learning rate: 0.00019869209559534342
0.00019273133272748312
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.938e-01
Validation Loss: 3.439e+04
Validation ROC: 0.7577
No improvement, still saving model
75.51972157772622 epochs left to go

Training Epoch 23.48027842227378/100 starting at 2021-08-21 10:50:33.463411
[1]  [0/1724] loss: 0.549, ave_loss: 0.549
[2]  [20/1724] loss: 0.527, ave_loss: 0.538
[3]  [40/1724] loss: 0.365, ave_loss: 0.480
[4]  [60/1724] loss: 0.339, ave_loss: 0.445
[5]  [80/1724] loss: 0.357, ave_loss: 0.427
[6]  [100/1724] loss: 0.252, ave_loss: 0.398
[7]  [120/1724] loss: 0.216, ave_loss: 0.372
[8]  [140/1724] loss: 0.507, ave_loss: 0.389
[9]  [160/1724] loss: 0.287, ave_loss: 0.378
[10]  [180/1724] loss: 0.176, ave_loss: 0.358
[11]  [200/1724] loss: 0.418, ave_loss: 0.363
[12]  [220/1724] loss: 0.289, ave_loss: 0.357
[13]  [240/1724] loss: 0.397, ave_loss: 0.360
[14]  [260/1724] loss: 0.300, ave_loss: 0.356
[15]  [280/1724] loss: 0.487, ave_loss: 0.365
[16]  [300/1724] loss: 0.307, ave_loss: 0.361
[17]  [320/1724] loss: 0.487, ave_loss: 0.368
[18]  [340/1724] loss: 0.411, ave_loss: 0.371
[19]  [360/1724] loss: 0.460, ave_loss: 0.375
[20]  [380/1724] loss: 0.296, ave_loss: 0.371
[21]  [400/1724] loss: 0.326, ave_loss: 0.369
[22]  [420/1724] loss: 0.493, ave_loss: 0.375
[23]  [440/1724] loss: 0.280, ave_loss: 0.371
[24]  [460/1724] loss: 0.586, ave_loss: 0.380
[25]  [480/1724] loss: 0.392, ave_loss: 0.380
[26]  [500/1724] loss: 0.513, ave_loss: 0.385
[27]  [520/1724] loss: 0.344, ave_loss: 0.384
[28]  [540/1724] loss: 0.444, ave_loss: 0.386
[29]  [560/1724] loss: 0.476, ave_loss: 0.389
[30]  [580/1724] loss: 0.241, ave_loss: 0.384
[31]  [600/1724] loss: 0.417, ave_loss: 0.385
[32]  [620/1724] loss: 0.323, ave_loss: 0.383
[33]  [640/1724] loss: 0.553, ave_loss: 0.388
[34]  [660/1724] loss: 0.303, ave_loss: 0.386
[35]  [680/1724] loss: 0.327, ave_loss: 0.384
[36]  [700/1724] loss: 0.260, ave_loss: 0.381
[37]  [720/1724] loss: 0.276, ave_loss: 0.378
[38]  [740/1724] loss: 0.311, ave_loss: 0.376
[39]  [760/1724] loss: 0.577, ave_loss: 0.381
[40]  [780/1724] loss: 0.248, ave_loss: 0.378
[41]  [800/1724] loss: 0.515, ave_loss: 0.381
[42]  [820/1724] loss: 0.386, ave_loss: 0.381
[43]  [840/1724] loss: 0.290, ave_loss: 0.379
[44]  [860/1724] loss: 0.321, ave_loss: 0.378
[45]  [880/1724] loss: 0.490, ave_loss: 0.380
[46]  [900/1724] loss: 0.424, ave_loss: 0.381
[47]  [920/1724] loss: 0.381, ave_loss: 0.381
[48]  [940/1724] loss: 0.323, ave_loss: 0.380
[49]  [960/1724] loss: 0.584, ave_loss: 0.384
[50]  [980/1724] loss: 0.309, ave_loss: 0.383
[51]  [1000/1724] loss: 0.428, ave_loss: 0.384
[52]  [1020/1724] loss: 0.326, ave_loss: 0.383
[53]  [1040/1724] loss: 0.392, ave_loss: 0.383
[54]  [1060/1724] loss: 0.387, ave_loss: 0.383
[55]  [1080/1724] loss: 0.326, ave_loss: 0.382
[56]  [1100/1724] loss: 0.516, ave_loss: 0.384
[57]  [1120/1724] loss: 0.293, ave_loss: 0.383
[58]  [1140/1724] loss: 0.280, ave_loss: 0.381
[59]  [1160/1724] loss: 0.330, ave_loss: 0.380
[60]  [1180/1724] loss: 0.304, ave_loss: 0.379
[61]  [1200/1724] loss: 0.468, ave_loss: 0.380
[62]  [1220/1724] loss: 0.550, ave_loss: 0.383
[63]  [1240/1724] loss: 0.354, ave_loss: 0.382
[64]  [1260/1724] loss: 0.342, ave_loss: 0.382
[65]  [1280/1724] loss: 0.250, ave_loss: 0.380
[66]  [1300/1724] loss: 0.424, ave_loss: 0.380
[67]  [1320/1724] loss: 0.415, ave_loss: 0.381
[68]  [1340/1724] loss: 0.306, ave_loss: 0.380
[69]  [1360/1724] loss: 0.351, ave_loss: 0.379
[70]  [1380/1724] loss: 0.381, ave_loss: 0.379
[71]  [1400/1724] loss: 0.245, ave_loss: 0.378
[72]  [1420/1724] loss: 0.471, ave_loss: 0.379
[73]  [1440/1724] loss: 0.280, ave_loss: 0.378
[74]  [1460/1724] loss: 0.329, ave_loss: 0.377
[75]  [1480/1724] loss: 0.350, ave_loss: 0.377
[76]  [1500/1724] loss: 0.340, ave_loss: 0.376
[77]  [1520/1724] loss: 0.429, ave_loss: 0.377
[78]  [1540/1724] loss: 0.380, ave_loss: 0.377
[79]  [1560/1724] loss: 0.256, ave_loss: 0.375
[80]  [1580/1724] loss: 0.580, ave_loss: 0.378
[81]  [1600/1724] loss: 0.313, ave_loss: 0.377
[82]  [1620/1724] loss: 0.376, ave_loss: 0.377
[83]  [1640/1724] loss: 0.323, ave_loss: 0.376
[84]  [1660/1724] loss: 0.356, ave_loss: 0.376
[85]  [1680/1724] loss: 0.297, ave_loss: 0.375
[86]  [1700/1724] loss: 0.295, ave_loss: 0.374
[87]  [1720/1724] loss: 0.396, ave_loss: 0.374
[88]  [1740/1724] loss: 0.370, ave_loss: 0.374

Finished Training finishing at 2021-08-21 10:52:43.712565
printing_out epoch  24.501160092807424 learning rate: 0.00018062917781394856
0.0001752103024795301
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.744e-01
Validation Loss: 3.476e+04
Validation ROC: 0.7528
No improvement, still saving model
74.49883990719258 epochs left to go

Training Epoch 24.501160092807424/100 starting at 2021-08-21 10:53:29.496239
[1]  [0/1724] loss: 0.447, ave_loss: 0.447
[2]  [20/1724] loss: 0.337, ave_loss: 0.392
[3]  [40/1724] loss: 0.426, ave_loss: 0.403
[4]  [60/1724] loss: 0.393, ave_loss: 0.401
[5]  [80/1724] loss: 0.414, ave_loss: 0.403
[6]  [100/1724] loss: 0.377, ave_loss: 0.399
[7]  [120/1724] loss: 0.235, ave_loss: 0.376
[8]  [140/1724] loss: 0.465, ave_loss: 0.387
[9]  [160/1724] loss: 0.317, ave_loss: 0.379
[10]  [180/1724] loss: 0.348, ave_loss: 0.376
[11]  [200/1724] loss: 0.403, ave_loss: 0.378
[12]  [220/1724] loss: 0.333, ave_loss: 0.375
[13]  [240/1724] loss: 0.514, ave_loss: 0.385
[14]  [260/1724] loss: 0.289, ave_loss: 0.378
[15]  [280/1724] loss: 0.313, ave_loss: 0.374
[16]  [300/1724] loss: 0.390, ave_loss: 0.375
[17]  [320/1724] loss: 0.338, ave_loss: 0.373
[18]  [340/1724] loss: 0.334, ave_loss: 0.371
[19]  [360/1724] loss: 0.340, ave_loss: 0.369
[20]  [380/1724] loss: 0.452, ave_loss: 0.373
[21]  [400/1724] loss: 0.277, ave_loss: 0.369
[22]  [420/1724] loss: 0.318, ave_loss: 0.366
[23]  [440/1724] loss: 0.361, ave_loss: 0.366
[24]  [460/1724] loss: 0.546, ave_loss: 0.374
[25]  [480/1724] loss: 0.219, ave_loss: 0.367
[26]  [500/1724] loss: 0.244, ave_loss: 0.363
[27]  [520/1724] loss: 0.439, ave_loss: 0.365
[28]  [540/1724] loss: 0.516, ave_loss: 0.371
[29]  [560/1724] loss: 0.342, ave_loss: 0.370
[30]  [580/1724] loss: 0.281, ave_loss: 0.367
[31]  [600/1724] loss: 0.380, ave_loss: 0.367
[32]  [620/1724] loss: 0.432, ave_loss: 0.369
[33]  [640/1724] loss: 0.411, ave_loss: 0.371
[34]  [660/1724] loss: 0.287, ave_loss: 0.368
[35]  [680/1724] loss: 0.338, ave_loss: 0.367
[36]  [700/1724] loss: 0.473, ave_loss: 0.370
[37]  [720/1724] loss: 0.483, ave_loss: 0.373
[38]  [740/1724] loss: 0.283, ave_loss: 0.371
[39]  [760/1724] loss: 0.348, ave_loss: 0.370
[40]  [780/1724] loss: 0.405, ave_loss: 0.371
[41]  [800/1724] loss: 0.251, ave_loss: 0.368
[42]  [820/1724] loss: 0.434, ave_loss: 0.370
[43]  [840/1724] loss: 0.329, ave_loss: 0.369
[44]  [860/1724] loss: 0.340, ave_loss: 0.368
[45]  [880/1724] loss: 0.321, ave_loss: 0.367
[46]  [900/1724] loss: 0.307, ave_loss: 0.366
[47]  [920/1724] loss: 0.269, ave_loss: 0.364
[48]  [940/1724] loss: 0.578, ave_loss: 0.368
[49]  [960/1724] loss: 0.248, ave_loss: 0.366
[50]  [980/1724] loss: 0.427, ave_loss: 0.367
[51]  [1000/1724] loss: 0.504, ave_loss: 0.370
[52]  [1020/1724] loss: 0.401, ave_loss: 0.370
[53]  [1040/1724] loss: 0.489, ave_loss: 0.373
[54]  [1060/1724] loss: 0.377, ave_loss: 0.373
[55]  [1080/1724] loss: 0.319, ave_loss: 0.372
[56]  [1100/1724] loss: 0.360, ave_loss: 0.371
[57]  [1120/1724] loss: 0.436, ave_loss: 0.373
[58]  [1140/1724] loss: 0.449, ave_loss: 0.374
[59]  [1160/1724] loss: 0.455, ave_loss: 0.375
[60]  [1180/1724] loss: 0.319, ave_loss: 0.374
[61]  [1200/1724] loss: 0.394, ave_loss: 0.375
[62]  [1220/1724] loss: 0.286, ave_loss: 0.373
[63]  [1240/1724] loss: 0.419, ave_loss: 0.374
[64]  [1260/1724] loss: 0.413, ave_loss: 0.375
[65]  [1280/1724] loss: 0.367, ave_loss: 0.374
[66]  [1300/1724] loss: 0.382, ave_loss: 0.375
[67]  [1320/1724] loss: 0.298, ave_loss: 0.373
[68]  [1340/1724] loss: 0.375, ave_loss: 0.373
[69]  [1360/1724] loss: 0.439, ave_loss: 0.374
[70]  [1380/1724] loss: 0.331, ave_loss: 0.374
[71]  [1400/1724] loss: 0.363, ave_loss: 0.374
[72]  [1420/1724] loss: 0.349, ave_loss: 0.373
[73]  [1440/1724] loss: 0.282, ave_loss: 0.372
[74]  [1460/1724] loss: 0.425, ave_loss: 0.373
[75]  [1480/1724] loss: 0.340, ave_loss: 0.372
[76]  [1500/1724] loss: 0.328, ave_loss: 0.372
[77]  [1520/1724] loss: 0.410, ave_loss: 0.372
[78]  [1540/1724] loss: 0.422, ave_loss: 0.373
[79]  [1560/1724] loss: 0.316, ave_loss: 0.372
[80]  [1580/1724] loss: 0.542, ave_loss: 0.374
[81]  [1600/1724] loss: 0.319, ave_loss: 0.374
[82]  [1620/1724] loss: 0.300, ave_loss: 0.373
[83]  [1640/1724] loss: 0.378, ave_loss: 0.373
[84]  [1660/1724] loss: 0.395, ave_loss: 0.373
[85]  [1680/1724] loss: 0.409, ave_loss: 0.373
[86]  [1700/1724] loss: 0.238, ave_loss: 0.372
[87]  [1720/1724] loss: 0.382, ave_loss: 0.372
[88]  [1740/1724] loss: 0.275, ave_loss: 0.371

Finished Training finishing at 2021-08-21 10:55:33.645576
printing_out epoch  25.52204176334107 learning rate: 0.00016420834346722596
0.00015928209316320917
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.708e-01
Validation Loss: 2.556e+04
Validation ROC: 0.7543
No improvement, still saving model
73.47795823665894 epochs left to go

Training Epoch 25.52204176334107/100 starting at 2021-08-21 10:56:18.354082
[1]  [0/1724] loss: 0.599, ave_loss: 0.599
[2]  [20/1724] loss: 0.402, ave_loss: 0.501
[3]  [40/1724] loss: 0.573, ave_loss: 0.525
[4]  [60/1724] loss: 0.322, ave_loss: 0.474
[5]  [80/1724] loss: 0.397, ave_loss: 0.459
[6]  [100/1724] loss: 0.444, ave_loss: 0.456
[7]  [120/1724] loss: 0.476, ave_loss: 0.459
[8]  [140/1724] loss: 0.291, ave_loss: 0.438
[9]  [160/1724] loss: 0.456, ave_loss: 0.440
[10]  [180/1724] loss: 0.504, ave_loss: 0.447
[11]  [200/1724] loss: 0.309, ave_loss: 0.434
[12]  [220/1724] loss: 0.364, ave_loss: 0.428
[13]  [240/1724] loss: 0.268, ave_loss: 0.416
[14]  [260/1724] loss: 0.460, ave_loss: 0.419
[15]  [280/1724] loss: 0.468, ave_loss: 0.422
[16]  [300/1724] loss: 0.595, ave_loss: 0.433
[17]  [320/1724] loss: 0.317, ave_loss: 0.426
[18]  [340/1724] loss: 0.434, ave_loss: 0.427
[19]  [360/1724] loss: 0.315, ave_loss: 0.421
[20]  [380/1724] loss: 0.363, ave_loss: 0.418
[21]  [400/1724] loss: 0.466, ave_loss: 0.420
[22]  [420/1724] loss: 0.383, ave_loss: 0.419
[23]  [440/1724] loss: 0.429, ave_loss: 0.419
[24]  [460/1724] loss: 0.246, ave_loss: 0.412
[25]  [480/1724] loss: 0.392, ave_loss: 0.411
[26]  [500/1724] loss: 0.306, ave_loss: 0.407
[27]  [520/1724] loss: 0.509, ave_loss: 0.411
[28]  [540/1724] loss: 0.476, ave_loss: 0.413
[29]  [560/1724] loss: 0.501, ave_loss: 0.416
[30]  [580/1724] loss: 0.484, ave_loss: 0.418
[31]  [600/1724] loss: 0.463, ave_loss: 0.420
[32]  [620/1724] loss: 0.459, ave_loss: 0.421
[33]  [640/1724] loss: 0.390, ave_loss: 0.420
[34]  [660/1724] loss: 0.304, ave_loss: 0.417
[35]  [680/1724] loss: 0.421, ave_loss: 0.417
[36]  [700/1724] loss: 0.345, ave_loss: 0.415
[37]  [720/1724] loss: 0.298, ave_loss: 0.412
[38]  [740/1724] loss: 0.261, ave_loss: 0.408
[39]  [760/1724] loss: 0.304, ave_loss: 0.405
[40]  [780/1724] loss: 0.269, ave_loss: 0.402
[41]  [800/1724] loss: 0.461, ave_loss: 0.403
[42]  [820/1724] loss: 0.487, ave_loss: 0.405
[43]  [840/1724] loss: 0.290, ave_loss: 0.402
[44]  [860/1724] loss: 0.468, ave_loss: 0.404
[45]  [880/1724] loss: 0.446, ave_loss: 0.405
[46]  [900/1724] loss: 0.318, ave_loss: 0.403
[47]  [920/1724] loss: 0.340, ave_loss: 0.402
[48]  [940/1724] loss: 0.326, ave_loss: 0.400
[49]  [960/1724] loss: 0.353, ave_loss: 0.399
[50]  [980/1724] loss: 0.285, ave_loss: 0.397
[51]  [1000/1724] loss: 0.335, ave_loss: 0.396
[52]  [1020/1724] loss: 0.384, ave_loss: 0.395
[53]  [1040/1724] loss: 0.288, ave_loss: 0.393
[54]  [1060/1724] loss: 0.249, ave_loss: 0.391
[55]  [1080/1724] loss: 0.250, ave_loss: 0.388
[56]  [1100/1724] loss: 0.467, ave_loss: 0.389
[57]  [1120/1724] loss: 0.364, ave_loss: 0.389
[58]  [1140/1724] loss: 0.472, ave_loss: 0.390
[59]  [1160/1724] loss: 0.386, ave_loss: 0.390
[60]  [1180/1724] loss: 0.527, ave_loss: 0.393
[61]  [1200/1724] loss: 0.453, ave_loss: 0.394
[62]  [1220/1724] loss: 0.502, ave_loss: 0.395
[63]  [1240/1724] loss: 0.354, ave_loss: 0.395
[64]  [1260/1724] loss: 0.384, ave_loss: 0.395
[65]  [1280/1724] loss: 0.434, ave_loss: 0.395
[66]  [1300/1724] loss: 0.284, ave_loss: 0.393
[67]  [1320/1724] loss: 0.364, ave_loss: 0.393
[68]  [1340/1724] loss: 0.361, ave_loss: 0.393
[69]  [1360/1724] loss: 0.369, ave_loss: 0.392
[70]  [1380/1724] loss: 0.329, ave_loss: 0.391
[71]  [1400/1724] loss: 0.347, ave_loss: 0.391
[72]  [1420/1724] loss: 0.382, ave_loss: 0.391
[73]  [1440/1724] loss: 0.349, ave_loss: 0.390
[74]  [1460/1724] loss: 0.330, ave_loss: 0.389
[75]  [1480/1724] loss: 0.316, ave_loss: 0.388
[76]  [1500/1724] loss: 0.238, ave_loss: 0.386
[77]  [1520/1724] loss: 0.310, ave_loss: 0.385
[78]  [1540/1724] loss: 0.619, ave_loss: 0.388
[79]  [1560/1724] loss: 0.388, ave_loss: 0.388
[80]  [1580/1724] loss: 0.335, ave_loss: 0.388
[81]  [1600/1724] loss: 0.358, ave_loss: 0.387
[82]  [1620/1724] loss: 0.299, ave_loss: 0.386
[83]  [1640/1724] loss: 0.447, ave_loss: 0.387
[84]  [1660/1724] loss: 0.665, ave_loss: 0.390
[85]  [1680/1724] loss: 0.378, ave_loss: 0.390
[86]  [1700/1724] loss: 0.343, ave_loss: 0.389
[87]  [1720/1724] loss: 0.383, ave_loss: 0.389
[88]  [1740/1724] loss: 0.494, ave_loss: 0.391

Finished Training finishing at 2021-08-21 10:58:18.655993
printing_out epoch  26.54292343387471 learning rate: 0.0001492803122429327
0.0001448019028756447
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.906e-01
Validation Loss: 2.188e+04
Validation ROC: 0.7664
Saving model
72.4570765661253 epochs left to go

Training Epoch 26.54292343387471/100 starting at 2021-08-21 10:59:37.164542
[1]  [0/1724] loss: 0.746, ave_loss: 0.746
[2]  [20/1724] loss: 0.367, ave_loss: 0.556
[3]  [40/1724] loss: 0.398, ave_loss: 0.503
[4]  [60/1724] loss: 0.267, ave_loss: 0.444
[5]  [80/1724] loss: 0.375, ave_loss: 0.430
[6]  [100/1724] loss: 0.369, ave_loss: 0.420
[7]  [120/1724] loss: 0.276, ave_loss: 0.400
[8]  [140/1724] loss: 0.340, ave_loss: 0.392
[9]  [160/1724] loss: 0.391, ave_loss: 0.392
[10]  [180/1724] loss: 0.359, ave_loss: 0.389
[11]  [200/1724] loss: 0.380, ave_loss: 0.388
[12]  [220/1724] loss: 0.234, ave_loss: 0.375
[13]  [240/1724] loss: 0.369, ave_loss: 0.375
[14]  [260/1724] loss: 0.422, ave_loss: 0.378
[15]  [280/1724] loss: 0.323, ave_loss: 0.374
[16]  [300/1724] loss: 0.315, ave_loss: 0.371
[17]  [320/1724] loss: 0.382, ave_loss: 0.371
[18]  [340/1724] loss: 0.337, ave_loss: 0.369
[19]  [360/1724] loss: 0.252, ave_loss: 0.363
[20]  [380/1724] loss: 0.332, ave_loss: 0.362
[21]  [400/1724] loss: 0.367, ave_loss: 0.362
[22]  [420/1724] loss: 0.433, ave_loss: 0.365
[23]  [440/1724] loss: 0.690, ave_loss: 0.379
[24]  [460/1724] loss: 0.332, ave_loss: 0.377
[25]  [480/1724] loss: 0.315, ave_loss: 0.375
[26]  [500/1724] loss: 0.382, ave_loss: 0.375
[27]  [520/1724] loss: 0.213, ave_loss: 0.369
[28]  [540/1724] loss: 0.470, ave_loss: 0.373
[29]  [560/1724] loss: 0.566, ave_loss: 0.379
[30]  [580/1724] loss: 0.323, ave_loss: 0.377
[31]  [600/1724] loss: 0.298, ave_loss: 0.375
[32]  [620/1724] loss: 0.222, ave_loss: 0.370
[33]  [640/1724] loss: 0.540, ave_loss: 0.375
[34]  [660/1724] loss: 0.478, ave_loss: 0.378
[35]  [680/1724] loss: 0.327, ave_loss: 0.377
[36]  [700/1724] loss: 0.424, ave_loss: 0.378
[37]  [720/1724] loss: 0.408, ave_loss: 0.379
[38]  [740/1724] loss: 0.430, ave_loss: 0.380
[39]  [760/1724] loss: 0.493, ave_loss: 0.383
[40]  [780/1724] loss: 0.249, ave_loss: 0.380
[41]  [800/1724] loss: 0.469, ave_loss: 0.382
[42]  [820/1724] loss: 0.384, ave_loss: 0.382
[43]  [840/1724] loss: 0.310, ave_loss: 0.380
[44]  [860/1724] loss: 0.379, ave_loss: 0.380
[45]  [880/1724] loss: 0.310, ave_loss: 0.379
[46]  [900/1724] loss: 0.460, ave_loss: 0.381
[47]  [920/1724] loss: 0.384, ave_loss: 0.381
[48]  [940/1724] loss: 0.253, ave_loss: 0.378
[49]  [960/1724] loss: 0.389, ave_loss: 0.378
[50]  [980/1724] loss: 0.273, ave_loss: 0.376
[51]  [1000/1724] loss: 0.523, ave_loss: 0.379
[52]  [1020/1724] loss: 0.300, ave_loss: 0.377
[53]  [1040/1724] loss: 0.373, ave_loss: 0.377
[54]  [1060/1724] loss: 0.197, ave_loss: 0.374
[55]  [1080/1724] loss: 0.427, ave_loss: 0.375
[56]  [1100/1724] loss: 0.584, ave_loss: 0.379
[57]  [1120/1724] loss: 0.255, ave_loss: 0.377
[58]  [1140/1724] loss: 0.297, ave_loss: 0.375
[59]  [1160/1724] loss: 0.349, ave_loss: 0.375
[60]  [1180/1724] loss: 0.247, ave_loss: 0.373
[61]  [1200/1724] loss: 0.562, ave_loss: 0.376
[62]  [1220/1724] loss: 0.346, ave_loss: 0.375
[63]  [1240/1724] loss: 0.212, ave_loss: 0.373
[64]  [1260/1724] loss: 0.401, ave_loss: 0.373
[65]  [1280/1724] loss: 0.371, ave_loss: 0.373
[66]  [1300/1724] loss: 0.403, ave_loss: 0.373
[67]  [1320/1724] loss: 0.273, ave_loss: 0.372
[68]  [1340/1724] loss: 0.403, ave_loss: 0.372
[69]  [1360/1724] loss: 0.359, ave_loss: 0.372
[70]  [1380/1724] loss: 0.338, ave_loss: 0.372
[71]  [1400/1724] loss: 0.375, ave_loss: 0.372
[72]  [1420/1724] loss: 0.380, ave_loss: 0.372
[73]  [1440/1724] loss: 0.354, ave_loss: 0.372
[74]  [1460/1724] loss: 0.416, ave_loss: 0.372
[75]  [1480/1724] loss: 0.388, ave_loss: 0.372
[76]  [1500/1724] loss: 0.365, ave_loss: 0.372
[77]  [1520/1724] loss: 0.389, ave_loss: 0.373
[78]  [1540/1724] loss: 0.359, ave_loss: 0.372
[79]  [1560/1724] loss: 0.340, ave_loss: 0.372
[80]  [1580/1724] loss: 0.369, ave_loss: 0.372
[81]  [1600/1724] loss: 0.247, ave_loss: 0.370
[82]  [1620/1724] loss: 0.328, ave_loss: 0.370
[83]  [1640/1724] loss: 0.330, ave_loss: 0.369
[84]  [1660/1724] loss: 0.345, ave_loss: 0.369
[85]  [1680/1724] loss: 0.350, ave_loss: 0.369
[86]  [1700/1724] loss: 0.310, ave_loss: 0.368
[87]  [1720/1724] loss: 0.396, ave_loss: 0.369
[88]  [1740/1724] loss: 0.362, ave_loss: 0.368

Finished Training finishing at 2021-08-21 11:01:34.432764
printing_out epoch  27.563805104408353 learning rate: 0.0001492803122429327
0.00014045784578937536
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.685e-01
Validation Loss: 2.314e+04
Validation ROC: 0.7634
No improvement, still saving model
71.43619489559165 epochs left to go

Training Epoch 27.563805104408353/100 starting at 2021-08-21 11:02:05.615493
[1]  [0/1724] loss: 0.211, ave_loss: 0.211
[2]  [20/1724] loss: 0.570, ave_loss: 0.390
[3]  [40/1724] loss: 0.253, ave_loss: 0.345
[4]  [60/1724] loss: 0.317, ave_loss: 0.338
[5]  [80/1724] loss: 0.131, ave_loss: 0.296
[6]  [100/1724] loss: 0.548, ave_loss: 0.338
[7]  [120/1724] loss: 0.298, ave_loss: 0.333
[8]  [140/1724] loss: 0.242, ave_loss: 0.321
[9]  [160/1724] loss: 0.390, ave_loss: 0.329
[10]  [180/1724] loss: 0.429, ave_loss: 0.339
[11]  [200/1724] loss: 0.567, ave_loss: 0.360
[12]  [220/1724] loss: 0.410, ave_loss: 0.364
[13]  [240/1724] loss: 0.311, ave_loss: 0.360
[14]  [260/1724] loss: 0.452, ave_loss: 0.366
[15]  [280/1724] loss: 0.411, ave_loss: 0.369
[16]  [300/1724] loss: 0.328, ave_loss: 0.367
[17]  [320/1724] loss: 0.503, ave_loss: 0.375
[18]  [340/1724] loss: 0.340, ave_loss: 0.373
[19]  [360/1724] loss: 0.329, ave_loss: 0.371
[20]  [380/1724] loss: 0.349, ave_loss: 0.369
[21]  [400/1724] loss: 0.291, ave_loss: 0.366
[22]  [420/1724] loss: 0.272, ave_loss: 0.361
[23]  [440/1724] loss: 0.347, ave_loss: 0.361
[24]  [460/1724] loss: 0.327, ave_loss: 0.359
[25]  [480/1724] loss: 0.214, ave_loss: 0.354
[26]  [500/1724] loss: 0.293, ave_loss: 0.351
[27]  [520/1724] loss: 0.411, ave_loss: 0.353
[28]  [540/1724] loss: 0.299, ave_loss: 0.352
[29]  [560/1724] loss: 0.307, ave_loss: 0.350
[30]  [580/1724] loss: 0.366, ave_loss: 0.351
[31]  [600/1724] loss: 0.357, ave_loss: 0.351
[32]  [620/1724] loss: 0.459, ave_loss: 0.354
[33]  [640/1724] loss: 0.266, ave_loss: 0.351
[34]  [660/1724] loss: 0.375, ave_loss: 0.352
[35]  [680/1724] loss: 0.508, ave_loss: 0.357
[36]  [700/1724] loss: 0.208, ave_loss: 0.352
[37]  [720/1724] loss: 0.481, ave_loss: 0.356
[38]  [740/1724] loss: 0.434, ave_loss: 0.358
[39]  [760/1724] loss: 0.369, ave_loss: 0.358
[40]  [780/1724] loss: 0.260, ave_loss: 0.356
[41]  [800/1724] loss: 0.386, ave_loss: 0.357
[42]  [820/1724] loss: 0.423, ave_loss: 0.358
[43]  [840/1724] loss: 0.374, ave_loss: 0.359
[44]  [860/1724] loss: 0.402, ave_loss: 0.360
[45]  [880/1724] loss: 0.462, ave_loss: 0.362
[46]  [900/1724] loss: 0.353, ave_loss: 0.362
[47]  [920/1724] loss: 0.316, ave_loss: 0.361
[48]  [940/1724] loss: 0.220, ave_loss: 0.358
[49]  [960/1724] loss: 0.368, ave_loss: 0.358
[50]  [980/1724] loss: 0.408, ave_loss: 0.359
[51]  [1000/1724] loss: 0.424, ave_loss: 0.360
[52]  [1020/1724] loss: 0.488, ave_loss: 0.363
[53]  [1040/1724] loss: 0.431, ave_loss: 0.364
[54]  [1060/1724] loss: 0.232, ave_loss: 0.361
[55]  [1080/1724] loss: 0.287, ave_loss: 0.360
[56]  [1100/1724] loss: 0.408, ave_loss: 0.361
[57]  [1120/1724] loss: 0.260, ave_loss: 0.359
[58]  [1140/1724] loss: 0.347, ave_loss: 0.359
[59]  [1160/1724] loss: 0.247, ave_loss: 0.357
[60]  [1180/1724] loss: 0.315, ave_loss: 0.356
[61]  [1200/1724] loss: 0.297, ave_loss: 0.355
[62]  [1220/1724] loss: 0.464, ave_loss: 0.357
[63]  [1240/1724] loss: 0.178, ave_loss: 0.354
[64]  [1260/1724] loss: 0.357, ave_loss: 0.354
[65]  [1280/1724] loss: 0.401, ave_loss: 0.355
[66]  [1300/1724] loss: 0.283, ave_loss: 0.354
[67]  [1320/1724] loss: 0.400, ave_loss: 0.355
[68]  [1340/1724] loss: 0.212, ave_loss: 0.353
[69]  [1360/1724] loss: 0.291, ave_loss: 0.352
[70]  [1380/1724] loss: 0.295, ave_loss: 0.351
[71]  [1400/1724] loss: 0.591, ave_loss: 0.354
[72]  [1420/1724] loss: 0.240, ave_loss: 0.353
[73]  [1440/1724] loss: 0.313, ave_loss: 0.352
[74]  [1460/1724] loss: 0.476, ave_loss: 0.354
[75]  [1480/1724] loss: 0.427, ave_loss: 0.355
[76]  [1500/1724] loss: 0.431, ave_loss: 0.356
[77]  [1520/1724] loss: 0.491, ave_loss: 0.358
[78]  [1540/1724] loss: 0.552, ave_loss: 0.360
[79]  [1560/1724] loss: 0.306, ave_loss: 0.359
[80]  [1580/1724] loss: 0.338, ave_loss: 0.359
[81]  [1600/1724] loss: 0.310, ave_loss: 0.359
[82]  [1620/1724] loss: 0.441, ave_loss: 0.360
[83]  [1640/1724] loss: 0.304, ave_loss: 0.359
[84]  [1660/1724] loss: 0.327, ave_loss: 0.358
[85]  [1680/1724] loss: 0.391, ave_loss: 0.359
[86]  [1700/1724] loss: 0.411, ave_loss: 0.359
[87]  [1720/1724] loss: 0.418, ave_loss: 0.360
[88]  [1740/1724] loss: 0.368, ave_loss: 0.360

Finished Training finishing at 2021-08-21 11:04:03.786063
printing_out epoch  28.584686774941996 learning rate: 0.00013570937476630243
0.00013163809352331336
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.602e-01
Validation Loss: 1.837e+04
Validation ROC: 0.7569
No improvement, still saving model
70.415313225058 epochs left to go

Training Epoch 28.584686774941996/100 starting at 2021-08-21 11:04:35.194506
[1]  [0/1724] loss: 0.529, ave_loss: 0.529
[2]  [20/1724] loss: 0.402, ave_loss: 0.466
[3]  [40/1724] loss: 0.438, ave_loss: 0.457
[4]  [60/1724] loss: 0.299, ave_loss: 0.417
[5]  [80/1724] loss: 0.261, ave_loss: 0.386
[6]  [100/1724] loss: 0.241, ave_loss: 0.362
[7]  [120/1724] loss: 0.387, ave_loss: 0.365
[8]  [140/1724] loss: 0.234, ave_loss: 0.349
[9]  [160/1724] loss: 0.477, ave_loss: 0.363
[10]  [180/1724] loss: 0.342, ave_loss: 0.361
[11]  [200/1724] loss: 0.428, ave_loss: 0.367
[12]  [220/1724] loss: 0.532, ave_loss: 0.381
[13]  [240/1724] loss: 0.517, ave_loss: 0.391
[14]  [260/1724] loss: 0.365, ave_loss: 0.390
[15]  [280/1724] loss: 0.272, ave_loss: 0.382
[16]  [300/1724] loss: 0.367, ave_loss: 0.381
[17]  [320/1724] loss: 0.244, ave_loss: 0.373
[18]  [340/1724] loss: 0.380, ave_loss: 0.373
[19]  [360/1724] loss: 0.334, ave_loss: 0.371
[20]  [380/1724] loss: 0.343, ave_loss: 0.370
[21]  [400/1724] loss: 0.448, ave_loss: 0.373
[22]  [420/1724] loss: 0.339, ave_loss: 0.372
[23]  [440/1724] loss: 0.290, ave_loss: 0.368
[24]  [460/1724] loss: 0.299, ave_loss: 0.365
[25]  [480/1724] loss: 0.232, ave_loss: 0.360
[26]  [500/1724] loss: 0.411, ave_loss: 0.362
[27]  [520/1724] loss: 0.357, ave_loss: 0.362
[28]  [540/1724] loss: 0.248, ave_loss: 0.358
[29]  [560/1724] loss: 0.290, ave_loss: 0.355
[30]  [580/1724] loss: 0.486, ave_loss: 0.360
[31]  [600/1724] loss: 0.309, ave_loss: 0.358
[32]  [620/1724] loss: 0.386, ave_loss: 0.359
[33]  [640/1724] loss: 0.408, ave_loss: 0.361
[34]  [660/1724] loss: 0.232, ave_loss: 0.357
[35]  [680/1724] loss: 0.402, ave_loss: 0.358
[36]  [700/1724] loss: 0.348, ave_loss: 0.358
[37]  [720/1724] loss: 0.345, ave_loss: 0.357
[38]  [740/1724] loss: 0.261, ave_loss: 0.355
[39]  [760/1724] loss: 0.339, ave_loss: 0.354
[40]  [780/1724] loss: 0.345, ave_loss: 0.354
[41]  [800/1724] loss: 0.270, ave_loss: 0.352
[42]  [820/1724] loss: 0.491, ave_loss: 0.356
[43]  [840/1724] loss: 0.526, ave_loss: 0.359
[44]  [860/1724] loss: 0.315, ave_loss: 0.358
[45]  [880/1724] loss: 0.417, ave_loss: 0.360
[46]  [900/1724] loss: 0.249, ave_loss: 0.357
[47]  [920/1724] loss: 0.353, ave_loss: 0.357
[48]  [940/1724] loss: 0.541, ave_loss: 0.361
[49]  [960/1724] loss: 0.298, ave_loss: 0.360
[50]  [980/1724] loss: 0.320, ave_loss: 0.359
[51]  [1000/1724] loss: 0.329, ave_loss: 0.358
[52]  [1020/1724] loss: 0.323, ave_loss: 0.358
[53]  [1040/1724] loss: 0.207, ave_loss: 0.355
[54]  [1060/1724] loss: 0.369, ave_loss: 0.355
[55]  [1080/1724] loss: 0.321, ave_loss: 0.355
[56]  [1100/1724] loss: 0.289, ave_loss: 0.353
[57]  [1120/1724] loss: 0.288, ave_loss: 0.352
[58]  [1140/1724] loss: 0.231, ave_loss: 0.350
[59]  [1160/1724] loss: 0.348, ave_loss: 0.350
[60]  [1180/1724] loss: 0.492, ave_loss: 0.352
[61]  [1200/1724] loss: 0.379, ave_loss: 0.353
[62]  [1220/1724] loss: 0.291, ave_loss: 0.352
[63]  [1240/1724] loss: 0.338, ave_loss: 0.352
[64]  [1260/1724] loss: 0.388, ave_loss: 0.352
[65]  [1280/1724] loss: 0.447, ave_loss: 0.354
[66]  [1300/1724] loss: 0.244, ave_loss: 0.352
[67]  [1320/1724] loss: 0.465, ave_loss: 0.354
[68]  [1340/1724] loss: 0.267, ave_loss: 0.352
[69]  [1360/1724] loss: 0.240, ave_loss: 0.351
[70]  [1380/1724] loss: 0.316, ave_loss: 0.350
[71]  [1400/1724] loss: 0.424, ave_loss: 0.351
[72]  [1420/1724] loss: 0.498, ave_loss: 0.353
[73]  [1440/1724] loss: 0.353, ave_loss: 0.353
[74]  [1460/1724] loss: 0.307, ave_loss: 0.353
[75]  [1480/1724] loss: 0.297, ave_loss: 0.352
[76]  [1500/1724] loss: 0.253, ave_loss: 0.351
[77]  [1520/1724] loss: 0.265, ave_loss: 0.350
[78]  [1540/1724] loss: 0.397, ave_loss: 0.350
[79]  [1560/1724] loss: 0.472, ave_loss: 0.352
[80]  [1580/1724] loss: 0.230, ave_loss: 0.350
[81]  [1600/1724] loss: 0.324, ave_loss: 0.350
[82]  [1620/1724] loss: 0.259, ave_loss: 0.349
[83]  [1640/1724] loss: 0.246, ave_loss: 0.348
[84]  [1660/1724] loss: 0.383, ave_loss: 0.348
[85]  [1680/1724] loss: 0.264, ave_loss: 0.347
[86]  [1700/1724] loss: 0.484, ave_loss: 0.349
[87]  [1720/1724] loss: 0.385, ave_loss: 0.349
[88]  [1740/1724] loss: 0.442, ave_loss: 0.350

Finished Training finishing at 2021-08-21 11:06:39.748784
printing_out epoch  29.605568445475637 learning rate: 0.00012337215887845676
0.00011967099411210306
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.501e-01
Validation Loss: 1.739e+04
Validation ROC: 0.7725
Saving model
69.39443155452436 epochs left to go

Training Epoch 29.605568445475637/100 starting at 2021-08-21 11:07:19.401387
[1]  [0/1724] loss: 0.708, ave_loss: 0.708
[2]  [20/1724] loss: 0.341, ave_loss: 0.525
[3]  [40/1724] loss: 0.185, ave_loss: 0.411
[4]  [60/1724] loss: 0.399, ave_loss: 0.408
[5]  [80/1724] loss: 0.442, ave_loss: 0.415
[6]  [100/1724] loss: 0.395, ave_loss: 0.412
[7]  [120/1724] loss: 0.497, ave_loss: 0.424
[8]  [140/1724] loss: 0.354, ave_loss: 0.415
[9]  [160/1724] loss: 0.368, ave_loss: 0.410
[10]  [180/1724] loss: 0.394, ave_loss: 0.408
[11]  [200/1724] loss: 0.298, ave_loss: 0.398
[12]  [220/1724] loss: 0.314, ave_loss: 0.391
[13]  [240/1724] loss: 0.278, ave_loss: 0.383
[14]  [260/1724] loss: 0.278, ave_loss: 0.375
[15]  [280/1724] loss: 0.359, ave_loss: 0.374
[16]  [300/1724] loss: 0.273, ave_loss: 0.368
[17]  [320/1724] loss: 0.383, ave_loss: 0.369
[18]  [340/1724] loss: 0.347, ave_loss: 0.367
[19]  [360/1724] loss: 0.297, ave_loss: 0.364
[20]  [380/1724] loss: 0.407, ave_loss: 0.366
[21]  [400/1724] loss: 0.183, ave_loss: 0.357
[22]  [420/1724] loss: 0.466, ave_loss: 0.362
[23]  [440/1724] loss: 0.349, ave_loss: 0.361
[24]  [460/1724] loss: 0.245, ave_loss: 0.357
[25]  [480/1724] loss: 0.308, ave_loss: 0.355
[26]  [500/1724] loss: 0.305, ave_loss: 0.353
[27]  [520/1724] loss: 0.237, ave_loss: 0.348
[28]  [540/1724] loss: 0.387, ave_loss: 0.350
[29]  [560/1724] loss: 0.367, ave_loss: 0.350
[30]  [580/1724] loss: 0.231, ave_loss: 0.346
[31]  [600/1724] loss: 0.410, ave_loss: 0.349
[32]  [620/1724] loss: 0.361, ave_loss: 0.349
[33]  [640/1724] loss: 0.591, ave_loss: 0.356
[34]  [660/1724] loss: 0.475, ave_loss: 0.360
[35]  [680/1724] loss: 0.401, ave_loss: 0.361
[36]  [700/1724] loss: 0.324, ave_loss: 0.360
[37]  [720/1724] loss: 0.267, ave_loss: 0.357
[38]  [740/1724] loss: 0.525, ave_loss: 0.362
[39]  [760/1724] loss: 0.443, ave_loss: 0.364
[40]  [780/1724] loss: 0.304, ave_loss: 0.362
[41]  [800/1724] loss: 0.297, ave_loss: 0.361
[42]  [820/1724] loss: 0.322, ave_loss: 0.360
[43]  [840/1724] loss: 0.436, ave_loss: 0.362
[44]  [860/1724] loss: 0.417, ave_loss: 0.363
[45]  [880/1724] loss: 0.440, ave_loss: 0.365
[46]  [900/1724] loss: 0.544, ave_loss: 0.369
[47]  [920/1724] loss: 0.371, ave_loss: 0.369
[48]  [940/1724] loss: 0.259, ave_loss: 0.366
[49]  [960/1724] loss: 0.357, ave_loss: 0.366
[50]  [980/1724] loss: 0.440, ave_loss: 0.368
[51]  [1000/1724] loss: 0.431, ave_loss: 0.369
[52]  [1020/1724] loss: 0.519, ave_loss: 0.372
[53]  [1040/1724] loss: 0.326, ave_loss: 0.371
[54]  [1060/1724] loss: 0.361, ave_loss: 0.371
[55]  [1080/1724] loss: 0.313, ave_loss: 0.370
[56]  [1100/1724] loss: 0.258, ave_loss: 0.368
[57]  [1120/1724] loss: 0.265, ave_loss: 0.366
[58]  [1140/1724] loss: 0.288, ave_loss: 0.365
[59]  [1160/1724] loss: 0.280, ave_loss: 0.363
[60]  [1180/1724] loss: 0.423, ave_loss: 0.364
[61]  [1200/1724] loss: 0.283, ave_loss: 0.363
[62]  [1220/1724] loss: 0.379, ave_loss: 0.363
[63]  [1240/1724] loss: 0.416, ave_loss: 0.364
[64]  [1260/1724] loss: 0.289, ave_loss: 0.363
[65]  [1280/1724] loss: 0.349, ave_loss: 0.362
[66]  [1300/1724] loss: 0.220, ave_loss: 0.360
[67]  [1320/1724] loss: 0.371, ave_loss: 0.360
[68]  [1340/1724] loss: 0.409, ave_loss: 0.361
[69]  [1360/1724] loss: 0.311, ave_loss: 0.360
[70]  [1380/1724] loss: 0.364, ave_loss: 0.361
[71]  [1400/1724] loss: 0.216, ave_loss: 0.358
[72]  [1420/1724] loss: 0.371, ave_loss: 0.359
[73]  [1440/1724] loss: 0.320, ave_loss: 0.358
[74]  [1460/1724] loss: 0.401, ave_loss: 0.359
[75]  [1480/1724] loss: 0.394, ave_loss: 0.359
[76]  [1500/1724] loss: 0.257, ave_loss: 0.358
[77]  [1520/1724] loss: 0.501, ave_loss: 0.360
[78]  [1540/1724] loss: 0.398, ave_loss: 0.360
[79]  [1560/1724] loss: 0.441, ave_loss: 0.361
[80]  [1580/1724] loss: 0.361, ave_loss: 0.361
[81]  [1600/1724] loss: 0.494, ave_loss: 0.363
[82]  [1620/1724] loss: 0.243, ave_loss: 0.361
[83]  [1640/1724] loss: 0.292, ave_loss: 0.361
[84]  [1660/1724] loss: 0.439, ave_loss: 0.361
[85]  [1680/1724] loss: 0.403, ave_loss: 0.362
[86]  [1700/1724] loss: 0.398, ave_loss: 0.362
[87]  [1720/1724] loss: 0.475, ave_loss: 0.364
[88]  [1740/1724] loss: 0.202, ave_loss: 0.362

Finished Training finishing at 2021-08-21 11:09:12.715745
printing_out epoch  30.62645011600928 learning rate: 0.00012337215887845676
0.00011608086428873997
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.618e-01
Validation Loss: 1.633e+04
Validation ROC: 0.7785
Saving model
68.37354988399072 epochs left to go

Training Epoch 30.62645011600928/100 starting at 2021-08-21 11:09:52.879696
[1]  [0/1724] loss: 0.577, ave_loss: 0.577
[2]  [20/1724] loss: 0.310, ave_loss: 0.444
[3]  [40/1724] loss: 0.359, ave_loss: 0.415
[4]  [60/1724] loss: 0.408, ave_loss: 0.413
[5]  [80/1724] loss: 0.466, ave_loss: 0.424
[6]  [100/1724] loss: 0.416, ave_loss: 0.423
[7]  [120/1724] loss: 0.280, ave_loss: 0.402
[8]  [140/1724] loss: 0.347, ave_loss: 0.395
[9]  [160/1724] loss: 0.446, ave_loss: 0.401
[10]  [180/1724] loss: 0.536, ave_loss: 0.414
[11]  [200/1724] loss: 0.401, ave_loss: 0.413
[12]  [220/1724] loss: 0.290, ave_loss: 0.403
[13]  [240/1724] loss: 0.510, ave_loss: 0.411
[14]  [260/1724] loss: 0.277, ave_loss: 0.402
[15]  [280/1724] loss: 0.440, ave_loss: 0.404
[16]  [300/1724] loss: 0.433, ave_loss: 0.406
[17]  [320/1724] loss: 0.364, ave_loss: 0.403
[18]  [340/1724] loss: 0.345, ave_loss: 0.400
[19]  [360/1724] loss: 0.237, ave_loss: 0.392
[20]  [380/1724] loss: 0.386, ave_loss: 0.391
[21]  [400/1724] loss: 0.333, ave_loss: 0.389
[22]  [420/1724] loss: 0.422, ave_loss: 0.390
[23]  [440/1724] loss: 0.400, ave_loss: 0.391
[24]  [460/1724] loss: 0.263, ave_loss: 0.385
[25]  [480/1724] loss: 0.362, ave_loss: 0.384
[26]  [500/1724] loss: 0.341, ave_loss: 0.383
[27]  [520/1724] loss: 0.337, ave_loss: 0.381
[28]  [540/1724] loss: 0.428, ave_loss: 0.383
[29]  [560/1724] loss: 0.375, ave_loss: 0.382
[30]  [580/1724] loss: 0.522, ave_loss: 0.387
[31]  [600/1724] loss: 0.344, ave_loss: 0.386
[32]  [620/1724] loss: 0.370, ave_loss: 0.385
[33]  [640/1724] loss: 0.506, ave_loss: 0.389
[34]  [660/1724] loss: 0.438, ave_loss: 0.390
[35]  [680/1724] loss: 0.262, ave_loss: 0.387
[36]  [700/1724] loss: 0.270, ave_loss: 0.383
[37]  [720/1724] loss: 0.367, ave_loss: 0.383
[38]  [740/1724] loss: 0.293, ave_loss: 0.381
[39]  [760/1724] loss: 0.358, ave_loss: 0.380
[40]  [780/1724] loss: 0.390, ave_loss: 0.380
[41]  [800/1724] loss: 0.388, ave_loss: 0.380
[42]  [820/1724] loss: 0.353, ave_loss: 0.380
[43]  [840/1724] loss: 0.423, ave_loss: 0.381
[44]  [860/1724] loss: 0.367, ave_loss: 0.380
[45]  [880/1724] loss: 0.423, ave_loss: 0.381
[46]  [900/1724] loss: 0.453, ave_loss: 0.383
[47]  [920/1724] loss: 0.401, ave_loss: 0.383
[48]  [940/1724] loss: 0.319, ave_loss: 0.382
[49]  [960/1724] loss: 0.218, ave_loss: 0.379
[50]  [980/1724] loss: 0.203, ave_loss: 0.375
[51]  [1000/1724] loss: 0.211, ave_loss: 0.372
[52]  [1020/1724] loss: 0.516, ave_loss: 0.375
[53]  [1040/1724] loss: 0.303, ave_loss: 0.373
[54]  [1060/1724] loss: 0.508, ave_loss: 0.376
[55]  [1080/1724] loss: 0.398, ave_loss: 0.376
[56]  [1100/1724] loss: 0.350, ave_loss: 0.376
[57]  [1120/1724] loss: 0.460, ave_loss: 0.377
[58]  [1140/1724] loss: 0.253, ave_loss: 0.375
[59]  [1160/1724] loss: 0.260, ave_loss: 0.373
[60]  [1180/1724] loss: 0.287, ave_loss: 0.372
[61]  [1200/1724] loss: 0.331, ave_loss: 0.371
[62]  [1220/1724] loss: 0.410, ave_loss: 0.372
[63]  [1240/1724] loss: 0.292, ave_loss: 0.370
[64]  [1260/1724] loss: 0.412, ave_loss: 0.371
[65]  [1280/1724] loss: 0.218, ave_loss: 0.369
[66]  [1300/1724] loss: 0.333, ave_loss: 0.368
[67]  [1320/1724] loss: 0.264, ave_loss: 0.367
[68]  [1340/1724] loss: 0.344, ave_loss: 0.366
[69]  [1360/1724] loss: 0.387, ave_loss: 0.367
[70]  [1380/1724] loss: 0.346, ave_loss: 0.366
[71]  [1400/1724] loss: 0.392, ave_loss: 0.367
[72]  [1420/1724] loss: 0.345, ave_loss: 0.366
[73]  [1440/1724] loss: 0.381, ave_loss: 0.367
[74]  [1460/1724] loss: 0.357, ave_loss: 0.366
[75]  [1480/1724] loss: 0.338, ave_loss: 0.366
[76]  [1500/1724] loss: 0.362, ave_loss: 0.366
[77]  [1520/1724] loss: 0.410, ave_loss: 0.367
[78]  [1540/1724] loss: 0.465, ave_loss: 0.368
[79]  [1560/1724] loss: 0.287, ave_loss: 0.367
[80]  [1580/1724] loss: 0.506, ave_loss: 0.369
[81]  [1600/1724] loss: 0.269, ave_loss: 0.367
[82]  [1620/1724] loss: 0.203, ave_loss: 0.365
[83]  [1640/1724] loss: 0.372, ave_loss: 0.365
[84]  [1660/1724] loss: 0.225, ave_loss: 0.364
[85]  [1680/1724] loss: 0.289, ave_loss: 0.363
[86]  [1700/1724] loss: 0.333, ave_loss: 0.363
[87]  [1720/1724] loss: 0.248, ave_loss: 0.361
[88]  [1740/1724] loss: 0.250, ave_loss: 0.360

Finished Training finishing at 2021-08-21 11:12:01.980350
printing_out epoch  31.647331786542924 learning rate: 0.00012337215887845676
0.00011259843836007776
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.599e-01
Validation Loss: 1.790e+04
Validation ROC: 0.7649
No improvement, still saving model
67.35266821345708 epochs left to go

Training Epoch 31.647331786542924/100 starting at 2021-08-21 11:13:18.400536
[1]  [0/1724] loss: 0.376, ave_loss: 0.376
[2]  [20/1724] loss: 0.312, ave_loss: 0.344
[3]  [40/1724] loss: 0.222, ave_loss: 0.303
[4]  [60/1724] loss: 0.463, ave_loss: 0.343
[5]  [80/1724] loss: 0.386, ave_loss: 0.352
[6]  [100/1724] loss: 0.274, ave_loss: 0.339
[7]  [120/1724] loss: 0.251, ave_loss: 0.326
[8]  [140/1724] loss: 0.386, ave_loss: 0.334
[9]  [160/1724] loss: 0.297, ave_loss: 0.330
[10]  [180/1724] loss: 0.559, ave_loss: 0.353
[11]  [200/1724] loss: 0.317, ave_loss: 0.349
[12]  [220/1724] loss: 0.354, ave_loss: 0.350
[13]  [240/1724] loss: 0.405, ave_loss: 0.354
[14]  [260/1724] loss: 0.323, ave_loss: 0.352
[15]  [280/1724] loss: 0.428, ave_loss: 0.357
[16]  [300/1724] loss: 0.432, ave_loss: 0.362
[17]  [320/1724] loss: 0.440, ave_loss: 0.366
[18]  [340/1724] loss: 0.353, ave_loss: 0.365
[19]  [360/1724] loss: 0.316, ave_loss: 0.363
[20]  [380/1724] loss: 0.396, ave_loss: 0.365
[21]  [400/1724] loss: 0.347, ave_loss: 0.364
[22]  [420/1724] loss: 0.307, ave_loss: 0.361
[23]  [440/1724] loss: 0.379, ave_loss: 0.362
[24]  [460/1724] loss: 0.592, ave_loss: 0.371
[25]  [480/1724] loss: 0.275, ave_loss: 0.368
[26]  [500/1724] loss: 0.390, ave_loss: 0.368
[27]  [520/1724] loss: 0.277, ave_loss: 0.365
[28]  [540/1724] loss: 0.269, ave_loss: 0.362
[29]  [560/1724] loss: 0.298, ave_loss: 0.359
[30]  [580/1724] loss: 0.277, ave_loss: 0.357
[31]  [600/1724] loss: 0.281, ave_loss: 0.354
[32]  [620/1724] loss: 0.439, ave_loss: 0.357
[33]  [640/1724] loss: 0.420, ave_loss: 0.359
[34]  [660/1724] loss: 0.374, ave_loss: 0.359
[35]  [680/1724] loss: 0.623, ave_loss: 0.367
[36]  [700/1724] loss: 0.380, ave_loss: 0.367
[37]  [720/1724] loss: 0.433, ave_loss: 0.369
[38]  [740/1724] loss: 0.327, ave_loss: 0.368
[39]  [760/1724] loss: 0.378, ave_loss: 0.368
[40]  [780/1724] loss: 0.368, ave_loss: 0.368
[41]  [800/1724] loss: 0.406, ave_loss: 0.369
[42]  [820/1724] loss: 0.443, ave_loss: 0.371
[43]  [840/1724] loss: 0.288, ave_loss: 0.369
[44]  [860/1724] loss: 0.278, ave_loss: 0.367
[45]  [880/1724] loss: 0.479, ave_loss: 0.369
[46]  [900/1724] loss: 0.352, ave_loss: 0.369
[47]  [920/1724] loss: 0.336, ave_loss: 0.368
[48]  [940/1724] loss: 0.470, ave_loss: 0.370
[49]  [960/1724] loss: 0.389, ave_loss: 0.371
[50]  [980/1724] loss: 0.411, ave_loss: 0.371
[51]  [1000/1724] loss: 0.411, ave_loss: 0.372
[52]  [1020/1724] loss: 0.281, ave_loss: 0.371
[53]  [1040/1724] loss: 0.431, ave_loss: 0.372
[54]  [1060/1724] loss: 0.362, ave_loss: 0.371
[55]  [1080/1724] loss: 0.293, ave_loss: 0.370
[56]  [1100/1724] loss: 0.337, ave_loss: 0.369
[57]  [1120/1724] loss: 0.297, ave_loss: 0.368
[58]  [1140/1724] loss: 0.366, ave_loss: 0.368
[59]  [1160/1724] loss: 0.424, ave_loss: 0.369
[60]  [1180/1724] loss: 0.540, ave_loss: 0.372
[61]  [1200/1724] loss: 0.333, ave_loss: 0.371
[62]  [1220/1724] loss: 0.337, ave_loss: 0.371
[63]  [1240/1724] loss: 0.302, ave_loss: 0.370
[64]  [1260/1724] loss: 0.549, ave_loss: 0.372
[65]  [1280/1724] loss: 0.399, ave_loss: 0.373
[66]  [1300/1724] loss: 0.421, ave_loss: 0.374
[67]  [1320/1724] loss: 0.406, ave_loss: 0.374
[68]  [1340/1724] loss: 0.281, ave_loss: 0.373
[69]  [1360/1724] loss: 0.306, ave_loss: 0.372
[70]  [1380/1724] loss: 0.334, ave_loss: 0.371
[71]  [1400/1724] loss: 0.646, ave_loss: 0.375
[72]  [1420/1724] loss: 0.198, ave_loss: 0.373
[73]  [1440/1724] loss: 0.295, ave_loss: 0.372
[74]  [1460/1724] loss: 0.306, ave_loss: 0.371
[75]  [1480/1724] loss: 0.698, ave_loss: 0.375
[76]  [1500/1724] loss: 0.399, ave_loss: 0.375
[77]  [1520/1724] loss: 0.276, ave_loss: 0.374
[78]  [1540/1724] loss: 0.487, ave_loss: 0.375
[79]  [1560/1724] loss: 0.483, ave_loss: 0.377
[80]  [1580/1724] loss: 0.289, ave_loss: 0.376
[81]  [1600/1724] loss: 0.256, ave_loss: 0.374
[82]  [1620/1724] loss: 0.270, ave_loss: 0.373
[83]  [1640/1724] loss: 0.299, ave_loss: 0.372
[84]  [1660/1724] loss: 0.406, ave_loss: 0.373
[85]  [1680/1724] loss: 0.346, ave_loss: 0.372
[86]  [1700/1724] loss: 0.514, ave_loss: 0.374
[87]  [1720/1724] loss: 0.337, ave_loss: 0.373
[88]  [1740/1724] loss: 0.458, ave_loss: 0.374

Finished Training finishing at 2021-08-21 11:15:12.648968
printing_out epoch  32.66821345707657 learning rate: 0.00011215650807132433
0.0001087918128291846
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.744e-01
Validation Loss: 1.853e+04
Validation ROC: 0.7674
No improvement, still saving model
66.33178654292342 epochs left to go

Training Epoch 32.66821345707657/100 starting at 2021-08-21 11:15:39.425081
[1]  [0/1724] loss: 0.332, ave_loss: 0.332
[2]  [20/1724] loss: 0.469, ave_loss: 0.400
[3]  [40/1724] loss: 0.344, ave_loss: 0.382
[4]  [60/1724] loss: 0.420, ave_loss: 0.391
[5]  [80/1724] loss: 0.170, ave_loss: 0.347
[6]  [100/1724] loss: 0.358, ave_loss: 0.349
[7]  [120/1724] loss: 0.399, ave_loss: 0.356
[8]  [140/1724] loss: 0.346, ave_loss: 0.355
[9]  [160/1724] loss: 0.398, ave_loss: 0.360
[10]  [180/1724] loss: 0.379, ave_loss: 0.362
[11]  [200/1724] loss: 0.277, ave_loss: 0.354
[12]  [220/1724] loss: 0.391, ave_loss: 0.357
[13]  [240/1724] loss: 0.340, ave_loss: 0.356
[14]  [260/1724] loss: 0.356, ave_loss: 0.356
[15]  [280/1724] loss: 0.267, ave_loss: 0.350
[16]  [300/1724] loss: 0.330, ave_loss: 0.349
[17]  [320/1724] loss: 0.436, ave_loss: 0.354
[18]  [340/1724] loss: 0.357, ave_loss: 0.354
[19]  [360/1724] loss: 0.352, ave_loss: 0.354
[20]  [380/1724] loss: 0.438, ave_loss: 0.358
[21]  [400/1724] loss: 0.328, ave_loss: 0.357
[22]  [420/1724] loss: 0.435, ave_loss: 0.360
[23]  [440/1724] loss: 0.258, ave_loss: 0.356
[24]  [460/1724] loss: 0.278, ave_loss: 0.353
[25]  [480/1724] loss: 0.332, ave_loss: 0.352
[26]  [500/1724] loss: 0.408, ave_loss: 0.354
[27]  [520/1724] loss: 0.455, ave_loss: 0.358
[28]  [540/1724] loss: 0.340, ave_loss: 0.357
[29]  [560/1724] loss: 0.412, ave_loss: 0.359
[30]  [580/1724] loss: 0.416, ave_loss: 0.361
[31]  [600/1724] loss: 0.409, ave_loss: 0.362
[32]  [620/1724] loss: 0.329, ave_loss: 0.361
[33]  [640/1724] loss: 0.417, ave_loss: 0.363
[34]  [660/1724] loss: 0.367, ave_loss: 0.363
[35]  [680/1724] loss: 0.363, ave_loss: 0.363
[36]  [700/1724] loss: 0.564, ave_loss: 0.369
[37]  [720/1724] loss: 0.367, ave_loss: 0.369
[38]  [740/1724] loss: 0.439, ave_loss: 0.370
[39]  [760/1724] loss: 0.301, ave_loss: 0.369
[40]  [780/1724] loss: 0.253, ave_loss: 0.366
[41]  [800/1724] loss: 0.288, ave_loss: 0.364
[42]  [820/1724] loss: 0.232, ave_loss: 0.361
[43]  [840/1724] loss: 0.331, ave_loss: 0.360
[44]  [860/1724] loss: 0.310, ave_loss: 0.359
[45]  [880/1724] loss: 0.428, ave_loss: 0.360
[46]  [900/1724] loss: 0.438, ave_loss: 0.362
[47]  [920/1724] loss: 0.327, ave_loss: 0.361
[48]  [940/1724] loss: 0.292, ave_loss: 0.360
[49]  [960/1724] loss: 0.395, ave_loss: 0.361
[50]  [980/1724] loss: 0.307, ave_loss: 0.360
[51]  [1000/1724] loss: 0.384, ave_loss: 0.360
[52]  [1020/1724] loss: 0.218, ave_loss: 0.357
[53]  [1040/1724] loss: 0.464, ave_loss: 0.359
[54]  [1060/1724] loss: 0.372, ave_loss: 0.360
[55]  [1080/1724] loss: 0.404, ave_loss: 0.360
[56]  [1100/1724] loss: 0.346, ave_loss: 0.360
[57]  [1120/1724] loss: 0.210, ave_loss: 0.358
[58]  [1140/1724] loss: 0.336, ave_loss: 0.357
[59]  [1160/1724] loss: 0.306, ave_loss: 0.356
[60]  [1180/1724] loss: 0.360, ave_loss: 0.356
[61]  [1200/1724] loss: 0.282, ave_loss: 0.355
[62]  [1220/1724] loss: 0.342, ave_loss: 0.355
[63]  [1240/1724] loss: 0.347, ave_loss: 0.355
[64]  [1260/1724] loss: 0.413, ave_loss: 0.356
[65]  [1280/1724] loss: 0.337, ave_loss: 0.355
[66]  [1300/1724] loss: 0.253, ave_loss: 0.354
[67]  [1320/1724] loss: 0.246, ave_loss: 0.352
[68]  [1340/1724] loss: 0.366, ave_loss: 0.352
[69]  [1360/1724] loss: 0.450, ave_loss: 0.354
[70]  [1380/1724] loss: 0.511, ave_loss: 0.356
[71]  [1400/1724] loss: 0.313, ave_loss: 0.356
[72]  [1420/1724] loss: 0.353, ave_loss: 0.355
[73]  [1440/1724] loss: 0.348, ave_loss: 0.355
[74]  [1460/1724] loss: 0.524, ave_loss: 0.358
[75]  [1480/1724] loss: 0.474, ave_loss: 0.359
[76]  [1500/1724] loss: 0.419, ave_loss: 0.360
[77]  [1520/1724] loss: 0.308, ave_loss: 0.359
[78]  [1540/1724] loss: 0.361, ave_loss: 0.359
[79]  [1560/1724] loss: 0.311, ave_loss: 0.359
[80]  [1580/1724] loss: 0.314, ave_loss: 0.358
[81]  [1600/1724] loss: 0.368, ave_loss: 0.358
[82]  [1620/1724] loss: 0.450, ave_loss: 0.359
[83]  [1640/1724] loss: 0.467, ave_loss: 0.361
[84]  [1660/1724] loss: 0.418, ave_loss: 0.361
[85]  [1680/1724] loss: 0.264, ave_loss: 0.360
[86]  [1700/1724] loss: 0.490, ave_loss: 0.362
[87]  [1720/1724] loss: 0.337, ave_loss: 0.361
[88]  [1740/1724] loss: 0.379, ave_loss: 0.362

Finished Training finishing at 2021-08-21 11:17:40.171274
printing_out epoch  33.68909512761021 learning rate: 0.00010196046188302211
9.890164802653145e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.617e-01
Validation Loss: 1.835e+04
Validation ROC: 0.7776
No improvement, still saving model
65.31090487238978 epochs left to go

Training Epoch 33.68909512761021/100 starting at 2021-08-21 11:18:13.177056
[1]  [0/1724] loss: 0.365, ave_loss: 0.365
[2]  [20/1724] loss: 0.325, ave_loss: 0.345
[3]  [40/1724] loss: 0.287, ave_loss: 0.326
[4]  [60/1724] loss: 0.268, ave_loss: 0.311
[5]  [80/1724] loss: 0.368, ave_loss: 0.323
[6]  [100/1724] loss: 0.452, ave_loss: 0.344
[7]  [120/1724] loss: 0.397, ave_loss: 0.352
[8]  [140/1724] loss: 0.292, ave_loss: 0.344
[9]  [160/1724] loss: 0.250, ave_loss: 0.334
[10]  [180/1724] loss: 0.509, ave_loss: 0.351
[11]  [200/1724] loss: 0.397, ave_loss: 0.355
[12]  [220/1724] loss: 0.345, ave_loss: 0.355
[13]  [240/1724] loss: 0.342, ave_loss: 0.354
[14]  [260/1724] loss: 0.396, ave_loss: 0.357
[15]  [280/1724] loss: 0.418, ave_loss: 0.361
[16]  [300/1724] loss: 0.353, ave_loss: 0.360
[17]  [320/1724] loss: 0.338, ave_loss: 0.359
[18]  [340/1724] loss: 0.152, ave_loss: 0.347
[19]  [360/1724] loss: 0.314, ave_loss: 0.346
[20]  [380/1724] loss: 0.318, ave_loss: 0.344
[21]  [400/1724] loss: 0.433, ave_loss: 0.349
[22]  [420/1724] loss: 0.304, ave_loss: 0.347
[23]  [440/1724] loss: 0.437, ave_loss: 0.350
[24]  [460/1724] loss: 0.478, ave_loss: 0.356
[25]  [480/1724] loss: 0.202, ave_loss: 0.350
[26]  [500/1724] loss: 0.269, ave_loss: 0.347
[27]  [520/1724] loss: 0.507, ave_loss: 0.352
[28]  [540/1724] loss: 0.277, ave_loss: 0.350
[29]  [560/1724] loss: 0.517, ave_loss: 0.356
[30]  [580/1724] loss: 0.303, ave_loss: 0.354
[31]  [600/1724] loss: 0.314, ave_loss: 0.352
[32]  [620/1724] loss: 0.214, ave_loss: 0.348
[33]  [640/1724] loss: 0.328, ave_loss: 0.348
[34]  [660/1724] loss: 0.327, ave_loss: 0.347
[35]  [680/1724] loss: 0.366, ave_loss: 0.347
[36]  [700/1724] loss: 0.339, ave_loss: 0.347
[37]  [720/1724] loss: 0.541, ave_loss: 0.352
[38]  [740/1724] loss: 0.275, ave_loss: 0.350
[39]  [760/1724] loss: 0.519, ave_loss: 0.355
[40]  [780/1724] loss: 0.483, ave_loss: 0.358
[41]  [800/1724] loss: 0.305, ave_loss: 0.357
[42]  [820/1724] loss: 0.272, ave_loss: 0.355
[43]  [840/1724] loss: 0.508, ave_loss: 0.358
[44]  [860/1724] loss: 0.332, ave_loss: 0.358
[45]  [880/1724] loss: 0.180, ave_loss: 0.354
[46]  [900/1724] loss: 0.284, ave_loss: 0.352
[47]  [920/1724] loss: 0.339, ave_loss: 0.352
[48]  [940/1724] loss: 0.448, ave_loss: 0.354
[49]  [960/1724] loss: 0.443, ave_loss: 0.356
[50]  [980/1724] loss: 0.322, ave_loss: 0.355
[51]  [1000/1724] loss: 0.352, ave_loss: 0.355
[52]  [1020/1724] loss: 0.377, ave_loss: 0.355
[53]  [1040/1724] loss: 0.307, ave_loss: 0.354
[54]  [1060/1724] loss: 0.258, ave_loss: 0.353
[55]  [1080/1724] loss: 0.355, ave_loss: 0.353
[56]  [1100/1724] loss: 0.394, ave_loss: 0.353
[57]  [1120/1724] loss: 0.303, ave_loss: 0.353
[58]  [1140/1724] loss: 0.216, ave_loss: 0.350
[59]  [1160/1724] loss: 0.452, ave_loss: 0.352
[60]  [1180/1724] loss: 0.252, ave_loss: 0.350
[61]  [1200/1724] loss: 0.289, ave_loss: 0.349
[62]  [1220/1724] loss: 0.470, ave_loss: 0.351
[63]  [1240/1724] loss: 0.570, ave_loss: 0.355
[64]  [1260/1724] loss: 0.273, ave_loss: 0.353
[65]  [1280/1724] loss: 0.448, ave_loss: 0.355
[66]  [1300/1724] loss: 0.275, ave_loss: 0.354
[67]  [1320/1724] loss: 0.447, ave_loss: 0.355
[68]  [1340/1724] loss: 0.401, ave_loss: 0.356
[69]  [1360/1724] loss: 0.286, ave_loss: 0.355
[70]  [1380/1724] loss: 0.333, ave_loss: 0.354
[71]  [1400/1724] loss: 0.433, ave_loss: 0.356
[72]  [1420/1724] loss: 0.291, ave_loss: 0.355
[73]  [1440/1724] loss: 0.343, ave_loss: 0.354
[74]  [1460/1724] loss: 0.408, ave_loss: 0.355
[75]  [1480/1724] loss: 0.246, ave_loss: 0.354
[76]  [1500/1724] loss: 0.194, ave_loss: 0.352
[77]  [1520/1724] loss: 0.489, ave_loss: 0.353
[78]  [1540/1724] loss: 0.275, ave_loss: 0.352
[79]  [1560/1724] loss: 0.292, ave_loss: 0.352
[80]  [1580/1724] loss: 0.368, ave_loss: 0.352
[81]  [1600/1724] loss: 0.425, ave_loss: 0.353
[82]  [1620/1724] loss: 0.461, ave_loss: 0.354
[83]  [1640/1724] loss: 0.346, ave_loss: 0.354
[84]  [1660/1724] loss: 0.460, ave_loss: 0.355
[85]  [1680/1724] loss: 0.281, ave_loss: 0.354
[86]  [1700/1724] loss: 0.353, ave_loss: 0.354
[87]  [1720/1724] loss: 0.343, ave_loss: 0.354
[88]  [1740/1724] loss: 0.286, ave_loss: 0.353

Finished Training finishing at 2021-08-21 11:20:07.640928
printing_out epoch  34.70997679814385 learning rate: 9.269132898456555e-05
8.991058911502858e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.535e-01
Validation Loss: 1.764e+04
Validation ROC: 0.7700
No improvement, still saving model
64.29002320185614 epochs left to go

Training Epoch 34.70997679814385/100 starting at 2021-08-21 11:20:56.571778
[1]  [0/1724] loss: 0.753, ave_loss: 0.753
[2]  [20/1724] loss: 0.438, ave_loss: 0.596
[3]  [40/1724] loss: 0.487, ave_loss: 0.559
[4]  [60/1724] loss: 0.469, ave_loss: 0.537
[5]  [80/1724] loss: 0.308, ave_loss: 0.491
[6]  [100/1724] loss: 0.342, ave_loss: 0.466
[7]  [120/1724] loss: 0.198, ave_loss: 0.428
[8]  [140/1724] loss: 0.397, ave_loss: 0.424
[9]  [160/1724] loss: 0.400, ave_loss: 0.421
[10]  [180/1724] loss: 0.512, ave_loss: 0.430
[11]  [200/1724] loss: 0.542, ave_loss: 0.441
[12]  [220/1724] loss: 0.486, ave_loss: 0.444
[13]  [240/1724] loss: 0.511, ave_loss: 0.449
[14]  [260/1724] loss: 0.254, ave_loss: 0.435
[15]  [280/1724] loss: 0.240, ave_loss: 0.422
[16]  [300/1724] loss: 0.256, ave_loss: 0.412
[17]  [320/1724] loss: 0.300, ave_loss: 0.405
[18]  [340/1724] loss: 0.291, ave_loss: 0.399
[19]  [360/1724] loss: 0.303, ave_loss: 0.394
[20]  [380/1724] loss: 0.216, ave_loss: 0.385
[21]  [400/1724] loss: 0.498, ave_loss: 0.391
[22]  [420/1724] loss: 0.278, ave_loss: 0.385
[23]  [440/1724] loss: 0.490, ave_loss: 0.390
[24]  [460/1724] loss: 0.302, ave_loss: 0.386
[25]  [480/1724] loss: 0.208, ave_loss: 0.379
[26]  [500/1724] loss: 0.309, ave_loss: 0.376
[27]  [520/1724] loss: 0.415, ave_loss: 0.378
[28]  [540/1724] loss: 0.284, ave_loss: 0.375
[29]  [560/1724] loss: 0.418, ave_loss: 0.376
[30]  [580/1724] loss: 0.264, ave_loss: 0.372
[31]  [600/1724] loss: 0.260, ave_loss: 0.369
[32]  [620/1724] loss: 0.328, ave_loss: 0.367
[33]  [640/1724] loss: 0.353, ave_loss: 0.367
[34]  [660/1724] loss: 0.421, ave_loss: 0.369
[35]  [680/1724] loss: 0.398, ave_loss: 0.369
[36]  [700/1724] loss: 0.379, ave_loss: 0.370
[37]  [720/1724] loss: 0.476, ave_loss: 0.372
[38]  [740/1724] loss: 0.360, ave_loss: 0.372
[39]  [760/1724] loss: 0.366, ave_loss: 0.372
[40]  [780/1724] loss: 0.396, ave_loss: 0.373
[41]  [800/1724] loss: 0.460, ave_loss: 0.375
[42]  [820/1724] loss: 0.425, ave_loss: 0.376
[43]  [840/1724] loss: 0.373, ave_loss: 0.376
[44]  [860/1724] loss: 0.303, ave_loss: 0.374
[45]  [880/1724] loss: 0.292, ave_loss: 0.372
[46]  [900/1724] loss: 0.358, ave_loss: 0.372
[47]  [920/1724] loss: 0.481, ave_loss: 0.374
[48]  [940/1724] loss: 0.432, ave_loss: 0.376
[49]  [960/1724] loss: 0.505, ave_loss: 0.378
[50]  [980/1724] loss: 0.508, ave_loss: 0.381
[51]  [1000/1724] loss: 0.427, ave_loss: 0.382
[52]  [1020/1724] loss: 0.382, ave_loss: 0.382
[53]  [1040/1724] loss: 0.294, ave_loss: 0.380
[54]  [1060/1724] loss: 0.263, ave_loss: 0.378
[55]  [1080/1724] loss: 0.339, ave_loss: 0.377
[56]  [1100/1724] loss: 0.406, ave_loss: 0.378
[57]  [1120/1724] loss: 0.427, ave_loss: 0.379
[58]  [1140/1724] loss: 0.424, ave_loss: 0.379
[59]  [1160/1724] loss: 0.391, ave_loss: 0.380
[60]  [1180/1724] loss: 0.317, ave_loss: 0.378
[61]  [1200/1724] loss: 0.356, ave_loss: 0.378
[62]  [1220/1724] loss: 0.423, ave_loss: 0.379
[63]  [1240/1724] loss: 0.420, ave_loss: 0.379
[64]  [1260/1724] loss: 0.400, ave_loss: 0.380
[65]  [1280/1724] loss: 0.325, ave_loss: 0.379
[66]  [1300/1724] loss: 0.355, ave_loss: 0.379
[67]  [1320/1724] loss: 0.323, ave_loss: 0.378
[68]  [1340/1724] loss: 0.295, ave_loss: 0.377
[69]  [1360/1724] loss: 0.381, ave_loss: 0.377
[70]  [1380/1724] loss: 0.321, ave_loss: 0.376
[71]  [1400/1724] loss: 0.305, ave_loss: 0.375
[72]  [1420/1724] loss: 0.291, ave_loss: 0.374
[73]  [1440/1724] loss: 0.494, ave_loss: 0.375
[74]  [1460/1724] loss: 0.575, ave_loss: 0.378
[75]  [1480/1724] loss: 0.272, ave_loss: 0.377
[76]  [1500/1724] loss: 0.301, ave_loss: 0.376
[77]  [1520/1724] loss: 0.382, ave_loss: 0.376
[78]  [1540/1724] loss: 0.464, ave_loss: 0.377
[79]  [1560/1724] loss: 0.179, ave_loss: 0.374
[80]  [1580/1724] loss: 0.346, ave_loss: 0.374
[81]  [1600/1724] loss: 0.265, ave_loss: 0.373
[82]  [1620/1724] loss: 0.410, ave_loss: 0.373
[83]  [1640/1724] loss: 0.521, ave_loss: 0.375
[84]  [1660/1724] loss: 0.280, ave_loss: 0.374
[85]  [1680/1724] loss: 0.409, ave_loss: 0.374
[86]  [1700/1724] loss: 0.378, ave_loss: 0.374
[87]  [1720/1724] loss: 0.381, ave_loss: 0.374
[88]  [1740/1724] loss: 0.413, ave_loss: 0.375

Finished Training finishing at 2021-08-21 11:23:01.038720
printing_out epoch  35.730858468677496 learning rate: 8.426484453142322e-05
8.173689919548052e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.747e-01
Validation Loss: 1.816e+04
Validation ROC: 0.7712
No improvement, still saving model
63.269141531322504 epochs left to go

Training Epoch 35.730858468677496/100 starting at 2021-08-21 11:23:41.152271
[1]  [0/1724] loss: 0.529, ave_loss: 0.529
[2]  [20/1724] loss: 0.259, ave_loss: 0.394
[3]  [40/1724] loss: 0.449, ave_loss: 0.412
[4]  [60/1724] loss: 0.280, ave_loss: 0.379
[5]  [80/1724] loss: 0.360, ave_loss: 0.375
[6]  [100/1724] loss: 0.465, ave_loss: 0.390
[7]  [120/1724] loss: 0.324, ave_loss: 0.381
[8]  [140/1724] loss: 0.353, ave_loss: 0.377
[9]  [160/1724] loss: 0.483, ave_loss: 0.389
[10]  [180/1724] loss: 0.399, ave_loss: 0.390
[11]  [200/1724] loss: 0.292, ave_loss: 0.381
[12]  [220/1724] loss: 0.232, ave_loss: 0.369
[13]  [240/1724] loss: 0.444, ave_loss: 0.375
[14]  [260/1724] loss: 0.307, ave_loss: 0.370
[15]  [280/1724] loss: 0.323, ave_loss: 0.367
[16]  [300/1724] loss: 0.316, ave_loss: 0.363
[17]  [320/1724] loss: 0.327, ave_loss: 0.361
[18]  [340/1724] loss: 0.566, ave_loss: 0.373
[19]  [360/1724] loss: 0.328, ave_loss: 0.370
[20]  [380/1724] loss: 0.504, ave_loss: 0.377
[21]  [400/1724] loss: 0.368, ave_loss: 0.377
[22]  [420/1724] loss: 0.403, ave_loss: 0.378
[23]  [440/1724] loss: 0.420, ave_loss: 0.380
[24]  [460/1724] loss: 0.379, ave_loss: 0.380
[25]  [480/1724] loss: 0.312, ave_loss: 0.377
[26]  [500/1724] loss: 0.229, ave_loss: 0.371
[27]  [520/1724] loss: 0.294, ave_loss: 0.368
[28]  [540/1724] loss: 0.284, ave_loss: 0.365
[29]  [560/1724] loss: 0.331, ave_loss: 0.364
[30]  [580/1724] loss: 0.503, ave_loss: 0.369
[31]  [600/1724] loss: 0.344, ave_loss: 0.368
[32]  [620/1724] loss: 0.530, ave_loss: 0.373
[33]  [640/1724] loss: 0.203, ave_loss: 0.368
[34]  [660/1724] loss: 0.482, ave_loss: 0.371
[35]  [680/1724] loss: 0.427, ave_loss: 0.373
[36]  [700/1724] loss: 0.226, ave_loss: 0.369
[37]  [720/1724] loss: 0.388, ave_loss: 0.369
[38]  [740/1724] loss: 0.279, ave_loss: 0.367
[39]  [760/1724] loss: 0.406, ave_loss: 0.368
[40]  [780/1724] loss: 0.317, ave_loss: 0.367
[41]  [800/1724] loss: 0.317, ave_loss: 0.365
[42]  [820/1724] loss: 0.549, ave_loss: 0.370
[43]  [840/1724] loss: 0.356, ave_loss: 0.369
[44]  [860/1724] loss: 0.324, ave_loss: 0.368
[45]  [880/1724] loss: 0.316, ave_loss: 0.367
[46]  [900/1724] loss: 0.311, ave_loss: 0.366
[47]  [920/1724] loss: 0.226, ave_loss: 0.363
[48]  [940/1724] loss: 0.265, ave_loss: 0.361
[49]  [960/1724] loss: 0.364, ave_loss: 0.361
[50]  [980/1724] loss: 0.256, ave_loss: 0.359
[51]  [1000/1724] loss: 0.410, ave_loss: 0.360
[52]  [1020/1724] loss: 0.433, ave_loss: 0.361
[53]  [1040/1724] loss: 0.351, ave_loss: 0.361
[54]  [1060/1724] loss: 0.338, ave_loss: 0.361
[55]  [1080/1724] loss: 0.380, ave_loss: 0.361
[56]  [1100/1724] loss: 0.357, ave_loss: 0.361
[57]  [1120/1724] loss: 0.432, ave_loss: 0.362
[58]  [1140/1724] loss: 0.361, ave_loss: 0.362
[59]  [1160/1724] loss: 0.267, ave_loss: 0.361
[60]  [1180/1724] loss: 0.346, ave_loss: 0.360
[61]  [1200/1724] loss: 0.310, ave_loss: 0.360
[62]  [1220/1724] loss: 0.464, ave_loss: 0.361
[63]  [1240/1724] loss: 0.428, ave_loss: 0.362
[64]  [1260/1724] loss: 0.187, ave_loss: 0.360
[65]  [1280/1724] loss: 0.380, ave_loss: 0.360
[66]  [1300/1724] loss: 0.379, ave_loss: 0.360
[67]  [1320/1724] loss: 0.411, ave_loss: 0.361
[68]  [1340/1724] loss: 0.315, ave_loss: 0.360
[69]  [1360/1724] loss: 0.355, ave_loss: 0.360
[70]  [1380/1724] loss: 0.338, ave_loss: 0.360
[71]  [1400/1724] loss: 0.392, ave_loss: 0.360
[72]  [1420/1724] loss: 0.356, ave_loss: 0.360
[73]  [1440/1724] loss: 0.399, ave_loss: 0.361
[74]  [1460/1724] loss: 0.481, ave_loss: 0.362
[75]  [1480/1724] loss: 0.341, ave_loss: 0.362
[76]  [1500/1724] loss: 0.384, ave_loss: 0.362
[77]  [1520/1724] loss: 0.443, ave_loss: 0.364
[78]  [1540/1724] loss: 0.478, ave_loss: 0.365
[79]  [1560/1724] loss: 0.303, ave_loss: 0.364
[80]  [1580/1724] loss: 0.318, ave_loss: 0.364
[81]  [1600/1724] loss: 0.324, ave_loss: 0.363
[82]  [1620/1724] loss: 0.510, ave_loss: 0.365
[83]  [1640/1724] loss: 0.376, ave_loss: 0.365
[84]  [1660/1724] loss: 0.525, ave_loss: 0.367
[85]  [1680/1724] loss: 0.294, ave_loss: 0.366
[86]  [1700/1724] loss: 0.448, ave_loss: 0.367
[87]  [1720/1724] loss: 0.395, ave_loss: 0.367
[88]  [1740/1724] loss: 0.176, ave_loss: 0.365

Finished Training finishing at 2021-08-21 11:25:35.150421
printing_out epoch  36.75174013921114 learning rate: 7.660440411947565e-05
7.430627199589138e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.652e-01
Validation Loss: 1.606e+04
Validation ROC: 0.7723
No improvement, still saving model
62.24825986078886 epochs left to go

Training Epoch 36.75174013921114/100 starting at 2021-08-21 11:26:49.099269
[1]  [0/1724] loss: 0.479, ave_loss: 0.479
[2]  [20/1724] loss: 0.363, ave_loss: 0.421
[3]  [40/1724] loss: 0.308, ave_loss: 0.383
[4]  [60/1724] loss: 0.257, ave_loss: 0.352
[5]  [80/1724] loss: 0.260, ave_loss: 0.333
[6]  [100/1724] loss: 0.444, ave_loss: 0.352
[7]  [120/1724] loss: 0.291, ave_loss: 0.343
[8]  [140/1724] loss: 0.391, ave_loss: 0.349
[9]  [160/1724] loss: 0.480, ave_loss: 0.364
[10]  [180/1724] loss: 0.282, ave_loss: 0.355
[11]  [200/1724] loss: 0.262, ave_loss: 0.347
[12]  [220/1724] loss: 0.262, ave_loss: 0.340
[13]  [240/1724] loss: 0.312, ave_loss: 0.338
[14]  [260/1724] loss: 0.255, ave_loss: 0.332
[15]  [280/1724] loss: 0.234, ave_loss: 0.325
[16]  [300/1724] loss: 0.276, ave_loss: 0.322
[17]  [320/1724] loss: 0.446, ave_loss: 0.330
[18]  [340/1724] loss: 0.377, ave_loss: 0.332
[19]  [360/1724] loss: 0.277, ave_loss: 0.329
[20]  [380/1724] loss: 0.539, ave_loss: 0.340
[21]  [400/1724] loss: 0.422, ave_loss: 0.344
[22]  [420/1724] loss: 0.370, ave_loss: 0.345
[23]  [440/1724] loss: 0.535, ave_loss: 0.353
[24]  [460/1724] loss: 0.287, ave_loss: 0.350
[25]  [480/1724] loss: 0.488, ave_loss: 0.356
[26]  [500/1724] loss: 0.402, ave_loss: 0.358
[27]  [520/1724] loss: 0.347, ave_loss: 0.357
[28]  [540/1724] loss: 0.487, ave_loss: 0.362
[29]  [560/1724] loss: 0.312, ave_loss: 0.360
[30]  [580/1724] loss: 0.298, ave_loss: 0.358
[31]  [600/1724] loss: 0.281, ave_loss: 0.356
[32]  [620/1724] loss: 0.285, ave_loss: 0.353
[33]  [640/1724] loss: 0.263, ave_loss: 0.351
[34]  [660/1724] loss: 0.425, ave_loss: 0.353
[35]  [680/1724] loss: 0.366, ave_loss: 0.353
[36]  [700/1724] loss: 0.321, ave_loss: 0.352
[37]  [720/1724] loss: 0.324, ave_loss: 0.352
[38]  [740/1724] loss: 0.429, ave_loss: 0.354
[39]  [760/1724] loss: 0.308, ave_loss: 0.352
[40]  [780/1724] loss: 0.367, ave_loss: 0.353
[41]  [800/1724] loss: 0.302, ave_loss: 0.352
[42]  [820/1724] loss: 0.247, ave_loss: 0.349
[43]  [840/1724] loss: 0.381, ave_loss: 0.350
[44]  [860/1724] loss: 0.315, ave_loss: 0.349
[45]  [880/1724] loss: 0.245, ave_loss: 0.347
[46]  [900/1724] loss: 0.326, ave_loss: 0.346
[47]  [920/1724] loss: 0.362, ave_loss: 0.347
[48]  [940/1724] loss: 0.321, ave_loss: 0.346
[49]  [960/1724] loss: 0.376, ave_loss: 0.347
[50]  [980/1724] loss: 0.320, ave_loss: 0.346
[51]  [1000/1724] loss: 0.288, ave_loss: 0.345
[52]  [1020/1724] loss: 0.326, ave_loss: 0.345
[53]  [1040/1724] loss: 0.277, ave_loss: 0.343
[54]  [1060/1724] loss: 0.260, ave_loss: 0.342
[55]  [1080/1724] loss: 0.376, ave_loss: 0.342
[56]  [1100/1724] loss: 0.312, ave_loss: 0.342
[57]  [1120/1724] loss: 0.352, ave_loss: 0.342
[58]  [1140/1724] loss: 0.284, ave_loss: 0.341
[59]  [1160/1724] loss: 0.373, ave_loss: 0.342
[60]  [1180/1724] loss: 0.451, ave_loss: 0.343
[61]  [1200/1724] loss: 0.350, ave_loss: 0.343
[62]  [1220/1724] loss: 0.345, ave_loss: 0.344
[63]  [1240/1724] loss: 0.394, ave_loss: 0.344
[64]  [1260/1724] loss: 0.297, ave_loss: 0.344
[65]  [1280/1724] loss: 0.326, ave_loss: 0.343
[66]  [1300/1724] loss: 0.349, ave_loss: 0.343
[67]  [1320/1724] loss: 0.310, ave_loss: 0.343
[68]  [1340/1724] loss: 0.514, ave_loss: 0.345
[69]  [1360/1724] loss: 0.329, ave_loss: 0.345
[70]  [1380/1724] loss: 0.543, ave_loss: 0.348
[71]  [1400/1724] loss: 0.333, ave_loss: 0.348
[72]  [1420/1724] loss: 0.355, ave_loss: 0.348
[73]  [1440/1724] loss: 0.361, ave_loss: 0.348
[74]  [1460/1724] loss: 0.376, ave_loss: 0.348
[75]  [1480/1724] loss: 0.251, ave_loss: 0.347
[76]  [1500/1724] loss: 0.276, ave_loss: 0.346
[77]  [1520/1724] loss: 0.210, ave_loss: 0.344
[78]  [1540/1724] loss: 0.378, ave_loss: 0.345
[79]  [1560/1724] loss: 0.405, ave_loss: 0.346
[80]  [1580/1724] loss: 0.325, ave_loss: 0.345
[81]  [1600/1724] loss: 0.375, ave_loss: 0.346
[82]  [1620/1724] loss: 0.557, ave_loss: 0.348
[83]  [1640/1724] loss: 0.444, ave_loss: 0.349
[84]  [1660/1724] loss: 0.553, ave_loss: 0.352
[85]  [1680/1724] loss: 0.390, ave_loss: 0.352
[86]  [1700/1724] loss: 0.324, ave_loss: 0.352
[87]  [1720/1724] loss: 0.377, ave_loss: 0.352
[88]  [1740/1724] loss: 0.314, ave_loss: 0.352

Finished Training finishing at 2021-08-21 11:28:49.316708
printing_out epoch  37.77262180974478 learning rate: 6.96403673813415e-05
6.755115635990125e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.518e-01
Validation Loss: 1.520e+04
Validation ROC: 0.7772
No improvement, still saving model
61.22737819025522 epochs left to go

Training Epoch 37.77262180974478/100 starting at 2021-08-21 11:29:16.224093
[1]  [0/1724] loss: 0.463, ave_loss: 0.463
[2]  [20/1724] loss: 0.471, ave_loss: 0.467
[3]  [40/1724] loss: 0.356, ave_loss: 0.430
[4]  [60/1724] loss: 0.338, ave_loss: 0.407
[5]  [80/1724] loss: 0.272, ave_loss: 0.380
[6]  [100/1724] loss: 0.198, ave_loss: 0.350
[7]  [120/1724] loss: 0.283, ave_loss: 0.340
[8]  [140/1724] loss: 0.481, ave_loss: 0.358
[9]  [160/1724] loss: 0.512, ave_loss: 0.375
[10]  [180/1724] loss: 0.498, ave_loss: 0.387
[11]  [200/1724] loss: 0.235, ave_loss: 0.373
[12]  [220/1724] loss: 0.440, ave_loss: 0.379
[13]  [240/1724] loss: 0.295, ave_loss: 0.372
[14]  [260/1724] loss: 0.343, ave_loss: 0.370
[15]  [280/1724] loss: 0.354, ave_loss: 0.369
[16]  [300/1724] loss: 0.442, ave_loss: 0.374
[17]  [320/1724] loss: 0.374, ave_loss: 0.374
[18]  [340/1724] loss: 0.329, ave_loss: 0.371
[19]  [360/1724] loss: 0.472, ave_loss: 0.377
[20]  [380/1724] loss: 0.247, ave_loss: 0.370
[21]  [400/1724] loss: 0.261, ave_loss: 0.365
[22]  [420/1724] loss: 0.350, ave_loss: 0.364
[23]  [440/1724] loss: 0.504, ave_loss: 0.370
[24]  [460/1724] loss: 0.281, ave_loss: 0.367
[25]  [480/1724] loss: 0.484, ave_loss: 0.371
[26]  [500/1724] loss: 0.372, ave_loss: 0.371
[27]  [520/1724] loss: 0.342, ave_loss: 0.370
[28]  [540/1724] loss: 0.368, ave_loss: 0.370
[29]  [560/1724] loss: 0.382, ave_loss: 0.371
[30]  [580/1724] loss: 0.424, ave_loss: 0.372
[31]  [600/1724] loss: 0.344, ave_loss: 0.371
[32]  [620/1724] loss: 0.383, ave_loss: 0.372
[33]  [640/1724] loss: 0.198, ave_loss: 0.367
[34]  [660/1724] loss: 0.305, ave_loss: 0.365
[35]  [680/1724] loss: 0.437, ave_loss: 0.367
[36]  [700/1724] loss: 0.310, ave_loss: 0.365
[37]  [720/1724] loss: 0.333, ave_loss: 0.364
[38]  [740/1724] loss: 0.194, ave_loss: 0.360
[39]  [760/1724] loss: 0.430, ave_loss: 0.362
[40]  [780/1724] loss: 0.353, ave_loss: 0.361
[41]  [800/1724] loss: 0.418, ave_loss: 0.363
[42]  [820/1724] loss: 0.364, ave_loss: 0.363
[43]  [840/1724] loss: 0.225, ave_loss: 0.360
[44]  [860/1724] loss: 0.416, ave_loss: 0.361
[45]  [880/1724] loss: 0.486, ave_loss: 0.364
[46]  [900/1724] loss: 0.505, ave_loss: 0.367
[47]  [920/1724] loss: 0.385, ave_loss: 0.367
[48]  [940/1724] loss: 0.382, ave_loss: 0.367
[49]  [960/1724] loss: 0.291, ave_loss: 0.366
[50]  [980/1724] loss: 0.305, ave_loss: 0.365
[51]  [1000/1724] loss: 0.314, ave_loss: 0.364
[52]  [1020/1724] loss: 0.450, ave_loss: 0.365
[53]  [1040/1724] loss: 0.243, ave_loss: 0.363
[54]  [1060/1724] loss: 0.394, ave_loss: 0.364
[55]  [1080/1724] loss: 0.449, ave_loss: 0.365
[56]  [1100/1724] loss: 0.435, ave_loss: 0.366
[57]  [1120/1724] loss: 0.302, ave_loss: 0.365
[58]  [1140/1724] loss: 0.253, ave_loss: 0.363
[59]  [1160/1724] loss: 0.413, ave_loss: 0.364
[60]  [1180/1724] loss: 0.250, ave_loss: 0.362
[61]  [1200/1724] loss: 0.416, ave_loss: 0.363
[62]  [1220/1724] loss: 0.460, ave_loss: 0.365
[63]  [1240/1724] loss: 0.352, ave_loss: 0.365
[64]  [1260/1724] loss: 0.382, ave_loss: 0.365
[65]  [1280/1724] loss: 0.318, ave_loss: 0.364
[66]  [1300/1724] loss: 0.402, ave_loss: 0.365
[67]  [1320/1724] loss: 0.504, ave_loss: 0.367
[68]  [1340/1724] loss: 0.438, ave_loss: 0.368
[69]  [1360/1724] loss: 0.449, ave_loss: 0.369
[70]  [1380/1724] loss: 0.388, ave_loss: 0.369
[71]  [1400/1724] loss: 0.324, ave_loss: 0.369
[72]  [1420/1724] loss: 0.324, ave_loss: 0.368
[73]  [1440/1724] loss: 0.451, ave_loss: 0.369
[74]  [1460/1724] loss: 0.314, ave_loss: 0.368
[75]  [1480/1724] loss: 0.458, ave_loss: 0.370
[76]  [1500/1724] loss: 0.346, ave_loss: 0.369
[77]  [1520/1724] loss: 0.344, ave_loss: 0.369
[78]  [1540/1724] loss: 0.291, ave_loss: 0.368
[79]  [1560/1724] loss: 0.295, ave_loss: 0.367
[80]  [1580/1724] loss: 0.311, ave_loss: 0.366
[81]  [1600/1724] loss: 0.442, ave_loss: 0.367
[82]  [1620/1724] loss: 0.572, ave_loss: 0.370
[83]  [1640/1724] loss: 0.269, ave_loss: 0.369
[84]  [1660/1724] loss: 0.420, ave_loss: 0.369
[85]  [1680/1724] loss: 0.386, ave_loss: 0.369
[86]  [1700/1724] loss: 0.470, ave_loss: 0.370
[87]  [1720/1724] loss: 0.260, ave_loss: 0.369
[88]  [1740/1724] loss: 0.432, ave_loss: 0.370

Finished Training finishing at 2021-08-21 11:31:18.821199
printing_out epoch  38.793503480278424 learning rate: 6.330942489212863e-05
6.141014214536477e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.699e-01
Validation Loss: 1.489e+04
Validation ROC: 0.7726
No improvement, still saving model
60.206496519721576 epochs left to go

Training Epoch 38.793503480278424/100 starting at 2021-08-21 11:31:47.868720
[1]  [0/1724] loss: 0.583, ave_loss: 0.583
[2]  [20/1724] loss: 0.213, ave_loss: 0.398
[3]  [40/1724] loss: 0.296, ave_loss: 0.364
[4]  [60/1724] loss: 0.327, ave_loss: 0.355
[5]  [80/1724] loss: 0.332, ave_loss: 0.350
[6]  [100/1724] loss: 0.311, ave_loss: 0.344
[7]  [120/1724] loss: 0.262, ave_loss: 0.332
[8]  [140/1724] loss: 0.320, ave_loss: 0.331
[9]  [160/1724] loss: 0.282, ave_loss: 0.325
[10]  [180/1724] loss: 0.477, ave_loss: 0.340
[11]  [200/1724] loss: 0.491, ave_loss: 0.354
[12]  [220/1724] loss: 0.295, ave_loss: 0.349
[13]  [240/1724] loss: 0.238, ave_loss: 0.341
[14]  [260/1724] loss: 0.478, ave_loss: 0.350
[15]  [280/1724] loss: 0.365, ave_loss: 0.351
[16]  [300/1724] loss: 0.341, ave_loss: 0.351
[17]  [320/1724] loss: 0.441, ave_loss: 0.356
[18]  [340/1724] loss: 0.328, ave_loss: 0.354
[19]  [360/1724] loss: 0.297, ave_loss: 0.351
[20]  [380/1724] loss: 0.359, ave_loss: 0.352
[21]  [400/1724] loss: 0.375, ave_loss: 0.353
[22]  [420/1724] loss: 0.210, ave_loss: 0.346
[23]  [440/1724] loss: 0.308, ave_loss: 0.345
[24]  [460/1724] loss: 0.308, ave_loss: 0.343
[25]  [480/1724] loss: 0.321, ave_loss: 0.342
[26]  [500/1724] loss: 0.258, ave_loss: 0.339
[27]  [520/1724] loss: 0.302, ave_loss: 0.338
[28]  [540/1724] loss: 0.354, ave_loss: 0.338
[29]  [560/1724] loss: 0.338, ave_loss: 0.338
[30]  [580/1724] loss: 0.471, ave_loss: 0.343
[31]  [600/1724] loss: 0.418, ave_loss: 0.345
[32]  [620/1724] loss: 0.384, ave_loss: 0.346
[33]  [640/1724] loss: 0.425, ave_loss: 0.349
[34]  [660/1724] loss: 0.310, ave_loss: 0.348
[35]  [680/1724] loss: 0.378, ave_loss: 0.348
[36]  [700/1724] loss: 0.382, ave_loss: 0.349
[37]  [720/1724] loss: 0.348, ave_loss: 0.349
[38]  [740/1724] loss: 0.456, ave_loss: 0.352
[39]  [760/1724] loss: 0.476, ave_loss: 0.355
[40]  [780/1724] loss: 0.475, ave_loss: 0.358
[41]  [800/1724] loss: 0.570, ave_loss: 0.363
[42]  [820/1724] loss: 0.433, ave_loss: 0.365
[43]  [840/1724] loss: 0.404, ave_loss: 0.366
[44]  [860/1724] loss: 0.392, ave_loss: 0.367
[45]  [880/1724] loss: 0.361, ave_loss: 0.367
[46]  [900/1724] loss: 0.337, ave_loss: 0.366
[47]  [920/1724] loss: 0.253, ave_loss: 0.363
[48]  [940/1724] loss: 0.290, ave_loss: 0.362
[49]  [960/1724] loss: 0.280, ave_loss: 0.360
[50]  [980/1724] loss: 0.442, ave_loss: 0.362
[51]  [1000/1724] loss: 0.337, ave_loss: 0.361
[52]  [1020/1724] loss: 0.499, ave_loss: 0.364
[53]  [1040/1724] loss: 0.237, ave_loss: 0.362
[54]  [1060/1724] loss: 0.283, ave_loss: 0.360
[55]  [1080/1724] loss: 0.446, ave_loss: 0.362
[56]  [1100/1724] loss: 0.296, ave_loss: 0.361
[57]  [1120/1724] loss: 0.449, ave_loss: 0.362
[58]  [1140/1724] loss: 0.315, ave_loss: 0.361
[59]  [1160/1724] loss: 0.333, ave_loss: 0.361
[60]  [1180/1724] loss: 0.207, ave_loss: 0.358
[61]  [1200/1724] loss: 0.336, ave_loss: 0.358
[62]  [1220/1724] loss: 0.341, ave_loss: 0.358
[63]  [1240/1724] loss: 0.285, ave_loss: 0.356
[64]  [1260/1724] loss: 0.295, ave_loss: 0.356
[65]  [1280/1724] loss: 0.351, ave_loss: 0.355
[66]  [1300/1724] loss: 0.395, ave_loss: 0.356
[67]  [1320/1724] loss: 0.334, ave_loss: 0.356
[68]  [1340/1724] loss: 0.392, ave_loss: 0.356
[69]  [1360/1724] loss: 0.336, ave_loss: 0.356
[70]  [1380/1724] loss: 0.396, ave_loss: 0.357
[71]  [1400/1724] loss: 0.342, ave_loss: 0.356
[72]  [1420/1724] loss: 0.394, ave_loss: 0.357
[73]  [1440/1724] loss: 0.265, ave_loss: 0.356
[74]  [1460/1724] loss: 0.290, ave_loss: 0.355
[75]  [1480/1724] loss: 0.360, ave_loss: 0.355
[76]  [1500/1724] loss: 0.389, ave_loss: 0.355
[77]  [1520/1724] loss: 0.251, ave_loss: 0.354
[78]  [1540/1724] loss: 0.388, ave_loss: 0.354
[79]  [1560/1724] loss: 0.378, ave_loss: 0.355
[80]  [1580/1724] loss: 0.364, ave_loss: 0.355
[81]  [1600/1724] loss: 0.351, ave_loss: 0.355
[82]  [1620/1724] loss: 0.271, ave_loss: 0.354
[83]  [1640/1724] loss: 0.449, ave_loss: 0.355
[84]  [1660/1724] loss: 0.242, ave_loss: 0.353
[85]  [1680/1724] loss: 0.382, ave_loss: 0.354
[86]  [1700/1724] loss: 0.265, ave_loss: 0.353
[87]  [1720/1724] loss: 0.229, ave_loss: 0.351
[88]  [1740/1724] loss: 0.358, ave_loss: 0.351

Finished Training finishing at 2021-08-21 11:33:46.489226
printing_out epoch  39.814385150812065 learning rate: 5.755402262920784e-05
5.58274019503316e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.514e-01
Validation Loss: 1.599e+04
Validation ROC: 0.7717
No improvement, still saving model
59.185614849187935 epochs left to go

Training Epoch 39.814385150812065/100 starting at 2021-08-21 11:34:36.191169
[1]  [0/1724] loss: 0.572, ave_loss: 0.572
[2]  [20/1724] loss: 0.319, ave_loss: 0.446
[3]  [40/1724] loss: 0.505, ave_loss: 0.465
[4]  [60/1724] loss: 0.530, ave_loss: 0.482
[5]  [80/1724] loss: 0.416, ave_loss: 0.468
[6]  [100/1724] loss: 0.356, ave_loss: 0.450
[7]  [120/1724] loss: 0.230, ave_loss: 0.418
[8]  [140/1724] loss: 0.257, ave_loss: 0.398
[9]  [160/1724] loss: 0.340, ave_loss: 0.392
[10]  [180/1724] loss: 0.270, ave_loss: 0.380
[11]  [200/1724] loss: 0.430, ave_loss: 0.384
[12]  [220/1724] loss: 0.351, ave_loss: 0.381
[13]  [240/1724] loss: 0.356, ave_loss: 0.379
[14]  [260/1724] loss: 0.443, ave_loss: 0.384
[15]  [280/1724] loss: 0.361, ave_loss: 0.382
[16]  [300/1724] loss: 0.446, ave_loss: 0.386
[17]  [320/1724] loss: 0.248, ave_loss: 0.378
[18]  [340/1724] loss: 0.383, ave_loss: 0.379
[19]  [360/1724] loss: 0.275, ave_loss: 0.373
[20]  [380/1724] loss: 0.293, ave_loss: 0.369
[21]  [400/1724] loss: 0.480, ave_loss: 0.374
[22]  [420/1724] loss: 0.312, ave_loss: 0.372
[23]  [440/1724] loss: 0.324, ave_loss: 0.369
[24]  [460/1724] loss: 0.399, ave_loss: 0.371
[25]  [480/1724] loss: 0.365, ave_loss: 0.370
[26]  [500/1724] loss: 0.455, ave_loss: 0.374
[27]  [520/1724] loss: 0.262, ave_loss: 0.370
[28]  [540/1724] loss: 0.254, ave_loss: 0.365
[29]  [560/1724] loss: 0.411, ave_loss: 0.367
[30]  [580/1724] loss: 0.231, ave_loss: 0.362
[31]  [600/1724] loss: 0.320, ave_loss: 0.361
[32]  [620/1724] loss: 0.325, ave_loss: 0.360
[33]  [640/1724] loss: 0.299, ave_loss: 0.358
[34]  [660/1724] loss: 0.341, ave_loss: 0.358
[35]  [680/1724] loss: 0.519, ave_loss: 0.362
[36]  [700/1724] loss: 0.260, ave_loss: 0.359
[37]  [720/1724] loss: 0.276, ave_loss: 0.357
[38]  [740/1724] loss: 0.278, ave_loss: 0.355
[39]  [760/1724] loss: 0.316, ave_loss: 0.354
[40]  [780/1724] loss: 0.189, ave_loss: 0.350
[41]  [800/1724] loss: 0.515, ave_loss: 0.354
[42]  [820/1724] loss: 0.270, ave_loss: 0.352
[43]  [840/1724] loss: 0.485, ave_loss: 0.355
[44]  [860/1724] loss: 0.434, ave_loss: 0.357
[45]  [880/1724] loss: 0.292, ave_loss: 0.355
[46]  [900/1724] loss: 0.355, ave_loss: 0.355
[47]  [920/1724] loss: 0.399, ave_loss: 0.356
[48]  [940/1724] loss: 0.195, ave_loss: 0.353
[49]  [960/1724] loss: 0.349, ave_loss: 0.353
[50]  [980/1724] loss: 0.475, ave_loss: 0.355
[51]  [1000/1724] loss: 0.351, ave_loss: 0.355
[52]  [1020/1724] loss: 0.323, ave_loss: 0.355
[53]  [1040/1724] loss: 0.536, ave_loss: 0.358
[54]  [1060/1724] loss: 0.337, ave_loss: 0.358
[55]  [1080/1724] loss: 0.545, ave_loss: 0.361
[56]  [1100/1724] loss: 0.357, ave_loss: 0.361
[57]  [1120/1724] loss: 0.509, ave_loss: 0.364
[58]  [1140/1724] loss: 0.341, ave_loss: 0.363
[59]  [1160/1724] loss: 0.344, ave_loss: 0.363
[60]  [1180/1724] loss: 0.300, ave_loss: 0.362
[61]  [1200/1724] loss: 0.412, ave_loss: 0.363
[62]  [1220/1724] loss: 0.236, ave_loss: 0.361
[63]  [1240/1724] loss: 0.304, ave_loss: 0.360
[64]  [1260/1724] loss: 0.501, ave_loss: 0.362
[65]  [1280/1724] loss: 0.374, ave_loss: 0.362
[66]  [1300/1724] loss: 0.387, ave_loss: 0.362
[67]  [1320/1724] loss: 0.218, ave_loss: 0.360
[68]  [1340/1724] loss: 0.311, ave_loss: 0.360
[69]  [1360/1724] loss: 0.239, ave_loss: 0.358
[70]  [1380/1724] loss: 0.269, ave_loss: 0.357
[71]  [1400/1724] loss: 0.476, ave_loss: 0.358
[72]  [1420/1724] loss: 0.346, ave_loss: 0.358
[73]  [1440/1724] loss: 0.343, ave_loss: 0.358
[74]  [1460/1724] loss: 0.423, ave_loss: 0.359
[75]  [1480/1724] loss: 0.395, ave_loss: 0.359
[76]  [1500/1724] loss: 0.348, ave_loss: 0.359
[77]  [1520/1724] loss: 0.332, ave_loss: 0.359
[78]  [1540/1724] loss: 0.358, ave_loss: 0.359
[79]  [1560/1724] loss: 0.218, ave_loss: 0.357
[80]  [1580/1724] loss: 0.343, ave_loss: 0.357
[81]  [1600/1724] loss: 0.323, ave_loss: 0.356
[82]  [1620/1724] loss: 0.351, ave_loss: 0.356
[83]  [1640/1724] loss: 0.418, ave_loss: 0.357
[84]  [1660/1724] loss: 0.266, ave_loss: 0.356
[85]  [1680/1724] loss: 0.360, ave_loss: 0.356
[86]  [1700/1724] loss: 0.224, ave_loss: 0.354
[87]  [1720/1724] loss: 0.438, ave_loss: 0.355
[88]  [1740/1724] loss: 0.312, ave_loss: 0.355

Finished Training finishing at 2021-08-21 11:36:37.811736
printing_out epoch  40.835266821345705 learning rate: 5.23218387538253e-05
5.0752183591210544e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.549e-01
Validation Loss: 1.692e+04
Validation ROC: 0.7675
No improvement, still saving model
58.164733178654295 epochs left to go

Training Epoch 40.835266821345705/100 starting at 2021-08-21 11:37:21.449590
[1]  [0/1724] loss: 0.492, ave_loss: 0.492
[2]  [20/1724] loss: 0.513, ave_loss: 0.503
[3]  [40/1724] loss: 0.269, ave_loss: 0.425
[4]  [60/1724] loss: 0.458, ave_loss: 0.433
[5]  [80/1724] loss: 0.270, ave_loss: 0.401
[6]  [100/1724] loss: 0.358, ave_loss: 0.393
[7]  [120/1724] loss: 0.265, ave_loss: 0.375
[8]  [140/1724] loss: 0.233, ave_loss: 0.357
[9]  [160/1724] loss: 0.283, ave_loss: 0.349
[10]  [180/1724] loss: 0.337, ave_loss: 0.348
[11]  [200/1724] loss: 0.515, ave_loss: 0.363
[12]  [220/1724] loss: 0.326, ave_loss: 0.360
[13]  [240/1724] loss: 0.249, ave_loss: 0.351
[14]  [260/1724] loss: 0.407, ave_loss: 0.355
[15]  [280/1724] loss: 0.309, ave_loss: 0.352
[16]  [300/1724] loss: 0.243, ave_loss: 0.346
[17]  [320/1724] loss: 0.376, ave_loss: 0.347
[18]  [340/1724] loss: 0.258, ave_loss: 0.342
[19]  [360/1724] loss: 0.407, ave_loss: 0.346
[20]  [380/1724] loss: 0.387, ave_loss: 0.348
[21]  [400/1724] loss: 0.237, ave_loss: 0.343
[22]  [420/1724] loss: 0.651, ave_loss: 0.357
[23]  [440/1724] loss: 0.374, ave_loss: 0.357
[24]  [460/1724] loss: 0.331, ave_loss: 0.356
[25]  [480/1724] loss: 0.309, ave_loss: 0.354
[26]  [500/1724] loss: 0.395, ave_loss: 0.356
[27]  [520/1724] loss: 0.359, ave_loss: 0.356
[28]  [540/1724] loss: 0.307, ave_loss: 0.354
[29]  [560/1724] loss: 0.403, ave_loss: 0.356
[30]  [580/1724] loss: 0.383, ave_loss: 0.357
[31]  [600/1724] loss: 0.304, ave_loss: 0.355
[32]  [620/1724] loss: 0.178, ave_loss: 0.350
[33]  [640/1724] loss: 0.266, ave_loss: 0.347
[34]  [660/1724] loss: 0.329, ave_loss: 0.347
[35]  [680/1724] loss: 0.273, ave_loss: 0.344
[36]  [700/1724] loss: 0.340, ave_loss: 0.344
[37]  [720/1724] loss: 0.330, ave_loss: 0.344
[38]  [740/1724] loss: 0.346, ave_loss: 0.344
[39]  [760/1724] loss: 0.325, ave_loss: 0.344
[40]  [780/1724] loss: 0.238, ave_loss: 0.341
[41]  [800/1724] loss: 0.395, ave_loss: 0.342
[42]  [820/1724] loss: 0.451, ave_loss: 0.345
[43]  [840/1724] loss: 0.399, ave_loss: 0.346
[44]  [860/1724] loss: 0.361, ave_loss: 0.346
[45]  [880/1724] loss: 0.397, ave_loss: 0.347
[46]  [900/1724] loss: 0.318, ave_loss: 0.347
[47]  [920/1724] loss: 0.449, ave_loss: 0.349
[48]  [940/1724] loss: 0.471, ave_loss: 0.352
[49]  [960/1724] loss: 0.336, ave_loss: 0.351
[50]  [980/1724] loss: 0.256, ave_loss: 0.349
[51]  [1000/1724] loss: 0.333, ave_loss: 0.349
[52]  [1020/1724] loss: 0.387, ave_loss: 0.350
[53]  [1040/1724] loss: 0.320, ave_loss: 0.349
[54]  [1060/1724] loss: 0.307, ave_loss: 0.348
[55]  [1080/1724] loss: 0.282, ave_loss: 0.347
[56]  [1100/1724] loss: 0.391, ave_loss: 0.348
[57]  [1120/1724] loss: 0.376, ave_loss: 0.348
[58]  [1140/1724] loss: 0.196, ave_loss: 0.346
[59]  [1160/1724] loss: 0.403, ave_loss: 0.347
[60]  [1180/1724] loss: 0.457, ave_loss: 0.349
[61]  [1200/1724] loss: 0.422, ave_loss: 0.350
[62]  [1220/1724] loss: 0.334, ave_loss: 0.350
[63]  [1240/1724] loss: 0.361, ave_loss: 0.350
[64]  [1260/1724] loss: 0.244, ave_loss: 0.348
[65]  [1280/1724] loss: 0.341, ave_loss: 0.348
[66]  [1300/1724] loss: 0.255, ave_loss: 0.347
[67]  [1320/1724] loss: 0.443, ave_loss: 0.348
[68]  [1340/1724] loss: 0.457, ave_loss: 0.350
[69]  [1360/1724] loss: 0.473, ave_loss: 0.351
[70]  [1380/1724] loss: 0.357, ave_loss: 0.352
[71]  [1400/1724] loss: 0.503, ave_loss: 0.354
[72]  [1420/1724] loss: 0.376, ave_loss: 0.354
[73]  [1440/1724] loss: 0.301, ave_loss: 0.353
[74]  [1460/1724] loss: 0.385, ave_loss: 0.354
[75]  [1480/1724] loss: 0.228, ave_loss: 0.352
[76]  [1500/1724] loss: 0.218, ave_loss: 0.350
[77]  [1520/1724] loss: 0.309, ave_loss: 0.350
[78]  [1540/1724] loss: 0.378, ave_loss: 0.350
[79]  [1560/1724] loss: 0.274, ave_loss: 0.349
[80]  [1580/1724] loss: 0.363, ave_loss: 0.349
[81]  [1600/1724] loss: 0.330, ave_loss: 0.349
[82]  [1620/1724] loss: 0.240, ave_loss: 0.348
[83]  [1640/1724] loss: 0.221, ave_loss: 0.346
[84]  [1660/1724] loss: 0.494, ave_loss: 0.348
[85]  [1680/1724] loss: 0.486, ave_loss: 0.350
[86]  [1700/1724] loss: 0.342, ave_loss: 0.349
[87]  [1720/1724] loss: 0.648, ave_loss: 0.353
[88]  [1740/1724] loss: 0.354, ave_loss: 0.353

Finished Training finishing at 2021-08-21 11:39:15.847123
printing_out epoch  41.85614849187935 learning rate: 4.7565307958023e-05
4.61383487192823e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.529e-01
Validation Loss: 1.464e+04
Validation ROC: 0.7788
Saving model
57.14385150812065 epochs left to go

Training Epoch 41.85614849187935/100 starting at 2021-08-21 11:40:46.530601
[1]  [0/1724] loss: 0.493, ave_loss: 0.493
[2]  [20/1724] loss: 0.328, ave_loss: 0.410
[3]  [40/1724] loss: 0.321, ave_loss: 0.381
[4]  [60/1724] loss: 0.439, ave_loss: 0.395
[5]  [80/1724] loss: 0.564, ave_loss: 0.429
[6]  [100/1724] loss: 0.355, ave_loss: 0.417
[7]  [120/1724] loss: 0.312, ave_loss: 0.402
[8]  [140/1724] loss: 0.267, ave_loss: 0.385
[9]  [160/1724] loss: 0.327, ave_loss: 0.378
[10]  [180/1724] loss: 0.471, ave_loss: 0.388
[11]  [200/1724] loss: 0.309, ave_loss: 0.381
[12]  [220/1724] loss: 0.344, ave_loss: 0.378
[13]  [240/1724] loss: 0.478, ave_loss: 0.385
[14]  [260/1724] loss: 0.388, ave_loss: 0.385
[15]  [280/1724] loss: 0.340, ave_loss: 0.382
[16]  [300/1724] loss: 0.193, ave_loss: 0.370
[17]  [320/1724] loss: 0.347, ave_loss: 0.369
[18]  [340/1724] loss: 0.311, ave_loss: 0.366
[19]  [360/1724] loss: 0.364, ave_loss: 0.366
[20]  [380/1724] loss: 0.250, ave_loss: 0.360
[21]  [400/1724] loss: 0.242, ave_loss: 0.354
[22]  [420/1724] loss: 0.495, ave_loss: 0.361
[23]  [440/1724] loss: 0.377, ave_loss: 0.361
[24]  [460/1724] loss: 0.315, ave_loss: 0.359
[25]  [480/1724] loss: 0.456, ave_loss: 0.363
[26]  [500/1724] loss: 0.430, ave_loss: 0.366
[27]  [520/1724] loss: 0.336, ave_loss: 0.365
[28]  [540/1724] loss: 0.514, ave_loss: 0.370
[29]  [560/1724] loss: 0.246, ave_loss: 0.366
[30]  [580/1724] loss: 0.364, ave_loss: 0.366
[31]  [600/1724] loss: 0.211, ave_loss: 0.361
[32]  [620/1724] loss: 0.402, ave_loss: 0.362
[33]  [640/1724] loss: 0.447, ave_loss: 0.365
[34]  [660/1724] loss: 0.372, ave_loss: 0.365
[35]  [680/1724] loss: 0.382, ave_loss: 0.365
[36]  [700/1724] loss: 0.338, ave_loss: 0.365
[37]  [720/1724] loss: 0.305, ave_loss: 0.363
[38]  [740/1724] loss: 0.399, ave_loss: 0.364
[39]  [760/1724] loss: 0.338, ave_loss: 0.363
[40]  [780/1724] loss: 0.268, ave_loss: 0.361
[41]  [800/1724] loss: 0.435, ave_loss: 0.363
[42]  [820/1724] loss: 0.392, ave_loss: 0.363
[43]  [840/1724] loss: 0.408, ave_loss: 0.364
[44]  [860/1724] loss: 0.318, ave_loss: 0.363
[45]  [880/1724] loss: 0.295, ave_loss: 0.362
[46]  [900/1724] loss: 0.262, ave_loss: 0.360
[47]  [920/1724] loss: 0.265, ave_loss: 0.358
[48]  [940/1724] loss: 0.327, ave_loss: 0.357
[49]  [960/1724] loss: 0.439, ave_loss: 0.359
[50]  [980/1724] loss: 0.245, ave_loss: 0.356
[51]  [1000/1724] loss: 0.456, ave_loss: 0.358
[52]  [1020/1724] loss: 0.379, ave_loss: 0.359
[53]  [1040/1724] loss: 0.257, ave_loss: 0.357
[54]  [1060/1724] loss: 0.433, ave_loss: 0.358
[55]  [1080/1724] loss: 0.365, ave_loss: 0.358
[56]  [1100/1724] loss: 0.395, ave_loss: 0.359
[57]  [1120/1724] loss: 0.356, ave_loss: 0.359
[58]  [1140/1724] loss: 0.343, ave_loss: 0.359
[59]  [1160/1724] loss: 0.346, ave_loss: 0.358
[60]  [1180/1724] loss: 0.500, ave_loss: 0.361
[61]  [1200/1724] loss: 0.314, ave_loss: 0.360
[62]  [1220/1724] loss: 0.397, ave_loss: 0.361
[63]  [1240/1724] loss: 0.357, ave_loss: 0.361
[64]  [1260/1724] loss: 0.281, ave_loss: 0.359
[65]  [1280/1724] loss: 0.458, ave_loss: 0.361
[66]  [1300/1724] loss: 0.271, ave_loss: 0.360
[67]  [1320/1724] loss: 0.266, ave_loss: 0.358
[68]  [1340/1724] loss: 0.294, ave_loss: 0.357
[69]  [1360/1724] loss: 0.384, ave_loss: 0.358
[70]  [1380/1724] loss: 0.366, ave_loss: 0.358
[71]  [1400/1724] loss: 0.361, ave_loss: 0.358
[72]  [1420/1724] loss: 0.361, ave_loss: 0.358
[73]  [1440/1724] loss: 0.339, ave_loss: 0.358
[74]  [1460/1724] loss: 0.552, ave_loss: 0.360
[75]  [1480/1724] loss: 0.300, ave_loss: 0.359
[76]  [1500/1724] loss: 0.492, ave_loss: 0.361
[77]  [1520/1724] loss: 0.394, ave_loss: 0.362
[78]  [1540/1724] loss: 0.424, ave_loss: 0.362
[79]  [1560/1724] loss: 0.354, ave_loss: 0.362
[80]  [1580/1724] loss: 0.332, ave_loss: 0.362
[81]  [1600/1724] loss: 0.292, ave_loss: 0.361
[82]  [1620/1724] loss: 0.347, ave_loss: 0.361
[83]  [1640/1724] loss: 0.238, ave_loss: 0.359
[84]  [1660/1724] loss: 0.391, ave_loss: 0.360
[85]  [1680/1724] loss: 0.403, ave_loss: 0.360
[86]  [1700/1724] loss: 0.261, ave_loss: 0.359
[87]  [1720/1724] loss: 0.315, ave_loss: 0.359
[88]  [1740/1724] loss: 0.170, ave_loss: 0.356

Finished Training finishing at 2021-08-21 11:42:48.448071
printing_out epoch  42.87703016241299 learning rate: 4.7565307958023e-05
4.475419825770383e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.564e-01
Validation Loss: 1.357e+04
Validation ROC: 0.7776
No improvement, still saving model
56.12296983758701 epochs left to go

Training Epoch 42.87703016241299/100 starting at 2021-08-21 11:43:15.070722
[1]  [0/1724] loss: 0.528, ave_loss: 0.528
[2]  [20/1724] loss: 0.466, ave_loss: 0.497
[3]  [40/1724] loss: 0.422, ave_loss: 0.472
[4]  [60/1724] loss: 0.317, ave_loss: 0.433
[5]  [80/1724] loss: 0.247, ave_loss: 0.396
[6]  [100/1724] loss: 0.371, ave_loss: 0.392
[7]  [120/1724] loss: 0.328, ave_loss: 0.383
[8]  [140/1724] loss: 0.450, ave_loss: 0.391
[9]  [160/1724] loss: 0.305, ave_loss: 0.382
[10]  [180/1724] loss: 0.238, ave_loss: 0.367
[11]  [200/1724] loss: 0.301, ave_loss: 0.361
[12]  [220/1724] loss: 0.343, ave_loss: 0.360
[13]  [240/1724] loss: 0.250, ave_loss: 0.351
[14]  [260/1724] loss: 0.370, ave_loss: 0.353
[15]  [280/1724] loss: 0.527, ave_loss: 0.364
[16]  [300/1724] loss: 0.409, ave_loss: 0.367
[17]  [320/1724] loss: 0.433, ave_loss: 0.371
[18]  [340/1724] loss: 0.339, ave_loss: 0.369
[19]  [360/1724] loss: 0.231, ave_loss: 0.362
[20]  [380/1724] loss: 0.290, ave_loss: 0.358
[21]  [400/1724] loss: 0.307, ave_loss: 0.356
[22]  [420/1724] loss: 0.363, ave_loss: 0.356
[23]  [440/1724] loss: 0.277, ave_loss: 0.353
[24]  [460/1724] loss: 0.151, ave_loss: 0.344
[25]  [480/1724] loss: 0.432, ave_loss: 0.348
[26]  [500/1724] loss: 0.507, ave_loss: 0.354
[27]  [520/1724] loss: 0.486, ave_loss: 0.359
[28]  [540/1724] loss: 0.274, ave_loss: 0.356
[29]  [560/1724] loss: 0.460, ave_loss: 0.359
[30]  [580/1724] loss: 0.408, ave_loss: 0.361
[31]  [600/1724] loss: 0.362, ave_loss: 0.361
[32]  [620/1724] loss: 0.279, ave_loss: 0.358
[33]  [640/1724] loss: 0.256, ave_loss: 0.355
[34]  [660/1724] loss: 0.425, ave_loss: 0.357
[35]  [680/1724] loss: 0.425, ave_loss: 0.359
[36]  [700/1724] loss: 0.336, ave_loss: 0.359
[37]  [720/1724] loss: 0.287, ave_loss: 0.357
[38]  [740/1724] loss: 0.331, ave_loss: 0.356
[39]  [760/1724] loss: 0.260, ave_loss: 0.354
[40]  [780/1724] loss: 0.253, ave_loss: 0.351
[41]  [800/1724] loss: 0.345, ave_loss: 0.351
[42]  [820/1724] loss: 0.569, ave_loss: 0.356
[43]  [840/1724] loss: 0.379, ave_loss: 0.357
[44]  [860/1724] loss: 0.279, ave_loss: 0.355
[45]  [880/1724] loss: 0.449, ave_loss: 0.357
[46]  [900/1724] loss: 0.509, ave_loss: 0.360
[47]  [920/1724] loss: 0.244, ave_loss: 0.358
[48]  [940/1724] loss: 0.344, ave_loss: 0.358
[49]  [960/1724] loss: 0.190, ave_loss: 0.354
[50]  [980/1724] loss: 0.336, ave_loss: 0.354
[51]  [1000/1724] loss: 0.303, ave_loss: 0.353
[52]  [1020/1724] loss: 0.299, ave_loss: 0.352
[53]  [1040/1724] loss: 0.420, ave_loss: 0.353
[54]  [1060/1724] loss: 0.290, ave_loss: 0.352
[55]  [1080/1724] loss: 0.489, ave_loss: 0.354
[56]  [1100/1724] loss: 0.247, ave_loss: 0.352
[57]  [1120/1724] loss: 0.459, ave_loss: 0.354
[58]  [1140/1724] loss: 0.433, ave_loss: 0.356
[59]  [1160/1724] loss: 0.283, ave_loss: 0.354
[60]  [1180/1724] loss: 0.409, ave_loss: 0.355
[61]  [1200/1724] loss: 0.360, ave_loss: 0.355
[62]  [1220/1724] loss: 0.313, ave_loss: 0.355
[63]  [1240/1724] loss: 0.245, ave_loss: 0.353
[64]  [1260/1724] loss: 0.315, ave_loss: 0.352
[65]  [1280/1724] loss: 0.507, ave_loss: 0.355
[66]  [1300/1724] loss: 0.384, ave_loss: 0.355
[67]  [1320/1724] loss: 0.272, ave_loss: 0.354
[68]  [1340/1724] loss: 0.531, ave_loss: 0.357
[69]  [1360/1724] loss: 0.352, ave_loss: 0.356
[70]  [1380/1724] loss: 0.417, ave_loss: 0.357
[71]  [1400/1724] loss: 0.369, ave_loss: 0.358
[72]  [1420/1724] loss: 0.315, ave_loss: 0.357
[73]  [1440/1724] loss: 0.289, ave_loss: 0.356
[74]  [1460/1724] loss: 0.313, ave_loss: 0.355
[75]  [1480/1724] loss: 0.486, ave_loss: 0.357
[76]  [1500/1724] loss: 0.305, ave_loss: 0.356
[77]  [1520/1724] loss: 0.440, ave_loss: 0.358
[78]  [1540/1724] loss: 0.313, ave_loss: 0.357
[79]  [1560/1724] loss: 0.314, ave_loss: 0.356
[80]  [1580/1724] loss: 0.338, ave_loss: 0.356
[81]  [1600/1724] loss: 0.390, ave_loss: 0.357
[82]  [1620/1724] loss: 0.399, ave_loss: 0.357
[83]  [1640/1724] loss: 0.300, ave_loss: 0.356
[84]  [1660/1724] loss: 0.379, ave_loss: 0.357
[85]  [1680/1724] loss: 0.417, ave_loss: 0.357
[86]  [1700/1724] loss: 0.394, ave_loss: 0.358
[87]  [1720/1724] loss: 0.262, ave_loss: 0.357
[88]  [1740/1724] loss: 0.397, ave_loss: 0.357

Finished Training finishing at 2021-08-21 11:45:13.750485
printing_out epoch  43.89791183294663 learning rate: 4.3241189052748176e-05
4.194395338116573e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.572e-01
Validation Loss: 1.435e+04
Validation ROC: 0.7675
No improvement, still saving model
55.10208816705337 epochs left to go

Training Epoch 43.89791183294663/100 starting at 2021-08-21 11:45:44.755187
[1]  [0/1724] loss: 0.664, ave_loss: 0.664
[2]  [20/1724] loss: 0.324, ave_loss: 0.494
[3]  [40/1724] loss: 0.241, ave_loss: 0.409
[4]  [60/1724] loss: 0.346, ave_loss: 0.394
[5]  [80/1724] loss: 0.296, ave_loss: 0.374
[6]  [100/1724] loss: 0.293, ave_loss: 0.361
[7]  [120/1724] loss: 0.343, ave_loss: 0.358
[8]  [140/1724] loss: 0.440, ave_loss: 0.368
[9]  [160/1724] loss: 0.408, ave_loss: 0.373
[10]  [180/1724] loss: 0.327, ave_loss: 0.368
[11]  [200/1724] loss: 0.419, ave_loss: 0.373
[12]  [220/1724] loss: 0.473, ave_loss: 0.381
[13]  [240/1724] loss: 0.296, ave_loss: 0.375
[14]  [260/1724] loss: 0.412, ave_loss: 0.377
[15]  [280/1724] loss: 0.241, ave_loss: 0.368
[16]  [300/1724] loss: 0.238, ave_loss: 0.360
[17]  [320/1724] loss: 0.263, ave_loss: 0.354
[18]  [340/1724] loss: 0.288, ave_loss: 0.351
[19]  [360/1724] loss: 0.440, ave_loss: 0.355
[20]  [380/1724] loss: 0.229, ave_loss: 0.349
[21]  [400/1724] loss: 0.247, ave_loss: 0.344
[22]  [420/1724] loss: 0.298, ave_loss: 0.342
[23]  [440/1724] loss: 0.309, ave_loss: 0.341
[24]  [460/1724] loss: 0.323, ave_loss: 0.340
[25]  [480/1724] loss: 0.308, ave_loss: 0.339
[26]  [500/1724] loss: 0.370, ave_loss: 0.340
[27]  [520/1724] loss: 0.301, ave_loss: 0.338
[28]  [540/1724] loss: 0.279, ave_loss: 0.336
[29]  [560/1724] loss: 0.385, ave_loss: 0.338
[30]  [580/1724] loss: 0.463, ave_loss: 0.342
[31]  [600/1724] loss: 0.483, ave_loss: 0.347
[32]  [620/1724] loss: 0.532, ave_loss: 0.352
[33]  [640/1724] loss: 0.486, ave_loss: 0.356
[34]  [660/1724] loss: 0.382, ave_loss: 0.357
[35]  [680/1724] loss: 0.301, ave_loss: 0.356
[36]  [700/1724] loss: 0.291, ave_loss: 0.354
[37]  [720/1724] loss: 0.410, ave_loss: 0.355
[38]  [740/1724] loss: 0.348, ave_loss: 0.355
[39]  [760/1724] loss: 0.341, ave_loss: 0.355
[40]  [780/1724] loss: 0.401, ave_loss: 0.356
[41]  [800/1724] loss: 0.263, ave_loss: 0.354
[42]  [820/1724] loss: 0.482, ave_loss: 0.357
[43]  [840/1724] loss: 0.457, ave_loss: 0.359
[44]  [860/1724] loss: 0.241, ave_loss: 0.356
[45]  [880/1724] loss: 0.229, ave_loss: 0.354
[46]  [900/1724] loss: 0.361, ave_loss: 0.354
[47]  [920/1724] loss: 0.335, ave_loss: 0.353
[48]  [940/1724] loss: 0.360, ave_loss: 0.353
[49]  [960/1724] loss: 0.303, ave_loss: 0.352
[50]  [980/1724] loss: 0.284, ave_loss: 0.351
[51]  [1000/1724] loss: 0.419, ave_loss: 0.352
[52]  [1020/1724] loss: 0.468, ave_loss: 0.355
[53]  [1040/1724] loss: 0.304, ave_loss: 0.354
[54]  [1060/1724] loss: 0.425, ave_loss: 0.355
[55]  [1080/1724] loss: 0.288, ave_loss: 0.354
[56]  [1100/1724] loss: 0.398, ave_loss: 0.355
[57]  [1120/1724] loss: 0.334, ave_loss: 0.354
[58]  [1140/1724] loss: 0.532, ave_loss: 0.357
[59]  [1160/1724] loss: 0.247, ave_loss: 0.355
[60]  [1180/1724] loss: 0.270, ave_loss: 0.354
[61]  [1200/1724] loss: 0.501, ave_loss: 0.356
[62]  [1220/1724] loss: 0.431, ave_loss: 0.358
[63]  [1240/1724] loss: 0.204, ave_loss: 0.355
[64]  [1260/1724] loss: 0.304, ave_loss: 0.354
[65]  [1280/1724] loss: 0.561, ave_loss: 0.358
[66]  [1300/1724] loss: 0.252, ave_loss: 0.356
[67]  [1320/1724] loss: 0.271, ave_loss: 0.355
[68]  [1340/1724] loss: 0.530, ave_loss: 0.357
[69]  [1360/1724] loss: 0.204, ave_loss: 0.355
[70]  [1380/1724] loss: 0.242, ave_loss: 0.353
[71]  [1400/1724] loss: 0.221, ave_loss: 0.352
[72]  [1420/1724] loss: 0.181, ave_loss: 0.349
[73]  [1440/1724] loss: 0.416, ave_loss: 0.350
[74]  [1460/1724] loss: 0.348, ave_loss: 0.350
[75]  [1480/1724] loss: 0.253, ave_loss: 0.349
[76]  [1500/1724] loss: 0.233, ave_loss: 0.347
[77]  [1520/1724] loss: 0.403, ave_loss: 0.348
[78]  [1540/1724] loss: 0.289, ave_loss: 0.347
[79]  [1560/1724] loss: 0.385, ave_loss: 0.348
[80]  [1580/1724] loss: 0.303, ave_loss: 0.347
[81]  [1600/1724] loss: 0.391, ave_loss: 0.348
[82]  [1620/1724] loss: 0.326, ave_loss: 0.347
[83]  [1640/1724] loss: 0.408, ave_loss: 0.348
[84]  [1660/1724] loss: 0.244, ave_loss: 0.347
[85]  [1680/1724] loss: 0.223, ave_loss: 0.345
[86]  [1700/1724] loss: 0.351, ave_loss: 0.345
[87]  [1720/1724] loss: 0.301, ave_loss: 0.345
[88]  [1740/1724] loss: 0.333, ave_loss: 0.345

Finished Training finishing at 2021-08-21 11:47:47.315009
printing_out epoch  44.91879350348028 learning rate: 3.93101718661347e-05
3.813086671015066e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.448e-01
Validation Loss: 1.421e+04
Validation ROC: 0.7737
No improvement, still saving model
54.08120649651972 epochs left to go

Training Epoch 44.91879350348028/100 starting at 2021-08-21 11:48:33.795551
[1]  [0/1724] loss: 0.401, ave_loss: 0.401
[2]  [20/1724] loss: 0.347, ave_loss: 0.374
[3]  [40/1724] loss: 0.406, ave_loss: 0.385
[4]  [60/1724] loss: 0.373, ave_loss: 0.382
[5]  [80/1724] loss: 0.356, ave_loss: 0.377
[6]  [100/1724] loss: 0.260, ave_loss: 0.357
[7]  [120/1724] loss: 0.288, ave_loss: 0.347
[8]  [140/1724] loss: 0.304, ave_loss: 0.342
[9]  [160/1724] loss: 0.438, ave_loss: 0.353
[10]  [180/1724] loss: 0.256, ave_loss: 0.343
[11]  [200/1724] loss: 0.453, ave_loss: 0.353
[12]  [220/1724] loss: 0.329, ave_loss: 0.351
[13]  [240/1724] loss: 0.298, ave_loss: 0.347
[14]  [260/1724] loss: 0.328, ave_loss: 0.345
[15]  [280/1724] loss: 0.425, ave_loss: 0.351
[16]  [300/1724] loss: 0.326, ave_loss: 0.349
[17]  [320/1724] loss: 0.254, ave_loss: 0.344
[18]  [340/1724] loss: 0.435, ave_loss: 0.349
[19]  [360/1724] loss: 0.326, ave_loss: 0.347
[20]  [380/1724] loss: 0.418, ave_loss: 0.351
[21]  [400/1724] loss: 0.351, ave_loss: 0.351
[22]  [420/1724] loss: 0.429, ave_loss: 0.354
[23]  [440/1724] loss: 0.408, ave_loss: 0.357
[24]  [460/1724] loss: 0.310, ave_loss: 0.355
[25]  [480/1724] loss: 0.279, ave_loss: 0.352
[26]  [500/1724] loss: 0.244, ave_loss: 0.348
[27]  [520/1724] loss: 0.469, ave_loss: 0.352
[28]  [540/1724] loss: 0.276, ave_loss: 0.349
[29]  [560/1724] loss: 0.321, ave_loss: 0.348
[30]  [580/1724] loss: 0.324, ave_loss: 0.348
[31]  [600/1724] loss: 0.450, ave_loss: 0.351
[32]  [620/1724] loss: 0.230, ave_loss: 0.347
[33]  [640/1724] loss: 0.290, ave_loss: 0.345
[34]  [660/1724] loss: 0.410, ave_loss: 0.347
[35]  [680/1724] loss: 0.330, ave_loss: 0.347
[36]  [700/1724] loss: 0.443, ave_loss: 0.350
[37]  [720/1724] loss: 0.333, ave_loss: 0.349
[38]  [740/1724] loss: 0.330, ave_loss: 0.349
[39]  [760/1724] loss: 0.342, ave_loss: 0.348
[40]  [780/1724] loss: 0.366, ave_loss: 0.349
[41]  [800/1724] loss: 0.344, ave_loss: 0.349
[42]  [820/1724] loss: 0.242, ave_loss: 0.346
[43]  [840/1724] loss: 0.375, ave_loss: 0.347
[44]  [860/1724] loss: 0.359, ave_loss: 0.347
[45]  [880/1724] loss: 0.274, ave_loss: 0.346
[46]  [900/1724] loss: 0.355, ave_loss: 0.346
[47]  [920/1724] loss: 0.313, ave_loss: 0.345
[48]  [940/1724] loss: 0.516, ave_loss: 0.349
[49]  [960/1724] loss: 0.445, ave_loss: 0.351
[50]  [980/1724] loss: 0.364, ave_loss: 0.351
[51]  [1000/1724] loss: 0.392, ave_loss: 0.352
[52]  [1020/1724] loss: 0.373, ave_loss: 0.352
[53]  [1040/1724] loss: 0.204, ave_loss: 0.349
[54]  [1060/1724] loss: 0.224, ave_loss: 0.347
[55]  [1080/1724] loss: 0.338, ave_loss: 0.347
[56]  [1100/1724] loss: 0.307, ave_loss: 0.346
[57]  [1120/1724] loss: 0.277, ave_loss: 0.345
[58]  [1140/1724] loss: 0.261, ave_loss: 0.343
[59]  [1160/1724] loss: 0.235, ave_loss: 0.342
[60]  [1180/1724] loss: 0.263, ave_loss: 0.340
[61]  [1200/1724] loss: 0.237, ave_loss: 0.339
[62]  [1220/1724] loss: 0.393, ave_loss: 0.339
[63]  [1240/1724] loss: 0.429, ave_loss: 0.341
[64]  [1260/1724] loss: 0.329, ave_loss: 0.341
[65]  [1280/1724] loss: 0.487, ave_loss: 0.343
[66]  [1300/1724] loss: 0.330, ave_loss: 0.343
[67]  [1320/1724] loss: 0.367, ave_loss: 0.343
[68]  [1340/1724] loss: 0.588, ave_loss: 0.347
[69]  [1360/1724] loss: 0.342, ave_loss: 0.347
[70]  [1380/1724] loss: 0.321, ave_loss: 0.346
[71]  [1400/1724] loss: 0.323, ave_loss: 0.346
[72]  [1420/1724] loss: 0.307, ave_loss: 0.345
[73]  [1440/1724] loss: 0.292, ave_loss: 0.345
[74]  [1460/1724] loss: 0.313, ave_loss: 0.344
[75]  [1480/1724] loss: 0.280, ave_loss: 0.343
[76]  [1500/1724] loss: 0.336, ave_loss: 0.343
[77]  [1520/1724] loss: 0.327, ave_loss: 0.343
[78]  [1540/1724] loss: 0.397, ave_loss: 0.344
[79]  [1560/1724] loss: 0.387, ave_loss: 0.344
[80]  [1580/1724] loss: 0.264, ave_loss: 0.343
[81]  [1600/1724] loss: 0.391, ave_loss: 0.344
[82]  [1620/1724] loss: 0.346, ave_loss: 0.344
[83]  [1640/1724] loss: 0.217, ave_loss: 0.342
[84]  [1660/1724] loss: 0.448, ave_loss: 0.344
[85]  [1680/1724] loss: 0.552, ave_loss: 0.346
[86]  [1700/1724] loss: 0.331, ave_loss: 0.346
[87]  [1720/1724] loss: 0.277, ave_loss: 0.345
[88]  [1740/1724] loss: 0.398, ave_loss: 0.346

Finished Training finishing at 2021-08-21 11:50:32.783653
printing_out epoch  45.93967517401392 learning rate: 3.573651987830427e-05
3.466442428195514e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.457e-01
Validation Loss: 1.432e+04
Validation ROC: 0.7803
Saving model
53.06032482598608 epochs left to go

Training Epoch 45.93967517401392/100 starting at 2021-08-21 11:51:15.368043
[1]  [0/1724] loss: 0.533, ave_loss: 0.533
[2]  [20/1724] loss: 0.318, ave_loss: 0.426
[3]  [40/1724] loss: 0.447, ave_loss: 0.433
[4]  [60/1724] loss: 0.410, ave_loss: 0.427
[5]  [80/1724] loss: 0.332, ave_loss: 0.408
[6]  [100/1724] loss: 0.368, ave_loss: 0.401
[7]  [120/1724] loss: 0.381, ave_loss: 0.398
[8]  [140/1724] loss: 0.332, ave_loss: 0.390
[9]  [160/1724] loss: 0.403, ave_loss: 0.392
[10]  [180/1724] loss: 0.359, ave_loss: 0.388
[11]  [200/1724] loss: 0.289, ave_loss: 0.379
[12]  [220/1724] loss: 0.269, ave_loss: 0.370
[13]  [240/1724] loss: 0.290, ave_loss: 0.364
[14]  [260/1724] loss: 0.243, ave_loss: 0.355
[15]  [280/1724] loss: 0.339, ave_loss: 0.354
[16]  [300/1724] loss: 0.396, ave_loss: 0.357
[17]  [320/1724] loss: 0.302, ave_loss: 0.354
[18]  [340/1724] loss: 0.621, ave_loss: 0.368
[19]  [360/1724] loss: 0.318, ave_loss: 0.366
[20]  [380/1724] loss: 0.326, ave_loss: 0.364
[21]  [400/1724] loss: 0.373, ave_loss: 0.364
[22]  [420/1724] loss: 0.407, ave_loss: 0.366
[23]  [440/1724] loss: 0.463, ave_loss: 0.370
[24]  [460/1724] loss: 0.341, ave_loss: 0.369
[25]  [480/1724] loss: 0.326, ave_loss: 0.367
[26]  [500/1724] loss: 0.354, ave_loss: 0.367
[27]  [520/1724] loss: 0.418, ave_loss: 0.369
[28]  [540/1724] loss: 0.332, ave_loss: 0.367
[29]  [560/1724] loss: 0.316, ave_loss: 0.366
[30]  [580/1724] loss: 0.355, ave_loss: 0.365
[31]  [600/1724] loss: 0.259, ave_loss: 0.362
[32]  [620/1724] loss: 0.407, ave_loss: 0.363
[33]  [640/1724] loss: 0.210, ave_loss: 0.359
[34]  [660/1724] loss: 0.385, ave_loss: 0.359
[35]  [680/1724] loss: 0.315, ave_loss: 0.358
[36]  [700/1724] loss: 0.388, ave_loss: 0.359
[37]  [720/1724] loss: 0.479, ave_loss: 0.362
[38]  [740/1724] loss: 0.537, ave_loss: 0.367
[39]  [760/1724] loss: 0.261, ave_loss: 0.364
[40]  [780/1724] loss: 0.439, ave_loss: 0.366
[41]  [800/1724] loss: 0.285, ave_loss: 0.364
[42]  [820/1724] loss: 0.443, ave_loss: 0.366
[43]  [840/1724] loss: 0.242, ave_loss: 0.363
[44]  [860/1724] loss: 0.266, ave_loss: 0.361
[45]  [880/1724] loss: 0.428, ave_loss: 0.362
[46]  [900/1724] loss: 0.469, ave_loss: 0.365
[47]  [920/1724] loss: 0.288, ave_loss: 0.363
[48]  [940/1724] loss: 0.310, ave_loss: 0.362
[49]  [960/1724] loss: 0.298, ave_loss: 0.361
[50]  [980/1724] loss: 0.214, ave_loss: 0.358
[51]  [1000/1724] loss: 0.336, ave_loss: 0.357
[52]  [1020/1724] loss: 0.527, ave_loss: 0.361
[53]  [1040/1724] loss: 0.239, ave_loss: 0.358
[54]  [1060/1724] loss: 0.469, ave_loss: 0.360
[55]  [1080/1724] loss: 0.271, ave_loss: 0.359
[56]  [1100/1724] loss: 0.234, ave_loss: 0.356
[57]  [1120/1724] loss: 0.438, ave_loss: 0.358
[58]  [1140/1724] loss: 0.240, ave_loss: 0.356
[59]  [1160/1724] loss: 0.411, ave_loss: 0.357
[60]  [1180/1724] loss: 0.229, ave_loss: 0.355
[61]  [1200/1724] loss: 0.379, ave_loss: 0.355
[62]  [1220/1724] loss: 0.335, ave_loss: 0.355
[63]  [1240/1724] loss: 0.331, ave_loss: 0.354
[64]  [1260/1724] loss: 0.371, ave_loss: 0.355
[65]  [1280/1724] loss: 0.296, ave_loss: 0.354
[66]  [1300/1724] loss: 0.505, ave_loss: 0.356
[67]  [1320/1724] loss: 0.415, ave_loss: 0.357
[68]  [1340/1724] loss: 0.385, ave_loss: 0.357
[69]  [1360/1724] loss: 0.295, ave_loss: 0.356
[70]  [1380/1724] loss: 0.367, ave_loss: 0.357
[71]  [1400/1724] loss: 0.487, ave_loss: 0.358
[72]  [1420/1724] loss: 0.413, ave_loss: 0.359
[73]  [1440/1724] loss: 0.390, ave_loss: 0.360
[74]  [1460/1724] loss: 0.227, ave_loss: 0.358
[75]  [1480/1724] loss: 0.336, ave_loss: 0.357
[76]  [1500/1724] loss: 0.342, ave_loss: 0.357
[77]  [1520/1724] loss: 0.541, ave_loss: 0.360
[78]  [1540/1724] loss: 0.286, ave_loss: 0.359
[79]  [1560/1724] loss: 0.433, ave_loss: 0.360
[80]  [1580/1724] loss: 0.379, ave_loss: 0.360
[81]  [1600/1724] loss: 0.370, ave_loss: 0.360
[82]  [1620/1724] loss: 0.435, ave_loss: 0.361
[83]  [1640/1724] loss: 0.354, ave_loss: 0.361
[84]  [1660/1724] loss: 0.357, ave_loss: 0.361
[85]  [1680/1724] loss: 0.327, ave_loss: 0.360
[86]  [1700/1724] loss: 0.481, ave_loss: 0.362
[87]  [1720/1724] loss: 0.357, ave_loss: 0.362
[88]  [1740/1724] loss: 0.261, ave_loss: 0.361

Finished Training finishing at 2021-08-21 11:53:06.838877
printing_out epoch  46.96055684454756 learning rate: 3.573651987830427e-05
3.362449155349649e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.606e-01
Validation Loss: 1.460e+04
Validation ROC: 0.7743
No improvement, still saving model
52.03944315545244 epochs left to go

Training Epoch 46.96055684454756/100 starting at 2021-08-21 11:54:26.493540
[1]  [0/1724] loss: 0.273, ave_loss: 0.273
[2]  [20/1724] loss: 0.266, ave_loss: 0.269
[3]  [40/1724] loss: 0.457, ave_loss: 0.332
[4]  [60/1724] loss: 0.391, ave_loss: 0.347
[5]  [80/1724] loss: 0.593, ave_loss: 0.396
[6]  [100/1724] loss: 0.430, ave_loss: 0.401
[7]  [120/1724] loss: 0.223, ave_loss: 0.376
[8]  [140/1724] loss: 0.402, ave_loss: 0.379
[9]  [160/1724] loss: 0.433, ave_loss: 0.385
[10]  [180/1724] loss: 0.277, ave_loss: 0.374
[11]  [200/1724] loss: 0.346, ave_loss: 0.372
[12]  [220/1724] loss: 0.319, ave_loss: 0.367
[13]  [240/1724] loss: 0.388, ave_loss: 0.369
[14]  [260/1724] loss: 0.386, ave_loss: 0.370
[15]  [280/1724] loss: 0.390, ave_loss: 0.372
[16]  [300/1724] loss: 0.219, ave_loss: 0.362
[17]  [320/1724] loss: 0.377, ave_loss: 0.363
[18]  [340/1724] loss: 0.394, ave_loss: 0.365
[19]  [360/1724] loss: 0.293, ave_loss: 0.361
[20]  [380/1724] loss: 0.325, ave_loss: 0.359
[21]  [400/1724] loss: 0.424, ave_loss: 0.362
[22]  [420/1724] loss: 0.413, ave_loss: 0.364
[23]  [440/1724] loss: 0.358, ave_loss: 0.364
[24]  [460/1724] loss: 0.478, ave_loss: 0.369
[25]  [480/1724] loss: 0.249, ave_loss: 0.364
[26]  [500/1724] loss: 0.363, ave_loss: 0.364
[27]  [520/1724] loss: 0.380, ave_loss: 0.365
[28]  [540/1724] loss: 0.255, ave_loss: 0.361
[29]  [560/1724] loss: 0.260, ave_loss: 0.357
[30]  [580/1724] loss: 0.312, ave_loss: 0.356
[31]  [600/1724] loss: 0.488, ave_loss: 0.360
[32]  [620/1724] loss: 0.307, ave_loss: 0.358
[33]  [640/1724] loss: 0.338, ave_loss: 0.358
[34]  [660/1724] loss: 0.302, ave_loss: 0.356
[35]  [680/1724] loss: 0.296, ave_loss: 0.354
[36]  [700/1724] loss: 0.259, ave_loss: 0.352
[37]  [720/1724] loss: 0.288, ave_loss: 0.350
[38]  [740/1724] loss: 0.304, ave_loss: 0.349
[39]  [760/1724] loss: 0.423, ave_loss: 0.351
[40]  [780/1724] loss: 0.253, ave_loss: 0.348
[41]  [800/1724] loss: 0.335, ave_loss: 0.348
[42]  [820/1724] loss: 0.250, ave_loss: 0.346
[43]  [840/1724] loss: 0.304, ave_loss: 0.345
[44]  [860/1724] loss: 0.263, ave_loss: 0.343
[45]  [880/1724] loss: 0.262, ave_loss: 0.341
[46]  [900/1724] loss: 0.465, ave_loss: 0.344
[47]  [920/1724] loss: 0.208, ave_loss: 0.341
[48]  [940/1724] loss: 0.472, ave_loss: 0.344
[49]  [960/1724] loss: 0.299, ave_loss: 0.343
[50]  [980/1724] loss: 0.427, ave_loss: 0.344
[51]  [1000/1724] loss: 0.470, ave_loss: 0.347
[52]  [1020/1724] loss: 0.471, ave_loss: 0.349
[53]  [1040/1724] loss: 0.412, ave_loss: 0.350
[54]  [1060/1724] loss: 0.275, ave_loss: 0.349
[55]  [1080/1724] loss: 0.335, ave_loss: 0.349
[56]  [1100/1724] loss: 0.345, ave_loss: 0.349
[57]  [1120/1724] loss: 0.337, ave_loss: 0.348
[58]  [1140/1724] loss: 0.287, ave_loss: 0.347
[59]  [1160/1724] loss: 0.247, ave_loss: 0.346
[60]  [1180/1724] loss: 0.233, ave_loss: 0.344
[61]  [1200/1724] loss: 0.445, ave_loss: 0.345
[62]  [1220/1724] loss: 0.197, ave_loss: 0.343
[63]  [1240/1724] loss: 0.312, ave_loss: 0.343
[64]  [1260/1724] loss: 0.216, ave_loss: 0.341
[65]  [1280/1724] loss: 0.307, ave_loss: 0.340
[66]  [1300/1724] loss: 0.400, ave_loss: 0.341
[67]  [1320/1724] loss: 0.287, ave_loss: 0.340
[68]  [1340/1724] loss: 0.353, ave_loss: 0.340
[69]  [1360/1724] loss: 0.237, ave_loss: 0.339
[70]  [1380/1724] loss: 0.295, ave_loss: 0.338
[71]  [1400/1724] loss: 0.247, ave_loss: 0.337
[72]  [1420/1724] loss: 0.354, ave_loss: 0.337
[73]  [1440/1724] loss: 0.275, ave_loss: 0.336
[74]  [1460/1724] loss: 0.328, ave_loss: 0.336
[75]  [1480/1724] loss: 0.300, ave_loss: 0.336
[76]  [1500/1724] loss: 0.324, ave_loss: 0.336
[77]  [1520/1724] loss: 0.428, ave_loss: 0.337
[78]  [1540/1724] loss: 0.248, ave_loss: 0.336
[79]  [1560/1724] loss: 0.292, ave_loss: 0.335
[80]  [1580/1724] loss: 0.299, ave_loss: 0.335
[81]  [1600/1724] loss: 0.389, ave_loss: 0.335
[82]  [1620/1724] loss: 0.263, ave_loss: 0.334
[83]  [1640/1724] loss: 0.288, ave_loss: 0.334
[84]  [1660/1724] loss: 0.236, ave_loss: 0.333
[85]  [1680/1724] loss: 0.319, ave_loss: 0.333
[86]  [1700/1724] loss: 0.500, ave_loss: 0.334
[87]  [1720/1724] loss: 0.197, ave_loss: 0.333
[88]  [1740/1724] loss: 0.376, ave_loss: 0.333

Finished Training finishing at 2021-08-21 11:56:20.063351
printing_out epoch  47.98143851508121 learning rate: 3.248774534391297e-05
3.151311298359558e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.334e-01
Validation Loss: 1.523e+04
Validation ROC: 0.7754
No improvement, still saving model
51.01856148491879 epochs left to go

Training Epoch 47.98143851508121/100 starting at 2021-08-21 11:56:46.033244
[1]  [0/1724] loss: 0.427, ave_loss: 0.427
[2]  [20/1724] loss: 0.344, ave_loss: 0.386
[3]  [40/1724] loss: 0.317, ave_loss: 0.363
[4]  [60/1724] loss: 0.347, ave_loss: 0.359
[5]  [80/1724] loss: 0.352, ave_loss: 0.358
[6]  [100/1724] loss: 0.282, ave_loss: 0.345
[7]  [120/1724] loss: 0.327, ave_loss: 0.342
[8]  [140/1724] loss: 0.441, ave_loss: 0.355
[9]  [160/1724] loss: 0.410, ave_loss: 0.361
[10]  [180/1724] loss: 0.379, ave_loss: 0.363
[11]  [200/1724] loss: 0.367, ave_loss: 0.363
[12]  [220/1724] loss: 0.347, ave_loss: 0.362
[13]  [240/1724] loss: 0.375, ave_loss: 0.363
[14]  [260/1724] loss: 0.312, ave_loss: 0.359
[15]  [280/1724] loss: 0.240, ave_loss: 0.351
[16]  [300/1724] loss: 0.399, ave_loss: 0.354
[17]  [320/1724] loss: 0.450, ave_loss: 0.360
[18]  [340/1724] loss: 0.401, ave_loss: 0.362
[19]  [360/1724] loss: 0.353, ave_loss: 0.362
[20]  [380/1724] loss: 0.385, ave_loss: 0.363
[21]  [400/1724] loss: 0.354, ave_loss: 0.362
[22]  [420/1724] loss: 0.404, ave_loss: 0.364
[23]  [440/1724] loss: 0.287, ave_loss: 0.361
[24]  [460/1724] loss: 0.392, ave_loss: 0.362
[25]  [480/1724] loss: 0.370, ave_loss: 0.362
[26]  [500/1724] loss: 0.325, ave_loss: 0.361
[27]  [520/1724] loss: 0.289, ave_loss: 0.358
[28]  [540/1724] loss: 0.294, ave_loss: 0.356
[29]  [560/1724] loss: 0.562, ave_loss: 0.363
[30]  [580/1724] loss: 0.312, ave_loss: 0.361
[31]  [600/1724] loss: 0.360, ave_loss: 0.361
[32]  [620/1724] loss: 0.306, ave_loss: 0.360
[33]  [640/1724] loss: 0.456, ave_loss: 0.363
[34]  [660/1724] loss: 0.262, ave_loss: 0.360
[35]  [680/1724] loss: 0.263, ave_loss: 0.357
[36]  [700/1724] loss: 0.409, ave_loss: 0.358
[37]  [720/1724] loss: 0.363, ave_loss: 0.358
[38]  [740/1724] loss: 0.385, ave_loss: 0.359
[39]  [760/1724] loss: 0.317, ave_loss: 0.358
[40]  [780/1724] loss: 0.271, ave_loss: 0.356
[41]  [800/1724] loss: 0.255, ave_loss: 0.353
[42]  [820/1724] loss: 0.361, ave_loss: 0.354
[43]  [840/1724] loss: 0.460, ave_loss: 0.356
[44]  [860/1724] loss: 0.391, ave_loss: 0.357
[45]  [880/1724] loss: 0.324, ave_loss: 0.356
[46]  [900/1724] loss: 0.509, ave_loss: 0.359
[47]  [920/1724] loss: 0.271, ave_loss: 0.358
[48]  [940/1724] loss: 0.673, ave_loss: 0.364
[49]  [960/1724] loss: 0.370, ave_loss: 0.364
[50]  [980/1724] loss: 0.387, ave_loss: 0.365
[51]  [1000/1724] loss: 0.341, ave_loss: 0.364
[52]  [1020/1724] loss: 0.414, ave_loss: 0.365
[53]  [1040/1724] loss: 0.359, ave_loss: 0.365
[54]  [1060/1724] loss: 0.425, ave_loss: 0.366
[55]  [1080/1724] loss: 0.296, ave_loss: 0.365
[56]  [1100/1724] loss: 0.424, ave_loss: 0.366
[57]  [1120/1724] loss: 0.296, ave_loss: 0.365
[58]  [1140/1724] loss: 0.348, ave_loss: 0.364
[59]  [1160/1724] loss: 0.472, ave_loss: 0.366
[60]  [1180/1724] loss: 0.163, ave_loss: 0.363
[61]  [1200/1724] loss: 0.323, ave_loss: 0.362
[62]  [1220/1724] loss: 0.289, ave_loss: 0.361
[63]  [1240/1724] loss: 0.298, ave_loss: 0.360
[64]  [1260/1724] loss: 0.289, ave_loss: 0.359
[65]  [1280/1724] loss: 0.356, ave_loss: 0.359
[66]  [1300/1724] loss: 0.330, ave_loss: 0.358
[67]  [1320/1724] loss: 0.432, ave_loss: 0.360
[68]  [1340/1724] loss: 0.397, ave_loss: 0.360
[69]  [1360/1724] loss: 0.439, ave_loss: 0.361
[70]  [1380/1724] loss: 0.237, ave_loss: 0.359
[71]  [1400/1724] loss: 0.393, ave_loss: 0.360
[72]  [1420/1724] loss: 0.228, ave_loss: 0.358
[73]  [1440/1724] loss: 0.339, ave_loss: 0.358
[74]  [1460/1724] loss: 0.629, ave_loss: 0.361
[75]  [1480/1724] loss: 0.450, ave_loss: 0.363
[76]  [1500/1724] loss: 0.370, ave_loss: 0.363
[77]  [1520/1724] loss: 0.293, ave_loss: 0.362
[78]  [1540/1724] loss: 0.319, ave_loss: 0.361
[79]  [1560/1724] loss: 0.352, ave_loss: 0.361
[80]  [1580/1724] loss: 0.507, ave_loss: 0.363
[81]  [1600/1724] loss: 0.265, ave_loss: 0.362
[82]  [1620/1724] loss: 0.478, ave_loss: 0.363
[83]  [1640/1724] loss: 0.415, ave_loss: 0.364
[84]  [1660/1724] loss: 0.602, ave_loss: 0.367
[85]  [1680/1724] loss: 0.534, ave_loss: 0.369
[86]  [1700/1724] loss: 0.290, ave_loss: 0.368
[87]  [1720/1724] loss: 0.258, ave_loss: 0.366
[88]  [1740/1724] loss: 0.367, ave_loss: 0.366

Finished Training finishing at 2021-08-21 11:58:47.998032
printing_out epoch  49.00232018561485 learning rate: 2.9534313949011786e-05
2.8648284530541432e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.665e-01
Validation Loss: 1.411e+04
Validation ROC: 0.7732
No improvement, still saving model
49.99767981438515 epochs left to go

Training Epoch 49.00232018561485/100 starting at 2021-08-21 11:59:16.339439
[1]  [0/1724] loss: 0.553, ave_loss: 0.553
[2]  [20/1724] loss: 0.385, ave_loss: 0.469
[3]  [40/1724] loss: 0.489, ave_loss: 0.475
[4]  [60/1724] loss: 0.437, ave_loss: 0.466
[5]  [80/1724] loss: 0.341, ave_loss: 0.441
[6]  [100/1724] loss: 0.338, ave_loss: 0.424
[7]  [120/1724] loss: 0.355, ave_loss: 0.414
[8]  [140/1724] loss: 0.349, ave_loss: 0.406
[9]  [160/1724] loss: 0.243, ave_loss: 0.388
[10]  [180/1724] loss: 0.388, ave_loss: 0.388
[11]  [200/1724] loss: 0.324, ave_loss: 0.382
[12]  [220/1724] loss: 0.377, ave_loss: 0.381
[13]  [240/1724] loss: 0.336, ave_loss: 0.378
[14]  [260/1724] loss: 0.442, ave_loss: 0.383
[15]  [280/1724] loss: 0.248, ave_loss: 0.374
[16]  [300/1724] loss: 0.302, ave_loss: 0.369
[17]  [320/1724] loss: 0.346, ave_loss: 0.368
[18]  [340/1724] loss: 0.287, ave_loss: 0.363
[19]  [360/1724] loss: 0.343, ave_loss: 0.362
[20]  [380/1724] loss: 0.417, ave_loss: 0.365
[21]  [400/1724] loss: 0.464, ave_loss: 0.370
[22]  [420/1724] loss: 0.316, ave_loss: 0.367
[23]  [440/1724] loss: 0.257, ave_loss: 0.362
[24]  [460/1724] loss: 0.261, ave_loss: 0.358
[25]  [480/1724] loss: 0.424, ave_loss: 0.361
[26]  [500/1724] loss: 0.224, ave_loss: 0.356
[27]  [520/1724] loss: 0.505, ave_loss: 0.361
[28]  [540/1724] loss: 0.351, ave_loss: 0.361
[29]  [560/1724] loss: 0.387, ave_loss: 0.362
[30]  [580/1724] loss: 0.316, ave_loss: 0.360
[31]  [600/1724] loss: 0.213, ave_loss: 0.355
[32]  [620/1724] loss: 0.384, ave_loss: 0.356
[33]  [640/1724] loss: 0.302, ave_loss: 0.355
[34]  [660/1724] loss: 0.332, ave_loss: 0.354
[35]  [680/1724] loss: 0.380, ave_loss: 0.355
[36]  [700/1724] loss: 0.385, ave_loss: 0.356
[37]  [720/1724] loss: 0.490, ave_loss: 0.359
[38]  [740/1724] loss: 0.425, ave_loss: 0.361
[39]  [760/1724] loss: 0.471, ave_loss: 0.364
[40]  [780/1724] loss: 0.365, ave_loss: 0.364
[41]  [800/1724] loss: 0.208, ave_loss: 0.360
[42]  [820/1724] loss: 0.500, ave_loss: 0.363
[43]  [840/1724] loss: 0.302, ave_loss: 0.362
[44]  [860/1724] loss: 0.218, ave_loss: 0.359
[45]  [880/1724] loss: 0.437, ave_loss: 0.360
[46]  [900/1724] loss: 0.575, ave_loss: 0.365
[47]  [920/1724] loss: 0.367, ave_loss: 0.365
[48]  [940/1724] loss: 0.447, ave_loss: 0.367
[49]  [960/1724] loss: 0.285, ave_loss: 0.365
[50]  [980/1724] loss: 0.290, ave_loss: 0.364
[51]  [1000/1724] loss: 0.514, ave_loss: 0.367
[52]  [1020/1724] loss: 0.249, ave_loss: 0.364
[53]  [1040/1724] loss: 0.409, ave_loss: 0.365
[54]  [1060/1724] loss: 0.252, ave_loss: 0.363
[55]  [1080/1724] loss: 0.298, ave_loss: 0.362
[56]  [1100/1724] loss: 0.406, ave_loss: 0.363
[57]  [1120/1724] loss: 0.339, ave_loss: 0.362
[58]  [1140/1724] loss: 0.289, ave_loss: 0.361
[59]  [1160/1724] loss: 0.432, ave_loss: 0.362
[60]  [1180/1724] loss: 0.405, ave_loss: 0.363
[61]  [1200/1724] loss: 0.284, ave_loss: 0.362
[62]  [1220/1724] loss: 0.423, ave_loss: 0.363
[63]  [1240/1724] loss: 0.288, ave_loss: 0.361
[64]  [1260/1724] loss: 0.366, ave_loss: 0.361
[65]  [1280/1724] loss: 0.335, ave_loss: 0.361
[66]  [1300/1724] loss: 0.333, ave_loss: 0.361
[67]  [1320/1724] loss: 0.230, ave_loss: 0.359
[68]  [1340/1724] loss: 0.432, ave_loss: 0.360
[69]  [1360/1724] loss: 0.400, ave_loss: 0.360
[70]  [1380/1724] loss: 0.251, ave_loss: 0.359
[71]  [1400/1724] loss: 0.214, ave_loss: 0.357
[72]  [1420/1724] loss: 0.199, ave_loss: 0.355
[73]  [1440/1724] loss: 0.288, ave_loss: 0.354
[74]  [1460/1724] loss: 0.361, ave_loss: 0.354
[75]  [1480/1724] loss: 0.293, ave_loss: 0.353
[76]  [1500/1724] loss: 0.501, ave_loss: 0.355
[77]  [1520/1724] loss: 0.374, ave_loss: 0.355
[78]  [1540/1724] loss: 0.281, ave_loss: 0.354
[79]  [1560/1724] loss: 0.336, ave_loss: 0.354
[80]  [1580/1724] loss: 0.235, ave_loss: 0.352
[81]  [1600/1724] loss: 0.456, ave_loss: 0.354
[82]  [1620/1724] loss: 0.244, ave_loss: 0.352
[83]  [1640/1724] loss: 0.368, ave_loss: 0.353
[84]  [1660/1724] loss: 0.364, ave_loss: 0.353
[85]  [1680/1724] loss: 0.266, ave_loss: 0.352
[86]  [1700/1724] loss: 0.405, ave_loss: 0.352
[87]  [1720/1724] loss: 0.268, ave_loss: 0.351
[88]  [1740/1724] loss: 0.281, ave_loss: 0.351

Finished Training finishing at 2021-08-21 12:01:10.134777
printing_out epoch  50.02320185614849 learning rate: 2.684937631728344e-05
2.6043895027764936e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.505e-01
Validation Loss: 1.480e+04
Validation ROC: 0.7760
No improvement, still saving model
48.97679814385151 epochs left to go

Training Epoch 50.02320185614849/100 starting at 2021-08-21 12:01:51.774259
[1]  [0/1724] loss: 0.555, ave_loss: 0.555
[2]  [20/1724] loss: 0.313, ave_loss: 0.434
[3]  [40/1724] loss: 0.282, ave_loss: 0.383
[4]  [60/1724] loss: 0.521, ave_loss: 0.418
[5]  [80/1724] loss: 0.395, ave_loss: 0.413
[6]  [100/1724] loss: 0.330, ave_loss: 0.399
[7]  [120/1724] loss: 0.245, ave_loss: 0.377
[8]  [140/1724] loss: 0.448, ave_loss: 0.386
[9]  [160/1724] loss: 0.300, ave_loss: 0.376
[10]  [180/1724] loss: 0.254, ave_loss: 0.364
[11]  [200/1724] loss: 0.445, ave_loss: 0.372
[12]  [220/1724] loss: 0.370, ave_loss: 0.371
[13]  [240/1724] loss: 0.301, ave_loss: 0.366
[14]  [260/1724] loss: 0.215, ave_loss: 0.355
[15]  [280/1724] loss: 0.471, ave_loss: 0.363
[16]  [300/1724] loss: 0.462, ave_loss: 0.369
[17]  [320/1724] loss: 0.347, ave_loss: 0.368
[18]  [340/1724] loss: 0.493, ave_loss: 0.375
[19]  [360/1724] loss: 0.267, ave_loss: 0.369
[20]  [380/1724] loss: 0.381, ave_loss: 0.370
[21]  [400/1724] loss: 0.192, ave_loss: 0.361
[22]  [420/1724] loss: 0.321, ave_loss: 0.360
[23]  [440/1724] loss: 0.365, ave_loss: 0.360
[24]  [460/1724] loss: 0.336, ave_loss: 0.359
[25]  [480/1724] loss: 0.392, ave_loss: 0.360
[26]  [500/1724] loss: 0.289, ave_loss: 0.357
[27]  [520/1724] loss: 0.303, ave_loss: 0.355
[28]  [540/1724] loss: 0.529, ave_loss: 0.362
[29]  [560/1724] loss: 0.287, ave_loss: 0.359
[30]  [580/1724] loss: 0.487, ave_loss: 0.363
[31]  [600/1724] loss: 0.407, ave_loss: 0.365
[32]  [620/1724] loss: 0.444, ave_loss: 0.367
[33]  [640/1724] loss: 0.468, ave_loss: 0.370
[34]  [660/1724] loss: 0.413, ave_loss: 0.371
[35]  [680/1724] loss: 0.351, ave_loss: 0.371
[36]  [700/1724] loss: 0.328, ave_loss: 0.370
[37]  [720/1724] loss: 0.223, ave_loss: 0.366
[38]  [740/1724] loss: 0.225, ave_loss: 0.362
[39]  [760/1724] loss: 0.407, ave_loss: 0.363
[40]  [780/1724] loss: 0.302, ave_loss: 0.362
[41]  [800/1724] loss: 0.238, ave_loss: 0.359
[42]  [820/1724] loss: 0.375, ave_loss: 0.359
[43]  [840/1724] loss: 0.316, ave_loss: 0.358
[44]  [860/1724] loss: 0.446, ave_loss: 0.360
[45]  [880/1724] loss: 0.261, ave_loss: 0.358
[46]  [900/1724] loss: 0.268, ave_loss: 0.356
[47]  [920/1724] loss: 0.367, ave_loss: 0.356
[48]  [940/1724] loss: 0.243, ave_loss: 0.354
[49]  [960/1724] loss: 0.268, ave_loss: 0.352
[50]  [980/1724] loss: 0.247, ave_loss: 0.350
[51]  [1000/1724] loss: 0.350, ave_loss: 0.350
[52]  [1020/1724] loss: 0.505, ave_loss: 0.353
[53]  [1040/1724] loss: 0.413, ave_loss: 0.354
[54]  [1060/1724] loss: 0.374, ave_loss: 0.354
[55]  [1080/1724] loss: 0.393, ave_loss: 0.355
[56]  [1100/1724] loss: 0.373, ave_loss: 0.355
[57]  [1120/1724] loss: 0.543, ave_loss: 0.359
[58]  [1140/1724] loss: 0.368, ave_loss: 0.359
[59]  [1160/1724] loss: 0.293, ave_loss: 0.358
[60]  [1180/1724] loss: 0.322, ave_loss: 0.357
[61]  [1200/1724] loss: 0.492, ave_loss: 0.359
[62]  [1220/1724] loss: 0.322, ave_loss: 0.359
[63]  [1240/1724] loss: 0.344, ave_loss: 0.359
[64]  [1260/1724] loss: 0.510, ave_loss: 0.361
[65]  [1280/1724] loss: 0.362, ave_loss: 0.361
[66]  [1300/1724] loss: 0.322, ave_loss: 0.360
[67]  [1320/1724] loss: 0.368, ave_loss: 0.360
[68]  [1340/1724] loss: 0.292, ave_loss: 0.359
[69]  [1360/1724] loss: 0.404, ave_loss: 0.360
[70]  [1380/1724] loss: 0.299, ave_loss: 0.359
[71]  [1400/1724] loss: 0.488, ave_loss: 0.361
[72]  [1420/1724] loss: 0.314, ave_loss: 0.360
[73]  [1440/1724] loss: 0.364, ave_loss: 0.360
[74]  [1460/1724] loss: 0.502, ave_loss: 0.362
[75]  [1480/1724] loss: 0.188, ave_loss: 0.360
[76]  [1500/1724] loss: 0.376, ave_loss: 0.360
[77]  [1520/1724] loss: 0.397, ave_loss: 0.361
[78]  [1540/1724] loss: 0.416, ave_loss: 0.361
[79]  [1560/1724] loss: 0.430, ave_loss: 0.362
[80]  [1580/1724] loss: 0.290, ave_loss: 0.361
[81]  [1600/1724] loss: 0.152, ave_loss: 0.359
[82]  [1620/1724] loss: 0.265, ave_loss: 0.358
[83]  [1640/1724] loss: 0.290, ave_loss: 0.357
[84]  [1660/1724] loss: 0.353, ave_loss: 0.357
[85]  [1680/1724] loss: 0.362, ave_loss: 0.357
[86]  [1700/1724] loss: 0.234, ave_loss: 0.355
[87]  [1720/1724] loss: 0.318, ave_loss: 0.355
[88]  [1740/1724] loss: 0.334, ave_loss: 0.355

Finished Training finishing at 2021-08-21 12:03:59.010844
printing_out epoch  51.04408352668214 learning rate: 2.4408523924803126e-05
2.367626820705903e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.547e-01
Validation Loss: 1.437e+04
Validation ROC: 0.7754
No improvement, still saving model
47.95591647331786 epochs left to go

Training Epoch 51.04408352668214/100 starting at 2021-08-21 12:04:39.802596
[1]  [0/1724] loss: 0.603, ave_loss: 0.603
[2]  [20/1724] loss: 0.317, ave_loss: 0.460
[3]  [40/1724] loss: 0.284, ave_loss: 0.401
[4]  [60/1724] loss: 0.299, ave_loss: 0.376
[5]  [80/1724] loss: 0.496, ave_loss: 0.400
[6]  [100/1724] loss: 0.316, ave_loss: 0.386
[7]  [120/1724] loss: 0.351, ave_loss: 0.381
[8]  [140/1724] loss: 0.385, ave_loss: 0.381
[9]  [160/1724] loss: 0.419, ave_loss: 0.385
[10]  [180/1724] loss: 0.429, ave_loss: 0.390
[11]  [200/1724] loss: 0.516, ave_loss: 0.401
[12]  [220/1724] loss: 0.282, ave_loss: 0.391
[13]  [240/1724] loss: 0.460, ave_loss: 0.397
[14]  [260/1724] loss: 0.411, ave_loss: 0.398
[15]  [280/1724] loss: 0.227, ave_loss: 0.386
[16]  [300/1724] loss: 0.280, ave_loss: 0.380
[17]  [320/1724] loss: 0.564, ave_loss: 0.390
[18]  [340/1724] loss: 0.366, ave_loss: 0.389
[19]  [360/1724] loss: 0.423, ave_loss: 0.391
[20]  [380/1724] loss: 0.303, ave_loss: 0.386
[21]  [400/1724] loss: 0.430, ave_loss: 0.388
[22]  [420/1724] loss: 0.282, ave_loss: 0.384
[23]  [440/1724] loss: 0.424, ave_loss: 0.385
[24]  [460/1724] loss: 0.270, ave_loss: 0.381
[25]  [480/1724] loss: 0.492, ave_loss: 0.385
[26]  [500/1724] loss: 0.339, ave_loss: 0.383
[27]  [520/1724] loss: 0.443, ave_loss: 0.385
[28]  [540/1724] loss: 0.345, ave_loss: 0.384
[29]  [560/1724] loss: 0.287, ave_loss: 0.381
[30]  [580/1724] loss: 0.375, ave_loss: 0.380
[31]  [600/1724] loss: 0.375, ave_loss: 0.380
[32]  [620/1724] loss: 0.246, ave_loss: 0.376
[33]  [640/1724] loss: 0.434, ave_loss: 0.378
[34]  [660/1724] loss: 0.325, ave_loss: 0.376
[35]  [680/1724] loss: 0.342, ave_loss: 0.375
[36]  [700/1724] loss: 0.373, ave_loss: 0.375
[37]  [720/1724] loss: 0.424, ave_loss: 0.377
[38]  [740/1724] loss: 0.378, ave_loss: 0.377
[39]  [760/1724] loss: 0.335, ave_loss: 0.376
[40]  [780/1724] loss: 0.311, ave_loss: 0.374
[41]  [800/1724] loss: 0.390, ave_loss: 0.374
[42]  [820/1724] loss: 0.339, ave_loss: 0.373
[43]  [840/1724] loss: 0.239, ave_loss: 0.370
[44]  [860/1724] loss: 0.313, ave_loss: 0.369
[45]  [880/1724] loss: 0.459, ave_loss: 0.371
[46]  [900/1724] loss: 0.375, ave_loss: 0.371
[47]  [920/1724] loss: 0.372, ave_loss: 0.371
[48]  [940/1724] loss: 0.342, ave_loss: 0.371
[49]  [960/1724] loss: 0.345, ave_loss: 0.370
[50]  [980/1724] loss: 0.362, ave_loss: 0.370
[51]  [1000/1724] loss: 0.381, ave_loss: 0.370
[52]  [1020/1724] loss: 0.317, ave_loss: 0.369
[53]  [1040/1724] loss: 0.305, ave_loss: 0.368
[54]  [1060/1724] loss: 0.378, ave_loss: 0.368
[55]  [1080/1724] loss: 0.342, ave_loss: 0.368
[56]  [1100/1724] loss: 0.378, ave_loss: 0.368
[57]  [1120/1724] loss: 0.206, ave_loss: 0.365
[58]  [1140/1724] loss: 0.340, ave_loss: 0.364
[59]  [1160/1724] loss: 0.501, ave_loss: 0.367
[60]  [1180/1724] loss: 0.672, ave_loss: 0.372
[61]  [1200/1724] loss: 0.402, ave_loss: 0.372
[62]  [1220/1724] loss: 0.452, ave_loss: 0.374
[63]  [1240/1724] loss: 0.324, ave_loss: 0.373
[64]  [1260/1724] loss: 0.332, ave_loss: 0.372
[65]  [1280/1724] loss: 0.265, ave_loss: 0.371
[66]  [1300/1724] loss: 0.430, ave_loss: 0.371
[67]  [1320/1724] loss: 0.476, ave_loss: 0.373
[68]  [1340/1724] loss: 0.277, ave_loss: 0.372
[69]  [1360/1724] loss: 0.249, ave_loss: 0.370
[70]  [1380/1724] loss: 0.315, ave_loss: 0.369
[71]  [1400/1724] loss: 0.315, ave_loss: 0.368
[72]  [1420/1724] loss: 0.457, ave_loss: 0.370
[73]  [1440/1724] loss: 0.326, ave_loss: 0.369
[74]  [1460/1724] loss: 0.390, ave_loss: 0.369
[75]  [1480/1724] loss: 0.455, ave_loss: 0.370
[76]  [1500/1724] loss: 0.377, ave_loss: 0.370
[77]  [1520/1724] loss: 0.457, ave_loss: 0.372
[78]  [1540/1724] loss: 0.531, ave_loss: 0.374
[79]  [1560/1724] loss: 0.395, ave_loss: 0.374
[80]  [1580/1724] loss: 0.389, ave_loss: 0.374
[81]  [1600/1724] loss: 0.311, ave_loss: 0.373
[82]  [1620/1724] loss: 0.422, ave_loss: 0.374
[83]  [1640/1724] loss: 0.336, ave_loss: 0.373
[84]  [1660/1724] loss: 0.403, ave_loss: 0.374
[85]  [1680/1724] loss: 0.465, ave_loss: 0.375
[86]  [1700/1724] loss: 0.362, ave_loss: 0.375
[87]  [1720/1724] loss: 0.378, ave_loss: 0.375
[88]  [1740/1724] loss: 0.304, ave_loss: 0.374

Finished Training finishing at 2021-08-21 12:06:44.976817
printing_out epoch  52.06496519721578 learning rate: 2.2189567204366477e-05
2.1523880188235482e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.739e-01
Validation Loss: 1.455e+04
Validation ROC: 0.7737
No improvement, still saving model
46.93503480278422 epochs left to go

Training Epoch 52.06496519721578/100 starting at 2021-08-21 12:08:26.898007
[1]  [0/1724] loss: 0.584, ave_loss: 0.584
[2]  [20/1724] loss: 0.337, ave_loss: 0.460
[3]  [40/1724] loss: 0.351, ave_loss: 0.424
[4]  [60/1724] loss: 0.397, ave_loss: 0.417
[5]  [80/1724] loss: 0.512, ave_loss: 0.436
[6]  [100/1724] loss: 0.369, ave_loss: 0.425
[7]  [120/1724] loss: 0.205, ave_loss: 0.394
[8]  [140/1724] loss: 0.334, ave_loss: 0.386
[9]  [160/1724] loss: 0.232, ave_loss: 0.369
[10]  [180/1724] loss: 0.473, ave_loss: 0.379
[11]  [200/1724] loss: 0.338, ave_loss: 0.376
[12]  [220/1724] loss: 0.467, ave_loss: 0.383
[13]  [240/1724] loss: 0.252, ave_loss: 0.373
[14]  [260/1724] loss: 0.311, ave_loss: 0.369
[15]  [280/1724] loss: 0.435, ave_loss: 0.373
[16]  [300/1724] loss: 0.450, ave_loss: 0.378
[17]  [320/1724] loss: 0.387, ave_loss: 0.378
[18]  [340/1724] loss: 0.363, ave_loss: 0.378
[19]  [360/1724] loss: 0.357, ave_loss: 0.377
[20]  [380/1724] loss: 0.286, ave_loss: 0.372
[21]  [400/1724] loss: 0.349, ave_loss: 0.371
[22]  [420/1724] loss: 0.417, ave_loss: 0.373
[23]  [440/1724] loss: 0.560, ave_loss: 0.381
[24]  [460/1724] loss: 0.488, ave_loss: 0.386
[25]  [480/1724] loss: 0.321, ave_loss: 0.383
[26]  [500/1724] loss: 0.297, ave_loss: 0.380
[27]  [520/1724] loss: 0.438, ave_loss: 0.382
[28]  [540/1724] loss: 0.391, ave_loss: 0.382
[29]  [560/1724] loss: 0.322, ave_loss: 0.380
[30]  [580/1724] loss: 0.377, ave_loss: 0.380
[31]  [600/1724] loss: 0.278, ave_loss: 0.377
[32]  [620/1724] loss: 0.373, ave_loss: 0.377
[33]  [640/1724] loss: 0.433, ave_loss: 0.378
[34]  [660/1724] loss: 0.461, ave_loss: 0.381
[35]  [680/1724] loss: 0.368, ave_loss: 0.380
[36]  [700/1724] loss: 0.219, ave_loss: 0.376
[37]  [720/1724] loss: 0.320, ave_loss: 0.374
[38]  [740/1724] loss: 0.310, ave_loss: 0.373
[39]  [760/1724] loss: 0.277, ave_loss: 0.370
[40]  [780/1724] loss: 0.506, ave_loss: 0.374
[41]  [800/1724] loss: 0.266, ave_loss: 0.371
[42]  [820/1724] loss: 0.250, ave_loss: 0.368
[43]  [840/1724] loss: 0.371, ave_loss: 0.368
[44]  [860/1724] loss: 0.350, ave_loss: 0.368
[45]  [880/1724] loss: 0.241, ave_loss: 0.365
[46]  [900/1724] loss: 0.292, ave_loss: 0.363
[47]  [920/1724] loss: 0.374, ave_loss: 0.364
[48]  [940/1724] loss: 0.429, ave_loss: 0.365
[49]  [960/1724] loss: 0.358, ave_loss: 0.365
[50]  [980/1724] loss: 0.334, ave_loss: 0.364
[51]  [1000/1724] loss: 0.363, ave_loss: 0.364
[52]  [1020/1724] loss: 0.422, ave_loss: 0.365
[53]  [1040/1724] loss: 0.377, ave_loss: 0.366
[54]  [1060/1724] loss: 0.336, ave_loss: 0.365
[55]  [1080/1724] loss: 0.272, ave_loss: 0.363
[56]  [1100/1724] loss: 0.494, ave_loss: 0.366
[57]  [1120/1724] loss: 0.411, ave_loss: 0.366
[58]  [1140/1724] loss: 0.366, ave_loss: 0.366
[59]  [1160/1724] loss: 0.363, ave_loss: 0.366
[60]  [1180/1724] loss: 0.380, ave_loss: 0.367
[61]  [1200/1724] loss: 0.485, ave_loss: 0.369
[62]  [1220/1724] loss: 0.373, ave_loss: 0.369
[63]  [1240/1724] loss: 0.409, ave_loss: 0.369
[64]  [1260/1724] loss: 0.405, ave_loss: 0.370
[65]  [1280/1724] loss: 0.433, ave_loss: 0.371
[66]  [1300/1724] loss: 0.437, ave_loss: 0.372
[67]  [1320/1724] loss: 0.296, ave_loss: 0.371
[68]  [1340/1724] loss: 0.430, ave_loss: 0.372
[69]  [1360/1724] loss: 0.352, ave_loss: 0.371
[70]  [1380/1724] loss: 0.284, ave_loss: 0.370
[71]  [1400/1724] loss: 0.298, ave_loss: 0.369
[72]  [1420/1724] loss: 0.447, ave_loss: 0.370
[73]  [1440/1724] loss: 0.429, ave_loss: 0.371
[74]  [1460/1724] loss: 0.287, ave_loss: 0.370
[75]  [1480/1724] loss: 0.207, ave_loss: 0.368
[76]  [1500/1724] loss: 0.368, ave_loss: 0.368
[77]  [1520/1724] loss: 0.234, ave_loss: 0.366
[78]  [1540/1724] loss: 0.371, ave_loss: 0.366
[79]  [1560/1724] loss: 0.278, ave_loss: 0.365
[80]  [1580/1724] loss: 0.318, ave_loss: 0.364
[81]  [1600/1724] loss: 0.234, ave_loss: 0.363
[82]  [1620/1724] loss: 0.362, ave_loss: 0.363
[83]  [1640/1724] loss: 0.382, ave_loss: 0.363
[84]  [1660/1724] loss: 0.482, ave_loss: 0.364
[85]  [1680/1724] loss: 0.338, ave_loss: 0.364
[86]  [1700/1724] loss: 0.434, ave_loss: 0.365
[87]  [1720/1724] loss: 0.317, ave_loss: 0.364
[88]  [1740/1724] loss: 0.369, ave_loss: 0.364

Finished Training finishing at 2021-08-21 12:10:39.214844
printing_out epoch  53.08584686774942 learning rate: 2.017233382215134e-05
1.9567163807486802e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.643e-01
Validation Loss: 1.368e+04
Validation ROC: 0.7749
No improvement, still saving model
45.91415313225058 epochs left to go

Training Epoch 53.08584686774942/100 starting at 2021-08-21 12:11:12.219028
[1]  [0/1724] loss: 0.445, ave_loss: 0.445
[2]  [20/1724] loss: 0.240, ave_loss: 0.343
[3]  [40/1724] loss: 0.282, ave_loss: 0.323
[4]  [60/1724] loss: 0.309, ave_loss: 0.319
[5]  [80/1724] loss: 0.307, ave_loss: 0.317
[6]  [100/1724] loss: 0.233, ave_loss: 0.303
[7]  [120/1724] loss: 0.335, ave_loss: 0.307
[8]  [140/1724] loss: 0.310, ave_loss: 0.308
[9]  [160/1724] loss: 0.344, ave_loss: 0.312
[10]  [180/1724] loss: 0.278, ave_loss: 0.308
[11]  [200/1724] loss: 0.393, ave_loss: 0.316
[12]  [220/1724] loss: 0.287, ave_loss: 0.314
[13]  [240/1724] loss: 0.438, ave_loss: 0.323
[14]  [260/1724] loss: 0.282, ave_loss: 0.320
[15]  [280/1724] loss: 0.300, ave_loss: 0.319
[16]  [300/1724] loss: 0.270, ave_loss: 0.316
[17]  [320/1724] loss: 0.484, ave_loss: 0.326
[18]  [340/1724] loss: 0.427, ave_loss: 0.331
[19]  [360/1724] loss: 0.306, ave_loss: 0.330
[20]  [380/1724] loss: 0.504, ave_loss: 0.339
[21]  [400/1724] loss: 0.451, ave_loss: 0.344
[22]  [420/1724] loss: 0.574, ave_loss: 0.355
[23]  [440/1724] loss: 0.317, ave_loss: 0.353
[24]  [460/1724] loss: 0.485, ave_loss: 0.358
[25]  [480/1724] loss: 0.328, ave_loss: 0.357
[26]  [500/1724] loss: 0.431, ave_loss: 0.360
[27]  [520/1724] loss: 0.320, ave_loss: 0.359
[28]  [540/1724] loss: 0.278, ave_loss: 0.356
[29]  [560/1724] loss: 0.249, ave_loss: 0.352
[30]  [580/1724] loss: 0.401, ave_loss: 0.354
[31]  [600/1724] loss: 0.307, ave_loss: 0.352
[32]  [620/1724] loss: 0.474, ave_loss: 0.356
[33]  [640/1724] loss: 0.315, ave_loss: 0.355
[34]  [660/1724] loss: 0.255, ave_loss: 0.352
[35]  [680/1724] loss: 0.276, ave_loss: 0.350
[36]  [700/1724] loss: 0.374, ave_loss: 0.350
[37]  [720/1724] loss: 0.195, ave_loss: 0.346
[38]  [740/1724] loss: 0.318, ave_loss: 0.345
[39]  [760/1724] loss: 0.342, ave_loss: 0.345
[40]  [780/1724] loss: 0.500, ave_loss: 0.349
[41]  [800/1724] loss: 0.300, ave_loss: 0.348
[42]  [820/1724] loss: 0.419, ave_loss: 0.350
[43]  [840/1724] loss: 0.311, ave_loss: 0.349
[44]  [860/1724] loss: 0.473, ave_loss: 0.352
[45]  [880/1724] loss: 0.388, ave_loss: 0.352
[46]  [900/1724] loss: 0.385, ave_loss: 0.353
[47]  [920/1724] loss: 0.400, ave_loss: 0.354
[48]  [940/1724] loss: 0.347, ave_loss: 0.354
[49]  [960/1724] loss: 0.496, ave_loss: 0.357
[50]  [980/1724] loss: 0.475, ave_loss: 0.359
[51]  [1000/1724] loss: 0.437, ave_loss: 0.361
[52]  [1020/1724] loss: 0.311, ave_loss: 0.360
[53]  [1040/1724] loss: 0.330, ave_loss: 0.359
[54]  [1060/1724] loss: 0.339, ave_loss: 0.359
[55]  [1080/1724] loss: 0.478, ave_loss: 0.361
[56]  [1100/1724] loss: 0.355, ave_loss: 0.361
[57]  [1120/1724] loss: 0.315, ave_loss: 0.360
[58]  [1140/1724] loss: 0.379, ave_loss: 0.360
[59]  [1160/1724] loss: 0.221, ave_loss: 0.358
[60]  [1180/1724] loss: 0.332, ave_loss: 0.358
[61]  [1200/1724] loss: 0.407, ave_loss: 0.358
[62]  [1220/1724] loss: 0.245, ave_loss: 0.357
[63]  [1240/1724] loss: 0.376, ave_loss: 0.357
[64]  [1260/1724] loss: 0.192, ave_loss: 0.354
[65]  [1280/1724] loss: 0.241, ave_loss: 0.353
[66]  [1300/1724] loss: 0.394, ave_loss: 0.353
[67]  [1320/1724] loss: 0.370, ave_loss: 0.353
[68]  [1340/1724] loss: 0.284, ave_loss: 0.352
[69]  [1360/1724] loss: 0.359, ave_loss: 0.353
[70]  [1380/1724] loss: 0.461, ave_loss: 0.354
[71]  [1400/1724] loss: 0.296, ave_loss: 0.353
[72]  [1420/1724] loss: 0.348, ave_loss: 0.353
[73]  [1440/1724] loss: 0.507, ave_loss: 0.355
[74]  [1460/1724] loss: 0.400, ave_loss: 0.356
[75]  [1480/1724] loss: 0.206, ave_loss: 0.354
[76]  [1500/1724] loss: 0.230, ave_loss: 0.352
[77]  [1520/1724] loss: 0.296, ave_loss: 0.352
[78]  [1540/1724] loss: 0.360, ave_loss: 0.352
[79]  [1560/1724] loss: 0.238, ave_loss: 0.350
[80]  [1580/1724] loss: 0.217, ave_loss: 0.349
[81]  [1600/1724] loss: 0.421, ave_loss: 0.349
[82]  [1620/1724] loss: 0.230, ave_loss: 0.348
[83]  [1640/1724] loss: 0.335, ave_loss: 0.348
[84]  [1660/1724] loss: 0.626, ave_loss: 0.351
[85]  [1680/1724] loss: 0.355, ave_loss: 0.351
[86]  [1700/1724] loss: 0.466, ave_loss: 0.353
[87]  [1720/1724] loss: 0.288, ave_loss: 0.352
[88]  [1740/1724] loss: 0.300, ave_loss: 0.351

Finished Training finishing at 2021-08-21 12:13:13.223656
printing_out epoch  54.106728538283065 learning rate: 1.8338485292864853e-05
1.7788330734078907e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.512e-01
Validation Loss: 1.389e+04
Validation ROC: 0.7732
No improvement, still saving model
44.893271461716935 epochs left to go

Training Epoch 54.106728538283065/100 starting at 2021-08-21 12:13:41.845193
[1]  [0/1724] loss: 0.351, ave_loss: 0.351
[2]  [20/1724] loss: 0.275, ave_loss: 0.313
[3]  [40/1724] loss: 0.469, ave_loss: 0.365
[4]  [60/1724] loss: 0.301, ave_loss: 0.349
[5]  [80/1724] loss: 0.322, ave_loss: 0.343
[6]  [100/1724] loss: 0.399, ave_loss: 0.353
[7]  [120/1724] loss: 0.327, ave_loss: 0.349
[8]  [140/1724] loss: 0.284, ave_loss: 0.341
[9]  [160/1724] loss: 0.450, ave_loss: 0.353
[10]  [180/1724] loss: 0.274, ave_loss: 0.345
[11]  [200/1724] loss: 0.361, ave_loss: 0.347
[12]  [220/1724] loss: 0.243, ave_loss: 0.338
[13]  [240/1724] loss: 0.266, ave_loss: 0.332
[14]  [260/1724] loss: 0.312, ave_loss: 0.331
[15]  [280/1724] loss: 0.347, ave_loss: 0.332
[16]  [300/1724] loss: 0.341, ave_loss: 0.333
[17]  [320/1724] loss: 0.418, ave_loss: 0.338
[18]  [340/1724] loss: 0.417, ave_loss: 0.342
[19]  [360/1724] loss: 0.558, ave_loss: 0.353
[20]  [380/1724] loss: 0.363, ave_loss: 0.354
[21]  [400/1724] loss: 0.253, ave_loss: 0.349
[22]  [420/1724] loss: 0.310, ave_loss: 0.347
[23]  [440/1724] loss: 0.503, ave_loss: 0.354
[24]  [460/1724] loss: 0.272, ave_loss: 0.351
[25]  [480/1724] loss: 0.277, ave_loss: 0.348
[26]  [500/1724] loss: 0.252, ave_loss: 0.344
[27]  [520/1724] loss: 0.302, ave_loss: 0.342
[28]  [540/1724] loss: 0.421, ave_loss: 0.345
[29]  [560/1724] loss: 0.391, ave_loss: 0.347
[30]  [580/1724] loss: 0.302, ave_loss: 0.345
[31]  [600/1724] loss: 0.202, ave_loss: 0.341
[32]  [620/1724] loss: 0.225, ave_loss: 0.337
[33]  [640/1724] loss: 0.248, ave_loss: 0.334
[34]  [660/1724] loss: 0.362, ave_loss: 0.335
[35]  [680/1724] loss: 0.249, ave_loss: 0.333
[36]  [700/1724] loss: 0.414, ave_loss: 0.335
[37]  [720/1724] loss: 0.281, ave_loss: 0.334
[38]  [740/1724] loss: 0.449, ave_loss: 0.337
[39]  [760/1724] loss: 0.414, ave_loss: 0.339
[40]  [780/1724] loss: 0.422, ave_loss: 0.341
[41]  [800/1724] loss: 0.407, ave_loss: 0.342
[42]  [820/1724] loss: 0.462, ave_loss: 0.345
[43]  [840/1724] loss: 0.265, ave_loss: 0.343
[44]  [860/1724] loss: 0.237, ave_loss: 0.341
[45]  [880/1724] loss: 0.380, ave_loss: 0.342
[46]  [900/1724] loss: 0.411, ave_loss: 0.343
[47]  [920/1724] loss: 0.240, ave_loss: 0.341
[48]  [940/1724] loss: 0.239, ave_loss: 0.339
[49]  [960/1724] loss: 0.263, ave_loss: 0.337
[50]  [980/1724] loss: 0.429, ave_loss: 0.339
[51]  [1000/1724] loss: 0.276, ave_loss: 0.338
[52]  [1020/1724] loss: 0.412, ave_loss: 0.339
[53]  [1040/1724] loss: 0.271, ave_loss: 0.338
[54]  [1060/1724] loss: 0.363, ave_loss: 0.339
[55]  [1080/1724] loss: 0.393, ave_loss: 0.340
[56]  [1100/1724] loss: 0.520, ave_loss: 0.343
[57]  [1120/1724] loss: 0.300, ave_loss: 0.342
[58]  [1140/1724] loss: 0.315, ave_loss: 0.342
[59]  [1160/1724] loss: 0.476, ave_loss: 0.344
[60]  [1180/1724] loss: 0.270, ave_loss: 0.343
[61]  [1200/1724] loss: 0.298, ave_loss: 0.342
[62]  [1220/1724] loss: 0.316, ave_loss: 0.341
[63]  [1240/1724] loss: 0.311, ave_loss: 0.341
[64]  [1260/1724] loss: 0.211, ave_loss: 0.339
[65]  [1280/1724] loss: 0.309, ave_loss: 0.338
[66]  [1300/1724] loss: 0.437, ave_loss: 0.340
[67]  [1320/1724] loss: 0.345, ave_loss: 0.340
[68]  [1340/1724] loss: 0.523, ave_loss: 0.343
[69]  [1360/1724] loss: 0.273, ave_loss: 0.342
[70]  [1380/1724] loss: 0.499, ave_loss: 0.344
[71]  [1400/1724] loss: 0.388, ave_loss: 0.345
[72]  [1420/1724] loss: 0.400, ave_loss: 0.345
[73]  [1440/1724] loss: 0.283, ave_loss: 0.344
[74]  [1460/1724] loss: 0.492, ave_loss: 0.346
[75]  [1480/1724] loss: 0.331, ave_loss: 0.346
[76]  [1500/1724] loss: 0.397, ave_loss: 0.347
[77]  [1520/1724] loss: 0.357, ave_loss: 0.347
[78]  [1540/1724] loss: 0.259, ave_loss: 0.346
[79]  [1560/1724] loss: 0.471, ave_loss: 0.348
[80]  [1580/1724] loss: 0.332, ave_loss: 0.347
[81]  [1600/1724] loss: 0.404, ave_loss: 0.348
[82]  [1620/1724] loss: 0.464, ave_loss: 0.349
[83]  [1640/1724] loss: 0.503, ave_loss: 0.351
[84]  [1660/1724] loss: 0.213, ave_loss: 0.350
[85]  [1680/1724] loss: 0.239, ave_loss: 0.348
[86]  [1700/1724] loss: 0.440, ave_loss: 0.349
[87]  [1720/1724] loss: 0.370, ave_loss: 0.350
[88]  [1740/1724] loss: 0.318, ave_loss: 0.349

Finished Training finishing at 2021-08-21 12:15:35.975467
printing_out epoch  55.127610208816705 learning rate: 1.6671350266240776e-05
1.6171209758253554e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.493e-01
Validation Loss: 1.383e+04
Validation ROC: 0.7747
No improvement, still saving model
43.872389791183295 epochs left to go

Training Epoch 55.127610208816705/100 starting at 2021-08-21 12:16:16.953171
[1]  [0/1724] loss: 0.550, ave_loss: 0.550
[2]  [20/1724] loss: 0.340, ave_loss: 0.445
[3]  [40/1724] loss: 0.414, ave_loss: 0.435
[4]  [60/1724] loss: 0.419, ave_loss: 0.431
[5]  [80/1724] loss: 0.320, ave_loss: 0.409
[6]  [100/1724] loss: 0.375, ave_loss: 0.403
[7]  [120/1724] loss: 0.215, ave_loss: 0.376
[8]  [140/1724] loss: 0.320, ave_loss: 0.369
[9]  [160/1724] loss: 0.426, ave_loss: 0.375
[10]  [180/1724] loss: 0.248, ave_loss: 0.363
[11]  [200/1724] loss: 0.264, ave_loss: 0.354
[12]  [220/1724] loss: 0.265, ave_loss: 0.346
[13]  [240/1724] loss: 0.436, ave_loss: 0.353
[14]  [260/1724] loss: 0.281, ave_loss: 0.348
[15]  [280/1724] loss: 0.424, ave_loss: 0.353
[16]  [300/1724] loss: 0.258, ave_loss: 0.347
[17]  [320/1724] loss: 0.282, ave_loss: 0.343
[18]  [340/1724] loss: 0.390, ave_loss: 0.346
[19]  [360/1724] loss: 0.302, ave_loss: 0.344
[20]  [380/1724] loss: 0.429, ave_loss: 0.348
[21]  [400/1724] loss: 0.334, ave_loss: 0.347
[22]  [420/1724] loss: 0.296, ave_loss: 0.345
[23]  [440/1724] loss: 0.270, ave_loss: 0.342
[24]  [460/1724] loss: 0.299, ave_loss: 0.340
[25]  [480/1724] loss: 0.594, ave_loss: 0.350
[26]  [500/1724] loss: 0.348, ave_loss: 0.350
[27]  [520/1724] loss: 0.398, ave_loss: 0.352
[28]  [540/1724] loss: 0.270, ave_loss: 0.349
[29]  [560/1724] loss: 0.317, ave_loss: 0.348
[30]  [580/1724] loss: 0.336, ave_loss: 0.347
[31]  [600/1724] loss: 0.434, ave_loss: 0.350
[32]  [620/1724] loss: 0.348, ave_loss: 0.350
[33]  [640/1724] loss: 0.277, ave_loss: 0.348
[34]  [660/1724] loss: 0.382, ave_loss: 0.349
[35]  [680/1724] loss: 0.322, ave_loss: 0.348
[36]  [700/1724] loss: 0.384, ave_loss: 0.349
[37]  [720/1724] loss: 0.228, ave_loss: 0.346
[38]  [740/1724] loss: 0.401, ave_loss: 0.347
[39]  [760/1724] loss: 0.337, ave_loss: 0.347
[40]  [780/1724] loss: 0.443, ave_loss: 0.349
[41]  [800/1724] loss: 0.474, ave_loss: 0.352
[42]  [820/1724] loss: 0.382, ave_loss: 0.353
[43]  [840/1724] loss: 0.381, ave_loss: 0.354
[44]  [860/1724] loss: 0.234, ave_loss: 0.351
[45]  [880/1724] loss: 0.329, ave_loss: 0.351
[46]  [900/1724] loss: 0.404, ave_loss: 0.352
[47]  [920/1724] loss: 0.350, ave_loss: 0.352
[48]  [940/1724] loss: 0.390, ave_loss: 0.352
[49]  [960/1724] loss: 0.252, ave_loss: 0.350
[50]  [980/1724] loss: 0.404, ave_loss: 0.351
[51]  [1000/1724] loss: 0.290, ave_loss: 0.350
[52]  [1020/1724] loss: 0.370, ave_loss: 0.351
[53]  [1040/1724] loss: 0.360, ave_loss: 0.351
[54]  [1060/1724] loss: 0.285, ave_loss: 0.350
[55]  [1080/1724] loss: 0.321, ave_loss: 0.349
[56]  [1100/1724] loss: 0.467, ave_loss: 0.351
[57]  [1120/1724] loss: 0.364, ave_loss: 0.351
[58]  [1140/1724] loss: 0.220, ave_loss: 0.349
[59]  [1160/1724] loss: 0.325, ave_loss: 0.349
[60]  [1180/1724] loss: 0.357, ave_loss: 0.349
[61]  [1200/1724] loss: 0.270, ave_loss: 0.348
[62]  [1220/1724] loss: 0.583, ave_loss: 0.351
[63]  [1240/1724] loss: 0.238, ave_loss: 0.350
[64]  [1260/1724] loss: 0.270, ave_loss: 0.348
[65]  [1280/1724] loss: 0.300, ave_loss: 0.348
[66]  [1300/1724] loss: 0.261, ave_loss: 0.346
[67]  [1320/1724] loss: 0.333, ave_loss: 0.346
[68]  [1340/1724] loss: 0.338, ave_loss: 0.346
[69]  [1360/1724] loss: 0.482, ave_loss: 0.348
[70]  [1380/1724] loss: 0.434, ave_loss: 0.349
[71]  [1400/1724] loss: 0.379, ave_loss: 0.350
[72]  [1420/1724] loss: 0.314, ave_loss: 0.349
[73]  [1440/1724] loss: 0.364, ave_loss: 0.349
[74]  [1460/1724] loss: 0.241, ave_loss: 0.348
[75]  [1480/1724] loss: 0.387, ave_loss: 0.348
[76]  [1500/1724] loss: 0.293, ave_loss: 0.348
[77]  [1520/1724] loss: 0.299, ave_loss: 0.347
[78]  [1540/1724] loss: 0.299, ave_loss: 0.346
[79]  [1560/1724] loss: 0.355, ave_loss: 0.346
[80]  [1580/1724] loss: 0.507, ave_loss: 0.348
[81]  [1600/1724] loss: 0.500, ave_loss: 0.350
[82]  [1620/1724] loss: 0.357, ave_loss: 0.350
[83]  [1640/1724] loss: 0.223, ave_loss: 0.349
[84]  [1660/1724] loss: 0.324, ave_loss: 0.349
[85]  [1680/1724] loss: 0.264, ave_loss: 0.348
[86]  [1700/1724] loss: 0.313, ave_loss: 0.347
[87]  [1720/1724] loss: 0.396, ave_loss: 0.348
[88]  [1740/1724] loss: 0.354, ave_loss: 0.348

Finished Training finishing at 2021-08-21 12:18:06.999274
printing_out epoch  56.148491879350345 learning rate: 1.5155772969309795e-05
1.47010997802305e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.478e-01
Validation Loss: 1.328e+04
Validation ROC: 0.7774
No improvement, still saving model
42.851508120649655 epochs left to go

Training Epoch 56.148491879350345/100 starting at 2021-08-21 12:18:47.205104
[1]  [0/1724] loss: 0.586, ave_loss: 0.586
[2]  [20/1724] loss: 0.450, ave_loss: 0.518
[3]  [40/1724] loss: 0.423, ave_loss: 0.486
[4]  [60/1724] loss: 0.266, ave_loss: 0.431
[5]  [80/1724] loss: 0.343, ave_loss: 0.413
[6]  [100/1724] loss: 0.361, ave_loss: 0.405
[7]  [120/1724] loss: 0.262, ave_loss: 0.384
[8]  [140/1724] loss: 0.369, ave_loss: 0.382
[9]  [160/1724] loss: 0.312, ave_loss: 0.375
[10]  [180/1724] loss: 0.234, ave_loss: 0.360
[11]  [200/1724] loss: 0.445, ave_loss: 0.368
[12]  [220/1724] loss: 0.299, ave_loss: 0.362
[13]  [240/1724] loss: 0.307, ave_loss: 0.358
[14]  [260/1724] loss: 0.364, ave_loss: 0.359
[15]  [280/1724] loss: 0.341, ave_loss: 0.357
[16]  [300/1724] loss: 0.428, ave_loss: 0.362
[17]  [320/1724] loss: 0.321, ave_loss: 0.359
[18]  [340/1724] loss: 0.299, ave_loss: 0.356
[19]  [360/1724] loss: 0.463, ave_loss: 0.362
[20]  [380/1724] loss: 0.289, ave_loss: 0.358
[21]  [400/1724] loss: 0.418, ave_loss: 0.361
[22]  [420/1724] loss: 0.441, ave_loss: 0.365
[23]  [440/1724] loss: 0.506, ave_loss: 0.371
[24]  [460/1724] loss: 0.204, ave_loss: 0.364
[25]  [480/1724] loss: 0.419, ave_loss: 0.366
[26]  [500/1724] loss: 0.383, ave_loss: 0.367
[27]  [520/1724] loss: 0.345, ave_loss: 0.366
[28]  [540/1724] loss: 0.434, ave_loss: 0.368
[29]  [560/1724] loss: 0.422, ave_loss: 0.370
[30]  [580/1724] loss: 0.383, ave_loss: 0.370
[31]  [600/1724] loss: 0.230, ave_loss: 0.366
[32]  [620/1724] loss: 0.376, ave_loss: 0.366
[33]  [640/1724] loss: 0.415, ave_loss: 0.368
[34]  [660/1724] loss: 0.338, ave_loss: 0.367
[35]  [680/1724] loss: 0.473, ave_loss: 0.370
[36]  [700/1724] loss: 0.328, ave_loss: 0.369
[37]  [720/1724] loss: 0.215, ave_loss: 0.365
[38]  [740/1724] loss: 0.287, ave_loss: 0.363
[39]  [760/1724] loss: 0.401, ave_loss: 0.364
[40]  [780/1724] loss: 0.329, ave_loss: 0.363
[41]  [800/1724] loss: 0.307, ave_loss: 0.361
[42]  [820/1724] loss: 0.444, ave_loss: 0.363
[43]  [840/1724] loss: 0.421, ave_loss: 0.365
[44]  [860/1724] loss: 0.323, ave_loss: 0.364
[45]  [880/1724] loss: 0.339, ave_loss: 0.363
[46]  [900/1724] loss: 0.370, ave_loss: 0.363
[47]  [920/1724] loss: 0.217, ave_loss: 0.360
[48]  [940/1724] loss: 0.292, ave_loss: 0.359
[49]  [960/1724] loss: 0.304, ave_loss: 0.358
[50]  [980/1724] loss: 0.288, ave_loss: 0.356
[51]  [1000/1724] loss: 0.349, ave_loss: 0.356
[52]  [1020/1724] loss: 0.396, ave_loss: 0.357
[53]  [1040/1724] loss: 0.346, ave_loss: 0.357
[54]  [1060/1724] loss: 0.330, ave_loss: 0.356
[55]  [1080/1724] loss: 0.471, ave_loss: 0.358
[56]  [1100/1724] loss: 0.432, ave_loss: 0.360
[57]  [1120/1724] loss: 0.354, ave_loss: 0.359
[58]  [1140/1724] loss: 0.453, ave_loss: 0.361
[59]  [1160/1724] loss: 0.300, ave_loss: 0.360
[60]  [1180/1724] loss: 0.286, ave_loss: 0.359
[61]  [1200/1724] loss: 0.400, ave_loss: 0.359
[62]  [1220/1724] loss: 0.220, ave_loss: 0.357
[63]  [1240/1724] loss: 0.345, ave_loss: 0.357
[64]  [1260/1724] loss: 0.448, ave_loss: 0.358
[65]  [1280/1724] loss: 0.341, ave_loss: 0.358
[66]  [1300/1724] loss: 0.348, ave_loss: 0.358
[67]  [1320/1724] loss: 0.297, ave_loss: 0.357
[68]  [1340/1724] loss: 0.317, ave_loss: 0.357
[69]  [1360/1724] loss: 0.345, ave_loss: 0.356
[70]  [1380/1724] loss: 0.378, ave_loss: 0.357
[71]  [1400/1724] loss: 0.286, ave_loss: 0.356
[72]  [1420/1724] loss: 0.570, ave_loss: 0.359
[73]  [1440/1724] loss: 0.336, ave_loss: 0.358
[74]  [1460/1724] loss: 0.385, ave_loss: 0.359
[75]  [1480/1724] loss: 0.347, ave_loss: 0.359
[76]  [1500/1724] loss: 0.283, ave_loss: 0.358
[77]  [1520/1724] loss: 0.187, ave_loss: 0.355
[78]  [1540/1724] loss: 0.428, ave_loss: 0.356
[79]  [1560/1724] loss: 0.409, ave_loss: 0.357
[80]  [1580/1724] loss: 0.436, ave_loss: 0.358
[81]  [1600/1724] loss: 0.324, ave_loss: 0.357
[82]  [1620/1724] loss: 0.450, ave_loss: 0.359
[83]  [1640/1724] loss: 0.513, ave_loss: 0.360
[84]  [1660/1724] loss: 0.281, ave_loss: 0.360
[85]  [1680/1724] loss: 0.253, ave_loss: 0.358
[86]  [1700/1724] loss: 0.505, ave_loss: 0.360
[87]  [1720/1724] loss: 0.314, ave_loss: 0.359
[88]  [1740/1724] loss: 0.197, ave_loss: 0.358

Finished Training finishing at 2021-08-21 12:20:46.216486
printing_out epoch  57.16937354988399 learning rate: 1.3777975426645267e-05
1.3364636163845909e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.576e-01
Validation Loss: 1.292e+04
Validation ROC: 0.7788
No improvement, still saving model
41.83062645011601 epochs left to go

Training Epoch 57.16937354988399/100 starting at 2021-08-21 12:22:12.959944
[1]  [0/1724] loss: 0.551, ave_loss: 0.551
[2]  [20/1724] loss: 0.448, ave_loss: 0.499
[3]  [40/1724] loss: 0.340, ave_loss: 0.446
[4]  [60/1724] loss: 0.248, ave_loss: 0.397
[5]  [80/1724] loss: 0.300, ave_loss: 0.377
[6]  [100/1724] loss: 0.494, ave_loss: 0.397
[7]  [120/1724] loss: 0.356, ave_loss: 0.391
[8]  [140/1724] loss: 0.411, ave_loss: 0.393
[9]  [160/1724] loss: 0.440, ave_loss: 0.398
[10]  [180/1724] loss: 0.330, ave_loss: 0.392
[11]  [200/1724] loss: 0.401, ave_loss: 0.392
[12]  [220/1724] loss: 0.335, ave_loss: 0.388
[13]  [240/1724] loss: 0.436, ave_loss: 0.391
[14]  [260/1724] loss: 0.388, ave_loss: 0.391
[15]  [280/1724] loss: 0.232, ave_loss: 0.381
[16]  [300/1724] loss: 0.355, ave_loss: 0.379
[17]  [320/1724] loss: 0.335, ave_loss: 0.376
[18]  [340/1724] loss: 0.238, ave_loss: 0.369
[19]  [360/1724] loss: 0.391, ave_loss: 0.370
[20]  [380/1724] loss: 0.248, ave_loss: 0.364
[21]  [400/1724] loss: 0.302, ave_loss: 0.361
[22]  [420/1724] loss: 0.307, ave_loss: 0.358
[23]  [440/1724] loss: 0.322, ave_loss: 0.357
[24]  [460/1724] loss: 0.332, ave_loss: 0.356
[25]  [480/1724] loss: 0.361, ave_loss: 0.356
[26]  [500/1724] loss: 0.350, ave_loss: 0.356
[27]  [520/1724] loss: 0.280, ave_loss: 0.353
[28]  [540/1724] loss: 0.385, ave_loss: 0.354
[29]  [560/1724] loss: 0.321, ave_loss: 0.353
[30]  [580/1724] loss: 0.443, ave_loss: 0.356
[31]  [600/1724] loss: 0.346, ave_loss: 0.356
[32]  [620/1724] loss: 0.288, ave_loss: 0.353
[33]  [640/1724] loss: 0.327, ave_loss: 0.353
[34]  [660/1724] loss: 0.233, ave_loss: 0.349
[35]  [680/1724] loss: 0.322, ave_loss: 0.348
[36]  [700/1724] loss: 0.354, ave_loss: 0.349
[37]  [720/1724] loss: 0.426, ave_loss: 0.351
[38]  [740/1724] loss: 0.336, ave_loss: 0.350
[39]  [760/1724] loss: 0.200, ave_loss: 0.346
[40]  [780/1724] loss: 0.518, ave_loss: 0.351
[41]  [800/1724] loss: 0.490, ave_loss: 0.354
[42]  [820/1724] loss: 0.458, ave_loss: 0.357
[43]  [840/1724] loss: 0.455, ave_loss: 0.359
[44]  [860/1724] loss: 0.397, ave_loss: 0.360
[45]  [880/1724] loss: 0.361, ave_loss: 0.360
[46]  [900/1724] loss: 0.397, ave_loss: 0.361
[47]  [920/1724] loss: 0.317, ave_loss: 0.360
[48]  [940/1724] loss: 0.265, ave_loss: 0.358
[49]  [960/1724] loss: 0.286, ave_loss: 0.356
[50]  [980/1724] loss: 0.311, ave_loss: 0.355
[51]  [1000/1724] loss: 0.374, ave_loss: 0.356
[52]  [1020/1724] loss: 0.355, ave_loss: 0.356
[53]  [1040/1724] loss: 0.427, ave_loss: 0.357
[54]  [1060/1724] loss: 0.455, ave_loss: 0.359
[55]  [1080/1724] loss: 0.240, ave_loss: 0.357
[56]  [1100/1724] loss: 0.274, ave_loss: 0.355
[57]  [1120/1724] loss: 0.392, ave_loss: 0.356
[58]  [1140/1724] loss: 0.223, ave_loss: 0.354
[59]  [1160/1724] loss: 0.323, ave_loss: 0.353
[60]  [1180/1724] loss: 0.284, ave_loss: 0.352
[61]  [1200/1724] loss: 0.297, ave_loss: 0.351
[62]  [1220/1724] loss: 0.476, ave_loss: 0.353
[63]  [1240/1724] loss: 0.228, ave_loss: 0.351
[64]  [1260/1724] loss: 0.530, ave_loss: 0.354
[65]  [1280/1724] loss: 0.304, ave_loss: 0.353
[66]  [1300/1724] loss: 0.221, ave_loss: 0.351
[67]  [1320/1724] loss: 0.266, ave_loss: 0.350
[68]  [1340/1724] loss: 0.275, ave_loss: 0.349
[69]  [1360/1724] loss: 0.444, ave_loss: 0.350
[70]  [1380/1724] loss: 0.500, ave_loss: 0.352
[71]  [1400/1724] loss: 0.440, ave_loss: 0.353
[72]  [1420/1724] loss: 0.282, ave_loss: 0.352
[73]  [1440/1724] loss: 0.332, ave_loss: 0.352
[74]  [1460/1724] loss: 0.421, ave_loss: 0.353
[75]  [1480/1724] loss: 0.244, ave_loss: 0.352
[76]  [1500/1724] loss: 0.309, ave_loss: 0.351
[77]  [1520/1724] loss: 0.431, ave_loss: 0.352
[78]  [1540/1724] loss: 0.350, ave_loss: 0.352
[79]  [1560/1724] loss: 0.256, ave_loss: 0.351
[80]  [1580/1724] loss: 0.272, ave_loss: 0.350
[81]  [1600/1724] loss: 0.512, ave_loss: 0.352
[82]  [1620/1724] loss: 0.426, ave_loss: 0.353
[83]  [1640/1724] loss: 0.266, ave_loss: 0.352
[84]  [1660/1724] loss: 0.250, ave_loss: 0.351
[85]  [1680/1724] loss: 0.251, ave_loss: 0.349
[86]  [1700/1724] loss: 0.362, ave_loss: 0.349
[87]  [1720/1724] loss: 0.280, ave_loss: 0.349
[88]  [1740/1724] loss: 0.437, ave_loss: 0.350

Finished Training finishing at 2021-08-21 12:24:19.634288
printing_out epoch  58.19025522041763 learning rate: 1.252543220604115e-05
1.2149669239859915e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.497e-01
Validation Loss: 1.357e+04
Validation ROC: 0.7756
No improvement, still saving model
40.80974477958237 epochs left to go

Training Epoch 58.19025522041763/100 starting at 2021-08-21 12:24:50.721691
[1]  [0/1724] loss: 0.529, ave_loss: 0.529
[2]  [20/1724] loss: 0.380, ave_loss: 0.454
[3]  [40/1724] loss: 0.381, ave_loss: 0.430
[4]  [60/1724] loss: 0.318, ave_loss: 0.402
[5]  [80/1724] loss: 0.279, ave_loss: 0.378
[6]  [100/1724] loss: 0.328, ave_loss: 0.369
[7]  [120/1724] loss: 0.366, ave_loss: 0.369
[8]  [140/1724] loss: 0.340, ave_loss: 0.365
[9]  [160/1724] loss: 0.276, ave_loss: 0.355
[10]  [180/1724] loss: 0.266, ave_loss: 0.346
[11]  [200/1724] loss: 0.254, ave_loss: 0.338
[12]  [220/1724] loss: 0.316, ave_loss: 0.336
[13]  [240/1724] loss: 0.405, ave_loss: 0.341
[14]  [260/1724] loss: 0.483, ave_loss: 0.352
[15]  [280/1724] loss: 0.292, ave_loss: 0.348
[16]  [300/1724] loss: 0.357, ave_loss: 0.348
[17]  [320/1724] loss: 0.514, ave_loss: 0.358
[18]  [340/1724] loss: 0.384, ave_loss: 0.359
[19]  [360/1724] loss: 0.455, ave_loss: 0.364
[20]  [380/1724] loss: 0.319, ave_loss: 0.362
[21]  [400/1724] loss: 0.386, ave_loss: 0.363
[22]  [420/1724] loss: 0.365, ave_loss: 0.363
[23]  [440/1724] loss: 0.314, ave_loss: 0.361
[24]  [460/1724] loss: 0.375, ave_loss: 0.362
[25]  [480/1724] loss: 0.345, ave_loss: 0.361
[26]  [500/1724] loss: 0.415, ave_loss: 0.363
[27]  [520/1724] loss: 0.363, ave_loss: 0.363
[28]  [540/1724] loss: 0.526, ave_loss: 0.369
[29]  [560/1724] loss: 0.305, ave_loss: 0.367
[30]  [580/1724] loss: 0.300, ave_loss: 0.365
[31]  [600/1724] loss: 0.265, ave_loss: 0.361
[32]  [620/1724] loss: 0.221, ave_loss: 0.357
[33]  [640/1724] loss: 0.315, ave_loss: 0.356
[34]  [660/1724] loss: 0.428, ave_loss: 0.358
[35]  [680/1724] loss: 0.361, ave_loss: 0.358
[36]  [700/1724] loss: 0.422, ave_loss: 0.360
[37]  [720/1724] loss: 0.208, ave_loss: 0.356
[38]  [740/1724] loss: 0.307, ave_loss: 0.354
[39]  [760/1724] loss: 0.221, ave_loss: 0.351
[40]  [780/1724] loss: 0.382, ave_loss: 0.352
[41]  [800/1724] loss: 0.459, ave_loss: 0.354
[42]  [820/1724] loss: 0.387, ave_loss: 0.355
[43]  [840/1724] loss: 0.349, ave_loss: 0.355
[44]  [860/1724] loss: 0.577, ave_loss: 0.360
[45]  [880/1724] loss: 0.353, ave_loss: 0.360
[46]  [900/1724] loss: 0.454, ave_loss: 0.362
[47]  [920/1724] loss: 0.442, ave_loss: 0.364
[48]  [940/1724] loss: 0.334, ave_loss: 0.363
[49]  [960/1724] loss: 0.336, ave_loss: 0.362
[50]  [980/1724] loss: 0.399, ave_loss: 0.363
[51]  [1000/1724] loss: 0.366, ave_loss: 0.363
[52]  [1020/1724] loss: 0.463, ave_loss: 0.365
[53]  [1040/1724] loss: 0.518, ave_loss: 0.368
[54]  [1060/1724] loss: 0.500, ave_loss: 0.371
[55]  [1080/1724] loss: 0.400, ave_loss: 0.371
[56]  [1100/1724] loss: 0.396, ave_loss: 0.371
[57]  [1120/1724] loss: 0.207, ave_loss: 0.369
[58]  [1140/1724] loss: 0.296, ave_loss: 0.367
[59]  [1160/1724] loss: 0.364, ave_loss: 0.367
[60]  [1180/1724] loss: 0.316, ave_loss: 0.366
[61]  [1200/1724] loss: 0.370, ave_loss: 0.366
[62]  [1220/1724] loss: 0.357, ave_loss: 0.366
[63]  [1240/1724] loss: 0.553, ave_loss: 0.369
[64]  [1260/1724] loss: 0.285, ave_loss: 0.368
[65]  [1280/1724] loss: 0.340, ave_loss: 0.368
[66]  [1300/1724] loss: 0.294, ave_loss: 0.366
[67]  [1320/1724] loss: 0.372, ave_loss: 0.367
[68]  [1340/1724] loss: 0.339, ave_loss: 0.366
[69]  [1360/1724] loss: 0.423, ave_loss: 0.367
[70]  [1380/1724] loss: 0.372, ave_loss: 0.367
[71]  [1400/1724] loss: 0.288, ave_loss: 0.366
[72]  [1420/1724] loss: 0.411, ave_loss: 0.367
[73]  [1440/1724] loss: 0.358, ave_loss: 0.366
[74]  [1460/1724] loss: 0.273, ave_loss: 0.365
[75]  [1480/1724] loss: 0.382, ave_loss: 0.365
[76]  [1500/1724] loss: 0.400, ave_loss: 0.366
[77]  [1520/1724] loss: 0.308, ave_loss: 0.365
[78]  [1540/1724] loss: 0.329, ave_loss: 0.365
[79]  [1560/1724] loss: 0.243, ave_loss: 0.363
[80]  [1580/1724] loss: 0.301, ave_loss: 0.362
[81]  [1600/1724] loss: 0.227, ave_loss: 0.361
[82]  [1620/1724] loss: 0.230, ave_loss: 0.359
[83]  [1640/1724] loss: 0.350, ave_loss: 0.359
[84]  [1660/1724] loss: 0.269, ave_loss: 0.358
[85]  [1680/1724] loss: 0.423, ave_loss: 0.359
[86]  [1700/1724] loss: 0.350, ave_loss: 0.359
[87]  [1720/1724] loss: 0.382, ave_loss: 0.359
[88]  [1740/1724] loss: 0.384, ave_loss: 0.359

Finished Training finishing at 2021-08-21 12:27:00.133616
printing_out epoch  59.21113689095127 learning rate: 1.13867565509465e-05
1.1045153854418104e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.591e-01
Validation Loss: 1.371e+04
Validation ROC: 0.7747
No improvement, still saving model
39.78886310904873 epochs left to go

Training Epoch 59.21113689095127/100 starting at 2021-08-21 12:27:31.560240
[1]  [0/1724] loss: 0.800, ave_loss: 0.800
[2]  [20/1724] loss: 0.283, ave_loss: 0.542
[3]  [40/1724] loss: 0.307, ave_loss: 0.463
[4]  [60/1724] loss: 0.302, ave_loss: 0.423
[5]  [80/1724] loss: 0.349, ave_loss: 0.408
[6]  [100/1724] loss: 0.198, ave_loss: 0.373
[7]  [120/1724] loss: 0.465, ave_loss: 0.386
[8]  [140/1724] loss: 0.303, ave_loss: 0.376
[9]  [160/1724] loss: 0.256, ave_loss: 0.363
[10]  [180/1724] loss: 0.384, ave_loss: 0.365
[11]  [200/1724] loss: 0.331, ave_loss: 0.362
[12]  [220/1724] loss: 0.428, ave_loss: 0.367
[13]  [240/1724] loss: 0.302, ave_loss: 0.362
[14]  [260/1724] loss: 0.304, ave_loss: 0.358
[15]  [280/1724] loss: 0.477, ave_loss: 0.366
[16]  [300/1724] loss: 0.340, ave_loss: 0.364
[17]  [320/1724] loss: 0.291, ave_loss: 0.360
[18]  [340/1724] loss: 0.393, ave_loss: 0.362
[19]  [360/1724] loss: 0.224, ave_loss: 0.355
[20]  [380/1724] loss: 0.287, ave_loss: 0.351
[21]  [400/1724] loss: 0.330, ave_loss: 0.350
[22]  [420/1724] loss: 0.308, ave_loss: 0.348
[23]  [440/1724] loss: 0.346, ave_loss: 0.348
[24]  [460/1724] loss: 0.297, ave_loss: 0.346
[25]  [480/1724] loss: 0.362, ave_loss: 0.347
[26]  [500/1724] loss: 0.412, ave_loss: 0.349
[27]  [520/1724] loss: 0.279, ave_loss: 0.347
[28]  [540/1724] loss: 0.228, ave_loss: 0.342
[29]  [560/1724] loss: 0.299, ave_loss: 0.341
[30]  [580/1724] loss: 0.247, ave_loss: 0.338
[31]  [600/1724] loss: 0.309, ave_loss: 0.337
[32]  [620/1724] loss: 0.187, ave_loss: 0.332
[33]  [640/1724] loss: 0.489, ave_loss: 0.337
[34]  [660/1724] loss: 0.337, ave_loss: 0.337
[35]  [680/1724] loss: 0.375, ave_loss: 0.338
[36]  [700/1724] loss: 0.350, ave_loss: 0.338
[37]  [720/1724] loss: 0.381, ave_loss: 0.340
[38]  [740/1724] loss: 0.262, ave_loss: 0.337
[39]  [760/1724] loss: 0.553, ave_loss: 0.343
[40]  [780/1724] loss: 0.427, ave_loss: 0.345
[41]  [800/1724] loss: 0.287, ave_loss: 0.344
[42]  [820/1724] loss: 0.421, ave_loss: 0.346
[43]  [840/1724] loss: 0.360, ave_loss: 0.346
[44]  [860/1724] loss: 0.311, ave_loss: 0.345
[45]  [880/1724] loss: 0.228, ave_loss: 0.342
[46]  [900/1724] loss: 0.265, ave_loss: 0.341
[47]  [920/1724] loss: 0.231, ave_loss: 0.338
[48]  [940/1724] loss: 0.346, ave_loss: 0.339
[49]  [960/1724] loss: 0.416, ave_loss: 0.340
[50]  [980/1724] loss: 0.302, ave_loss: 0.339
[51]  [1000/1724] loss: 0.273, ave_loss: 0.338
[52]  [1020/1724] loss: 0.432, ave_loss: 0.340
[53]  [1040/1724] loss: 0.383, ave_loss: 0.341
[54]  [1060/1724] loss: 0.391, ave_loss: 0.342
[55]  [1080/1724] loss: 0.411, ave_loss: 0.343
[56]  [1100/1724] loss: 0.254, ave_loss: 0.341
[57]  [1120/1724] loss: 0.222, ave_loss: 0.339
[58]  [1140/1724] loss: 0.310, ave_loss: 0.339
[59]  [1160/1724] loss: 0.338, ave_loss: 0.339
[60]  [1180/1724] loss: 0.380, ave_loss: 0.339
[61]  [1200/1724] loss: 0.402, ave_loss: 0.340
[62]  [1220/1724] loss: 0.230, ave_loss: 0.339
[63]  [1240/1724] loss: 0.437, ave_loss: 0.340
[64]  [1260/1724] loss: 0.390, ave_loss: 0.341
[65]  [1280/1724] loss: 0.408, ave_loss: 0.342
[66]  [1300/1724] loss: 0.271, ave_loss: 0.341
[67]  [1320/1724] loss: 0.211, ave_loss: 0.339
[68]  [1340/1724] loss: 0.243, ave_loss: 0.338
[69]  [1360/1724] loss: 0.344, ave_loss: 0.338
[70]  [1380/1724] loss: 0.305, ave_loss: 0.337
[71]  [1400/1724] loss: 0.229, ave_loss: 0.336
[72]  [1420/1724] loss: 0.214, ave_loss: 0.334
[73]  [1440/1724] loss: 0.338, ave_loss: 0.334
[74]  [1460/1724] loss: 0.374, ave_loss: 0.335
[75]  [1480/1724] loss: 0.295, ave_loss: 0.334
[76]  [1500/1724] loss: 0.360, ave_loss: 0.334
[77]  [1520/1724] loss: 0.383, ave_loss: 0.335
[78]  [1540/1724] loss: 0.243, ave_loss: 0.334
[79]  [1560/1724] loss: 0.432, ave_loss: 0.335
[80]  [1580/1724] loss: 0.315, ave_loss: 0.335
[81]  [1600/1724] loss: 0.269, ave_loss: 0.334
[82]  [1620/1724] loss: 0.360, ave_loss: 0.334
[83]  [1640/1724] loss: 0.536, ave_loss: 0.337
[84]  [1660/1724] loss: 0.518, ave_loss: 0.339
[85]  [1680/1724] loss: 0.432, ave_loss: 0.340
[86]  [1700/1724] loss: 0.352, ave_loss: 0.340
[87]  [1720/1724] loss: 0.393, ave_loss: 0.341
[88]  [1740/1724] loss: 0.271, ave_loss: 0.340

Finished Training finishing at 2021-08-21 12:29:29.340996
printing_out epoch  60.23201856148492 learning rate: 1.0351596864496817e-05
1.0041048958561912e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.400e-01
Validation Loss: 1.376e+04
Validation ROC: 0.7769
No improvement, still saving model
38.76798143851508 epochs left to go

Training Epoch 60.23201856148492/100 starting at 2021-08-21 12:30:15.866197
[1]  [0/1724] loss: 0.599, ave_loss: 0.599
[2]  [20/1724] loss: 0.377, ave_loss: 0.488
[3]  [40/1724] loss: 0.265, ave_loss: 0.414
[4]  [60/1724] loss: 0.397, ave_loss: 0.410
[5]  [80/1724] loss: 0.331, ave_loss: 0.394
[6]  [100/1724] loss: 0.267, ave_loss: 0.373
[7]  [120/1724] loss: 0.295, ave_loss: 0.362
[8]  [140/1724] loss: 0.301, ave_loss: 0.354
[9]  [160/1724] loss: 0.215, ave_loss: 0.339
[10]  [180/1724] loss: 0.375, ave_loss: 0.342
[11]  [200/1724] loss: 0.268, ave_loss: 0.335
[12]  [220/1724] loss: 0.273, ave_loss: 0.330
[13]  [240/1724] loss: 0.310, ave_loss: 0.329
[14]  [260/1724] loss: 0.355, ave_loss: 0.331
[15]  [280/1724] loss: 0.364, ave_loss: 0.333
[16]  [300/1724] loss: 0.323, ave_loss: 0.332
[17]  [320/1724] loss: 0.365, ave_loss: 0.334
[18]  [340/1724] loss: 0.315, ave_loss: 0.333
[19]  [360/1724] loss: 0.362, ave_loss: 0.335
[20]  [380/1724] loss: 0.347, ave_loss: 0.335
[21]  [400/1724] loss: 0.337, ave_loss: 0.335
[22]  [420/1724] loss: 0.327, ave_loss: 0.335
[23]  [440/1724] loss: 0.424, ave_loss: 0.339
[24]  [460/1724] loss: 0.231, ave_loss: 0.334
[25]  [480/1724] loss: 0.456, ave_loss: 0.339
[26]  [500/1724] loss: 0.296, ave_loss: 0.337
[27]  [520/1724] loss: 0.297, ave_loss: 0.336
[28]  [540/1724] loss: 0.352, ave_loss: 0.337
[29]  [560/1724] loss: 0.269, ave_loss: 0.334
[30]  [580/1724] loss: 0.342, ave_loss: 0.334
[31]  [600/1724] loss: 0.312, ave_loss: 0.334
[32]  [620/1724] loss: 0.428, ave_loss: 0.337
[33]  [640/1724] loss: 0.423, ave_loss: 0.339
[34]  [660/1724] loss: 0.286, ave_loss: 0.338
[35]  [680/1724] loss: 0.588, ave_loss: 0.345
[36]  [700/1724] loss: 0.426, ave_loss: 0.347
[37]  [720/1724] loss: 0.310, ave_loss: 0.346
[38]  [740/1724] loss: 0.323, ave_loss: 0.346
[39]  [760/1724] loss: 0.325, ave_loss: 0.345
[40]  [780/1724] loss: 0.313, ave_loss: 0.344
[41]  [800/1724] loss: 0.229, ave_loss: 0.341
[42]  [820/1724] loss: 0.465, ave_loss: 0.344
[43]  [840/1724] loss: 0.405, ave_loss: 0.346
[44]  [860/1724] loss: 0.259, ave_loss: 0.344
[45]  [880/1724] loss: 0.231, ave_loss: 0.341
[46]  [900/1724] loss: 0.408, ave_loss: 0.343
[47]  [920/1724] loss: 0.349, ave_loss: 0.343
[48]  [940/1724] loss: 0.387, ave_loss: 0.344
[49]  [960/1724] loss: 0.407, ave_loss: 0.345
[50]  [980/1724] loss: 0.402, ave_loss: 0.346
[51]  [1000/1724] loss: 0.347, ave_loss: 0.346
[52]  [1020/1724] loss: 0.325, ave_loss: 0.346
[53]  [1040/1724] loss: 0.276, ave_loss: 0.345
[54]  [1060/1724] loss: 0.282, ave_loss: 0.343
[55]  [1080/1724] loss: 0.298, ave_loss: 0.343
[56]  [1100/1724] loss: 0.189, ave_loss: 0.340
[57]  [1120/1724] loss: 0.555, ave_loss: 0.344
[58]  [1140/1724] loss: 0.290, ave_loss: 0.343
[59]  [1160/1724] loss: 0.340, ave_loss: 0.343
[60]  [1180/1724] loss: 0.383, ave_loss: 0.343
[61]  [1200/1724] loss: 0.416, ave_loss: 0.344
[62]  [1220/1724] loss: 0.469, ave_loss: 0.346
[63]  [1240/1724] loss: 0.417, ave_loss: 0.348
[64]  [1260/1724] loss: 0.279, ave_loss: 0.347
[65]  [1280/1724] loss: 0.209, ave_loss: 0.344
[66]  [1300/1724] loss: 0.316, ave_loss: 0.344
[67]  [1320/1724] loss: 0.398, ave_loss: 0.345
[68]  [1340/1724] loss: 0.331, ave_loss: 0.345
[69]  [1360/1724] loss: 0.431, ave_loss: 0.346
[70]  [1380/1724] loss: 0.223, ave_loss: 0.344
[71]  [1400/1724] loss: 0.313, ave_loss: 0.344
[72]  [1420/1724] loss: 0.324, ave_loss: 0.343
[73]  [1440/1724] loss: 0.337, ave_loss: 0.343
[74]  [1460/1724] loss: 0.304, ave_loss: 0.343
[75]  [1480/1724] loss: 0.297, ave_loss: 0.342
[76]  [1500/1724] loss: 0.390, ave_loss: 0.343
[77]  [1520/1724] loss: 0.329, ave_loss: 0.343
[78]  [1540/1724] loss: 0.204, ave_loss: 0.341
[79]  [1560/1724] loss: 0.372, ave_loss: 0.341
[80]  [1580/1724] loss: 0.394, ave_loss: 0.342
[81]  [1600/1724] loss: 0.331, ave_loss: 0.342
[82]  [1620/1724] loss: 0.256, ave_loss: 0.341
[83]  [1640/1724] loss: 0.370, ave_loss: 0.341
[84]  [1660/1724] loss: 0.346, ave_loss: 0.341
[85]  [1680/1724] loss: 0.262, ave_loss: 0.340
[86]  [1700/1724] loss: 0.445, ave_loss: 0.341
[87]  [1720/1724] loss: 0.281, ave_loss: 0.341
[88]  [1740/1724] loss: 0.290, ave_loss: 0.340

Finished Training finishing at 2021-08-21 12:32:19.342289
printing_out epoch  61.25290023201856 learning rate: 9.410542604088015e-06
9.128226325965374e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.401e-01
Validation Loss: 1.383e+04
Validation ROC: 0.7770
No improvement, still saving model
37.74709976798144 epochs left to go

Training Epoch 61.25290023201856/100 starting at 2021-08-21 12:33:06.690129
[1]  [0/1724] loss: 0.481, ave_loss: 0.481
[2]  [20/1724] loss: 0.337, ave_loss: 0.409
[3]  [40/1724] loss: 0.359, ave_loss: 0.392
[4]  [60/1724] loss: 0.312, ave_loss: 0.372
[5]  [80/1724] loss: 0.449, ave_loss: 0.387
[6]  [100/1724] loss: 0.176, ave_loss: 0.352
[7]  [120/1724] loss: 0.346, ave_loss: 0.351
[8]  [140/1724] loss: 0.409, ave_loss: 0.359
[9]  [160/1724] loss: 0.314, ave_loss: 0.354
[10]  [180/1724] loss: 0.264, ave_loss: 0.345
[11]  [200/1724] loss: 0.365, ave_loss: 0.347
[12]  [220/1724] loss: 0.458, ave_loss: 0.356
[13]  [240/1724] loss: 0.406, ave_loss: 0.360
[14]  [260/1724] loss: 0.306, ave_loss: 0.356
[15]  [280/1724] loss: 0.337, ave_loss: 0.355
[16]  [300/1724] loss: 0.233, ave_loss: 0.347
[17]  [320/1724] loss: 0.573, ave_loss: 0.360
[18]  [340/1724] loss: 0.409, ave_loss: 0.363
[19]  [360/1724] loss: 0.229, ave_loss: 0.356
[20]  [380/1724] loss: 0.262, ave_loss: 0.351
[21]  [400/1724] loss: 0.324, ave_loss: 0.350
[22]  [420/1724] loss: 0.291, ave_loss: 0.347
[23]  [440/1724] loss: 0.312, ave_loss: 0.346
[24]  [460/1724] loss: 0.268, ave_loss: 0.342
[25]  [480/1724] loss: 0.492, ave_loss: 0.348
[26]  [500/1724] loss: 0.368, ave_loss: 0.349
[27]  [520/1724] loss: 0.465, ave_loss: 0.353
[28]  [540/1724] loss: 0.292, ave_loss: 0.351
[29]  [560/1724] loss: 0.232, ave_loss: 0.347
[30]  [580/1724] loss: 0.402, ave_loss: 0.349
[31]  [600/1724] loss: 0.237, ave_loss: 0.345
[32]  [620/1724] loss: 0.353, ave_loss: 0.346
[33]  [640/1724] loss: 0.456, ave_loss: 0.349
[34]  [660/1724] loss: 0.332, ave_loss: 0.348
[35]  [680/1724] loss: 0.235, ave_loss: 0.345
[36]  [700/1724] loss: 0.379, ave_loss: 0.346
[37]  [720/1724] loss: 0.431, ave_loss: 0.348
[38]  [740/1724] loss: 0.437, ave_loss: 0.351
[39]  [760/1724] loss: 0.351, ave_loss: 0.351
[40]  [780/1724] loss: 0.339, ave_loss: 0.350
[41]  [800/1724] loss: 0.304, ave_loss: 0.349
[42]  [820/1724] loss: 0.397, ave_loss: 0.350
[43]  [840/1724] loss: 0.343, ave_loss: 0.350
[44]  [860/1724] loss: 0.340, ave_loss: 0.350
[45]  [880/1724] loss: 0.349, ave_loss: 0.350
[46]  [900/1724] loss: 0.181, ave_loss: 0.346
[47]  [920/1724] loss: 0.422, ave_loss: 0.348
[48]  [940/1724] loss: 0.253, ave_loss: 0.346
[49]  [960/1724] loss: 0.258, ave_loss: 0.344
[50]  [980/1724] loss: 0.530, ave_loss: 0.348
[51]  [1000/1724] loss: 0.183, ave_loss: 0.345
[52]  [1020/1724] loss: 0.396, ave_loss: 0.346
[53]  [1040/1724] loss: 0.390, ave_loss: 0.347
[54]  [1060/1724] loss: 0.266, ave_loss: 0.345
[55]  [1080/1724] loss: 0.237, ave_loss: 0.343
[56]  [1100/1724] loss: 0.240, ave_loss: 0.341
[57]  [1120/1724] loss: 0.326, ave_loss: 0.341
[58]  [1140/1724] loss: 0.349, ave_loss: 0.341
[59]  [1160/1724] loss: 0.253, ave_loss: 0.340
[60]  [1180/1724] loss: 0.471, ave_loss: 0.342
[61]  [1200/1724] loss: 0.454, ave_loss: 0.344
[62]  [1220/1724] loss: 0.424, ave_loss: 0.345
[63]  [1240/1724] loss: 0.283, ave_loss: 0.344
[64]  [1260/1724] loss: 0.340, ave_loss: 0.344
[65]  [1280/1724] loss: 0.437, ave_loss: 0.345
[66]  [1300/1724] loss: 0.357, ave_loss: 0.345
[67]  [1320/1724] loss: 0.315, ave_loss: 0.345
[68]  [1340/1724] loss: 0.409, ave_loss: 0.346
[69]  [1360/1724] loss: 0.346, ave_loss: 0.346
[70]  [1380/1724] loss: 0.374, ave_loss: 0.346
[71]  [1400/1724] loss: 0.235, ave_loss: 0.345
[72]  [1420/1724] loss: 0.195, ave_loss: 0.343
[73]  [1440/1724] loss: 0.246, ave_loss: 0.341
[74]  [1460/1724] loss: 0.290, ave_loss: 0.341
[75]  [1480/1724] loss: 0.395, ave_loss: 0.341
[76]  [1500/1724] loss: 0.276, ave_loss: 0.341
[77]  [1520/1724] loss: 0.366, ave_loss: 0.341
[78]  [1540/1724] loss: 0.452, ave_loss: 0.342
[79]  [1560/1724] loss: 0.337, ave_loss: 0.342
[80]  [1580/1724] loss: 0.422, ave_loss: 0.343
[81]  [1600/1724] loss: 0.448, ave_loss: 0.345
[82]  [1620/1724] loss: 0.301, ave_loss: 0.344
[83]  [1640/1724] loss: 0.268, ave_loss: 0.343
[84]  [1660/1724] loss: 0.207, ave_loss: 0.341
[85]  [1680/1724] loss: 0.305, ave_loss: 0.341
[86]  [1700/1724] loss: 0.482, ave_loss: 0.343
[87]  [1720/1724] loss: 0.495, ave_loss: 0.344
[88]  [1740/1724] loss: 0.282, ave_loss: 0.344

Finished Training finishing at 2021-08-21 12:34:59.539158
printing_out epoch  62.2737819025522 learning rate: 8.555038730989104e-06
8.29838756905943e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.437e-01
Validation Loss: 1.353e+04
Validation ROC: 0.7767
No improvement, still saving model
36.7262180974478 epochs left to go

Training Epoch 62.2737819025522/100 starting at 2021-08-21 12:36:23.655587
[1]  [0/1724] loss: 0.482, ave_loss: 0.482
[2]  [20/1724] loss: 0.440, ave_loss: 0.461
[3]  [40/1724] loss: 0.303, ave_loss: 0.408
[4]  [60/1724] loss: 0.288, ave_loss: 0.378
[5]  [80/1724] loss: 0.300, ave_loss: 0.363
[6]  [100/1724] loss: 0.244, ave_loss: 0.343
[7]  [120/1724] loss: 0.360, ave_loss: 0.345
[8]  [140/1724] loss: 0.328, ave_loss: 0.343
[9]  [160/1724] loss: 0.389, ave_loss: 0.348
[10]  [180/1724] loss: 0.278, ave_loss: 0.341
[11]  [200/1724] loss: 0.292, ave_loss: 0.337
[12]  [220/1724] loss: 0.453, ave_loss: 0.346
[13]  [240/1724] loss: 0.413, ave_loss: 0.352
[14]  [260/1724] loss: 0.387, ave_loss: 0.354
[15]  [280/1724] loss: 0.345, ave_loss: 0.353
[16]  [300/1724] loss: 0.501, ave_loss: 0.363
[17]  [320/1724] loss: 0.252, ave_loss: 0.356
[18]  [340/1724] loss: 0.243, ave_loss: 0.350
[19]  [360/1724] loss: 0.242, ave_loss: 0.344
[20]  [380/1724] loss: 0.395, ave_loss: 0.347
[21]  [400/1724] loss: 0.469, ave_loss: 0.353
[22]  [420/1724] loss: 0.453, ave_loss: 0.357
[23]  [440/1724] loss: 0.309, ave_loss: 0.355
[24]  [460/1724] loss: 0.436, ave_loss: 0.358
[25]  [480/1724] loss: 0.277, ave_loss: 0.355
[26]  [500/1724] loss: 0.374, ave_loss: 0.356
[27]  [520/1724] loss: 0.213, ave_loss: 0.351
[28]  [540/1724] loss: 0.377, ave_loss: 0.351
[29]  [560/1724] loss: 0.403, ave_loss: 0.353
[30]  [580/1724] loss: 0.374, ave_loss: 0.354
[31]  [600/1724] loss: 0.392, ave_loss: 0.355
[32]  [620/1724] loss: 0.289, ave_loss: 0.353
[33]  [640/1724] loss: 0.377, ave_loss: 0.354
[34]  [660/1724] loss: 0.220, ave_loss: 0.350
[35]  [680/1724] loss: 0.327, ave_loss: 0.349
[36]  [700/1724] loss: 0.264, ave_loss: 0.347
[37]  [720/1724] loss: 0.298, ave_loss: 0.346
[38]  [740/1724] loss: 0.320, ave_loss: 0.345
[39]  [760/1724] loss: 0.374, ave_loss: 0.346
[40]  [780/1724] loss: 0.323, ave_loss: 0.345
[41]  [800/1724] loss: 0.492, ave_loss: 0.349
[42]  [820/1724] loss: 0.285, ave_loss: 0.347
[43]  [840/1724] loss: 0.182, ave_loss: 0.343
[44]  [860/1724] loss: 0.328, ave_loss: 0.343
[45]  [880/1724] loss: 0.376, ave_loss: 0.344
[46]  [900/1724] loss: 0.331, ave_loss: 0.343
[47]  [920/1724] loss: 0.389, ave_loss: 0.344
[48]  [940/1724] loss: 0.382, ave_loss: 0.345
[49]  [960/1724] loss: 0.380, ave_loss: 0.346
[50]  [980/1724] loss: 0.175, ave_loss: 0.342
[51]  [1000/1724] loss: 0.580, ave_loss: 0.347
[52]  [1020/1724] loss: 0.405, ave_loss: 0.348
[53]  [1040/1724] loss: 0.274, ave_loss: 0.347
[54]  [1060/1724] loss: 0.327, ave_loss: 0.346
[55]  [1080/1724] loss: 0.319, ave_loss: 0.346
[56]  [1100/1724] loss: 0.397, ave_loss: 0.347
[57]  [1120/1724] loss: 0.236, ave_loss: 0.345
[58]  [1140/1724] loss: 0.321, ave_loss: 0.345
[59]  [1160/1724] loss: 0.352, ave_loss: 0.345
[60]  [1180/1724] loss: 0.167, ave_loss: 0.342
[61]  [1200/1724] loss: 0.230, ave_loss: 0.340
[62]  [1220/1724] loss: 0.370, ave_loss: 0.340
[63]  [1240/1724] loss: 0.240, ave_loss: 0.339
[64]  [1260/1724] loss: 0.361, ave_loss: 0.339
[65]  [1280/1724] loss: 0.285, ave_loss: 0.338
[66]  [1300/1724] loss: 0.309, ave_loss: 0.338
[67]  [1320/1724] loss: 0.134, ave_loss: 0.335
[68]  [1340/1724] loss: 0.406, ave_loss: 0.336
[69]  [1360/1724] loss: 0.319, ave_loss: 0.336
[70]  [1380/1724] loss: 0.289, ave_loss: 0.335
[71]  [1400/1724] loss: 0.408, ave_loss: 0.336
[72]  [1420/1724] loss: 0.415, ave_loss: 0.337
[73]  [1440/1724] loss: 0.384, ave_loss: 0.338
[74]  [1460/1724] loss: 0.380, ave_loss: 0.338
[75]  [1480/1724] loss: 0.530, ave_loss: 0.341
[76]  [1500/1724] loss: 0.278, ave_loss: 0.340
[77]  [1520/1724] loss: 0.304, ave_loss: 0.340
[78]  [1540/1724] loss: 0.321, ave_loss: 0.339
[79]  [1560/1724] loss: 0.321, ave_loss: 0.339
[80]  [1580/1724] loss: 0.238, ave_loss: 0.338
[81]  [1600/1724] loss: 0.356, ave_loss: 0.338
[82]  [1620/1724] loss: 0.481, ave_loss: 0.340
[83]  [1640/1724] loss: 0.284, ave_loss: 0.339
[84]  [1660/1724] loss: 0.434, ave_loss: 0.340
[85]  [1680/1724] loss: 0.464, ave_loss: 0.342
[86]  [1700/1724] loss: 0.474, ave_loss: 0.343
[87]  [1720/1724] loss: 0.381, ave_loss: 0.344
[88]  [1740/1724] loss: 0.371, ave_loss: 0.344

Finished Training finishing at 2021-08-21 12:38:29.726231
printing_out epoch  63.29466357308585 learning rate: 7.777307937262822e-06
7.543988699144937e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.440e-01
Validation Loss: 1.374e+04
Validation ROC: 0.7756
No improvement, still saving model
35.70533642691415 epochs left to go

Training Epoch 63.29466357308585/100 starting at 2021-08-21 12:38:57.242717
[1]  [0/1724] loss: 0.469, ave_loss: 0.469
[2]  [20/1724] loss: 0.443, ave_loss: 0.456
[3]  [40/1724] loss: 0.344, ave_loss: 0.419
[4]  [60/1724] loss: 0.308, ave_loss: 0.391
[5]  [80/1724] loss: 0.329, ave_loss: 0.379
[6]  [100/1724] loss: 0.356, ave_loss: 0.375
[7]  [120/1724] loss: 0.506, ave_loss: 0.394
[8]  [140/1724] loss: 0.294, ave_loss: 0.381
[9]  [160/1724] loss: 0.322, ave_loss: 0.375
[10]  [180/1724] loss: 0.483, ave_loss: 0.385
[11]  [200/1724] loss: 0.390, ave_loss: 0.386
[12]  [220/1724] loss: 0.371, ave_loss: 0.385
[13]  [240/1724] loss: 0.363, ave_loss: 0.383
[14]  [260/1724] loss: 0.395, ave_loss: 0.384
[15]  [280/1724] loss: 0.335, ave_loss: 0.381
[16]  [300/1724] loss: 0.526, ave_loss: 0.390
[17]  [320/1724] loss: 0.344, ave_loss: 0.387
[18]  [340/1724] loss: 0.386, ave_loss: 0.387
[19]  [360/1724] loss: 0.362, ave_loss: 0.386
[20]  [380/1724] loss: 0.335, ave_loss: 0.383
[21]  [400/1724] loss: 0.439, ave_loss: 0.386
[22]  [420/1724] loss: 0.243, ave_loss: 0.379
[23]  [440/1724] loss: 0.290, ave_loss: 0.375
[24]  [460/1724] loss: 0.312, ave_loss: 0.373
[25]  [480/1724] loss: 0.406, ave_loss: 0.374
[26]  [500/1724] loss: 0.285, ave_loss: 0.371
[27]  [520/1724] loss: 0.418, ave_loss: 0.372
[28]  [540/1724] loss: 0.479, ave_loss: 0.376
[29]  [560/1724] loss: 0.319, ave_loss: 0.374
[30]  [580/1724] loss: 0.350, ave_loss: 0.373
[31]  [600/1724] loss: 0.356, ave_loss: 0.373
[32]  [620/1724] loss: 0.409, ave_loss: 0.374
[33]  [640/1724] loss: 0.302, ave_loss: 0.372
[34]  [660/1724] loss: 0.280, ave_loss: 0.369
[35]  [680/1724] loss: 0.398, ave_loss: 0.370
[36]  [700/1724] loss: 0.318, ave_loss: 0.368
[37]  [720/1724] loss: 0.334, ave_loss: 0.367
[38]  [740/1724] loss: 0.330, ave_loss: 0.367
[39]  [760/1724] loss: 0.407, ave_loss: 0.368
[40]  [780/1724] loss: 0.287, ave_loss: 0.366
[41]  [800/1724] loss: 0.208, ave_loss: 0.362
[42]  [820/1724] loss: 0.391, ave_loss: 0.362
[43]  [840/1724] loss: 0.313, ave_loss: 0.361
[44]  [860/1724] loss: 0.324, ave_loss: 0.360
[45]  [880/1724] loss: 0.308, ave_loss: 0.359
[46]  [900/1724] loss: 0.441, ave_loss: 0.361
[47]  [920/1724] loss: 0.400, ave_loss: 0.362
[48]  [940/1724] loss: 0.284, ave_loss: 0.360
[49]  [960/1724] loss: 0.357, ave_loss: 0.360
[50]  [980/1724] loss: 0.369, ave_loss: 0.360
[51]  [1000/1724] loss: 0.465, ave_loss: 0.362
[52]  [1020/1724] loss: 0.381, ave_loss: 0.363
[53]  [1040/1724] loss: 0.303, ave_loss: 0.362
[54]  [1060/1724] loss: 0.306, ave_loss: 0.361
[55]  [1080/1724] loss: 0.492, ave_loss: 0.363
[56]  [1100/1724] loss: 0.363, ave_loss: 0.363
[57]  [1120/1724] loss: 0.452, ave_loss: 0.365
[58]  [1140/1724] loss: 0.433, ave_loss: 0.366
[59]  [1160/1724] loss: 0.222, ave_loss: 0.363
[60]  [1180/1724] loss: 0.358, ave_loss: 0.363
[61]  [1200/1724] loss: 0.238, ave_loss: 0.361
[62]  [1220/1724] loss: 0.381, ave_loss: 0.361
[63]  [1240/1724] loss: 0.382, ave_loss: 0.362
[64]  [1260/1724] loss: 0.368, ave_loss: 0.362
[65]  [1280/1724] loss: 0.285, ave_loss: 0.361
[66]  [1300/1724] loss: 0.191, ave_loss: 0.358
[67]  [1320/1724] loss: 0.260, ave_loss: 0.357
[68]  [1340/1724] loss: 0.236, ave_loss: 0.355
[69]  [1360/1724] loss: 0.375, ave_loss: 0.355
[70]  [1380/1724] loss: 0.340, ave_loss: 0.355
[71]  [1400/1724] loss: 0.309, ave_loss: 0.354
[72]  [1420/1724] loss: 0.306, ave_loss: 0.354
[73]  [1440/1724] loss: 0.288, ave_loss: 0.353
[74]  [1460/1724] loss: 0.402, ave_loss: 0.353
[75]  [1480/1724] loss: 0.392, ave_loss: 0.354
[76]  [1500/1724] loss: 0.333, ave_loss: 0.354
[77]  [1520/1724] loss: 0.362, ave_loss: 0.354
[78]  [1540/1724] loss: 0.292, ave_loss: 0.353
[79]  [1560/1724] loss: 0.427, ave_loss: 0.354
[80]  [1580/1724] loss: 0.334, ave_loss: 0.354
[81]  [1600/1724] loss: 0.227, ave_loss: 0.352
[82]  [1620/1724] loss: 0.369, ave_loss: 0.352
[83]  [1640/1724] loss: 0.252, ave_loss: 0.351
[84]  [1660/1724] loss: 0.368, ave_loss: 0.351
[85]  [1680/1724] loss: 0.383, ave_loss: 0.352
[86]  [1700/1724] loss: 0.301, ave_loss: 0.351
[87]  [1720/1724] loss: 0.284, ave_loss: 0.350
[88]  [1740/1724] loss: 0.302, ave_loss: 0.350

Finished Training finishing at 2021-08-21 12:41:03.516972
printing_out epoch  64.3155452436195 learning rate: 7.070279942966201e-06
6.8581715446772155e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.497e-01
Validation Loss: 1.363e+04
Validation ROC: 0.7743
No improvement, still saving model
34.684454756380504 epochs left to go

Training Epoch 64.3155452436195/100 starting at 2021-08-21 12:41:37.609180
[1]  [0/1724] loss: 0.524, ave_loss: 0.524
[2]  [20/1724] loss: 0.280, ave_loss: 0.402
[3]  [40/1724] loss: 0.306, ave_loss: 0.370
[4]  [60/1724] loss: 0.370, ave_loss: 0.370
[5]  [80/1724] loss: 0.464, ave_loss: 0.389
[6]  [100/1724] loss: 0.372, ave_loss: 0.386
[7]  [120/1724] loss: 0.450, ave_loss: 0.395
[8]  [140/1724] loss: 0.291, ave_loss: 0.382
[9]  [160/1724] loss: 0.416, ave_loss: 0.386
[10]  [180/1724] loss: 0.375, ave_loss: 0.385
[11]  [200/1724] loss: 0.183, ave_loss: 0.366
[12]  [220/1724] loss: 0.467, ave_loss: 0.375
[13]  [240/1724] loss: 0.371, ave_loss: 0.374
[14]  [260/1724] loss: 0.316, ave_loss: 0.370
[15]  [280/1724] loss: 0.240, ave_loss: 0.362
[16]  [300/1724] loss: 0.512, ave_loss: 0.371
[17]  [320/1724] loss: 0.437, ave_loss: 0.375
[18]  [340/1724] loss: 0.395, ave_loss: 0.376
[19]  [360/1724] loss: 0.276, ave_loss: 0.371
[20]  [380/1724] loss: 0.351, ave_loss: 0.370
[21]  [400/1724] loss: 0.364, ave_loss: 0.369
[22]  [420/1724] loss: 0.295, ave_loss: 0.366
[23]  [440/1724] loss: 0.374, ave_loss: 0.366
[24]  [460/1724] loss: 0.312, ave_loss: 0.364
[25]  [480/1724] loss: 0.548, ave_loss: 0.371
[26]  [500/1724] loss: 0.205, ave_loss: 0.365
[27]  [520/1724] loss: 0.362, ave_loss: 0.365
[28]  [540/1724] loss: 0.274, ave_loss: 0.362
[29]  [560/1724] loss: 0.303, ave_loss: 0.360
[30]  [580/1724] loss: 0.368, ave_loss: 0.360
[31]  [600/1724] loss: 0.316, ave_loss: 0.359
[32]  [620/1724] loss: 0.321, ave_loss: 0.357
[33]  [640/1724] loss: 0.205, ave_loss: 0.353
[34]  [660/1724] loss: 0.382, ave_loss: 0.354
[35]  [680/1724] loss: 0.417, ave_loss: 0.355
[36]  [700/1724] loss: 0.266, ave_loss: 0.353
[37]  [720/1724] loss: 0.316, ave_loss: 0.352
[38]  [740/1724] loss: 0.446, ave_loss: 0.354
[39]  [760/1724] loss: 0.316, ave_loss: 0.353
[40]  [780/1724] loss: 0.309, ave_loss: 0.352
[41]  [800/1724] loss: 0.279, ave_loss: 0.350
[42]  [820/1724] loss: 0.270, ave_loss: 0.349
[43]  [840/1724] loss: 0.266, ave_loss: 0.347
[44]  [860/1724] loss: 0.281, ave_loss: 0.345
[45]  [880/1724] loss: 0.443, ave_loss: 0.347
[46]  [900/1724] loss: 0.285, ave_loss: 0.346
[47]  [920/1724] loss: 0.256, ave_loss: 0.344
[48]  [940/1724] loss: 0.241, ave_loss: 0.342
[49]  [960/1724] loss: 0.361, ave_loss: 0.342
[50]  [980/1724] loss: 0.333, ave_loss: 0.342
[51]  [1000/1724] loss: 0.396, ave_loss: 0.343
[52]  [1020/1724] loss: 0.387, ave_loss: 0.344
[53]  [1040/1724] loss: 0.423, ave_loss: 0.346
[54]  [1060/1724] loss: 0.308, ave_loss: 0.345
[55]  [1080/1724] loss: 0.361, ave_loss: 0.345
[56]  [1100/1724] loss: 0.312, ave_loss: 0.345
[57]  [1120/1724] loss: 0.424, ave_loss: 0.346
[58]  [1140/1724] loss: 0.234, ave_loss: 0.344
[59]  [1160/1724] loss: 0.224, ave_loss: 0.342
[60]  [1180/1724] loss: 0.328, ave_loss: 0.342
[61]  [1200/1724] loss: 0.236, ave_loss: 0.340
[62]  [1220/1724] loss: 0.423, ave_loss: 0.341
[63]  [1240/1724] loss: 0.365, ave_loss: 0.342
[64]  [1260/1724] loss: 0.325, ave_loss: 0.341
[65]  [1280/1724] loss: 0.281, ave_loss: 0.341
[66]  [1300/1724] loss: 0.303, ave_loss: 0.340
[67]  [1320/1724] loss: 0.269, ave_loss: 0.339
[68]  [1340/1724] loss: 0.445, ave_loss: 0.340
[69]  [1360/1724] loss: 0.341, ave_loss: 0.340
[70]  [1380/1724] loss: 0.356, ave_loss: 0.341
[71]  [1400/1724] loss: 0.355, ave_loss: 0.341
[72]  [1420/1724] loss: 0.343, ave_loss: 0.341
[73]  [1440/1724] loss: 0.147, ave_loss: 0.338
[74]  [1460/1724] loss: 0.227, ave_loss: 0.337
[75]  [1480/1724] loss: 0.478, ave_loss: 0.339
[76]  [1500/1724] loss: 0.296, ave_loss: 0.338
[77]  [1520/1724] loss: 0.271, ave_loss: 0.337
[78]  [1540/1724] loss: 0.314, ave_loss: 0.337
[79]  [1560/1724] loss: 0.251, ave_loss: 0.336
[80]  [1580/1724] loss: 0.356, ave_loss: 0.336
[81]  [1600/1724] loss: 0.307, ave_loss: 0.336
[82]  [1620/1724] loss: 0.295, ave_loss: 0.335
[83]  [1640/1724] loss: 0.357, ave_loss: 0.335
[84]  [1660/1724] loss: 0.286, ave_loss: 0.335
[85]  [1680/1724] loss: 0.458, ave_loss: 0.336
[86]  [1700/1724] loss: 0.190, ave_loss: 0.335
[87]  [1720/1724] loss: 0.250, ave_loss: 0.334
[88]  [1740/1724] loss: 0.436, ave_loss: 0.335

Finished Training finishing at 2021-08-21 12:43:43.768486
printing_out epoch  65.33642691415314 learning rate: 6.427527220878365e-06
6.234701404252014e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.348e-01
Validation Loss: 1.349e+04
Validation ROC: 0.7743
No improvement, still saving model
33.66357308584686 epochs left to go

Training Epoch 65.33642691415314/100 starting at 2021-08-21 12:44:27.708452
[1]  [0/1724] loss: 0.499, ave_loss: 0.499
[2]  [20/1724] loss: 0.444, ave_loss: 0.472
[3]  [40/1724] loss: 0.219, ave_loss: 0.387
[4]  [60/1724] loss: 0.380, ave_loss: 0.386
[5]  [80/1724] loss: 0.352, ave_loss: 0.379
[6]  [100/1724] loss: 0.340, ave_loss: 0.372
[7]  [120/1724] loss: 0.459, ave_loss: 0.385
[8]  [140/1724] loss: 0.403, ave_loss: 0.387
[9]  [160/1724] loss: 0.283, ave_loss: 0.375
[10]  [180/1724] loss: 0.380, ave_loss: 0.376
[11]  [200/1724] loss: 0.360, ave_loss: 0.374
[12]  [220/1724] loss: 0.323, ave_loss: 0.370
[13]  [240/1724] loss: 0.232, ave_loss: 0.360
[14]  [260/1724] loss: 0.331, ave_loss: 0.358
[15]  [280/1724] loss: 0.349, ave_loss: 0.357
[16]  [300/1724] loss: 0.354, ave_loss: 0.357
[17]  [320/1724] loss: 0.388, ave_loss: 0.359
[18]  [340/1724] loss: 0.254, ave_loss: 0.353
[19]  [360/1724] loss: 0.341, ave_loss: 0.352
[20]  [380/1724] loss: 0.229, ave_loss: 0.346
[21]  [400/1724] loss: 0.349, ave_loss: 0.346
[22]  [420/1724] loss: 0.320, ave_loss: 0.345
[23]  [440/1724] loss: 0.411, ave_loss: 0.348
[24]  [460/1724] loss: 0.531, ave_loss: 0.356
[25]  [480/1724] loss: 0.304, ave_loss: 0.354
[26]  [500/1724] loss: 0.272, ave_loss: 0.350
[27]  [520/1724] loss: 0.288, ave_loss: 0.348
[28]  [540/1724] loss: 0.330, ave_loss: 0.347
[29]  [560/1724] loss: 0.254, ave_loss: 0.344
[30]  [580/1724] loss: 0.476, ave_loss: 0.349
[31]  [600/1724] loss: 0.463, ave_loss: 0.352
[32]  [620/1724] loss: 0.315, ave_loss: 0.351
[33]  [640/1724] loss: 0.330, ave_loss: 0.350
[34]  [660/1724] loss: 0.224, ave_loss: 0.347
[35]  [680/1724] loss: 0.329, ave_loss: 0.346
[36]  [700/1724] loss: 0.281, ave_loss: 0.344
[37]  [720/1724] loss: 0.303, ave_loss: 0.343
[38]  [740/1724] loss: 0.334, ave_loss: 0.343
[39]  [760/1724] loss: 0.247, ave_loss: 0.341
[40]  [780/1724] loss: 0.282, ave_loss: 0.339
[41]  [800/1724] loss: 0.305, ave_loss: 0.338
[42]  [820/1724] loss: 0.238, ave_loss: 0.336
[43]  [840/1724] loss: 0.395, ave_loss: 0.337
[44]  [860/1724] loss: 0.351, ave_loss: 0.338
[45]  [880/1724] loss: 0.356, ave_loss: 0.338
[46]  [900/1724] loss: 0.290, ave_loss: 0.337
[47]  [920/1724] loss: 0.509, ave_loss: 0.341
[48]  [940/1724] loss: 0.372, ave_loss: 0.341
[49]  [960/1724] loss: 0.547, ave_loss: 0.345
[50]  [980/1724] loss: 0.257, ave_loss: 0.344
[51]  [1000/1724] loss: 0.365, ave_loss: 0.344
[52]  [1020/1724] loss: 0.255, ave_loss: 0.342
[53]  [1040/1724] loss: 0.234, ave_loss: 0.340
[54]  [1060/1724] loss: 0.297, ave_loss: 0.340
[55]  [1080/1724] loss: 0.348, ave_loss: 0.340
[56]  [1100/1724] loss: 0.453, ave_loss: 0.342
[57]  [1120/1724] loss: 0.301, ave_loss: 0.341
[58]  [1140/1724] loss: 0.325, ave_loss: 0.341
[59]  [1160/1724] loss: 0.351, ave_loss: 0.341
[60]  [1180/1724] loss: 0.373, ave_loss: 0.341
[61]  [1200/1724] loss: 0.498, ave_loss: 0.344
[62]  [1220/1724] loss: 0.327, ave_loss: 0.344
[63]  [1240/1724] loss: 0.347, ave_loss: 0.344
[64]  [1260/1724] loss: 0.182, ave_loss: 0.341
[65]  [1280/1724] loss: 0.373, ave_loss: 0.342
[66]  [1300/1724] loss: 0.462, ave_loss: 0.344
[67]  [1320/1724] loss: 0.373, ave_loss: 0.344
[68]  [1340/1724] loss: 0.373, ave_loss: 0.344
[69]  [1360/1724] loss: 0.290, ave_loss: 0.344
[70]  [1380/1724] loss: 0.282, ave_loss: 0.343
[71]  [1400/1724] loss: 0.284, ave_loss: 0.342
[72]  [1420/1724] loss: 0.216, ave_loss: 0.340
[73]  [1440/1724] loss: 0.374, ave_loss: 0.341
[74]  [1460/1724] loss: 0.325, ave_loss: 0.340
[75]  [1480/1724] loss: 0.216, ave_loss: 0.339
[76]  [1500/1724] loss: 0.376, ave_loss: 0.339
[77]  [1520/1724] loss: 0.446, ave_loss: 0.341
[78]  [1540/1724] loss: 0.405, ave_loss: 0.341
[79]  [1560/1724] loss: 0.363, ave_loss: 0.342
[80]  [1580/1724] loss: 0.400, ave_loss: 0.342
[81]  [1600/1724] loss: 0.312, ave_loss: 0.342
[82]  [1620/1724] loss: 0.322, ave_loss: 0.342
[83]  [1640/1724] loss: 0.382, ave_loss: 0.342
[84]  [1660/1724] loss: 0.348, ave_loss: 0.342
[85]  [1680/1724] loss: 0.370, ave_loss: 0.343
[86]  [1700/1724] loss: 0.257, ave_loss: 0.342
[87]  [1720/1724] loss: 0.324, ave_loss: 0.342
[88]  [1740/1724] loss: 0.341, ave_loss: 0.342

Finished Training finishing at 2021-08-21 12:46:28.569155
printing_out epoch  66.35730858468678 learning rate: 5.843206564434877e-06
5.66791036750183e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.415e-01
Validation Loss: 1.343e+04
Validation ROC: 0.7761
No improvement, still saving model
32.64269141531322 epochs left to go

Training Epoch 66.35730858468678/100 starting at 2021-08-21 12:47:06.811928
[1]  [0/1724] loss: 0.976, ave_loss: 0.976
[2]  [20/1724] loss: 0.276, ave_loss: 0.626
[3]  [40/1724] loss: 0.344, ave_loss: 0.532
[4]  [60/1724] loss: 0.319, ave_loss: 0.479
[5]  [80/1724] loss: 0.438, ave_loss: 0.471
[6]  [100/1724] loss: 0.358, ave_loss: 0.452
[7]  [120/1724] loss: 0.241, ave_loss: 0.422
[8]  [140/1724] loss: 0.345, ave_loss: 0.412
[9]  [160/1724] loss: 0.378, ave_loss: 0.408
[10]  [180/1724] loss: 0.261, ave_loss: 0.394
[11]  [200/1724] loss: 0.395, ave_loss: 0.394
[12]  [220/1724] loss: 0.189, ave_loss: 0.377
[13]  [240/1724] loss: 0.291, ave_loss: 0.370
[14]  [260/1724] loss: 0.385, ave_loss: 0.371
[15]  [280/1724] loss: 0.290, ave_loss: 0.366
[16]  [300/1724] loss: 0.221, ave_loss: 0.357
[17]  [320/1724] loss: 0.356, ave_loss: 0.357
[18]  [340/1724] loss: 0.400, ave_loss: 0.359
[19]  [360/1724] loss: 0.429, ave_loss: 0.363
[20]  [380/1724] loss: 0.403, ave_loss: 0.365
[21]  [400/1724] loss: 0.412, ave_loss: 0.367
[22]  [420/1724] loss: 0.432, ave_loss: 0.370
[23]  [440/1724] loss: 0.342, ave_loss: 0.369
[24]  [460/1724] loss: 0.324, ave_loss: 0.367
[25]  [480/1724] loss: 0.351, ave_loss: 0.366
[26]  [500/1724] loss: 0.282, ave_loss: 0.363
[27]  [520/1724] loss: 0.359, ave_loss: 0.363
[28]  [540/1724] loss: 0.323, ave_loss: 0.361
[29]  [560/1724] loss: 0.252, ave_loss: 0.358
[30]  [580/1724] loss: 0.448, ave_loss: 0.361
[31]  [600/1724] loss: 0.348, ave_loss: 0.360
[32]  [620/1724] loss: 0.445, ave_loss: 0.363
[33]  [640/1724] loss: 0.263, ave_loss: 0.360
[34]  [660/1724] loss: 0.434, ave_loss: 0.362
[35]  [680/1724] loss: 0.479, ave_loss: 0.365
[36]  [700/1724] loss: 0.464, ave_loss: 0.368
[37]  [720/1724] loss: 0.365, ave_loss: 0.368
[38]  [740/1724] loss: 0.364, ave_loss: 0.368
[39]  [760/1724] loss: 0.523, ave_loss: 0.372
[40]  [780/1724] loss: 0.493, ave_loss: 0.375
[41]  [800/1724] loss: 0.173, ave_loss: 0.370
[42]  [820/1724] loss: 0.260, ave_loss: 0.367
[43]  [840/1724] loss: 0.396, ave_loss: 0.368
[44]  [860/1724] loss: 0.437, ave_loss: 0.370
[45]  [880/1724] loss: 0.345, ave_loss: 0.369
[46]  [900/1724] loss: 0.270, ave_loss: 0.367
[47]  [920/1724] loss: 0.323, ave_loss: 0.366
[48]  [940/1724] loss: 0.263, ave_loss: 0.364
[49]  [960/1724] loss: 0.367, ave_loss: 0.364
[50]  [980/1724] loss: 0.265, ave_loss: 0.362
[51]  [1000/1724] loss: 0.307, ave_loss: 0.361
[52]  [1020/1724] loss: 0.311, ave_loss: 0.360
[53]  [1040/1724] loss: 0.314, ave_loss: 0.359
[54]  [1060/1724] loss: 0.291, ave_loss: 0.358
[55]  [1080/1724] loss: 0.421, ave_loss: 0.359
[56]  [1100/1724] loss: 0.350, ave_loss: 0.359
[57]  [1120/1724] loss: 0.363, ave_loss: 0.359
[58]  [1140/1724] loss: 0.381, ave_loss: 0.359
[59]  [1160/1724] loss: 0.304, ave_loss: 0.358
[60]  [1180/1724] loss: 0.326, ave_loss: 0.358
[61]  [1200/1724] loss: 0.398, ave_loss: 0.358
[62]  [1220/1724] loss: 0.376, ave_loss: 0.359
[63]  [1240/1724] loss: 0.437, ave_loss: 0.360
[64]  [1260/1724] loss: 0.393, ave_loss: 0.360
[65]  [1280/1724] loss: 0.294, ave_loss: 0.359
[66]  [1300/1724] loss: 0.259, ave_loss: 0.358
[67]  [1320/1724] loss: 0.405, ave_loss: 0.359
[68]  [1340/1724] loss: 0.378, ave_loss: 0.359
[69]  [1360/1724] loss: 0.367, ave_loss: 0.359
[70]  [1380/1724] loss: 0.279, ave_loss: 0.358
[71]  [1400/1724] loss: 0.476, ave_loss: 0.359
[72]  [1420/1724] loss: 0.403, ave_loss: 0.360
[73]  [1440/1724] loss: 0.331, ave_loss: 0.360
[74]  [1460/1724] loss: 0.347, ave_loss: 0.360
[75]  [1480/1724] loss: 0.409, ave_loss: 0.360
[76]  [1500/1724] loss: 0.397, ave_loss: 0.361
[77]  [1520/1724] loss: 0.334, ave_loss: 0.360
[78]  [1540/1724] loss: 0.287, ave_loss: 0.359
[79]  [1560/1724] loss: 0.421, ave_loss: 0.360
[80]  [1580/1724] loss: 0.259, ave_loss: 0.359
[81]  [1600/1724] loss: 0.348, ave_loss: 0.359
[82]  [1620/1724] loss: 0.258, ave_loss: 0.358
[83]  [1640/1724] loss: 0.399, ave_loss: 0.358
[84]  [1660/1724] loss: 0.295, ave_loss: 0.357
[85]  [1680/1724] loss: 0.262, ave_loss: 0.356
[86]  [1700/1724] loss: 0.379, ave_loss: 0.356
[87]  [1720/1724] loss: 0.551, ave_loss: 0.359
[88]  [1740/1724] loss: 0.271, ave_loss: 0.358

Finished Training finishing at 2021-08-21 12:48:54.329661
printing_out epoch  67.37819025522042 learning rate: 5.3120059676680696e-06
5.152645788638028e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.576e-01
Validation Loss: 1.330e+04
Validation ROC: 0.7773
No improvement, still saving model
31.621809744779583 epochs left to go

Training Epoch 67.37819025522042/100 starting at 2021-08-21 12:50:21.660180
[1]  [0/1724] loss: 0.743, ave_loss: 0.743
[2]  [20/1724] loss: 0.415, ave_loss: 0.579
[3]  [40/1724] loss: 0.441, ave_loss: 0.533
[4]  [60/1724] loss: 0.266, ave_loss: 0.466
[5]  [80/1724] loss: 0.384, ave_loss: 0.450
[6]  [100/1724] loss: 0.271, ave_loss: 0.420
[7]  [120/1724] loss: 0.270, ave_loss: 0.399
[8]  [140/1724] loss: 0.266, ave_loss: 0.382
[9]  [160/1724] loss: 0.234, ave_loss: 0.366
[10]  [180/1724] loss: 0.314, ave_loss: 0.360
[11]  [200/1724] loss: 0.341, ave_loss: 0.359
[12]  [220/1724] loss: 0.372, ave_loss: 0.360
[13]  [240/1724] loss: 0.298, ave_loss: 0.355
[14]  [260/1724] loss: 0.294, ave_loss: 0.351
[15]  [280/1724] loss: 0.341, ave_loss: 0.350
[16]  [300/1724] loss: 0.300, ave_loss: 0.347
[17]  [320/1724] loss: 0.296, ave_loss: 0.344
[18]  [340/1724] loss: 0.326, ave_loss: 0.343
[19]  [360/1724] loss: 0.196, ave_loss: 0.335
[20]  [380/1724] loss: 0.331, ave_loss: 0.335
[21]  [400/1724] loss: 0.267, ave_loss: 0.332
[22]  [420/1724] loss: 0.272, ave_loss: 0.329
[23]  [440/1724] loss: 0.210, ave_loss: 0.324
[24]  [460/1724] loss: 0.385, ave_loss: 0.326
[25]  [480/1724] loss: 0.418, ave_loss: 0.330
[26]  [500/1724] loss: 0.280, ave_loss: 0.328
[27]  [520/1724] loss: 0.431, ave_loss: 0.332
[28]  [540/1724] loss: 0.378, ave_loss: 0.334
[29]  [560/1724] loss: 0.390, ave_loss: 0.336
[30]  [580/1724] loss: 0.312, ave_loss: 0.335
[31]  [600/1724] loss: 0.384, ave_loss: 0.336
[32]  [620/1724] loss: 0.235, ave_loss: 0.333
[33]  [640/1724] loss: 0.324, ave_loss: 0.333
[34]  [660/1724] loss: 0.331, ave_loss: 0.333
[35]  [680/1724] loss: 0.386, ave_loss: 0.334
[36]  [700/1724] loss: 0.246, ave_loss: 0.332
[37]  [720/1724] loss: 0.313, ave_loss: 0.331
[38]  [740/1724] loss: 0.258, ave_loss: 0.329
[39]  [760/1724] loss: 0.339, ave_loss: 0.330
[40]  [780/1724] loss: 0.425, ave_loss: 0.332
[41]  [800/1724] loss: 0.280, ave_loss: 0.331
[42]  [820/1724] loss: 0.384, ave_loss: 0.332
[43]  [840/1724] loss: 0.369, ave_loss: 0.333
[44]  [860/1724] loss: 0.364, ave_loss: 0.334
[45]  [880/1724] loss: 0.599, ave_loss: 0.340
[46]  [900/1724] loss: 0.392, ave_loss: 0.341
[47]  [920/1724] loss: 0.281, ave_loss: 0.339
[48]  [940/1724] loss: 0.513, ave_loss: 0.343
[49]  [960/1724] loss: 0.198, ave_loss: 0.340
[50]  [980/1724] loss: 0.322, ave_loss: 0.340
[51]  [1000/1724] loss: 0.392, ave_loss: 0.341
[52]  [1020/1724] loss: 0.229, ave_loss: 0.339
[53]  [1040/1724] loss: 0.547, ave_loss: 0.343
[54]  [1060/1724] loss: 0.350, ave_loss: 0.343
[55]  [1080/1724] loss: 0.374, ave_loss: 0.343
[56]  [1100/1724] loss: 0.325, ave_loss: 0.343
[57]  [1120/1724] loss: 0.287, ave_loss: 0.342
[58]  [1140/1724] loss: 0.350, ave_loss: 0.342
[59]  [1160/1724] loss: 0.339, ave_loss: 0.342
[60]  [1180/1724] loss: 0.250, ave_loss: 0.340
[61]  [1200/1724] loss: 0.272, ave_loss: 0.339
[62]  [1220/1724] loss: 0.524, ave_loss: 0.342
[63]  [1240/1724] loss: 0.313, ave_loss: 0.342
[64]  [1260/1724] loss: 0.384, ave_loss: 0.343
[65]  [1280/1724] loss: 0.211, ave_loss: 0.341
[66]  [1300/1724] loss: 0.319, ave_loss: 0.340
[67]  [1320/1724] loss: 0.503, ave_loss: 0.343
[68]  [1340/1724] loss: 0.526, ave_loss: 0.345
[69]  [1360/1724] loss: 0.379, ave_loss: 0.346
[70]  [1380/1724] loss: 0.287, ave_loss: 0.345
[71]  [1400/1724] loss: 0.464, ave_loss: 0.347
[72]  [1420/1724] loss: 0.365, ave_loss: 0.347
[73]  [1440/1724] loss: 0.160, ave_loss: 0.344
[74]  [1460/1724] loss: 0.375, ave_loss: 0.345
[75]  [1480/1724] loss: 0.379, ave_loss: 0.345
[76]  [1500/1724] loss: 0.299, ave_loss: 0.345
[77]  [1520/1724] loss: 0.274, ave_loss: 0.344
[78]  [1540/1724] loss: 0.339, ave_loss: 0.344
[79]  [1560/1724] loss: 0.391, ave_loss: 0.344
[80]  [1580/1724] loss: 0.441, ave_loss: 0.345
[81]  [1600/1724] loss: 0.246, ave_loss: 0.344
[82]  [1620/1724] loss: 0.411, ave_loss: 0.345
[83]  [1640/1724] loss: 0.267, ave_loss: 0.344
[84]  [1660/1724] loss: 0.282, ave_loss: 0.343
[85]  [1680/1724] loss: 0.401, ave_loss: 0.344
[86]  [1700/1724] loss: 0.314, ave_loss: 0.344
[87]  [1720/1724] loss: 0.257, ave_loss: 0.343
[88]  [1740/1724] loss: 0.295, ave_loss: 0.342

Finished Training finishing at 2021-08-21 12:52:28.791284
printing_out epoch  68.39907192575406 learning rate: 4.8290963342436995e-06
4.684223444216388e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.421e-01
Validation Loss: 1.335e+04
Validation ROC: 0.7773
No improvement, still saving model
30.600928074245942 epochs left to go

Training Epoch 68.39907192575406/100 starting at 2021-08-21 12:52:57.447731
[1]  [0/1724] loss: 0.740, ave_loss: 0.740
[2]  [20/1724] loss: 0.398, ave_loss: 0.569
[3]  [40/1724] loss: 0.347, ave_loss: 0.495
[4]  [60/1724] loss: 0.230, ave_loss: 0.429
[5]  [80/1724] loss: 0.507, ave_loss: 0.444
[6]  [100/1724] loss: 0.392, ave_loss: 0.436
[7]  [120/1724] loss: 0.360, ave_loss: 0.425
[8]  [140/1724] loss: 0.366, ave_loss: 0.417
[9]  [160/1724] loss: 0.197, ave_loss: 0.393
[10]  [180/1724] loss: 0.313, ave_loss: 0.385
[11]  [200/1724] loss: 0.227, ave_loss: 0.370
[12]  [220/1724] loss: 0.387, ave_loss: 0.372
[13]  [240/1724] loss: 0.197, ave_loss: 0.358
[14]  [260/1724] loss: 0.298, ave_loss: 0.354
[15]  [280/1724] loss: 0.313, ave_loss: 0.351
[16]  [300/1724] loss: 0.321, ave_loss: 0.350
[17]  [320/1724] loss: 0.619, ave_loss: 0.365
[18]  [340/1724] loss: 0.229, ave_loss: 0.358
[19]  [360/1724] loss: 0.248, ave_loss: 0.352
[20]  [380/1724] loss: 0.243, ave_loss: 0.347
[21]  [400/1724] loss: 0.501, ave_loss: 0.354
[22]  [420/1724] loss: 0.302, ave_loss: 0.352
[23]  [440/1724] loss: 0.426, ave_loss: 0.355
[24]  [460/1724] loss: 0.578, ave_loss: 0.364
[25]  [480/1724] loss: 0.417, ave_loss: 0.366
[26]  [500/1724] loss: 0.218, ave_loss: 0.361
[27]  [520/1724] loss: 0.500, ave_loss: 0.366
[28]  [540/1724] loss: 0.325, ave_loss: 0.364
[29]  [560/1724] loss: 0.352, ave_loss: 0.364
[30]  [580/1724] loss: 0.540, ave_loss: 0.370
[31]  [600/1724] loss: 0.314, ave_loss: 0.368
[32]  [620/1724] loss: 0.260, ave_loss: 0.365
[33]  [640/1724] loss: 0.302, ave_loss: 0.363
[34]  [660/1724] loss: 0.320, ave_loss: 0.361
[35]  [680/1724] loss: 0.409, ave_loss: 0.363
[36]  [700/1724] loss: 0.327, ave_loss: 0.362
[37]  [720/1724] loss: 0.264, ave_loss: 0.359
[38]  [740/1724] loss: 0.296, ave_loss: 0.357
[39]  [760/1724] loss: 0.208, ave_loss: 0.354
[40]  [780/1724] loss: 0.345, ave_loss: 0.353
[41]  [800/1724] loss: 0.304, ave_loss: 0.352
[42]  [820/1724] loss: 0.475, ave_loss: 0.355
[43]  [840/1724] loss: 0.272, ave_loss: 0.353
[44]  [860/1724] loss: 0.242, ave_loss: 0.351
[45]  [880/1724] loss: 0.204, ave_loss: 0.347
[46]  [900/1724] loss: 0.307, ave_loss: 0.347
[47]  [920/1724] loss: 0.370, ave_loss: 0.347
[48]  [940/1724] loss: 0.407, ave_loss: 0.348
[49]  [960/1724] loss: 0.226, ave_loss: 0.346
[50]  [980/1724] loss: 0.305, ave_loss: 0.345
[51]  [1000/1724] loss: 0.272, ave_loss: 0.344
[52]  [1020/1724] loss: 0.356, ave_loss: 0.344
[53]  [1040/1724] loss: 0.420, ave_loss: 0.345
[54]  [1060/1724] loss: 0.195, ave_loss: 0.342
[55]  [1080/1724] loss: 0.266, ave_loss: 0.341
[56]  [1100/1724] loss: 0.393, ave_loss: 0.342
[57]  [1120/1724] loss: 0.306, ave_loss: 0.341
[58]  [1140/1724] loss: 0.299, ave_loss: 0.341
[59]  [1160/1724] loss: 0.297, ave_loss: 0.340
[60]  [1180/1724] loss: 0.345, ave_loss: 0.340
[61]  [1200/1724] loss: 0.565, ave_loss: 0.344
[62]  [1220/1724] loss: 0.348, ave_loss: 0.344
[63]  [1240/1724] loss: 0.272, ave_loss: 0.343
[64]  [1260/1724] loss: 0.338, ave_loss: 0.342
[65]  [1280/1724] loss: 0.426, ave_loss: 0.344
[66]  [1300/1724] loss: 0.356, ave_loss: 0.344
[67]  [1320/1724] loss: 0.349, ave_loss: 0.344
[68]  [1340/1724] loss: 0.283, ave_loss: 0.343
[69]  [1360/1724] loss: 0.285, ave_loss: 0.342
[70]  [1380/1724] loss: 0.266, ave_loss: 0.341
[71]  [1400/1724] loss: 0.392, ave_loss: 0.342
[72]  [1420/1724] loss: 0.511, ave_loss: 0.344
[73]  [1440/1724] loss: 0.419, ave_loss: 0.345
[74]  [1460/1724] loss: 0.291, ave_loss: 0.345
[75]  [1480/1724] loss: 0.395, ave_loss: 0.345
[76]  [1500/1724] loss: 0.418, ave_loss: 0.346
[77]  [1520/1724] loss: 0.316, ave_loss: 0.346
[78]  [1540/1724] loss: 0.369, ave_loss: 0.346
[79]  [1560/1724] loss: 0.381, ave_loss: 0.347
[80]  [1580/1724] loss: 0.487, ave_loss: 0.348
[81]  [1600/1724] loss: 0.240, ave_loss: 0.347
[82]  [1620/1724] loss: 0.357, ave_loss: 0.347
[83]  [1640/1724] loss: 0.382, ave_loss: 0.347
[84]  [1660/1724] loss: 0.274, ave_loss: 0.347
[85]  [1680/1724] loss: 0.304, ave_loss: 0.346
[86]  [1700/1724] loss: 0.560, ave_loss: 0.349
[87]  [1720/1724] loss: 0.488, ave_loss: 0.350
[88]  [1740/1724] loss: 0.292, ave_loss: 0.350

Finished Training finishing at 2021-08-21 12:55:08.816371
printing_out epoch  69.4199535962877 learning rate: 4.390087576585181e-06
4.258384949287625e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.495e-01
Validation Loss: 1.359e+04
Validation ROC: 0.7761
No improvement, still saving model
29.580046403712302 epochs left to go

Training Epoch 69.4199535962877/100 starting at 2021-08-21 12:55:38.247510
[1]  [0/1724] loss: 0.521, ave_loss: 0.521
[2]  [20/1724] loss: 0.357, ave_loss: 0.439
[3]  [40/1724] loss: 0.252, ave_loss: 0.377
[4]  [60/1724] loss: 0.346, ave_loss: 0.369
[5]  [80/1724] loss: 0.347, ave_loss: 0.365
[6]  [100/1724] loss: 0.453, ave_loss: 0.379
[7]  [120/1724] loss: 0.345, ave_loss: 0.374
[8]  [140/1724] loss: 0.341, ave_loss: 0.370
[9]  [160/1724] loss: 0.516, ave_loss: 0.386
[10]  [180/1724] loss: 0.252, ave_loss: 0.373
[11]  [200/1724] loss: 0.469, ave_loss: 0.382
[12]  [220/1724] loss: 0.454, ave_loss: 0.388
[13]  [240/1724] loss: 0.319, ave_loss: 0.382
[14]  [260/1724] loss: 0.329, ave_loss: 0.379
[15]  [280/1724] loss: 0.445, ave_loss: 0.383
[16]  [300/1724] loss: 0.256, ave_loss: 0.375
[17]  [320/1724] loss: 0.397, ave_loss: 0.376
[18]  [340/1724] loss: 0.235, ave_loss: 0.369
[19]  [360/1724] loss: 0.378, ave_loss: 0.369
[20]  [380/1724] loss: 0.262, ave_loss: 0.364
[21]  [400/1724] loss: 0.311, ave_loss: 0.361
[22]  [420/1724] loss: 0.380, ave_loss: 0.362
[23]  [440/1724] loss: 0.255, ave_loss: 0.357
[24]  [460/1724] loss: 0.406, ave_loss: 0.359
[25]  [480/1724] loss: 0.211, ave_loss: 0.353
[26]  [500/1724] loss: 0.222, ave_loss: 0.348
[27]  [520/1724] loss: 0.303, ave_loss: 0.347
[28]  [540/1724] loss: 0.354, ave_loss: 0.347
[29]  [560/1724] loss: 0.339, ave_loss: 0.347
[30]  [580/1724] loss: 0.222, ave_loss: 0.343
[31]  [600/1724] loss: 0.390, ave_loss: 0.344
[32]  [620/1724] loss: 0.301, ave_loss: 0.343
[33]  [640/1724] loss: 0.238, ave_loss: 0.340
[34]  [660/1724] loss: 0.293, ave_loss: 0.338
[35]  [680/1724] loss: 0.466, ave_loss: 0.342
[36]  [700/1724] loss: 0.387, ave_loss: 0.343
[37]  [720/1724] loss: 0.458, ave_loss: 0.346
[38]  [740/1724] loss: 0.408, ave_loss: 0.348
[39]  [760/1724] loss: 0.337, ave_loss: 0.348
[40]  [780/1724] loss: 0.326, ave_loss: 0.347
[41]  [800/1724] loss: 0.266, ave_loss: 0.345
[42]  [820/1724] loss: 0.415, ave_loss: 0.347
[43]  [840/1724] loss: 0.282, ave_loss: 0.345
[44]  [860/1724] loss: 0.309, ave_loss: 0.344
[45]  [880/1724] loss: 0.319, ave_loss: 0.344
[46]  [900/1724] loss: 0.503, ave_loss: 0.347
[47]  [920/1724] loss: 0.319, ave_loss: 0.347
[48]  [940/1724] loss: 0.380, ave_loss: 0.347
[49]  [960/1724] loss: 0.326, ave_loss: 0.347
[50]  [980/1724] loss: 0.257, ave_loss: 0.345
[51]  [1000/1724] loss: 0.226, ave_loss: 0.343
[52]  [1020/1724] loss: 0.422, ave_loss: 0.344
[53]  [1040/1724] loss: 0.314, ave_loss: 0.344
[54]  [1060/1724] loss: 0.287, ave_loss: 0.343
[55]  [1080/1724] loss: 0.359, ave_loss: 0.343
[56]  [1100/1724] loss: 0.348, ave_loss: 0.343
[57]  [1120/1724] loss: 0.281, ave_loss: 0.342
[58]  [1140/1724] loss: 0.269, ave_loss: 0.341
[59]  [1160/1724] loss: 0.229, ave_loss: 0.339
[60]  [1180/1724] loss: 0.368, ave_loss: 0.339
[61]  [1200/1724] loss: 0.254, ave_loss: 0.338
[62]  [1220/1724] loss: 0.356, ave_loss: 0.338
[63]  [1240/1724] loss: 0.324, ave_loss: 0.338
[64]  [1260/1724] loss: 0.423, ave_loss: 0.339
[65]  [1280/1724] loss: 0.235, ave_loss: 0.338
[66]  [1300/1724] loss: 0.355, ave_loss: 0.338
[67]  [1320/1724] loss: 0.332, ave_loss: 0.338
[68]  [1340/1724] loss: 0.204, ave_loss: 0.336
[69]  [1360/1724] loss: 0.213, ave_loss: 0.334
[70]  [1380/1724] loss: 0.370, ave_loss: 0.335
[71]  [1400/1724] loss: 0.272, ave_loss: 0.334
[72]  [1420/1724] loss: 0.363, ave_loss: 0.334
[73]  [1440/1724] loss: 0.345, ave_loss: 0.334
[74]  [1460/1724] loss: 0.342, ave_loss: 0.334
[75]  [1480/1724] loss: 0.336, ave_loss: 0.334
[76]  [1500/1724] loss: 0.236, ave_loss: 0.333
[77]  [1520/1724] loss: 0.556, ave_loss: 0.336
[78]  [1540/1724] loss: 0.629, ave_loss: 0.340
[79]  [1560/1724] loss: 0.378, ave_loss: 0.340
[80]  [1580/1724] loss: 0.347, ave_loss: 0.340
[81]  [1600/1724] loss: 0.285, ave_loss: 0.340
[82]  [1620/1724] loss: 0.293, ave_loss: 0.339
[83]  [1640/1724] loss: 0.391, ave_loss: 0.340
[84]  [1660/1724] loss: 0.303, ave_loss: 0.339
[85]  [1680/1724] loss: 0.290, ave_loss: 0.339
[86]  [1700/1724] loss: 0.303, ave_loss: 0.338
[87]  [1720/1724] loss: 0.199, ave_loss: 0.337
[88]  [1740/1724] loss: 0.165, ave_loss: 0.335

Finished Training finishing at 2021-08-21 12:57:37.441395
printing_out epoch  70.44083526682135 learning rate: 3.990988705986528e-06
3.871259044806932e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.348e-01
Validation Loss: 1.344e+04
Validation ROC: 0.7759
No improvement, still saving model
28.559164733178648 epochs left to go

Training Epoch 70.44083526682135/100 starting at 2021-08-21 12:58:23.396841
[1]  [0/1724] loss: 0.617, ave_loss: 0.617
[2]  [20/1724] loss: 0.251, ave_loss: 0.434
[3]  [40/1724] loss: 0.522, ave_loss: 0.463
[4]  [60/1724] loss: 0.394, ave_loss: 0.446
[5]  [80/1724] loss: 0.374, ave_loss: 0.431
[6]  [100/1724] loss: 0.310, ave_loss: 0.411
[7]  [120/1724] loss: 0.418, ave_loss: 0.412
[8]  [140/1724] loss: 0.230, ave_loss: 0.389
[9]  [160/1724] loss: 0.662, ave_loss: 0.420
[10]  [180/1724] loss: 0.248, ave_loss: 0.403
[11]  [200/1724] loss: 0.395, ave_loss: 0.402
[12]  [220/1724] loss: 0.384, ave_loss: 0.400
[13]  [240/1724] loss: 0.263, ave_loss: 0.390
[14]  [260/1724] loss: 0.415, ave_loss: 0.392
[15]  [280/1724] loss: 0.336, ave_loss: 0.388
[16]  [300/1724] loss: 0.501, ave_loss: 0.395
[17]  [320/1724] loss: 0.226, ave_loss: 0.385
[18]  [340/1724] loss: 0.258, ave_loss: 0.378
[19]  [360/1724] loss: 0.255, ave_loss: 0.372
[20]  [380/1724] loss: 0.322, ave_loss: 0.369
[21]  [400/1724] loss: 0.281, ave_loss: 0.365
[22]  [420/1724] loss: 0.376, ave_loss: 0.365
[23]  [440/1724] loss: 0.461, ave_loss: 0.370
[24]  [460/1724] loss: 0.263, ave_loss: 0.365
[25]  [480/1724] loss: 0.306, ave_loss: 0.363
[26]  [500/1724] loss: 0.326, ave_loss: 0.361
[27]  [520/1724] loss: 0.298, ave_loss: 0.359
[28]  [540/1724] loss: 0.348, ave_loss: 0.359
[29]  [560/1724] loss: 0.201, ave_loss: 0.353
[30]  [580/1724] loss: 0.395, ave_loss: 0.355
[31]  [600/1724] loss: 0.482, ave_loss: 0.359
[32]  [620/1724] loss: 0.326, ave_loss: 0.358
[33]  [640/1724] loss: 0.237, ave_loss: 0.354
[34]  [660/1724] loss: 0.243, ave_loss: 0.351
[35]  [680/1724] loss: 0.310, ave_loss: 0.350
[36]  [700/1724] loss: 0.462, ave_loss: 0.353
[37]  [720/1724] loss: 0.371, ave_loss: 0.353
[38]  [740/1724] loss: 0.394, ave_loss: 0.354
[39]  [760/1724] loss: 0.535, ave_loss: 0.359
[40]  [780/1724] loss: 0.308, ave_loss: 0.358
[41]  [800/1724] loss: 0.339, ave_loss: 0.357
[42]  [820/1724] loss: 0.381, ave_loss: 0.358
[43]  [840/1724] loss: 0.306, ave_loss: 0.357
[44]  [860/1724] loss: 0.247, ave_loss: 0.354
[45]  [880/1724] loss: 0.443, ave_loss: 0.356
[46]  [900/1724] loss: 0.403, ave_loss: 0.357
[47]  [920/1724] loss: 0.336, ave_loss: 0.357
[48]  [940/1724] loss: 0.280, ave_loss: 0.355
[49]  [960/1724] loss: 0.338, ave_loss: 0.355
[50]  [980/1724] loss: 0.311, ave_loss: 0.354
[51]  [1000/1724] loss: 0.400, ave_loss: 0.355
[52]  [1020/1724] loss: 0.385, ave_loss: 0.355
[53]  [1040/1724] loss: 0.235, ave_loss: 0.353
[54]  [1060/1724] loss: 0.410, ave_loss: 0.354
[55]  [1080/1724] loss: 0.416, ave_loss: 0.355
[56]  [1100/1724] loss: 0.220, ave_loss: 0.353
[57]  [1120/1724] loss: 0.473, ave_loss: 0.355
[58]  [1140/1724] loss: 0.416, ave_loss: 0.356
[59]  [1160/1724] loss: 0.451, ave_loss: 0.358
[60]  [1180/1724] loss: 0.283, ave_loss: 0.356
[61]  [1200/1724] loss: 0.266, ave_loss: 0.355
[62]  [1220/1724] loss: 0.250, ave_loss: 0.353
[63]  [1240/1724] loss: 0.547, ave_loss: 0.356
[64]  [1260/1724] loss: 0.297, ave_loss: 0.355
[65]  [1280/1724] loss: 0.267, ave_loss: 0.354
[66]  [1300/1724] loss: 0.349, ave_loss: 0.354
[67]  [1320/1724] loss: 0.342, ave_loss: 0.354
[68]  [1340/1724] loss: 0.422, ave_loss: 0.355
[69]  [1360/1724] loss: 0.354, ave_loss: 0.355
[70]  [1380/1724] loss: 0.296, ave_loss: 0.354
[71]  [1400/1724] loss: 0.419, ave_loss: 0.355
[72]  [1420/1724] loss: 0.396, ave_loss: 0.355
[73]  [1440/1724] loss: 0.257, ave_loss: 0.354
[74]  [1460/1724] loss: 0.329, ave_loss: 0.354
[75]  [1480/1724] loss: 0.457, ave_loss: 0.355
[76]  [1500/1724] loss: 0.251, ave_loss: 0.354
[77]  [1520/1724] loss: 0.389, ave_loss: 0.354
[78]  [1540/1724] loss: 0.260, ave_loss: 0.353
[79]  [1560/1724] loss: 0.249, ave_loss: 0.352
[80]  [1580/1724] loss: 0.202, ave_loss: 0.350
[81]  [1600/1724] loss: 0.267, ave_loss: 0.349
[82]  [1620/1724] loss: 0.294, ave_loss: 0.348
[83]  [1640/1724] loss: 0.340, ave_loss: 0.348
[84]  [1660/1724] loss: 0.245, ave_loss: 0.347
[85]  [1680/1724] loss: 0.546, ave_loss: 0.349
[86]  [1700/1724] loss: 0.348, ave_loss: 0.349
[87]  [1720/1724] loss: 0.396, ave_loss: 0.350
[88]  [1740/1724] loss: 0.354, ave_loss: 0.350

Finished Training finishing at 2021-08-21 13:00:19.432856
printing_out epoch  71.46171693735499 learning rate: 3.6281715508968433e-06
3.519326404369938e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.496e-01
Validation Loss: 1.348e+04
Validation ROC: 0.7763
No improvement, still saving model
27.538283062645007 epochs left to go

Training Epoch 71.46171693735499/100 starting at 2021-08-21 13:00:58.724866
[1]  [0/1724] loss: 0.539, ave_loss: 0.539
[2]  [20/1724] loss: 0.348, ave_loss: 0.443
[3]  [40/1724] loss: 0.417, ave_loss: 0.435
[4]  [60/1724] loss: 0.396, ave_loss: 0.425
[5]  [80/1724] loss: 0.467, ave_loss: 0.433
[6]  [100/1724] loss: 0.432, ave_loss: 0.433
[7]  [120/1724] loss: 0.205, ave_loss: 0.401
[8]  [140/1724] loss: 0.477, ave_loss: 0.410
[9]  [160/1724] loss: 0.358, ave_loss: 0.404
[10]  [180/1724] loss: 0.318, ave_loss: 0.396
[11]  [200/1724] loss: 0.497, ave_loss: 0.405
[12]  [220/1724] loss: 0.239, ave_loss: 0.391
[13]  [240/1724] loss: 0.248, ave_loss: 0.380
[14]  [260/1724] loss: 0.234, ave_loss: 0.370
[15]  [280/1724] loss: 0.507, ave_loss: 0.379
[16]  [300/1724] loss: 0.336, ave_loss: 0.376
[17]  [320/1724] loss: 0.262, ave_loss: 0.369
[18]  [340/1724] loss: 0.255, ave_loss: 0.363
[19]  [360/1724] loss: 0.328, ave_loss: 0.361
[20]  [380/1724] loss: 0.533, ave_loss: 0.370
[21]  [400/1724] loss: 0.471, ave_loss: 0.375
[22]  [420/1724] loss: 0.298, ave_loss: 0.371
[23]  [440/1724] loss: 0.431, ave_loss: 0.374
[24]  [460/1724] loss: 0.327, ave_loss: 0.372
[25]  [480/1724] loss: 0.328, ave_loss: 0.370
[26]  [500/1724] loss: 0.204, ave_loss: 0.364
[27]  [520/1724] loss: 0.260, ave_loss: 0.360
[28]  [540/1724] loss: 0.405, ave_loss: 0.361
[29]  [560/1724] loss: 0.343, ave_loss: 0.361
[30]  [580/1724] loss: 0.311, ave_loss: 0.359
[31]  [600/1724] loss: 0.304, ave_loss: 0.357
[32]  [620/1724] loss: 0.296, ave_loss: 0.355
[33]  [640/1724] loss: 0.319, ave_loss: 0.354
[34]  [660/1724] loss: 0.165, ave_loss: 0.349
[35]  [680/1724] loss: 0.324, ave_loss: 0.348
[36]  [700/1724] loss: 0.237, ave_loss: 0.345
[37]  [720/1724] loss: 0.414, ave_loss: 0.347
[38]  [740/1724] loss: 0.407, ave_loss: 0.348
[39]  [760/1724] loss: 0.353, ave_loss: 0.348
[40]  [780/1724] loss: 0.377, ave_loss: 0.349
[41]  [800/1724] loss: 0.334, ave_loss: 0.349
[42]  [820/1724] loss: 0.290, ave_loss: 0.347
[43]  [840/1724] loss: 0.248, ave_loss: 0.345
[44]  [860/1724] loss: 0.385, ave_loss: 0.346
[45]  [880/1724] loss: 0.338, ave_loss: 0.346
[46]  [900/1724] loss: 0.316, ave_loss: 0.345
[47]  [920/1724] loss: 0.321, ave_loss: 0.345
[48]  [940/1724] loss: 0.355, ave_loss: 0.345
[49]  [960/1724] loss: 0.188, ave_loss: 0.342
[50]  [980/1724] loss: 0.427, ave_loss: 0.343
[51]  [1000/1724] loss: 0.590, ave_loss: 0.348
[52]  [1020/1724] loss: 0.314, ave_loss: 0.348
[53]  [1040/1724] loss: 0.298, ave_loss: 0.347
[54]  [1060/1724] loss: 0.309, ave_loss: 0.346
[55]  [1080/1724] loss: 0.293, ave_loss: 0.345
[56]  [1100/1724] loss: 0.223, ave_loss: 0.343
[57]  [1120/1724] loss: 0.293, ave_loss: 0.342
[58]  [1140/1724] loss: 0.390, ave_loss: 0.343
[59]  [1160/1724] loss: 0.356, ave_loss: 0.343
[60]  [1180/1724] loss: 0.354, ave_loss: 0.343
[61]  [1200/1724] loss: 0.294, ave_loss: 0.342
[62]  [1220/1724] loss: 0.271, ave_loss: 0.341
[63]  [1240/1724] loss: 0.463, ave_loss: 0.343
[64]  [1260/1724] loss: 0.330, ave_loss: 0.343
[65]  [1280/1724] loss: 0.354, ave_loss: 0.343
[66]  [1300/1724] loss: 0.265, ave_loss: 0.342
[67]  [1320/1724] loss: 0.401, ave_loss: 0.343
[68]  [1340/1724] loss: 0.376, ave_loss: 0.343
[69]  [1360/1724] loss: 0.199, ave_loss: 0.341
[70]  [1380/1724] loss: 0.330, ave_loss: 0.341
[71]  [1400/1724] loss: 0.344, ave_loss: 0.341
[72]  [1420/1724] loss: 0.211, ave_loss: 0.339
[73]  [1440/1724] loss: 0.299, ave_loss: 0.339
[74]  [1460/1724] loss: 0.304, ave_loss: 0.338
[75]  [1480/1724] loss: 0.299, ave_loss: 0.338
[76]  [1500/1724] loss: 0.383, ave_loss: 0.338
[77]  [1520/1724] loss: 0.186, ave_loss: 0.336
[78]  [1540/1724] loss: 0.318, ave_loss: 0.336
[79]  [1560/1724] loss: 0.336, ave_loss: 0.336
[80]  [1580/1724] loss: 0.492, ave_loss: 0.338
[81]  [1600/1724] loss: 0.541, ave_loss: 0.341
[82]  [1620/1724] loss: 0.307, ave_loss: 0.340
[83]  [1640/1724] loss: 0.350, ave_loss: 0.340
[84]  [1660/1724] loss: 0.369, ave_loss: 0.341
[85]  [1680/1724] loss: 0.370, ave_loss: 0.341
[86]  [1700/1724] loss: 0.262, ave_loss: 0.340
[87]  [1720/1724] loss: 0.397, ave_loss: 0.341
[88]  [1740/1724] loss: 0.304, ave_loss: 0.340

Finished Training finishing at 2021-08-21 13:02:54.063374
printing_out epoch  72.48259860788863 learning rate: 3.2983377735425847e-06
3.199387640336307e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.403e-01
Validation Loss: 1.336e+04
Validation ROC: 0.7772
No improvement, still saving model
26.517401392111367 epochs left to go

Training Epoch 72.48259860788863/100 starting at 2021-08-21 13:04:27.347227
[1]  [0/1724] loss: 0.454, ave_loss: 0.454
[2]  [20/1724] loss: 0.414, ave_loss: 0.434
[3]  [40/1724] loss: 0.301, ave_loss: 0.390
[4]  [60/1724] loss: 0.310, ave_loss: 0.370
[5]  [80/1724] loss: 0.281, ave_loss: 0.352
[6]  [100/1724] loss: 0.436, ave_loss: 0.366
[7]  [120/1724] loss: 0.419, ave_loss: 0.374
[8]  [140/1724] loss: 0.415, ave_loss: 0.379
[9]  [160/1724] loss: 0.405, ave_loss: 0.382
[10]  [180/1724] loss: 0.255, ave_loss: 0.369
[11]  [200/1724] loss: 0.305, ave_loss: 0.363
[12]  [220/1724] loss: 0.472, ave_loss: 0.372
[13]  [240/1724] loss: 0.257, ave_loss: 0.364
[14]  [260/1724] loss: 0.353, ave_loss: 0.363
[15]  [280/1724] loss: 0.324, ave_loss: 0.360
[16]  [300/1724] loss: 0.284, ave_loss: 0.355
[17]  [320/1724] loss: 0.257, ave_loss: 0.350
[18]  [340/1724] loss: 0.373, ave_loss: 0.351
[19]  [360/1724] loss: 0.329, ave_loss: 0.350
[20]  [380/1724] loss: 0.428, ave_loss: 0.354
[21]  [400/1724] loss: 0.272, ave_loss: 0.350
[22]  [420/1724] loss: 0.346, ave_loss: 0.350
[23]  [440/1724] loss: 0.414, ave_loss: 0.352
[24]  [460/1724] loss: 0.356, ave_loss: 0.353
[25]  [480/1724] loss: 0.287, ave_loss: 0.350
[26]  [500/1724] loss: 0.256, ave_loss: 0.346
[27]  [520/1724] loss: 0.309, ave_loss: 0.345
[28]  [540/1724] loss: 0.241, ave_loss: 0.341
[29]  [560/1724] loss: 0.270, ave_loss: 0.339
[30]  [580/1724] loss: 0.496, ave_loss: 0.344
[31]  [600/1724] loss: 0.305, ave_loss: 0.343
[32]  [620/1724] loss: 0.198, ave_loss: 0.338
[33]  [640/1724] loss: 0.233, ave_loss: 0.335
[34]  [660/1724] loss: 0.368, ave_loss: 0.336
[35]  [680/1724] loss: 0.269, ave_loss: 0.334
[36]  [700/1724] loss: 0.337, ave_loss: 0.334
[37]  [720/1724] loss: 0.379, ave_loss: 0.335
[38]  [740/1724] loss: 0.285, ave_loss: 0.334
[39]  [760/1724] loss: 0.372, ave_loss: 0.335
[40]  [780/1724] loss: 0.321, ave_loss: 0.335
[41]  [800/1724] loss: 0.316, ave_loss: 0.334
[42]  [820/1724] loss: 0.426, ave_loss: 0.336
[43]  [840/1724] loss: 0.272, ave_loss: 0.335
[44]  [860/1724] loss: 0.259, ave_loss: 0.333
[45]  [880/1724] loss: 0.395, ave_loss: 0.335
[46]  [900/1724] loss: 0.272, ave_loss: 0.333
[47]  [920/1724] loss: 0.415, ave_loss: 0.335
[48]  [940/1724] loss: 0.220, ave_loss: 0.333
[49]  [960/1724] loss: 0.262, ave_loss: 0.331
[50]  [980/1724] loss: 0.479, ave_loss: 0.334
[51]  [1000/1724] loss: 0.339, ave_loss: 0.334
[52]  [1020/1724] loss: 0.359, ave_loss: 0.335
[53]  [1040/1724] loss: 0.281, ave_loss: 0.334
[54]  [1060/1724] loss: 0.290, ave_loss: 0.333
[55]  [1080/1724] loss: 0.220, ave_loss: 0.331
[56]  [1100/1724] loss: 0.394, ave_loss: 0.332
[57]  [1120/1724] loss: 0.239, ave_loss: 0.330
[58]  [1140/1724] loss: 0.274, ave_loss: 0.329
[59]  [1160/1724] loss: 0.415, ave_loss: 0.331
[60]  [1180/1724] loss: 0.314, ave_loss: 0.330
[61]  [1200/1724] loss: 0.441, ave_loss: 0.332
[62]  [1220/1724] loss: 0.311, ave_loss: 0.332
[63]  [1240/1724] loss: 0.317, ave_loss: 0.332
[64]  [1260/1724] loss: 0.440, ave_loss: 0.333
[65]  [1280/1724] loss: 0.397, ave_loss: 0.334
[66]  [1300/1724] loss: 0.259, ave_loss: 0.333
[67]  [1320/1724] loss: 0.609, ave_loss: 0.337
[68]  [1340/1724] loss: 0.396, ave_loss: 0.338
[69]  [1360/1724] loss: 0.298, ave_loss: 0.338
[70]  [1380/1724] loss: 0.384, ave_loss: 0.338
[71]  [1400/1724] loss: 0.272, ave_loss: 0.337
[72]  [1420/1724] loss: 0.296, ave_loss: 0.337
[73]  [1440/1724] loss: 0.204, ave_loss: 0.335
[74]  [1460/1724] loss: 0.335, ave_loss: 0.335
[75]  [1480/1724] loss: 0.541, ave_loss: 0.338
[76]  [1500/1724] loss: 0.179, ave_loss: 0.336
[77]  [1520/1724] loss: 0.370, ave_loss: 0.336
[78]  [1540/1724] loss: 0.420, ave_loss: 0.337
[79]  [1560/1724] loss: 0.354, ave_loss: 0.337
[80]  [1580/1724] loss: 0.442, ave_loss: 0.339
[81]  [1600/1724] loss: 0.389, ave_loss: 0.339
[82]  [1620/1724] loss: 0.539, ave_loss: 0.342
[83]  [1640/1724] loss: 0.293, ave_loss: 0.341
[84]  [1660/1724] loss: 0.384, ave_loss: 0.342
[85]  [1680/1724] loss: 0.325, ave_loss: 0.341
[86]  [1700/1724] loss: 0.409, ave_loss: 0.342
[87]  [1720/1724] loss: 0.436, ave_loss: 0.343
[88]  [1740/1724] loss: 0.373, ave_loss: 0.344

Finished Training finishing at 2021-08-21 13:06:30.387263
printing_out epoch  73.50348027842227 learning rate: 2.998488885038713e-06
2.9085342184875518e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.437e-01
Validation Loss: 1.321e+04
Validation ROC: 0.7775
No improvement, still saving model
25.496519721577727 epochs left to go

Training Epoch 73.50348027842227/100 starting at 2021-08-21 13:06:57.742147
[1]  [0/1724] loss: 0.285, ave_loss: 0.285
[2]  [20/1724] loss: 0.249, ave_loss: 0.267
[3]  [40/1724] loss: 0.345, ave_loss: 0.293
[4]  [60/1724] loss: 0.385, ave_loss: 0.316
[5]  [80/1724] loss: 0.220, ave_loss: 0.297
[6]  [100/1724] loss: 0.299, ave_loss: 0.297
[7]  [120/1724] loss: 0.360, ave_loss: 0.306
[8]  [140/1724] loss: 0.438, ave_loss: 0.322
[9]  [160/1724] loss: 0.186, ave_loss: 0.307
[10]  [180/1724] loss: 0.307, ave_loss: 0.307
[11]  [200/1724] loss: 0.457, ave_loss: 0.321
[12]  [220/1724] loss: 0.363, ave_loss: 0.324
[13]  [240/1724] loss: 0.370, ave_loss: 0.328
[14]  [260/1724] loss: 0.312, ave_loss: 0.327
[15]  [280/1724] loss: 0.311, ave_loss: 0.326
[16]  [300/1724] loss: 0.288, ave_loss: 0.323
[17]  [320/1724] loss: 0.409, ave_loss: 0.328
[18]  [340/1724] loss: 0.410, ave_loss: 0.333
[19]  [360/1724] loss: 0.278, ave_loss: 0.330
[20]  [380/1724] loss: 0.310, ave_loss: 0.329
[21]  [400/1724] loss: 0.489, ave_loss: 0.337
[22]  [420/1724] loss: 0.235, ave_loss: 0.332
[23]  [440/1724] loss: 0.428, ave_loss: 0.336
[24]  [460/1724] loss: 0.341, ave_loss: 0.336
[25]  [480/1724] loss: 0.333, ave_loss: 0.336
[26]  [500/1724] loss: 0.358, ave_loss: 0.337
[27]  [520/1724] loss: 0.287, ave_loss: 0.335
[28]  [540/1724] loss: 0.280, ave_loss: 0.333
[29]  [560/1724] loss: 0.435, ave_loss: 0.337
[30]  [580/1724] loss: 0.273, ave_loss: 0.335
[31]  [600/1724] loss: 0.228, ave_loss: 0.331
[32]  [620/1724] loss: 0.423, ave_loss: 0.334
[33]  [640/1724] loss: 0.449, ave_loss: 0.338
[34]  [660/1724] loss: 0.468, ave_loss: 0.341
[35]  [680/1724] loss: 0.445, ave_loss: 0.344
[36]  [700/1724] loss: 0.412, ave_loss: 0.346
[37]  [720/1724] loss: 0.335, ave_loss: 0.346
[38]  [740/1724] loss: 0.644, ave_loss: 0.354
[39]  [760/1724] loss: 0.416, ave_loss: 0.355
[40]  [780/1724] loss: 0.481, ave_loss: 0.358
[41]  [800/1724] loss: 0.302, ave_loss: 0.357
[42]  [820/1724] loss: 0.289, ave_loss: 0.355
[43]  [840/1724] loss: 0.312, ave_loss: 0.354
[44]  [860/1724] loss: 0.232, ave_loss: 0.352
[45]  [880/1724] loss: 0.384, ave_loss: 0.352
[46]  [900/1724] loss: 0.424, ave_loss: 0.354
[47]  [920/1724] loss: 0.330, ave_loss: 0.353
[48]  [940/1724] loss: 0.509, ave_loss: 0.357
[49]  [960/1724] loss: 0.535, ave_loss: 0.360
[50]  [980/1724] loss: 0.227, ave_loss: 0.358
[51]  [1000/1724] loss: 0.292, ave_loss: 0.356
[52]  [1020/1724] loss: 0.276, ave_loss: 0.355
[53]  [1040/1724] loss: 0.344, ave_loss: 0.355
[54]  [1060/1724] loss: 0.236, ave_loss: 0.352
[55]  [1080/1724] loss: 0.257, ave_loss: 0.351
[56]  [1100/1724] loss: 0.245, ave_loss: 0.349
[57]  [1120/1724] loss: 0.411, ave_loss: 0.350
[58]  [1140/1724] loss: 0.329, ave_loss: 0.350
[59]  [1160/1724] loss: 0.219, ave_loss: 0.347
[60]  [1180/1724] loss: 0.240, ave_loss: 0.346
[61]  [1200/1724] loss: 0.334, ave_loss: 0.345
[62]  [1220/1724] loss: 0.250, ave_loss: 0.344
[63]  [1240/1724] loss: 0.426, ave_loss: 0.345
[64]  [1260/1724] loss: 0.425, ave_loss: 0.346
[65]  [1280/1724] loss: 0.480, ave_loss: 0.348
[66]  [1300/1724] loss: 0.393, ave_loss: 0.349
[67]  [1320/1724] loss: 0.261, ave_loss: 0.348
[68]  [1340/1724] loss: 0.277, ave_loss: 0.347
[69]  [1360/1724] loss: 0.278, ave_loss: 0.346
[70]  [1380/1724] loss: 0.369, ave_loss: 0.346
[71]  [1400/1724] loss: 0.253, ave_loss: 0.345
[72]  [1420/1724] loss: 0.380, ave_loss: 0.345
[73]  [1440/1724] loss: 0.378, ave_loss: 0.346
[74]  [1460/1724] loss: 0.358, ave_loss: 0.346
[75]  [1480/1724] loss: 0.338, ave_loss: 0.346
[76]  [1500/1724] loss: 0.383, ave_loss: 0.346
[77]  [1520/1724] loss: 0.254, ave_loss: 0.345
[78]  [1540/1724] loss: 0.273, ave_loss: 0.344
[79]  [1560/1724] loss: 0.490, ave_loss: 0.346
[80]  [1580/1724] loss: 0.374, ave_loss: 0.346
[81]  [1600/1724] loss: 0.394, ave_loss: 0.347
[82]  [1620/1724] loss: 0.345, ave_loss: 0.347
[83]  [1640/1724] loss: 0.309, ave_loss: 0.346
[84]  [1660/1724] loss: 0.283, ave_loss: 0.346
[85]  [1680/1724] loss: 0.361, ave_loss: 0.346
[86]  [1700/1724] loss: 0.362, ave_loss: 0.346
[87]  [1720/1724] loss: 0.299, ave_loss: 0.346
[88]  [1740/1724] loss: 0.225, ave_loss: 0.344

Finished Training finishing at 2021-08-21 13:09:08.651647
printing_out epoch  74.52436194895591 learning rate: 2.72589898639883e-06
2.644122016806865e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.441e-01
Validation Loss: 1.323e+04
Validation ROC: 0.7774
No improvement, still saving model
24.475638051044086 epochs left to go

Training Epoch 74.52436194895591/100 starting at 2021-08-21 13:09:39.116165
[1]  [0/1724] loss: 0.661, ave_loss: 0.661
[2]  [20/1724] loss: 0.303, ave_loss: 0.482
[3]  [40/1724] loss: 0.494, ave_loss: 0.486
[4]  [60/1724] loss: 0.359, ave_loss: 0.455
[5]  [80/1724] loss: 0.378, ave_loss: 0.439
[6]  [100/1724] loss: 0.260, ave_loss: 0.409
[7]  [120/1724] loss: 0.397, ave_loss: 0.408
[8]  [140/1724] loss: 0.217, ave_loss: 0.384
[9]  [160/1724] loss: 0.251, ave_loss: 0.369
[10]  [180/1724] loss: 0.228, ave_loss: 0.355
[11]  [200/1724] loss: 0.393, ave_loss: 0.358
[12]  [220/1724] loss: 0.477, ave_loss: 0.368
[13]  [240/1724] loss: 0.329, ave_loss: 0.365
[14]  [260/1724] loss: 0.375, ave_loss: 0.366
[15]  [280/1724] loss: 0.355, ave_loss: 0.365
[16]  [300/1724] loss: 0.373, ave_loss: 0.366
[17]  [320/1724] loss: 0.292, ave_loss: 0.361
[18]  [340/1724] loss: 0.294, ave_loss: 0.358
[19]  [360/1724] loss: 0.399, ave_loss: 0.360
[20]  [380/1724] loss: 0.421, ave_loss: 0.363
[21]  [400/1724] loss: 0.236, ave_loss: 0.357
[22]  [420/1724] loss: 0.418, ave_loss: 0.360
[23]  [440/1724] loss: 0.245, ave_loss: 0.355
[24]  [460/1724] loss: 0.411, ave_loss: 0.357
[25]  [480/1724] loss: 0.296, ave_loss: 0.354
[26]  [500/1724] loss: 0.323, ave_loss: 0.353
[27]  [520/1724] loss: 0.411, ave_loss: 0.355
[28]  [540/1724] loss: 0.407, ave_loss: 0.357
[29]  [560/1724] loss: 0.429, ave_loss: 0.360
[30]  [580/1724] loss: 0.425, ave_loss: 0.362
[31]  [600/1724] loss: 0.247, ave_loss: 0.358
[32]  [620/1724] loss: 0.327, ave_loss: 0.357
[33]  [640/1724] loss: 0.297, ave_loss: 0.355
[34]  [660/1724] loss: 0.162, ave_loss: 0.350
[35]  [680/1724] loss: 0.265, ave_loss: 0.347
[36]  [700/1724] loss: 0.373, ave_loss: 0.348
[37]  [720/1724] loss: 0.253, ave_loss: 0.345
[38]  [740/1724] loss: 0.328, ave_loss: 0.345
[39]  [760/1724] loss: 0.514, ave_loss: 0.349
[40]  [780/1724] loss: 0.382, ave_loss: 0.350
[41]  [800/1724] loss: 0.288, ave_loss: 0.349
[42]  [820/1724] loss: 0.289, ave_loss: 0.347
[43]  [840/1724] loss: 0.291, ave_loss: 0.346
[44]  [860/1724] loss: 0.319, ave_loss: 0.345
[45]  [880/1724] loss: 0.325, ave_loss: 0.345
[46]  [900/1724] loss: 0.355, ave_loss: 0.345
[47]  [920/1724] loss: 0.289, ave_loss: 0.344
[48]  [940/1724] loss: 0.191, ave_loss: 0.341
[49]  [960/1724] loss: 0.360, ave_loss: 0.341
[50]  [980/1724] loss: 0.360, ave_loss: 0.341
[51]  [1000/1724] loss: 0.254, ave_loss: 0.340
[52]  [1020/1724] loss: 0.566, ave_loss: 0.344
[53]  [1040/1724] loss: 0.440, ave_loss: 0.346
[54]  [1060/1724] loss: 0.392, ave_loss: 0.347
[55]  [1080/1724] loss: 0.340, ave_loss: 0.347
[56]  [1100/1724] loss: 0.245, ave_loss: 0.345
[57]  [1120/1724] loss: 0.250, ave_loss: 0.343
[58]  [1140/1724] loss: 0.292, ave_loss: 0.342
[59]  [1160/1724] loss: 0.267, ave_loss: 0.341
[60]  [1180/1724] loss: 0.173, ave_loss: 0.338
[61]  [1200/1724] loss: 0.370, ave_loss: 0.339
[62]  [1220/1724] loss: 0.313, ave_loss: 0.338
[63]  [1240/1724] loss: 0.313, ave_loss: 0.338
[64]  [1260/1724] loss: 0.442, ave_loss: 0.340
[65]  [1280/1724] loss: 0.496, ave_loss: 0.342
[66]  [1300/1724] loss: 0.229, ave_loss: 0.340
[67]  [1320/1724] loss: 0.170, ave_loss: 0.338
[68]  [1340/1724] loss: 0.448, ave_loss: 0.339
[69]  [1360/1724] loss: 0.435, ave_loss: 0.341
[70]  [1380/1724] loss: 0.276, ave_loss: 0.340
[71]  [1400/1724] loss: 0.456, ave_loss: 0.341
[72]  [1420/1724] loss: 0.263, ave_loss: 0.340
[73]  [1440/1724] loss: 0.454, ave_loss: 0.342
[74]  [1460/1724] loss: 0.511, ave_loss: 0.344
[75]  [1480/1724] loss: 0.236, ave_loss: 0.343
[76]  [1500/1724] loss: 0.327, ave_loss: 0.343
[77]  [1520/1724] loss: 0.300, ave_loss: 0.342
[78]  [1540/1724] loss: 0.271, ave_loss: 0.341
[79]  [1560/1724] loss: 0.432, ave_loss: 0.342
[80]  [1580/1724] loss: 0.386, ave_loss: 0.343
[81]  [1600/1724] loss: 0.317, ave_loss: 0.342
[82]  [1620/1724] loss: 0.248, ave_loss: 0.341
[83]  [1640/1724] loss: 0.231, ave_loss: 0.340
[84]  [1660/1724] loss: 0.366, ave_loss: 0.340
[85]  [1680/1724] loss: 0.303, ave_loss: 0.340
[86]  [1700/1724] loss: 0.326, ave_loss: 0.340
[87]  [1720/1724] loss: 0.425, ave_loss: 0.341
[88]  [1740/1724] loss: 0.193, ave_loss: 0.339

Finished Training finishing at 2021-08-21 13:11:30.470676
printing_out epoch  75.54524361948955 learning rate: 2.4780899876353e-06
2.403747288006241e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.390e-01
Validation Loss: 1.330e+04
Validation ROC: 0.7766
No improvement, still saving model
23.454756380510446 epochs left to go

Training Epoch 75.54524361948955/100 starting at 2021-08-21 13:12:19.793927
[1]  [0/1724] loss: 0.355, ave_loss: 0.355
[2]  [20/1724] loss: 0.409, ave_loss: 0.382
[3]  [40/1724] loss: 0.379, ave_loss: 0.381
[4]  [60/1724] loss: 0.453, ave_loss: 0.399
[5]  [80/1724] loss: 0.262, ave_loss: 0.372
[6]  [100/1724] loss: 0.310, ave_loss: 0.361
[7]  [120/1724] loss: 0.273, ave_loss: 0.349
[8]  [140/1724] loss: 0.348, ave_loss: 0.349
[9]  [160/1724] loss: 0.308, ave_loss: 0.344
[10]  [180/1724] loss: 0.273, ave_loss: 0.337
[11]  [200/1724] loss: 0.267, ave_loss: 0.331
[12]  [220/1724] loss: 0.296, ave_loss: 0.328
[13]  [240/1724] loss: 0.296, ave_loss: 0.325
[14]  [260/1724] loss: 0.320, ave_loss: 0.325
[15]  [280/1724] loss: 0.215, ave_loss: 0.318
[16]  [300/1724] loss: 0.383, ave_loss: 0.322
[17]  [320/1724] loss: 0.397, ave_loss: 0.326
[18]  [340/1724] loss: 0.333, ave_loss: 0.327
[19]  [360/1724] loss: 0.390, ave_loss: 0.330
[20]  [380/1724] loss: 0.307, ave_loss: 0.329
[21]  [400/1724] loss: 0.386, ave_loss: 0.331
[22]  [420/1724] loss: 0.213, ave_loss: 0.326
[23]  [440/1724] loss: 0.365, ave_loss: 0.328
[24]  [460/1724] loss: 0.385, ave_loss: 0.330
[25]  [480/1724] loss: 0.458, ave_loss: 0.335
[26]  [500/1724] loss: 0.461, ave_loss: 0.340
[27]  [520/1724] loss: 0.382, ave_loss: 0.342
[28]  [540/1724] loss: 0.441, ave_loss: 0.345
[29]  [560/1724] loss: 0.183, ave_loss: 0.340
[30]  [580/1724] loss: 0.490, ave_loss: 0.345
[31]  [600/1724] loss: 0.467, ave_loss: 0.349
[32]  [620/1724] loss: 0.476, ave_loss: 0.352
[33]  [640/1724] loss: 0.378, ave_loss: 0.353
[34]  [660/1724] loss: 0.367, ave_loss: 0.354
[35]  [680/1724] loss: 0.303, ave_loss: 0.352
[36]  [700/1724] loss: 0.414, ave_loss: 0.354
[37]  [720/1724] loss: 0.395, ave_loss: 0.355
[38]  [740/1724] loss: 0.387, ave_loss: 0.356
[39]  [760/1724] loss: 0.425, ave_loss: 0.358
[40]  [780/1724] loss: 0.299, ave_loss: 0.356
[41]  [800/1724] loss: 0.426, ave_loss: 0.358
[42]  [820/1724] loss: 0.359, ave_loss: 0.358
[43]  [840/1724] loss: 0.477, ave_loss: 0.361
[44]  [860/1724] loss: 0.489, ave_loss: 0.364
[45]  [880/1724] loss: 0.398, ave_loss: 0.364
[46]  [900/1724] loss: 0.267, ave_loss: 0.362
[47]  [920/1724] loss: 0.371, ave_loss: 0.362
[48]  [940/1724] loss: 0.335, ave_loss: 0.362
[49]  [960/1724] loss: 0.186, ave_loss: 0.358
[50]  [980/1724] loss: 0.459, ave_loss: 0.360
[51]  [1000/1724] loss: 0.490, ave_loss: 0.363
[52]  [1020/1724] loss: 0.278, ave_loss: 0.361
[53]  [1040/1724] loss: 0.330, ave_loss: 0.361
[54]  [1060/1724] loss: 0.455, ave_loss: 0.362
[55]  [1080/1724] loss: 0.374, ave_loss: 0.363
[56]  [1100/1724] loss: 0.402, ave_loss: 0.363
[57]  [1120/1724] loss: 0.408, ave_loss: 0.364
[58]  [1140/1724] loss: 0.214, ave_loss: 0.361
[59]  [1160/1724] loss: 0.326, ave_loss: 0.361
[60]  [1180/1724] loss: 0.284, ave_loss: 0.360
[61]  [1200/1724] loss: 0.354, ave_loss: 0.360
[62]  [1220/1724] loss: 0.303, ave_loss: 0.359
[63]  [1240/1724] loss: 0.429, ave_loss: 0.360
[64]  [1260/1724] loss: 0.324, ave_loss: 0.359
[65]  [1280/1724] loss: 0.396, ave_loss: 0.360
[66]  [1300/1724] loss: 0.311, ave_loss: 0.359
[67]  [1320/1724] loss: 0.277, ave_loss: 0.358
[68]  [1340/1724] loss: 0.385, ave_loss: 0.358
[69]  [1360/1724] loss: 0.342, ave_loss: 0.358
[70]  [1380/1724] loss: 0.309, ave_loss: 0.357
[71]  [1400/1724] loss: 0.220, ave_loss: 0.355
[72]  [1420/1724] loss: 0.432, ave_loss: 0.356
[73]  [1440/1724] loss: 0.242, ave_loss: 0.355
[74]  [1460/1724] loss: 0.461, ave_loss: 0.356
[75]  [1480/1724] loss: 0.503, ave_loss: 0.358
[76]  [1500/1724] loss: 0.256, ave_loss: 0.357
[77]  [1520/1724] loss: 0.306, ave_loss: 0.356
[78]  [1540/1724] loss: 0.346, ave_loss: 0.356
[79]  [1560/1724] loss: 0.327, ave_loss: 0.356
[80]  [1580/1724] loss: 0.309, ave_loss: 0.355
[81]  [1600/1724] loss: 0.329, ave_loss: 0.355
[82]  [1620/1724] loss: 0.303, ave_loss: 0.354
[83]  [1640/1724] loss: 0.228, ave_loss: 0.353
[84]  [1660/1724] loss: 0.293, ave_loss: 0.352
[85]  [1680/1724] loss: 0.349, ave_loss: 0.352
[86]  [1700/1724] loss: 0.217, ave_loss: 0.350
[87]  [1720/1724] loss: 0.390, ave_loss: 0.351
[88]  [1740/1724] loss: 0.351, ave_loss: 0.351

Finished Training finishing at 2021-08-21 13:14:16.490847
printing_out epoch  76.56612529002321 learning rate: 2.252809079668454e-06
2.1852248072784004e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.508e-01
Validation Loss: 1.333e+04
Validation ROC: 0.7764
No improvement, still saving model
22.43387470997679 epochs left to go

Training Epoch 76.56612529002321/100 starting at 2021-08-21 13:15:01.656546
[1]  [0/1724] loss: 0.493, ave_loss: 0.493
[2]  [20/1724] loss: 0.449, ave_loss: 0.471
[3]  [40/1724] loss: 0.219, ave_loss: 0.387
[4]  [60/1724] loss: 0.354, ave_loss: 0.379
[5]  [80/1724] loss: 0.398, ave_loss: 0.383
[6]  [100/1724] loss: 0.270, ave_loss: 0.364
[7]  [120/1724] loss: 0.370, ave_loss: 0.365
[8]  [140/1724] loss: 0.439, ave_loss: 0.374
[9]  [160/1724] loss: 0.351, ave_loss: 0.372
[10]  [180/1724] loss: 0.369, ave_loss: 0.371
[11]  [200/1724] loss: 0.424, ave_loss: 0.376
[12]  [220/1724] loss: 0.433, ave_loss: 0.381
[13]  [240/1724] loss: 0.376, ave_loss: 0.380
[14]  [260/1724] loss: 0.324, ave_loss: 0.376
[15]  [280/1724] loss: 0.412, ave_loss: 0.379
[16]  [300/1724] loss: 0.323, ave_loss: 0.375
[17]  [320/1724] loss: 0.333, ave_loss: 0.373
[18]  [340/1724] loss: 0.345, ave_loss: 0.371
[19]  [360/1724] loss: 0.325, ave_loss: 0.369
[20]  [380/1724] loss: 0.416, ave_loss: 0.371
[21]  [400/1724] loss: 0.212, ave_loss: 0.364
[22]  [420/1724] loss: 0.354, ave_loss: 0.363
[23]  [440/1724] loss: 0.348, ave_loss: 0.363
[24]  [460/1724] loss: 0.321, ave_loss: 0.361
[25]  [480/1724] loss: 0.427, ave_loss: 0.363
[26]  [500/1724] loss: 0.304, ave_loss: 0.361
[27]  [520/1724] loss: 0.286, ave_loss: 0.358
[28]  [540/1724] loss: 0.440, ave_loss: 0.361
[29]  [560/1724] loss: 0.302, ave_loss: 0.359
[30]  [580/1724] loss: 0.331, ave_loss: 0.358
[31]  [600/1724] loss: 0.332, ave_loss: 0.357
[32]  [620/1724] loss: 0.361, ave_loss: 0.358
[33]  [640/1724] loss: 0.326, ave_loss: 0.357
[34]  [660/1724] loss: 0.437, ave_loss: 0.359
[35]  [680/1724] loss: 0.129, ave_loss: 0.352
[36]  [700/1724] loss: 0.388, ave_loss: 0.353
[37]  [720/1724] loss: 0.367, ave_loss: 0.354
[38]  [740/1724] loss: 0.367, ave_loss: 0.354
[39]  [760/1724] loss: 0.346, ave_loss: 0.354
[40]  [780/1724] loss: 0.512, ave_loss: 0.358
[41]  [800/1724] loss: 0.420, ave_loss: 0.359
[42]  [820/1724] loss: 0.277, ave_loss: 0.357
[43]  [840/1724] loss: 0.344, ave_loss: 0.357
[44]  [860/1724] loss: 0.354, ave_loss: 0.357
[45]  [880/1724] loss: 0.533, ave_loss: 0.361
[46]  [900/1724] loss: 0.377, ave_loss: 0.361
[47]  [920/1724] loss: 0.311, ave_loss: 0.360
[48]  [940/1724] loss: 0.404, ave_loss: 0.361
[49]  [960/1724] loss: 0.328, ave_loss: 0.360
[50]  [980/1724] loss: 0.417, ave_loss: 0.362
[51]  [1000/1724] loss: 0.425, ave_loss: 0.363
[52]  [1020/1724] loss: 0.288, ave_loss: 0.361
[53]  [1040/1724] loss: 0.252, ave_loss: 0.359
[54]  [1060/1724] loss: 0.253, ave_loss: 0.357
[55]  [1080/1724] loss: 0.375, ave_loss: 0.358
[56]  [1100/1724] loss: 0.545, ave_loss: 0.361
[57]  [1120/1724] loss: 0.339, ave_loss: 0.361
[58]  [1140/1724] loss: 0.313, ave_loss: 0.360
[59]  [1160/1724] loss: 0.505, ave_loss: 0.362
[60]  [1180/1724] loss: 0.262, ave_loss: 0.361
[61]  [1200/1724] loss: 0.348, ave_loss: 0.360
[62]  [1220/1724] loss: 0.319, ave_loss: 0.360
[63]  [1240/1724] loss: 0.294, ave_loss: 0.359
[64]  [1260/1724] loss: 0.227, ave_loss: 0.357
[65]  [1280/1724] loss: 0.329, ave_loss: 0.356
[66]  [1300/1724] loss: 0.321, ave_loss: 0.356
[67]  [1320/1724] loss: 0.215, ave_loss: 0.354
[68]  [1340/1724] loss: 0.463, ave_loss: 0.355
[69]  [1360/1724] loss: 0.364, ave_loss: 0.355
[70]  [1380/1724] loss: 0.410, ave_loss: 0.356
[71]  [1400/1724] loss: 0.384, ave_loss: 0.356
[72]  [1420/1724] loss: 0.463, ave_loss: 0.358
[73]  [1440/1724] loss: 0.351, ave_loss: 0.358
[74]  [1460/1724] loss: 0.403, ave_loss: 0.358
[75]  [1480/1724] loss: 0.320, ave_loss: 0.358
[76]  [1500/1724] loss: 0.383, ave_loss: 0.358
[77]  [1520/1724] loss: 0.230, ave_loss: 0.357
[78]  [1540/1724] loss: 0.219, ave_loss: 0.355
[79]  [1560/1724] loss: 0.416, ave_loss: 0.356
[80]  [1580/1724] loss: 0.435, ave_loss: 0.357
[81]  [1600/1724] loss: 0.421, ave_loss: 0.357
[82]  [1620/1724] loss: 0.410, ave_loss: 0.358
[83]  [1640/1724] loss: 0.286, ave_loss: 0.357
[84]  [1660/1724] loss: 0.285, ave_loss: 0.356
[85]  [1680/1724] loss: 0.359, ave_loss: 0.356
[86]  [1700/1724] loss: 0.284, ave_loss: 0.356
[87]  [1720/1724] loss: 0.282, ave_loss: 0.355
[88]  [1740/1724] loss: 0.322, ave_loss: 0.354

Finished Training finishing at 2021-08-21 13:16:53.829325
printing_out epoch  77.58700696055685 learning rate: 2.048008254244049e-06
1.9865680066167276e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.543e-01
Validation Loss: 1.330e+04
Validation ROC: 0.7762
No improvement, still saving model
21.41299303944315 epochs left to go

Training Epoch 77.58700696055685/100 starting at 2021-08-21 13:18:16.587230
[1]  [0/1724] loss: 0.507, ave_loss: 0.507
[2]  [20/1724] loss: 0.288, ave_loss: 0.397
[3]  [40/1724] loss: 0.278, ave_loss: 0.358
[4]  [60/1724] loss: 0.374, ave_loss: 0.362
[5]  [80/1724] loss: 0.352, ave_loss: 0.360
[6]  [100/1724] loss: 0.316, ave_loss: 0.352
[7]  [120/1724] loss: 0.370, ave_loss: 0.355
[8]  [140/1724] loss: 0.264, ave_loss: 0.343
[9]  [160/1724] loss: 0.250, ave_loss: 0.333
[10]  [180/1724] loss: 0.308, ave_loss: 0.331
[11]  [200/1724] loss: 0.501, ave_loss: 0.346
[12]  [220/1724] loss: 0.341, ave_loss: 0.346
[13]  [240/1724] loss: 0.294, ave_loss: 0.342
[14]  [260/1724] loss: 0.313, ave_loss: 0.340
[15]  [280/1724] loss: 0.225, ave_loss: 0.332
[16]  [300/1724] loss: 0.337, ave_loss: 0.332
[17]  [320/1724] loss: 0.243, ave_loss: 0.327
[18]  [340/1724] loss: 0.406, ave_loss: 0.331
[19]  [360/1724] loss: 0.366, ave_loss: 0.333
[20]  [380/1724] loss: 0.240, ave_loss: 0.329
[21]  [400/1724] loss: 0.264, ave_loss: 0.325
[22]  [420/1724] loss: 0.254, ave_loss: 0.322
[23]  [440/1724] loss: 0.318, ave_loss: 0.322
[24]  [460/1724] loss: 0.296, ave_loss: 0.321
[25]  [480/1724] loss: 0.434, ave_loss: 0.325
[26]  [500/1724] loss: 0.479, ave_loss: 0.331
[27]  [520/1724] loss: 0.184, ave_loss: 0.326
[28]  [540/1724] loss: 0.263, ave_loss: 0.324
[29]  [560/1724] loss: 0.398, ave_loss: 0.326
[30]  [580/1724] loss: 0.313, ave_loss: 0.326
[31]  [600/1724] loss: 0.313, ave_loss: 0.325
[32]  [620/1724] loss: 0.358, ave_loss: 0.326
[33]  [640/1724] loss: 0.252, ave_loss: 0.324
[34]  [660/1724] loss: 0.207, ave_loss: 0.321
[35]  [680/1724] loss: 0.394, ave_loss: 0.323
[36]  [700/1724] loss: 0.291, ave_loss: 0.322
[37]  [720/1724] loss: 0.365, ave_loss: 0.323
[38]  [740/1724] loss: 0.356, ave_loss: 0.324
[39]  [760/1724] loss: 0.375, ave_loss: 0.325
[40]  [780/1724] loss: 0.254, ave_loss: 0.323
[41]  [800/1724] loss: 0.299, ave_loss: 0.323
[42]  [820/1724] loss: 0.316, ave_loss: 0.323
[43]  [840/1724] loss: 0.356, ave_loss: 0.323
[44]  [860/1724] loss: 0.375, ave_loss: 0.325
[45]  [880/1724] loss: 0.315, ave_loss: 0.324
[46]  [900/1724] loss: 0.415, ave_loss: 0.326
[47]  [920/1724] loss: 0.246, ave_loss: 0.325
[48]  [940/1724] loss: 0.206, ave_loss: 0.322
[49]  [960/1724] loss: 0.359, ave_loss: 0.323
[50]  [980/1724] loss: 0.346, ave_loss: 0.323
[51]  [1000/1724] loss: 0.334, ave_loss: 0.324
[52]  [1020/1724] loss: 0.373, ave_loss: 0.325
[53]  [1040/1724] loss: 0.287, ave_loss: 0.324
[54]  [1060/1724] loss: 0.519, ave_loss: 0.327
[55]  [1080/1724] loss: 0.399, ave_loss: 0.329
[56]  [1100/1724] loss: 0.349, ave_loss: 0.329
[57]  [1120/1724] loss: 0.353, ave_loss: 0.330
[58]  [1140/1724] loss: 0.397, ave_loss: 0.331
[59]  [1160/1724] loss: 0.407, ave_loss: 0.332
[60]  [1180/1724] loss: 0.341, ave_loss: 0.332
[61]  [1200/1724] loss: 0.391, ave_loss: 0.333
[62]  [1220/1724] loss: 0.264, ave_loss: 0.332
[63]  [1240/1724] loss: 0.382, ave_loss: 0.333
[64]  [1260/1724] loss: 0.441, ave_loss: 0.334
[65]  [1280/1724] loss: 0.386, ave_loss: 0.335
[66]  [1300/1724] loss: 0.455, ave_loss: 0.337
[67]  [1320/1724] loss: 0.303, ave_loss: 0.337
[68]  [1340/1724] loss: 0.374, ave_loss: 0.337
[69]  [1360/1724] loss: 0.455, ave_loss: 0.339
[70]  [1380/1724] loss: 0.333, ave_loss: 0.339
[71]  [1400/1724] loss: 0.284, ave_loss: 0.338
[72]  [1420/1724] loss: 0.368, ave_loss: 0.338
[73]  [1440/1724] loss: 0.272, ave_loss: 0.337
[74]  [1460/1724] loss: 0.355, ave_loss: 0.338
[75]  [1480/1724] loss: 0.312, ave_loss: 0.337
[76]  [1500/1724] loss: 0.378, ave_loss: 0.338
[77]  [1520/1724] loss: 0.276, ave_loss: 0.337
[78]  [1540/1724] loss: 0.299, ave_loss: 0.337
[79]  [1560/1724] loss: 0.226, ave_loss: 0.335
[80]  [1580/1724] loss: 0.367, ave_loss: 0.336
[81]  [1600/1724] loss: 0.544, ave_loss: 0.338
[82]  [1620/1724] loss: 0.291, ave_loss: 0.338
[83]  [1640/1724] loss: 0.163, ave_loss: 0.335
[84]  [1660/1724] loss: 0.442, ave_loss: 0.337
[85]  [1680/1724] loss: 0.438, ave_loss: 0.338
[86]  [1700/1724] loss: 0.322, ave_loss: 0.338
[87]  [1720/1724] loss: 0.385, ave_loss: 0.338
[88]  [1740/1724] loss: 0.384, ave_loss: 0.339

Finished Training finishing at 2021-08-21 13:20:24.285684
printing_out epoch  78.60788863109049 learning rate: 1.8618256856764081e-06
1.8059709151061159e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.388e-01
Validation Loss: 1.343e+04
Validation ROC: 0.7763
No improvement, still saving model
20.39211136890951 epochs left to go

Training Epoch 78.60788863109049/100 starting at 2021-08-21 13:20:50.762285
[1]  [0/1724] loss: 0.495, ave_loss: 0.495
[2]  [20/1724] loss: 0.323, ave_loss: 0.409
[3]  [40/1724] loss: 0.290, ave_loss: 0.370
[4]  [60/1724] loss: 0.578, ave_loss: 0.422
[5]  [80/1724] loss: 0.364, ave_loss: 0.410
[6]  [100/1724] loss: 0.272, ave_loss: 0.387
[7]  [120/1724] loss: 0.484, ave_loss: 0.401
[8]  [140/1724] loss: 0.298, ave_loss: 0.388
[9]  [160/1724] loss: 0.218, ave_loss: 0.369
[10]  [180/1724] loss: 0.396, ave_loss: 0.372
[11]  [200/1724] loss: 0.240, ave_loss: 0.360
[12]  [220/1724] loss: 0.233, ave_loss: 0.349
[13]  [240/1724] loss: 0.304, ave_loss: 0.346
[14]  [260/1724] loss: 0.429, ave_loss: 0.352
[15]  [280/1724] loss: 0.293, ave_loss: 0.348
[16]  [300/1724] loss: 0.522, ave_loss: 0.359
[17]  [320/1724] loss: 0.270, ave_loss: 0.354
[18]  [340/1724] loss: 0.313, ave_loss: 0.351
[19]  [360/1724] loss: 0.349, ave_loss: 0.351
[20]  [380/1724] loss: 0.282, ave_loss: 0.348
[21]  [400/1724] loss: 0.276, ave_loss: 0.344
[22]  [420/1724] loss: 0.377, ave_loss: 0.346
[23]  [440/1724] loss: 0.361, ave_loss: 0.346
[24]  [460/1724] loss: 0.257, ave_loss: 0.343
[25]  [480/1724] loss: 0.219, ave_loss: 0.338
[26]  [500/1724] loss: 0.329, ave_loss: 0.337
[27]  [520/1724] loss: 0.279, ave_loss: 0.335
[28]  [540/1724] loss: 0.293, ave_loss: 0.334
[29]  [560/1724] loss: 0.485, ave_loss: 0.339
[30]  [580/1724] loss: 0.293, ave_loss: 0.337
[31]  [600/1724] loss: 0.328, ave_loss: 0.337
[32]  [620/1724] loss: 0.366, ave_loss: 0.338
[33]  [640/1724] loss: 0.310, ave_loss: 0.337
[34]  [660/1724] loss: 0.377, ave_loss: 0.338
[35]  [680/1724] loss: 0.512, ave_loss: 0.343
[36]  [700/1724] loss: 0.254, ave_loss: 0.341
[37]  [720/1724] loss: 0.400, ave_loss: 0.342
[38]  [740/1724] loss: 0.343, ave_loss: 0.342
[39]  [760/1724] loss: 0.413, ave_loss: 0.344
[40]  [780/1724] loss: 0.341, ave_loss: 0.344
[41]  [800/1724] loss: 0.263, ave_loss: 0.342
[42]  [820/1724] loss: 0.319, ave_loss: 0.342
[43]  [840/1724] loss: 0.341, ave_loss: 0.342
[44]  [860/1724] loss: 0.459, ave_loss: 0.344
[45]  [880/1724] loss: 0.432, ave_loss: 0.346
[46]  [900/1724] loss: 0.295, ave_loss: 0.345
[47]  [920/1724] loss: 0.441, ave_loss: 0.347
[48]  [940/1724] loss: 0.401, ave_loss: 0.348
[49]  [960/1724] loss: 0.308, ave_loss: 0.347
[50]  [980/1724] loss: 0.310, ave_loss: 0.347
[51]  [1000/1724] loss: 0.314, ave_loss: 0.346
[52]  [1020/1724] loss: 0.180, ave_loss: 0.343
[53]  [1040/1724] loss: 0.210, ave_loss: 0.340
[54]  [1060/1724] loss: 0.316, ave_loss: 0.340
[55]  [1080/1724] loss: 0.458, ave_loss: 0.342
[56]  [1100/1724] loss: 0.428, ave_loss: 0.344
[57]  [1120/1724] loss: 0.411, ave_loss: 0.345
[58]  [1140/1724] loss: 0.488, ave_loss: 0.347
[59]  [1160/1724] loss: 0.341, ave_loss: 0.347
[60]  [1180/1724] loss: 0.335, ave_loss: 0.347
[61]  [1200/1724] loss: 0.285, ave_loss: 0.346
[62]  [1220/1724] loss: 0.301, ave_loss: 0.345
[63]  [1240/1724] loss: 0.385, ave_loss: 0.346
[64]  [1260/1724] loss: 0.464, ave_loss: 0.348
[65]  [1280/1724] loss: 0.302, ave_loss: 0.347
[66]  [1300/1724] loss: 0.387, ave_loss: 0.348
[67]  [1320/1724] loss: 0.307, ave_loss: 0.347
[68]  [1340/1724] loss: 0.432, ave_loss: 0.348
[69]  [1360/1724] loss: 0.338, ave_loss: 0.348
[70]  [1380/1724] loss: 0.357, ave_loss: 0.348
[71]  [1400/1724] loss: 0.499, ave_loss: 0.350
[72]  [1420/1724] loss: 0.516, ave_loss: 0.353
[73]  [1440/1724] loss: 0.420, ave_loss: 0.354
[74]  [1460/1724] loss: 0.378, ave_loss: 0.354
[75]  [1480/1724] loss: 0.370, ave_loss: 0.354
[76]  [1500/1724] loss: 0.159, ave_loss: 0.352
[77]  [1520/1724] loss: 0.316, ave_loss: 0.351
[78]  [1540/1724] loss: 0.317, ave_loss: 0.351
[79]  [1560/1724] loss: 0.303, ave_loss: 0.350
[80]  [1580/1724] loss: 0.306, ave_loss: 0.350
[81]  [1600/1724] loss: 0.317, ave_loss: 0.349
[82]  [1620/1724] loss: 0.441, ave_loss: 0.350
[83]  [1640/1724] loss: 0.298, ave_loss: 0.350
[84]  [1660/1724] loss: 0.240, ave_loss: 0.348
[85]  [1680/1724] loss: 0.478, ave_loss: 0.350
[86]  [1700/1724] loss: 0.406, ave_loss: 0.350
[87]  [1720/1724] loss: 0.300, ave_loss: 0.350
[88]  [1740/1724] loss: 0.297, ave_loss: 0.349

Finished Training finishing at 2021-08-21 13:22:52.960329
printing_out epoch  79.62877030162413 learning rate: 1.6925688051603708e-06
1.6417917410055596e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.493e-01
Validation Loss: 1.339e+04
Validation ROC: 0.7762
No improvement, still saving model
19.37122969837587 epochs left to go

Training Epoch 79.62877030162413/100 starting at 2021-08-21 13:23:24.466055
[1]  [0/1724] loss: 0.321, ave_loss: 0.321
[2]  [20/1724] loss: 0.253, ave_loss: 0.287
[3]  [40/1724] loss: 0.171, ave_loss: 0.248
[4]  [60/1724] loss: 0.348, ave_loss: 0.273
[5]  [80/1724] loss: 0.330, ave_loss: 0.284
[6]  [100/1724] loss: 0.252, ave_loss: 0.279
[7]  [120/1724] loss: 0.465, ave_loss: 0.306
[8]  [140/1724] loss: 0.375, ave_loss: 0.314
[9]  [160/1724] loss: 0.404, ave_loss: 0.324
[10]  [180/1724] loss: 0.240, ave_loss: 0.316
[11]  [200/1724] loss: 0.252, ave_loss: 0.310
[12]  [220/1724] loss: 0.357, ave_loss: 0.314
[13]  [240/1724] loss: 0.273, ave_loss: 0.311
[14]  [260/1724] loss: 0.337, ave_loss: 0.313
[15]  [280/1724] loss: 0.211, ave_loss: 0.306
[16]  [300/1724] loss: 0.433, ave_loss: 0.314
[17]  [320/1724] loss: 0.263, ave_loss: 0.311
[18]  [340/1724] loss: 0.212, ave_loss: 0.305
[19]  [360/1724] loss: 0.542, ave_loss: 0.318
[20]  [380/1724] loss: 0.370, ave_loss: 0.320
[21]  [400/1724] loss: 0.427, ave_loss: 0.326
[22]  [420/1724] loss: 0.276, ave_loss: 0.323
[23]  [440/1724] loss: 0.419, ave_loss: 0.327
[24]  [460/1724] loss: 0.391, ave_loss: 0.330
[25]  [480/1724] loss: 0.250, ave_loss: 0.327
[26]  [500/1724] loss: 0.352, ave_loss: 0.328
[27]  [520/1724] loss: 0.305, ave_loss: 0.327
[28]  [540/1724] loss: 0.409, ave_loss: 0.330
[29]  [560/1724] loss: 0.320, ave_loss: 0.330
[30]  [580/1724] loss: 0.288, ave_loss: 0.328
[31]  [600/1724] loss: 0.296, ave_loss: 0.327
[32]  [620/1724] loss: 0.354, ave_loss: 0.328
[33]  [640/1724] loss: 0.292, ave_loss: 0.327
[34]  [660/1724] loss: 0.369, ave_loss: 0.328
[35]  [680/1724] loss: 0.323, ave_loss: 0.328
[36]  [700/1724] loss: 0.311, ave_loss: 0.328
[37]  [720/1724] loss: 0.322, ave_loss: 0.327
[38]  [740/1724] loss: 0.346, ave_loss: 0.328
[39]  [760/1724] loss: 0.416, ave_loss: 0.330
[40]  [780/1724] loss: 0.282, ave_loss: 0.329
[41]  [800/1724] loss: 0.418, ave_loss: 0.331
[42]  [820/1724] loss: 0.221, ave_loss: 0.328
[43]  [840/1724] loss: 0.452, ave_loss: 0.331
[44]  [860/1724] loss: 0.354, ave_loss: 0.332
[45]  [880/1724] loss: 0.387, ave_loss: 0.333
[46]  [900/1724] loss: 0.353, ave_loss: 0.333
[47]  [920/1724] loss: 0.262, ave_loss: 0.332
[48]  [940/1724] loss: 0.380, ave_loss: 0.333
[49]  [960/1724] loss: 0.363, ave_loss: 0.334
[50]  [980/1724] loss: 0.267, ave_loss: 0.332
[51]  [1000/1724] loss: 0.240, ave_loss: 0.330
[52]  [1020/1724] loss: 0.258, ave_loss: 0.329
[53]  [1040/1724] loss: 0.337, ave_loss: 0.329
[54]  [1060/1724] loss: 0.251, ave_loss: 0.328
[55]  [1080/1724] loss: 0.276, ave_loss: 0.327
[56]  [1100/1724] loss: 0.268, ave_loss: 0.326
[57]  [1120/1724] loss: 0.322, ave_loss: 0.326
[58]  [1140/1724] loss: 0.399, ave_loss: 0.327
[59]  [1160/1724] loss: 0.229, ave_loss: 0.325
[60]  [1180/1724] loss: 0.235, ave_loss: 0.324
[61]  [1200/1724] loss: 0.489, ave_loss: 0.326
[62]  [1220/1724] loss: 0.359, ave_loss: 0.327
[63]  [1240/1724] loss: 0.402, ave_loss: 0.328
[64]  [1260/1724] loss: 0.286, ave_loss: 0.328
[65]  [1280/1724] loss: 0.236, ave_loss: 0.326
[66]  [1300/1724] loss: 0.359, ave_loss: 0.327
[67]  [1320/1724] loss: 0.228, ave_loss: 0.325
[68]  [1340/1724] loss: 0.524, ave_loss: 0.328
[69]  [1360/1724] loss: 0.388, ave_loss: 0.329
[70]  [1380/1724] loss: 0.274, ave_loss: 0.328
[71]  [1400/1724] loss: 0.240, ave_loss: 0.327
[72]  [1420/1724] loss: 0.591, ave_loss: 0.331
[73]  [1440/1724] loss: 0.257, ave_loss: 0.330
[74]  [1460/1724] loss: 0.299, ave_loss: 0.329
[75]  [1480/1724] loss: 0.350, ave_loss: 0.329
[76]  [1500/1724] loss: 0.516, ave_loss: 0.332
[77]  [1520/1724] loss: 0.490, ave_loss: 0.334
[78]  [1540/1724] loss: 0.277, ave_loss: 0.333
[79]  [1560/1724] loss: 0.324, ave_loss: 0.333
[80]  [1580/1724] loss: 0.308, ave_loss: 0.333
[81]  [1600/1724] loss: 0.336, ave_loss: 0.333
[82]  [1620/1724] loss: 0.232, ave_loss: 0.332
[83]  [1640/1724] loss: 0.322, ave_loss: 0.331
[84]  [1660/1724] loss: 0.292, ave_loss: 0.331
[85]  [1680/1724] loss: 0.417, ave_loss: 0.332
[86]  [1700/1724] loss: 0.337, ave_loss: 0.332
[87]  [1720/1724] loss: 0.448, ave_loss: 0.333
[88]  [1740/1724] loss: 0.359, ave_loss: 0.334

Finished Training finishing at 2021-08-21 13:25:23.137623
printing_out epoch  80.64965197215777 learning rate: 1.538698913782155e-06
1.4925379463686903e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.337e-01
Validation Loss: 1.334e+04
Validation ROC: 0.7762
No improvement, still saving model
18.35034802784223 epochs left to go

Training Epoch 80.64965197215777/100 starting at 2021-08-21 13:26:10.274218
[1]  [0/1724] loss: 0.534, ave_loss: 0.534
[2]  [20/1724] loss: 0.382, ave_loss: 0.458
[3]  [40/1724] loss: 0.204, ave_loss: 0.373
[4]  [60/1724] loss: 0.360, ave_loss: 0.370
[5]  [80/1724] loss: 0.393, ave_loss: 0.374
[6]  [100/1724] loss: 0.322, ave_loss: 0.366
[7]  [120/1724] loss: 0.339, ave_loss: 0.362
[8]  [140/1724] loss: 0.349, ave_loss: 0.360
[9]  [160/1724] loss: 0.341, ave_loss: 0.358
[10]  [180/1724] loss: 0.199, ave_loss: 0.342
[11]  [200/1724] loss: 0.245, ave_loss: 0.333
[12]  [220/1724] loss: 0.375, ave_loss: 0.337
[13]  [240/1724] loss: 0.461, ave_loss: 0.346
[14]  [260/1724] loss: 0.446, ave_loss: 0.353
[15]  [280/1724] loss: 0.374, ave_loss: 0.355
[16]  [300/1724] loss: 0.302, ave_loss: 0.352
[17]  [320/1724] loss: 0.312, ave_loss: 0.349
[18]  [340/1724] loss: 0.297, ave_loss: 0.346
[19]  [360/1724] loss: 0.392, ave_loss: 0.349
[20]  [380/1724] loss: 0.273, ave_loss: 0.345
[21]  [400/1724] loss: 0.466, ave_loss: 0.351
[22]  [420/1724] loss: 0.343, ave_loss: 0.350
[23]  [440/1724] loss: 0.253, ave_loss: 0.346
[24]  [460/1724] loss: 0.185, ave_loss: 0.339
[25]  [480/1724] loss: 0.328, ave_loss: 0.339
[26]  [500/1724] loss: 0.265, ave_loss: 0.336
[27]  [520/1724] loss: 0.285, ave_loss: 0.334
[28]  [540/1724] loss: 0.413, ave_loss: 0.337
[29]  [560/1724] loss: 0.283, ave_loss: 0.335
[30]  [580/1724] loss: 0.261, ave_loss: 0.333
[31]  [600/1724] loss: 0.419, ave_loss: 0.336
[32]  [620/1724] loss: 0.245, ave_loss: 0.333
[33]  [640/1724] loss: 0.257, ave_loss: 0.330
[34]  [660/1724] loss: 0.426, ave_loss: 0.333
[35]  [680/1724] loss: 0.404, ave_loss: 0.335
[36]  [700/1724] loss: 0.309, ave_loss: 0.335
[37]  [720/1724] loss: 0.467, ave_loss: 0.338
[38]  [740/1724] loss: 0.292, ave_loss: 0.337
[39]  [760/1724] loss: 0.338, ave_loss: 0.337
[40]  [780/1724] loss: 0.333, ave_loss: 0.337
[41]  [800/1724] loss: 0.186, ave_loss: 0.333
[42]  [820/1724] loss: 0.287, ave_loss: 0.332
[43]  [840/1724] loss: 0.441, ave_loss: 0.335
[44]  [860/1724] loss: 0.405, ave_loss: 0.336
[45]  [880/1724] loss: 0.384, ave_loss: 0.337
[46]  [900/1724] loss: 0.238, ave_loss: 0.335
[47]  [920/1724] loss: 0.328, ave_loss: 0.335
[48]  [940/1724] loss: 0.354, ave_loss: 0.335
[49]  [960/1724] loss: 0.406, ave_loss: 0.337
[50]  [980/1724] loss: 0.303, ave_loss: 0.336
[51]  [1000/1724] loss: 0.440, ave_loss: 0.338
[52]  [1020/1724] loss: 0.334, ave_loss: 0.338
[53]  [1040/1724] loss: 0.400, ave_loss: 0.339
[54]  [1060/1724] loss: 0.192, ave_loss: 0.336
[55]  [1080/1724] loss: 0.278, ave_loss: 0.335
[56]  [1100/1724] loss: 0.377, ave_loss: 0.336
[57]  [1120/1724] loss: 0.374, ave_loss: 0.337
[58]  [1140/1724] loss: 0.250, ave_loss: 0.335
[59]  [1160/1724] loss: 0.302, ave_loss: 0.335
[60]  [1180/1724] loss: 0.437, ave_loss: 0.336
[61]  [1200/1724] loss: 0.340, ave_loss: 0.337
[62]  [1220/1724] loss: 0.299, ave_loss: 0.336
[63]  [1240/1724] loss: 0.426, ave_loss: 0.337
[64]  [1260/1724] loss: 0.612, ave_loss: 0.342
[65]  [1280/1724] loss: 0.206, ave_loss: 0.340
[66]  [1300/1724] loss: 0.316, ave_loss: 0.339
[67]  [1320/1724] loss: 0.413, ave_loss: 0.340
[68]  [1340/1724] loss: 0.314, ave_loss: 0.340
[69]  [1360/1724] loss: 0.354, ave_loss: 0.340
[70]  [1380/1724] loss: 0.414, ave_loss: 0.341
[71]  [1400/1724] loss: 0.229, ave_loss: 0.340
[72]  [1420/1724] loss: 0.329, ave_loss: 0.339
[73]  [1440/1724] loss: 0.333, ave_loss: 0.339
[74]  [1460/1724] loss: 0.343, ave_loss: 0.339
[75]  [1480/1724] loss: 0.309, ave_loss: 0.339
[76]  [1500/1724] loss: 0.367, ave_loss: 0.339
[77]  [1520/1724] loss: 0.288, ave_loss: 0.339
[78]  [1540/1724] loss: 0.231, ave_loss: 0.337
[79]  [1560/1724] loss: 0.245, ave_loss: 0.336
[80]  [1580/1724] loss: 0.295, ave_loss: 0.336
[81]  [1600/1724] loss: 0.429, ave_loss: 0.337
[82]  [1620/1724] loss: 0.387, ave_loss: 0.337
[83]  [1640/1724] loss: 0.349, ave_loss: 0.338
[84]  [1660/1724] loss: 0.288, ave_loss: 0.337
[85]  [1680/1724] loss: 0.281, ave_loss: 0.336
[86]  [1700/1724] loss: 0.385, ave_loss: 0.337
[87]  [1720/1724] loss: 0.456, ave_loss: 0.338
[88]  [1740/1724] loss: 0.186, ave_loss: 0.336

Finished Training finishing at 2021-08-21 13:28:16.414811
printing_out epoch  81.67053364269141 learning rate: 1.3988171943474135e-06
1.356852678516991e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.365e-01
Validation Loss: 1.340e+04
Validation ROC: 0.7763
No improvement, still saving model
17.32946635730859 epochs left to go

Training Epoch 81.67053364269141/100 starting at 2021-08-21 13:28:59.095957
[1]  [0/1724] loss: 0.514, ave_loss: 0.514
[2]  [20/1724] loss: 0.342, ave_loss: 0.428
[3]  [40/1724] loss: 0.300, ave_loss: 0.386
[4]  [60/1724] loss: 0.326, ave_loss: 0.371
[5]  [80/1724] loss: 0.337, ave_loss: 0.364
[6]  [100/1724] loss: 0.303, ave_loss: 0.354
[7]  [120/1724] loss: 0.415, ave_loss: 0.363
[8]  [140/1724] loss: 0.318, ave_loss: 0.357
[9]  [160/1724] loss: 0.300, ave_loss: 0.351
[10]  [180/1724] loss: 0.273, ave_loss: 0.343
[11]  [200/1724] loss: 0.407, ave_loss: 0.349
[12]  [220/1724] loss: 0.278, ave_loss: 0.343
[13]  [240/1724] loss: 0.292, ave_loss: 0.339
[14]  [260/1724] loss: 0.224, ave_loss: 0.331
[15]  [280/1724] loss: 0.435, ave_loss: 0.338
[16]  [300/1724] loss: 0.305, ave_loss: 0.336
[17]  [320/1724] loss: 0.307, ave_loss: 0.334
[18]  [340/1724] loss: 0.268, ave_loss: 0.330
[19]  [360/1724] loss: 0.239, ave_loss: 0.326
[20]  [380/1724] loss: 0.353, ave_loss: 0.327
[21]  [400/1724] loss: 0.276, ave_loss: 0.324
[22]  [420/1724] loss: 0.205, ave_loss: 0.319
[23]  [440/1724] loss: 0.372, ave_loss: 0.321
[24]  [460/1724] loss: 0.683, ave_loss: 0.336
[25]  [480/1724] loss: 0.430, ave_loss: 0.340
[26]  [500/1724] loss: 0.385, ave_loss: 0.342
[27]  [520/1724] loss: 0.474, ave_loss: 0.347
[28]  [540/1724] loss: 0.503, ave_loss: 0.352
[29]  [560/1724] loss: 0.288, ave_loss: 0.350
[30]  [580/1724] loss: 0.491, ave_loss: 0.355
[31]  [600/1724] loss: 0.313, ave_loss: 0.353
[32]  [620/1724] loss: 0.269, ave_loss: 0.351
[33]  [640/1724] loss: 0.238, ave_loss: 0.347
[34]  [660/1724] loss: 0.237, ave_loss: 0.344
[35]  [680/1724] loss: 0.325, ave_loss: 0.344
[36]  [700/1724] loss: 0.353, ave_loss: 0.344
[37]  [720/1724] loss: 0.378, ave_loss: 0.345
[38]  [740/1724] loss: 0.342, ave_loss: 0.345
[39]  [760/1724] loss: 0.275, ave_loss: 0.343
[40]  [780/1724] loss: 0.296, ave_loss: 0.342
[41]  [800/1724] loss: 0.350, ave_loss: 0.342
[42]  [820/1724] loss: 0.541, ave_loss: 0.347
[43]  [840/1724] loss: 0.499, ave_loss: 0.350
[44]  [860/1724] loss: 0.307, ave_loss: 0.349
[45]  [880/1724] loss: 0.372, ave_loss: 0.350
[46]  [900/1724] loss: 0.334, ave_loss: 0.349
[47]  [920/1724] loss: 0.410, ave_loss: 0.351
[48]  [940/1724] loss: 0.381, ave_loss: 0.351
[49]  [960/1724] loss: 0.347, ave_loss: 0.351
[50]  [980/1724] loss: 0.209, ave_loss: 0.348
[51]  [1000/1724] loss: 0.386, ave_loss: 0.349
[52]  [1020/1724] loss: 0.297, ave_loss: 0.348
[53]  [1040/1724] loss: 0.387, ave_loss: 0.349
[54]  [1060/1724] loss: 0.347, ave_loss: 0.349
[55]  [1080/1724] loss: 0.423, ave_loss: 0.350
[56]  [1100/1724] loss: 0.349, ave_loss: 0.350
[57]  [1120/1724] loss: 0.410, ave_loss: 0.351
[58]  [1140/1724] loss: 0.287, ave_loss: 0.350
[59]  [1160/1724] loss: 0.175, ave_loss: 0.347
[60]  [1180/1724] loss: 0.233, ave_loss: 0.345
[61]  [1200/1724] loss: 0.295, ave_loss: 0.344
[62]  [1220/1724] loss: 0.267, ave_loss: 0.343
[63]  [1240/1724] loss: 0.311, ave_loss: 0.343
[64]  [1260/1724] loss: 0.439, ave_loss: 0.344
[65]  [1280/1724] loss: 0.344, ave_loss: 0.344
[66]  [1300/1724] loss: 0.438, ave_loss: 0.346
[67]  [1320/1724] loss: 0.424, ave_loss: 0.347
[68]  [1340/1724] loss: 0.322, ave_loss: 0.346
[69]  [1360/1724] loss: 0.312, ave_loss: 0.346
[70]  [1380/1724] loss: 0.287, ave_loss: 0.345
[71]  [1400/1724] loss: 0.252, ave_loss: 0.344
[72]  [1420/1724] loss: 0.374, ave_loss: 0.344
[73]  [1440/1724] loss: 0.394, ave_loss: 0.345
[74]  [1460/1724] loss: 0.301, ave_loss: 0.344
[75]  [1480/1724] loss: 0.303, ave_loss: 0.344
[76]  [1500/1724] loss: 0.381, ave_loss: 0.344
[77]  [1520/1724] loss: 0.326, ave_loss: 0.344
[78]  [1540/1724] loss: 0.364, ave_loss: 0.344
[79]  [1560/1724] loss: 0.335, ave_loss: 0.344
[80]  [1580/1724] loss: 0.264, ave_loss: 0.343
[81]  [1600/1724] loss: 0.474, ave_loss: 0.345
[82]  [1620/1724] loss: 0.351, ave_loss: 0.345
[83]  [1640/1724] loss: 0.396, ave_loss: 0.345
[84]  [1660/1724] loss: 0.298, ave_loss: 0.345
[85]  [1680/1724] loss: 0.466, ave_loss: 0.346
[86]  [1700/1724] loss: 0.301, ave_loss: 0.346
[87]  [1720/1724] loss: 0.129, ave_loss: 0.343
[88]  [1740/1724] loss: 0.241, ave_loss: 0.342

Finished Training finishing at 2021-08-21 13:30:53.536853
printing_out epoch  82.69141531322506 learning rate: 1.2716519948612849e-06
1.2335024350154462e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.421e-01
Validation Loss: 1.340e+04
Validation ROC: 0.7761
No improvement, still saving model
16.308584686774935 epochs left to go

Training Epoch 82.69141531322506/100 starting at 2021-08-21 13:32:19.676824
[1]  [0/1724] loss: 0.588, ave_loss: 0.588
[2]  [20/1724] loss: 0.373, ave_loss: 0.481
[3]  [40/1724] loss: 0.250, ave_loss: 0.404
[4]  [60/1724] loss: 0.294, ave_loss: 0.376
[5]  [80/1724] loss: 0.510, ave_loss: 0.403
[6]  [100/1724] loss: 0.273, ave_loss: 0.382
[7]  [120/1724] loss: 0.299, ave_loss: 0.370
[8]  [140/1724] loss: 0.387, ave_loss: 0.372
[9]  [160/1724] loss: 0.320, ave_loss: 0.366
[10]  [180/1724] loss: 0.296, ave_loss: 0.359
[11]  [200/1724] loss: 0.254, ave_loss: 0.349
[12]  [220/1724] loss: 0.399, ave_loss: 0.354
[13]  [240/1724] loss: 0.248, ave_loss: 0.346
[14]  [260/1724] loss: 0.354, ave_loss: 0.346
[15]  [280/1724] loss: 0.380, ave_loss: 0.348
[16]  [300/1724] loss: 0.348, ave_loss: 0.348
[17]  [320/1724] loss: 0.340, ave_loss: 0.348
[18]  [340/1724] loss: 0.405, ave_loss: 0.351
[19]  [360/1724] loss: 0.330, ave_loss: 0.350
[20]  [380/1724] loss: 0.392, ave_loss: 0.352
[21]  [400/1724] loss: 0.440, ave_loss: 0.356
[22]  [420/1724] loss: 0.266, ave_loss: 0.352
[23]  [440/1724] loss: 0.313, ave_loss: 0.350
[24]  [460/1724] loss: 0.449, ave_loss: 0.355
[25]  [480/1724] loss: 0.197, ave_loss: 0.348
[26]  [500/1724] loss: 0.427, ave_loss: 0.351
[27]  [520/1724] loss: 0.417, ave_loss: 0.354
[28]  [540/1724] loss: 0.529, ave_loss: 0.360
[29]  [560/1724] loss: 0.242, ave_loss: 0.356
[30]  [580/1724] loss: 0.265, ave_loss: 0.353
[31]  [600/1724] loss: 0.305, ave_loss: 0.351
[32]  [620/1724] loss: 0.545, ave_loss: 0.357
[33]  [640/1724] loss: 0.328, ave_loss: 0.357
[34]  [660/1724] loss: 0.364, ave_loss: 0.357
[35]  [680/1724] loss: 0.388, ave_loss: 0.358
[36]  [700/1724] loss: 0.317, ave_loss: 0.357
[37]  [720/1724] loss: 0.178, ave_loss: 0.352
[38]  [740/1724] loss: 0.266, ave_loss: 0.349
[39]  [760/1724] loss: 0.364, ave_loss: 0.350
[40]  [780/1724] loss: 0.341, ave_loss: 0.350
[41]  [800/1724] loss: 0.433, ave_loss: 0.352
[42]  [820/1724] loss: 0.411, ave_loss: 0.353
[43]  [840/1724] loss: 0.334, ave_loss: 0.353
[44]  [860/1724] loss: 0.291, ave_loss: 0.351
[45]  [880/1724] loss: 0.415, ave_loss: 0.353
[46]  [900/1724] loss: 0.222, ave_loss: 0.350
[47]  [920/1724] loss: 0.265, ave_loss: 0.348
[48]  [940/1724] loss: 0.452, ave_loss: 0.350
[49]  [960/1724] loss: 0.344, ave_loss: 0.350
[50]  [980/1724] loss: 0.360, ave_loss: 0.350
[51]  [1000/1724] loss: 0.570, ave_loss: 0.355
[52]  [1020/1724] loss: 0.309, ave_loss: 0.354
[53]  [1040/1724] loss: 0.283, ave_loss: 0.352
[54]  [1060/1724] loss: 0.307, ave_loss: 0.351
[55]  [1080/1724] loss: 0.264, ave_loss: 0.350
[56]  [1100/1724] loss: 0.448, ave_loss: 0.352
[57]  [1120/1724] loss: 0.219, ave_loss: 0.349
[58]  [1140/1724] loss: 0.466, ave_loss: 0.351
[59]  [1160/1724] loss: 0.531, ave_loss: 0.354
[60]  [1180/1724] loss: 0.326, ave_loss: 0.354
[61]  [1200/1724] loss: 0.317, ave_loss: 0.353
[62]  [1220/1724] loss: 0.359, ave_loss: 0.353
[63]  [1240/1724] loss: 0.373, ave_loss: 0.354
[64]  [1260/1724] loss: 0.419, ave_loss: 0.355
[65]  [1280/1724] loss: 0.278, ave_loss: 0.354
[66]  [1300/1724] loss: 0.286, ave_loss: 0.353
[67]  [1320/1724] loss: 0.292, ave_loss: 0.352
[68]  [1340/1724] loss: 0.288, ave_loss: 0.351
[69]  [1360/1724] loss: 0.397, ave_loss: 0.351
[70]  [1380/1724] loss: 0.304, ave_loss: 0.351
[71]  [1400/1724] loss: 0.341, ave_loss: 0.351
[72]  [1420/1724] loss: 0.341, ave_loss: 0.350
[73]  [1440/1724] loss: 0.421, ave_loss: 0.351
[74]  [1460/1724] loss: 0.271, ave_loss: 0.350
[75]  [1480/1724] loss: 0.165, ave_loss: 0.348
[76]  [1500/1724] loss: 0.452, ave_loss: 0.349
[77]  [1520/1724] loss: 0.333, ave_loss: 0.349
[78]  [1540/1724] loss: 0.244, ave_loss: 0.348
[79]  [1560/1724] loss: 0.350, ave_loss: 0.348
[80]  [1580/1724] loss: 0.331, ave_loss: 0.347
[81]  [1600/1724] loss: 0.263, ave_loss: 0.346
[82]  [1620/1724] loss: 0.246, ave_loss: 0.345
[83]  [1640/1724] loss: 0.351, ave_loss: 0.345
[84]  [1660/1724] loss: 0.323, ave_loss: 0.345
[85]  [1680/1724] loss: 0.499, ave_loss: 0.347
[86]  [1700/1724] loss: 0.396, ave_loss: 0.347
[87]  [1720/1724] loss: 0.320, ave_loss: 0.347
[88]  [1740/1724] loss: 0.606, ave_loss: 0.350

Finished Training finishing at 2021-08-21 13:34:30.874404
printing_out epoch  83.7122969837587 learning rate: 1.1560472680557133e-06
1.1213658500140419e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.500e-01
Validation Loss: 1.342e+04
Validation ROC: 0.7764
No improvement, still saving model
15.287703016241295 epochs left to go

Training Epoch 83.7122969837587/100 starting at 2021-08-21 13:34:59.749194
[1]  [0/1724] loss: 0.524, ave_loss: 0.524
[2]  [20/1724] loss: 0.379, ave_loss: 0.451
[3]  [40/1724] loss: 0.483, ave_loss: 0.462
[4]  [60/1724] loss: 0.408, ave_loss: 0.448
[5]  [80/1724] loss: 0.320, ave_loss: 0.423
[6]  [100/1724] loss: 0.350, ave_loss: 0.411
[7]  [120/1724] loss: 0.246, ave_loss: 0.387
[8]  [140/1724] loss: 0.448, ave_loss: 0.395
[9]  [160/1724] loss: 0.385, ave_loss: 0.394
[10]  [180/1724] loss: 0.306, ave_loss: 0.385
[11]  [200/1724] loss: 0.265, ave_loss: 0.374
[12]  [220/1724] loss: 0.588, ave_loss: 0.392
[13]  [240/1724] loss: 0.306, ave_loss: 0.385
[14]  [260/1724] loss: 0.248, ave_loss: 0.375
[15]  [280/1724] loss: 0.330, ave_loss: 0.372
[16]  [300/1724] loss: 0.462, ave_loss: 0.378
[17]  [320/1724] loss: 0.278, ave_loss: 0.372
[18]  [340/1724] loss: 0.226, ave_loss: 0.364
[19]  [360/1724] loss: 0.451, ave_loss: 0.368
[20]  [380/1724] loss: 0.294, ave_loss: 0.365
[21]  [400/1724] loss: 0.340, ave_loss: 0.364
[22]  [420/1724] loss: 0.198, ave_loss: 0.356
[23]  [440/1724] loss: 0.535, ave_loss: 0.364
[24]  [460/1724] loss: 0.314, ave_loss: 0.362
[25]  [480/1724] loss: 0.353, ave_loss: 0.361
[26]  [500/1724] loss: 0.376, ave_loss: 0.362
[27]  [520/1724] loss: 0.384, ave_loss: 0.363
[28]  [540/1724] loss: 0.281, ave_loss: 0.360
[29]  [560/1724] loss: 0.278, ave_loss: 0.357
[30]  [580/1724] loss: 0.489, ave_loss: 0.361
[31]  [600/1724] loss: 0.441, ave_loss: 0.364
[32]  [620/1724] loss: 0.350, ave_loss: 0.364
[33]  [640/1724] loss: 0.277, ave_loss: 0.361
[34]  [660/1724] loss: 0.499, ave_loss: 0.365
[35]  [680/1724] loss: 0.327, ave_loss: 0.364
[36]  [700/1724] loss: 0.311, ave_loss: 0.362
[37]  [720/1724] loss: 0.409, ave_loss: 0.364
[38]  [740/1724] loss: 0.367, ave_loss: 0.364
[39]  [760/1724] loss: 0.201, ave_loss: 0.360
[40]  [780/1724] loss: 0.378, ave_loss: 0.360
[41]  [800/1724] loss: 0.448, ave_loss: 0.362
[42]  [820/1724] loss: 0.409, ave_loss: 0.363
[43]  [840/1724] loss: 0.425, ave_loss: 0.365
[44]  [860/1724] loss: 0.493, ave_loss: 0.368
[45]  [880/1724] loss: 0.344, ave_loss: 0.367
[46]  [900/1724] loss: 0.274, ave_loss: 0.365
[47]  [920/1724] loss: 0.286, ave_loss: 0.363
[48]  [940/1724] loss: 0.341, ave_loss: 0.363
[49]  [960/1724] loss: 0.484, ave_loss: 0.365
[50]  [980/1724] loss: 0.422, ave_loss: 0.367
[51]  [1000/1724] loss: 0.374, ave_loss: 0.367
[52]  [1020/1724] loss: 0.422, ave_loss: 0.368
[53]  [1040/1724] loss: 0.404, ave_loss: 0.369
[54]  [1060/1724] loss: 0.354, ave_loss: 0.368
[55]  [1080/1724] loss: 0.335, ave_loss: 0.368
[56]  [1100/1724] loss: 0.349, ave_loss: 0.367
[57]  [1120/1724] loss: 0.274, ave_loss: 0.366
[58]  [1140/1724] loss: 0.405, ave_loss: 0.366
[59]  [1160/1724] loss: 0.216, ave_loss: 0.364
[60]  [1180/1724] loss: 0.480, ave_loss: 0.366
[61]  [1200/1724] loss: 0.225, ave_loss: 0.363
[62]  [1220/1724] loss: 0.372, ave_loss: 0.364
[63]  [1240/1724] loss: 0.336, ave_loss: 0.363
[64]  [1260/1724] loss: 0.483, ave_loss: 0.365
[65]  [1280/1724] loss: 0.272, ave_loss: 0.364
[66]  [1300/1724] loss: 0.439, ave_loss: 0.365
[67]  [1320/1724] loss: 0.390, ave_loss: 0.365
[68]  [1340/1724] loss: 0.298, ave_loss: 0.364
[69]  [1360/1724] loss: 0.339, ave_loss: 0.364
[70]  [1380/1724] loss: 0.251, ave_loss: 0.362
[71]  [1400/1724] loss: 0.493, ave_loss: 0.364
[72]  [1420/1724] loss: 0.280, ave_loss: 0.363
[73]  [1440/1724] loss: 0.315, ave_loss: 0.362
[74]  [1460/1724] loss: 0.266, ave_loss: 0.361
[75]  [1480/1724] loss: 0.376, ave_loss: 0.361
[76]  [1500/1724] loss: 0.411, ave_loss: 0.362
[77]  [1520/1724] loss: 0.474, ave_loss: 0.363
[78]  [1540/1724] loss: 0.438, ave_loss: 0.364
[79]  [1560/1724] loss: 0.369, ave_loss: 0.364
[80]  [1580/1724] loss: 0.506, ave_loss: 0.366
[81]  [1600/1724] loss: 0.457, ave_loss: 0.367
[82]  [1620/1724] loss: 0.288, ave_loss: 0.366
[83]  [1640/1724] loss: 0.276, ave_loss: 0.365
[84]  [1660/1724] loss: 0.335, ave_loss: 0.365
[85]  [1680/1724] loss: 0.277, ave_loss: 0.364
[86]  [1700/1724] loss: 0.181, ave_loss: 0.361
[87]  [1720/1724] loss: 0.297, ave_loss: 0.361
[88]  [1740/1724] loss: 0.431, ave_loss: 0.362

Finished Training finishing at 2021-08-21 13:36:53.558033
printing_out epoch  84.73317865429235 learning rate: 1.0509520618688303e-06
1.0194235000127655e-06
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.615e-01
Validation Loss: 1.340e+04
Validation ROC: 0.7762
No improvement, still saving model
14.266821345707655 epochs left to go

Training Epoch 84.73317865429235/100 starting at 2021-08-21 13:37:23.860807
[1]  [0/1724] loss: 0.557, ave_loss: 0.557
[2]  [20/1724] loss: 0.337, ave_loss: 0.447
[3]  [40/1724] loss: 0.261, ave_loss: 0.385
[4]  [60/1724] loss: 0.198, ave_loss: 0.338
[5]  [80/1724] loss: 0.422, ave_loss: 0.355
[6]  [100/1724] loss: 0.333, ave_loss: 0.351
[7]  [120/1724] loss: 0.282, ave_loss: 0.341
[8]  [140/1724] loss: 0.302, ave_loss: 0.336
[9]  [160/1724] loss: 0.261, ave_loss: 0.328
[10]  [180/1724] loss: 0.415, ave_loss: 0.337
[11]  [200/1724] loss: 0.365, ave_loss: 0.339
[12]  [220/1724] loss: 0.321, ave_loss: 0.338
[13]  [240/1724] loss: 0.273, ave_loss: 0.333
[14]  [260/1724] loss: 0.405, ave_loss: 0.338
[15]  [280/1724] loss: 0.330, ave_loss: 0.337
[16]  [300/1724] loss: 0.386, ave_loss: 0.340
[17]  [320/1724] loss: 0.346, ave_loss: 0.341
[18]  [340/1724] loss: 0.304, ave_loss: 0.339
[19]  [360/1724] loss: 0.284, ave_loss: 0.336
[20]  [380/1724] loss: 0.255, ave_loss: 0.332
[21]  [400/1724] loss: 0.324, ave_loss: 0.331
[22]  [420/1724] loss: 0.337, ave_loss: 0.332
[23]  [440/1724] loss: 0.354, ave_loss: 0.333
[24]  [460/1724] loss: 0.244, ave_loss: 0.329
[25]  [480/1724] loss: 0.239, ave_loss: 0.325
[26]  [500/1724] loss: 0.233, ave_loss: 0.322
[27]  [520/1724] loss: 0.263, ave_loss: 0.320
[28]  [540/1724] loss: 0.302, ave_loss: 0.319
[29]  [560/1724] loss: 0.452, ave_loss: 0.323
[30]  [580/1724] loss: 0.311, ave_loss: 0.323
[31]  [600/1724] loss: 0.336, ave_loss: 0.323
[32]  [620/1724] loss: 0.377, ave_loss: 0.325
[33]  [640/1724] loss: 0.319, ave_loss: 0.325
[34]  [660/1724] loss: 0.274, ave_loss: 0.323
[35]  [680/1724] loss: 0.364, ave_loss: 0.325
[36]  [700/1724] loss: 0.356, ave_loss: 0.326
[37]  [720/1724] loss: 0.446, ave_loss: 0.329
[38]  [740/1724] loss: 0.419, ave_loss: 0.331
[39]  [760/1724] loss: 0.293, ave_loss: 0.330
[40]  [780/1724] loss: 0.285, ave_loss: 0.329
[41]  [800/1724] loss: 0.295, ave_loss: 0.328
[42]  [820/1724] loss: 0.421, ave_loss: 0.330
[43]  [840/1724] loss: 0.446, ave_loss: 0.333
[44]  [860/1724] loss: 0.423, ave_loss: 0.335
[45]  [880/1724] loss: 0.247, ave_loss: 0.333
[46]  [900/1724] loss: 0.338, ave_loss: 0.333
[47]  [920/1724] loss: 0.187, ave_loss: 0.330
[48]  [940/1724] loss: 0.454, ave_loss: 0.333
[49]  [960/1724] loss: 0.331, ave_loss: 0.333
[50]  [980/1724] loss: 0.294, ave_loss: 0.332
[51]  [1000/1724] loss: 0.431, ave_loss: 0.334
[52]  [1020/1724] loss: 0.349, ave_loss: 0.334
[53]  [1040/1724] loss: 0.466, ave_loss: 0.337
[54]  [1060/1724] loss: 0.250, ave_loss: 0.335
[55]  [1080/1724] loss: 0.241, ave_loss: 0.333
[56]  [1100/1724] loss: 0.368, ave_loss: 0.334
[57]  [1120/1724] loss: 0.214, ave_loss: 0.332
[58]  [1140/1724] loss: 0.470, ave_loss: 0.334
[59]  [1160/1724] loss: 0.325, ave_loss: 0.334
[60]  [1180/1724] loss: 0.369, ave_loss: 0.335
[61]  [1200/1724] loss: 0.410, ave_loss: 0.336
[62]  [1220/1724] loss: 0.267, ave_loss: 0.335
[63]  [1240/1724] loss: 0.288, ave_loss: 0.334
[64]  [1260/1724] loss: 0.259, ave_loss: 0.333
[65]  [1280/1724] loss: 0.292, ave_loss: 0.332
[66]  [1300/1724] loss: 0.382, ave_loss: 0.333
[67]  [1320/1724] loss: 0.292, ave_loss: 0.332
[68]  [1340/1724] loss: 0.359, ave_loss: 0.333
[69]  [1360/1724] loss: 0.330, ave_loss: 0.333
[70]  [1380/1724] loss: 0.235, ave_loss: 0.331
[71]  [1400/1724] loss: 0.337, ave_loss: 0.331
[72]  [1420/1724] loss: 0.222, ave_loss: 0.330
[73]  [1440/1724] loss: 0.415, ave_loss: 0.331
[74]  [1460/1724] loss: 0.418, ave_loss: 0.332
[75]  [1480/1724] loss: 0.364, ave_loss: 0.333
[76]  [1500/1724] loss: 0.253, ave_loss: 0.332
[77]  [1520/1724] loss: 0.314, ave_loss: 0.331
[78]  [1540/1724] loss: 0.296, ave_loss: 0.331
[79]  [1560/1724] loss: 0.386, ave_loss: 0.332
[80]  [1580/1724] loss: 0.390, ave_loss: 0.332
[81]  [1600/1724] loss: 0.320, ave_loss: 0.332
[82]  [1620/1724] loss: 0.466, ave_loss: 0.334
[83]  [1640/1724] loss: 0.332, ave_loss: 0.334
[84]  [1660/1724] loss: 0.328, ave_loss: 0.334
[85]  [1680/1724] loss: 0.228, ave_loss: 0.333
[86]  [1700/1724] loss: 0.329, ave_loss: 0.332
[87]  [1720/1724] loss: 0.302, ave_loss: 0.332
[88]  [1740/1724] loss: 0.347, ave_loss: 0.332

Finished Training finishing at 2021-08-21 13:39:22.908649
printing_out epoch  85.75406032482599 learning rate: 9.554109653353002e-07
9.267486363752412e-07
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.323e-01
Validation Loss: 1.341e+04
Validation ROC: 0.7763
No improvement, still saving model
13.245939675174014 epochs left to go

Training Epoch 85.75406032482599/100 starting at 2021-08-21 13:40:08.327065
[1]  [0/1724] loss: 0.775, ave_loss: 0.775
[2]  [20/1724] loss: 0.354, ave_loss: 0.564
[3]  [40/1724] loss: 0.397, ave_loss: 0.509
[4]  [60/1724] loss: 0.320, ave_loss: 0.462
[5]  [80/1724] loss: 0.266, ave_loss: 0.423
[6]  [100/1724] loss: 0.241, ave_loss: 0.392
[7]  [120/1724] loss: 0.303, ave_loss: 0.379
[8]  [140/1724] loss: 0.336, ave_loss: 0.374
[9]  [160/1724] loss: 0.307, ave_loss: 0.367
[10]  [180/1724] loss: 0.231, ave_loss: 0.353
[11]  [200/1724] loss: 0.350, ave_loss: 0.353
[12]  [220/1724] loss: 0.346, ave_loss: 0.352
[13]  [240/1724] loss: 0.250, ave_loss: 0.344
[14]  [260/1724] loss: 0.314, ave_loss: 0.342
[15]  [280/1724] loss: 0.302, ave_loss: 0.340
[16]  [300/1724] loss: 0.333, ave_loss: 0.339
[17]  [320/1724] loss: 0.463, ave_loss: 0.346
[18]  [340/1724] loss: 0.378, ave_loss: 0.348
[19]  [360/1724] loss: 0.279, ave_loss: 0.345
[20]  [380/1724] loss: 0.270, ave_loss: 0.341
[21]  [400/1724] loss: 0.370, ave_loss: 0.342
[22]  [420/1724] loss: 0.286, ave_loss: 0.340
[23]  [440/1724] loss: 0.363, ave_loss: 0.341
[24]  [460/1724] loss: 0.349, ave_loss: 0.341
[25]  [480/1724] loss: 0.469, ave_loss: 0.346
[26]  [500/1724] loss: 0.453, ave_loss: 0.350
[27]  [520/1724] loss: 0.442, ave_loss: 0.354
[28]  [540/1724] loss: 0.280, ave_loss: 0.351
[29]  [560/1724] loss: 0.557, ave_loss: 0.358
[30]  [580/1724] loss: 0.310, ave_loss: 0.357
[31]  [600/1724] loss: 0.472, ave_loss: 0.360
[32]  [620/1724] loss: 0.351, ave_loss: 0.360
[33]  [640/1724] loss: 0.262, ave_loss: 0.357
[34]  [660/1724] loss: 0.308, ave_loss: 0.356
[35]  [680/1724] loss: 0.322, ave_loss: 0.355
[36]  [700/1724] loss: 0.176, ave_loss: 0.350
[37]  [720/1724] loss: 0.290, ave_loss: 0.348
[38]  [740/1724] loss: 0.279, ave_loss: 0.346
[39]  [760/1724] loss: 0.266, ave_loss: 0.344
[40]  [780/1724] loss: 0.467, ave_loss: 0.347
[41]  [800/1724] loss: 0.364, ave_loss: 0.348
[42]  [820/1724] loss: 0.312, ave_loss: 0.347
[43]  [840/1724] loss: 0.316, ave_loss: 0.346
[44]  [860/1724] loss: 0.297, ave_loss: 0.345
[45]  [880/1724] loss: 0.305, ave_loss: 0.344
[46]  [900/1724] loss: 0.304, ave_loss: 0.343
[47]  [920/1724] loss: 0.399, ave_loss: 0.344
[48]  [940/1724] loss: 0.425, ave_loss: 0.346
[49]  [960/1724] loss: 0.294, ave_loss: 0.345
[50]  [980/1724] loss: 0.325, ave_loss: 0.345
[51]  [1000/1724] loss: 0.362, ave_loss: 0.345
[52]  [1020/1724] loss: 0.335, ave_loss: 0.345
[53]  [1040/1724] loss: 0.331, ave_loss: 0.344
[54]  [1060/1724] loss: 0.241, ave_loss: 0.343
[55]  [1080/1724] loss: 0.347, ave_loss: 0.343
[56]  [1100/1724] loss: 0.372, ave_loss: 0.343
[57]  [1120/1724] loss: 0.373, ave_loss: 0.344
[58]  [1140/1724] loss: 0.310, ave_loss: 0.343
[59]  [1160/1724] loss: 0.311, ave_loss: 0.343
[60]  [1180/1724] loss: 0.417, ave_loss: 0.344

reading from multiple data folder!**********************************************
Selected signals (determines which signals are used for training):
[q95 safety factor, internal inductance, plasma current, Locked mode amplitude, Normalized Beta, stored energy, Plasma density, Radiated Power Core, Radiated Power Edge, Input Power (beam for d3d), Input Beam Torque, plasma current direction, plasma current target, plasma current error, Electron temperature profile, Electron density profile]
Arguments:  Namespace(channels_spatial=['c16', 'c8', 'c4', 'c2'], channels_temporal=['c4', 'd4', 'd4', 'd4', 'd4', 'd4', 'd4'], input_div=1.0, kernel_spatial=4, kernel_temporal=4, linear_sizes=[20, 5], no_scalars=False, subsampling=10, tcn_hidden=4, tcn_layers=6, tcn_type='d')
...done
Training on 1724 shots, testing on 857 shots
Classical convolution with channels  2 16
Classical convolution with channels  16 8
Classical convolution with channels  8 4
Classical convolution with channels  4 2
InputBlock parameters:  14 2 64 ['c16', 'c8', 'c4', 'c2'] 4 [20, 5] 0.08
TCN parameters:  19 1 ['c4', 'd4', 'd4', 'd4', 'd4', 'd4', 'd4'] 4 0.08
29 epochs left to go

Training Epoch 0/30 starting at 2021-08-29 18:29:57.130934
[1]  [0/1724] loss: 6.600, ave_loss: 6.600
tensor(11.2578, device='cuda:0', grad_fn=<MseLossBackward>)
[2]  [20/1724] loss anomaly, ave_loss: 6.600
[3]  [40/1724] loss: 9.627, ave_loss: 7.609
[4]  [60/1724] loss: 7.428, ave_loss: 7.564
[5]  [80/1724] loss: 8.740, ave_loss: 7.799
tensor(10.7091, device='cuda:0', grad_fn=<MseLossBackward>)
[6]  [100/1724] loss anomaly, ave_loss: 7.799
[7]  [120/1724] loss: 6.676, ave_loss: 7.639
[8]  [140/1724] loss: 9.896, ave_loss: 7.921
[9]  [160/1724] loss: 7.480, ave_loss: 7.872
tensor(10.1080, device='cuda:0', grad_fn=<MseLossBackward>)
[10]  [180/1724] loss anomaly, ave_loss: 7.872
[11]  [200/1724] loss: 9.766, ave_loss: 8.044
tensor(10.7890, device='cuda:0', grad_fn=<MseLossBackward>)
[12]  [220/1724] loss anomaly, ave_loss: 8.044
[13]  [240/1724] loss: 7.072, ave_loss: 7.969
[14]  [260/1724] loss: 8.922, ave_loss: 8.037
[15]  [280/1724] loss: 7.884, ave_loss: 8.027
[16]  [300/1724] loss: 8.163, ave_loss: 8.035
[17]  [320/1724] loss: 5.520, ave_loss: 7.888
[18]  [340/1724] loss: 6.906, ave_loss: 7.833
[19]  [360/1724] loss: 5.216, ave_loss: 7.695
[20]  [380/1724] loss: 6.166, ave_loss: 7.619
[21]  [400/1724] loss: 4.190, ave_loss: 7.456
[22]  [420/1724] loss: 3.911, ave_loss: 7.294
[23]  [440/1724] loss: 5.276, ave_loss: 7.207
[24]  [460/1724] loss: 4.807, ave_loss: 7.107
[25]  [480/1724] loss: 5.683, ave_loss: 7.050
[26]  [500/1724] loss: 2.822, ave_loss: 6.887
[27]  [520/1724] loss: 6.936, ave_loss: 6.889
[28]  [540/1724] loss: 3.509, ave_loss: 6.768
[29]  [560/1724] loss: 7.310, ave_loss: 6.787
[30]  [580/1724] loss: 3.346, ave_loss: 6.672
[31]  [600/1724] loss: 4.293, ave_loss: 6.595
[32]  [620/1724] loss: 4.929, ave_loss: 6.543
[33]  [640/1724] loss: 6.892, ave_loss: 6.554
[34]  [660/1724] loss: 4.699, ave_loss: 6.499
[35]  [680/1724] loss: 2.904, ave_loss: 6.397
[36]  [700/1724] loss: 4.388, ave_loss: 6.341
[37]  [720/1724] loss: 6.862, ave_loss: 6.355
[38]  [740/1724] loss: 2.763, ave_loss: 6.260
[39]  [760/1724] loss: 4.741, ave_loss: 6.221
[40]  [780/1724] loss: 4.284, ave_loss: 6.173
[41]  [800/1724] loss: 4.505, ave_loss: 6.132
[42]  [820/1724] loss: 3.303, ave_loss: 6.065
[43]  [840/1724] loss: 3.193, ave_loss: 5.998
[44]  [860/1724] loss: 2.295, ave_loss: 5.914
[45]  [880/1724] loss: 3.588, ave_loss: 5.862
[46]  [900/1724] loss: 3.313, ave_loss: 5.807
[47]  [920/1724] loss: 2.347, ave_loss: 5.733
[48]  [940/1724] loss: 3.056, ave_loss: 5.678
[49]  [960/1724] loss: 2.974, ave_loss: 5.622
[50]  [980/1724] loss: 3.879, ave_loss: 5.587
[51]  [1000/1724] loss: 3.399, ave_loss: 5.545
[52]  [1020/1724] loss: 2.503, ave_loss: 5.486
[53]  [1040/1724] loss: 3.770, ave_loss: 5.454
[54]  [1060/1724] loss: 2.419, ave_loss: 5.397
[55]  [1080/1724] loss: 1.858, ave_loss: 5.333
[56]  [1100/1724] loss: 2.856, ave_loss: 5.289
[57]  [1120/1724] loss: 4.654, ave_loss: 5.278
[58]  [1140/1724] loss: 5.586, ave_loss: 5.283
[59]  [1160/1724] loss: 2.280, ave_loss: 5.232
[60]  [1180/1724] loss: 1.659, ave_loss: 5.173
[61]  [1200/1724] loss: 2.291, ave_loss: 5.125
[62]  [1220/1724] loss: 4.684, ave_loss: 5.118
[63]  [1240/1724] loss: 2.769, ave_loss: 5.081
[64]  [1260/1724] loss: 2.743, ave_loss: 5.044
[65]  [1280/1724] loss: 2.154, ave_loss: 5.000
[66]  [1300/1724] loss: 2.344, ave_loss: 4.960
[67]  [1320/1724] loss: 2.216, ave_loss: 4.919
[68]  [1340/1724] loss: 1.635, ave_loss: 4.870
[69]  [1360/1724] loss: 3.753, ave_loss: 4.854
[70]  [1380/1724] loss: 2.084, ave_loss: 4.815
[71]  [1400/1724] loss: 3.053, ave_loss: 4.790
[72]  [1420/1724] loss: 1.695, ave_loss: 4.747
[73]  [1440/1724] loss: 1.534, ave_loss: 4.703
[74]  [1460/1724] loss: 3.090, ave_loss: 4.681
[75]  [1480/1724] loss: 1.379, ave_loss: 4.637
[76]  [1500/1724] loss: 2.197, ave_loss: 4.605
[77]  [1520/1724] loss: 1.668, ave_loss: 4.567
[78]  [1540/1724] loss: 1.497, ave_loss: 4.527
[79]  [1560/1724] loss: 1.679, ave_loss: 4.491
[80]  [1580/1724] loss: 1.985, ave_loss: 4.460
[81]  [1600/1724] loss: 1.227, ave_loss: 4.420
[82]  [1620/1724] loss: 1.519, ave_loss: 4.385
[83]  [1640/1724] loss: 1.650, ave_loss: 4.352
[84]  [1660/1724] loss: 1.933, ave_loss: 4.323
[85]  [1680/1724] loss: 1.488, ave_loss: 4.290
[86]  [1700/1724] loss: 1.477, ave_loss: 4.257
[87]  [1720/1724] loss: 1.224, ave_loss: 4.222
[88]  [1740/1724] loss: 1.193, ave_loss: 4.188

Finished Training finishing at 2021-08-29 18:34:48.747316
printing_out epoch  1.0208816705336428 learning rate: 0.0005153561248318907
0.000499895441086934
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.188e+00
Validation Loss: 1.764e+06
Validation ROC: 0.1635
Saving model
27.979118329466356 epochs left to go

Training Epoch 1.0208816705336428/30 starting at 2021-08-29 18:37:32.071693
[1]  [0/1724] loss: 1.512, ave_loss: 1.512
[2]  [20/1724] loss: 1.339, ave_loss: 1.425
[3]  [40/1724] loss: 1.621, ave_loss: 1.491
[4]  [60/1724] loss: 1.752, ave_loss: 1.556
[5]  [80/1724] loss: 1.459, ave_loss: 1.537
[6]  [100/1724] loss: 1.267, ave_loss: 1.492
[7]  [120/1724] loss: 1.147, ave_loss: 1.442
[8]  [140/1724] loss: 1.585, ave_loss: 1.460
[9]  [160/1724] loss: 0.936, ave_loss: 1.402
[10]  [180/1724] loss: 1.347, ave_loss: 1.396
[11]  [200/1724] loss: 1.415, ave_loss: 1.398
[12]  [220/1724] loss: 1.254, ave_loss: 1.386
[13]  [240/1724] loss: 1.632, ave_loss: 1.405
[14]  [260/1724] loss: 1.106, ave_loss: 1.384
[15]  [280/1724] loss: 1.122, ave_loss: 1.366
[16]  [300/1724] loss: 1.199, ave_loss: 1.356
[17]  [320/1724] loss: 1.631, ave_loss: 1.372
[18]  [340/1724] loss: 1.503, ave_loss: 1.379
[19]  [360/1724] loss: 1.172, ave_loss: 1.368
[20]  [380/1724] loss: 1.341, ave_loss: 1.367
[21]  [400/1724] loss: 1.128, ave_loss: 1.356
[22]  [420/1724] loss: 0.899, ave_loss: 1.335
[23]  [440/1724] loss: 1.015, ave_loss: 1.321
[24]  [460/1724] loss: 1.179, ave_loss: 1.315
[25]  [480/1724] loss: 1.372, ave_loss: 1.317
[26]  [500/1724] loss: 1.118, ave_loss: 1.310
[27]  [520/1724] loss: 1.005, ave_loss: 1.298
[28]  [540/1724] loss: 0.968, ave_loss: 1.287
[29]  [560/1724] loss: 1.248, ave_loss: 1.285
[30]  [580/1724] loss: 1.046, ave_loss: 1.277
[31]  [600/1724] loss: 1.292, ave_loss: 1.278
[32]  [620/1724] loss: 1.272, ave_loss: 1.278
[33]  [640/1724] loss: 1.155, ave_loss: 1.274
[34]  [660/1724] loss: 1.995, ave_loss: 1.295
[35]  [680/1724] loss: 1.393, ave_loss: 1.298
[36]  [700/1724] loss: 1.103, ave_loss: 1.293
[37]  [720/1724] loss: 1.113, ave_loss: 1.288
[38]  [740/1724] loss: 1.110, ave_loss: 1.283
[39]  [760/1724] loss: 1.210, ave_loss: 1.281
[40]  [780/1724] loss: 1.147, ave_loss: 1.278
[41]  [800/1724] loss: 1.143, ave_loss: 1.274
[42]  [820/1724] loss: 0.927, ave_loss: 1.266
[43]  [840/1724] loss: 1.329, ave_loss: 1.268
[44]  [860/1724] loss: 1.166, ave_loss: 1.265
[45]  [880/1724] loss: 1.126, ave_loss: 1.262
[46]  [900/1724] loss: 1.343, ave_loss: 1.264
[47]  [920/1724] loss: 1.251, ave_loss: 1.264
[48]  [940/1724] loss: 1.266, ave_loss: 1.264
[49]  [960/1724] loss: 1.000, ave_loss: 1.258
[50]  [980/1724] loss: 1.287, ave_loss: 1.259
[51]  [1000/1724] loss: 1.426, ave_loss: 1.262
[52]  [1020/1724] loss: 1.177, ave_loss: 1.261
[53]  [1040/1724] loss: 1.318, ave_loss: 1.262
[54]  [1060/1724] loss: 0.919, ave_loss: 1.255
[55]  [1080/1724] loss: 0.936, ave_loss: 1.250
[56]  [1100/1724] loss: 0.917, ave_loss: 1.244
[57]  [1120/1724] loss: 1.000, ave_loss: 1.239
[58]  [1140/1724] loss: 1.113, ave_loss: 1.237
[59]  [1160/1724] loss: 1.142, ave_loss: 1.236
[60]  [1180/1724] loss: 0.887, ave_loss: 1.230
[61]  [1200/1724] loss: 1.172, ave_loss: 1.229
[62]  [1220/1724] loss: 1.262, ave_loss: 1.229
[63]  [1240/1724] loss: 1.016, ave_loss: 1.226
[64]  [1260/1724] loss: 1.091, ave_loss: 1.224
[65]  [1280/1724] loss: 1.187, ave_loss: 1.223
[66]  [1300/1724] loss: 0.681, ave_loss: 1.215
[67]  [1320/1724] loss: 0.562, ave_loss: 1.205
[68]  [1340/1724] loss: 1.124, ave_loss: 1.204
[69]  [1360/1724] loss: 1.007, ave_loss: 1.201
[70]  [1380/1724] loss: 1.294, ave_loss: 1.203
[71]  [1400/1724] loss: 1.027, ave_loss: 1.200
[72]  [1420/1724] loss: 1.028, ave_loss: 1.198
[73]  [1440/1724] loss: 1.017, ave_loss: 1.195
[74]  [1460/1724] loss: 1.232, ave_loss: 1.196
[75]  [1480/1724] loss: 0.946, ave_loss: 1.192
[76]  [1500/1724] loss: 1.128, ave_loss: 1.192
[77]  [1520/1724] loss: 1.060, ave_loss: 1.190
[78]  [1540/1724] loss: 1.178, ave_loss: 1.190
[79]  [1560/1724] loss: 0.963, ave_loss: 1.187
[80]  [1580/1724] loss: 1.169, ave_loss: 1.187
[81]  [1600/1724] loss: 1.046, ave_loss: 1.185
[82]  [1620/1724] loss: 1.025, ave_loss: 1.183
[83]  [1640/1724] loss: 0.951, ave_loss: 1.180
[84]  [1660/1724] loss: 1.053, ave_loss: 1.179
[85]  [1680/1724] loss: 1.036, ave_loss: 1.177
[86]  [1700/1724] loss: 0.922, ave_loss: 1.174
[87]  [1720/1724] loss: 0.953, ave_loss: 1.171
[88]  [1740/1724] loss: 1.583, ave_loss: 1.176

Finished Training finishing at 2021-08-29 18:41:46.203101
printing_out epoch  2.0417633410672855 learning rate: 0.0005153561248318907
0.00048489857785432596
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 1.176e+00
Validation Loss: 1.622e+06
Validation ROC: 0.3601
Saving model
26.958236658932716 epochs left to go

Training Epoch 2.0417633410672855/30 starting at 2021-08-29 18:43:33.912609
[1]  [0/1724] loss: 1.110, ave_loss: 1.110
[2]  [20/1724] loss: 0.948, ave_loss: 1.029
[3]  [40/1724] loss: 1.335, ave_loss: 1.131
[4]  [60/1724] loss: 1.420, ave_loss: 1.203
[5]  [80/1724] loss: 1.200, ave_loss: 1.202
[6]  [100/1724] loss: 1.155, ave_loss: 1.194
[7]  [120/1724] loss: 0.902, ave_loss: 1.153
[8]  [140/1724] loss: 1.003, ave_loss: 1.134
[9]  [160/1724] loss: 0.960, ave_loss: 1.115
[10]  [180/1724] loss: 0.820, ave_loss: 1.085
[11]  [200/1724] loss: 1.087, ave_loss: 1.085
[12]  [220/1724] loss: 1.090, ave_loss: 1.086
[13]  [240/1724] loss: 1.009, ave_loss: 1.080
[14]  [260/1724] loss: 1.217, ave_loss: 1.090
[15]  [280/1724] loss: 1.140, ave_loss: 1.093
[16]  [300/1724] loss: 0.885, ave_loss: 1.080
[17]  [320/1724] loss: 1.225, ave_loss: 1.088
[18]  [340/1724] loss: 0.952, ave_loss: 1.081
[19]  [360/1724] loss: 0.776, ave_loss: 1.065
[20]  [380/1724] loss: 1.141, ave_loss: 1.069
[21]  [400/1724] loss: 1.063, ave_loss: 1.068
[22]  [420/1724] loss: 1.171, ave_loss: 1.073
[23]  [440/1724] loss: 1.065, ave_loss: 1.073
[24]  [460/1724] loss: 1.169, ave_loss: 1.077
[25]  [480/1724] loss: 0.892, ave_loss: 1.069
[26]  [500/1724] loss: 1.120, ave_loss: 1.071
[27]  [520/1724] loss: 1.040, ave_loss: 1.070
[28]  [540/1724] loss: 1.087, ave_loss: 1.071
[29]  [560/1724] loss: 0.759, ave_loss: 1.060
[30]  [580/1724] loss: 0.809, ave_loss: 1.052
[31]  [600/1724] loss: 0.993, ave_loss: 1.050
[32]  [620/1724] loss: 0.779, ave_loss: 1.041
[33]  [640/1724] loss: 1.094, ave_loss: 1.043
[34]  [660/1724] loss: 0.981, ave_loss: 1.041
[35]  [680/1724] loss: 0.949, ave_loss: 1.038
[36]  [700/1724] loss: 0.874, ave_loss: 1.034
[37]  [720/1724] loss: 1.184, ave_loss: 1.038
[38]  [740/1724] loss: 0.817, ave_loss: 1.032
[39]  [760/1724] loss: 1.035, ave_loss: 1.032
[40]  [780/1724] loss: 1.400, ave_loss: 1.041
[41]  [800/1724] loss: 1.209, ave_loss: 1.045
[42]  [820/1724] loss: 1.271, ave_loss: 1.051
[43]  [840/1724] loss: 1.251, ave_loss: 1.055
[44]  [860/1724] loss: 1.030, ave_loss: 1.055
[45]  [880/1724] loss: 1.172, ave_loss: 1.057
[46]  [900/1724] loss: 1.151, ave_loss: 1.060
[47]  [920/1724] loss: 1.040, ave_loss: 1.059
[48]  [940/1724] loss: 0.906, ave_loss: 1.056
[49]  [960/1724] loss: 1.096, ave_loss: 1.057
[50]  [980/1724] loss: 1.267, ave_loss: 1.061
[51]  [1000/1724] loss: 1.238, ave_loss: 1.064
[52]  [1020/1724] loss: 1.083, ave_loss: 1.065
[53]  [1040/1724] loss: 0.912, ave_loss: 1.062
[54]  [1060/1724] loss: 1.050, ave_loss: 1.062
[55]  [1080/1724] loss: 1.323, ave_loss: 1.066
[56]  [1100/1724] loss: 1.023, ave_loss: 1.066
[57]  [1120/1724] loss: 1.308, ave_loss: 1.070
[58]  [1140/1724] loss: 0.960, ave_loss: 1.068
[59]  [1160/1724] loss: 1.120, ave_loss: 1.069
[60]  [1180/1724] loss: 0.799, ave_loss: 1.064
[61]  [1200/1724] loss: 0.965, ave_loss: 1.063
[62]  [1220/1724] loss: 1.055, ave_loss: 1.063
[63]  [1240/1724] loss: 1.051, ave_loss: 1.062
[64]  [1260/1724] loss: 1.125, ave_loss: 1.063
[65]  [1280/1724] loss: 1.151, ave_loss: 1.065
[66]  [1300/1724] loss: 0.960, ave_loss: 1.063
[67]  [1320/1724] loss: 1.053, ave_loss: 1.063
[68]  [1340/1724] loss: 1.044, ave_loss: 1.063
[69]  [1360/1724] loss: 0.797, ave_loss: 1.059
[70]  [1380/1724] loss: 1.134, ave_loss: 1.060
[71]  [1400/1724] loss: 0.869, ave_loss: 1.057
[72]  [1420/1724] loss: 0.881, ave_loss: 1.055
[73]  [1440/1724] loss: 0.979, ave_loss: 1.054
[74]  [1460/1724] loss: 0.870, ave_loss: 1.051
[75]  [1480/1724] loss: 1.235, ave_loss: 1.054
[76]  [1500/1724] loss: 1.056, ave_loss: 1.054
[77]  [1520/1724] loss: 1.006, ave_loss: 1.053
[78]  [1540/1724] loss: 0.999, ave_loss: 1.052
[79]  [1560/1724] loss: 0.893, ave_loss: 1.050
[80]  [1580/1724] loss: 0.990, ave_loss: 1.050
[81]  [1600/1724] loss: 0.824, ave_loss: 1.047
[82]  [1620/1724] loss: 1.127, ave_loss: 1.048
[83]  [1640/1724] loss: 0.941, ave_loss: 1.047
[84]  [1660/1724] loss: 0.872, ave_loss: 1.045
[85]  [1680/1724] loss: 1.010, ave_loss: 1.044
[86]  [1700/1724] loss: 0.887, ave_loss: 1.042
[87]  [1720/1724] loss: 0.699, ave_loss: 1.038
[88]  [1740/1724] loss: 1.088, ave_loss: 1.039

Finished Training finishing at 2021-08-29 18:47:51.268289
printing_out epoch  3.062645011600928 learning rate: 0.0005153561248318907
0.00047035162051869614
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 1.039e+00
Validation Loss: 1.565e+06
Validation ROC: 0.4437
Saving model
25.937354988399072 epochs left to go

Training Epoch 3.062645011600928/30 starting at 2021-08-29 18:49:46.485865
[1]  [0/1724] loss: 0.781, ave_loss: 0.781
[2]  [20/1724] loss: 0.890, ave_loss: 0.835
[3]  [40/1724] loss: 1.119, ave_loss: 0.930
[4]  [60/1724] loss: 1.098, ave_loss: 0.972
[5]  [80/1724] loss: 1.104, ave_loss: 0.999
[6]  [100/1724] loss: 1.145, ave_loss: 1.023
[7]  [120/1724] loss: 1.245, ave_loss: 1.055
[8]  [140/1724] loss: 1.081, ave_loss: 1.058
[9]  [160/1724] loss: 0.866, ave_loss: 1.037
[10]  [180/1724] loss: 1.025, ave_loss: 1.035
[11]  [200/1724] loss: 0.873, ave_loss: 1.021
[12]  [220/1724] loss: 0.822, ave_loss: 1.004
[13]  [240/1724] loss: 0.708, ave_loss: 0.981
[14]  [260/1724] loss: 0.992, ave_loss: 0.982
[15]  [280/1724] loss: 0.683, ave_loss: 0.962
[16]  [300/1724] loss: 0.861, ave_loss: 0.956
[17]  [320/1724] loss: 1.008, ave_loss: 0.959
[18]  [340/1724] loss: 1.290, ave_loss: 0.977
[19]  [360/1724] loss: 0.865, ave_loss: 0.971
[20]  [380/1724] loss: 0.915, ave_loss: 0.969
[21]  [400/1724] loss: 0.700, ave_loss: 0.956
[22]  [420/1724] loss: 1.060, ave_loss: 0.960
[23]  [440/1724] loss: 0.975, ave_loss: 0.961
[24]  [460/1724] loss: 0.929, ave_loss: 0.960
[25]  [480/1724] loss: 0.928, ave_loss: 0.958
[26]  [500/1724] loss: 0.720, ave_loss: 0.949
[27]  [520/1724] loss: 1.540, ave_loss: 0.971
[28]  [540/1724] loss: 0.918, ave_loss: 0.969
[29]  [560/1724] loss: 0.645, ave_loss: 0.958
[30]  [580/1724] loss: 0.836, ave_loss: 0.954
[31]  [600/1724] loss: 0.899, ave_loss: 0.952
[32]  [620/1724] loss: 0.933, ave_loss: 0.952
[33]  [640/1724] loss: 1.086, ave_loss: 0.956
[34]  [660/1724] loss: 1.041, ave_loss: 0.958
[35]  [680/1724] loss: 1.198, ave_loss: 0.965
[36]  [700/1724] loss: 0.870, ave_loss: 0.962
[37]  [720/1724] loss: 1.211, ave_loss: 0.969
[38]  [740/1724] loss: 1.006, ave_loss: 0.970
[39]  [760/1724] loss: 1.213, ave_loss: 0.976
[40]  [780/1724] loss: 0.840, ave_loss: 0.973
[41]  [800/1724] loss: 1.235, ave_loss: 0.979
[42]  [820/1724] loss: 1.102, ave_loss: 0.982
[43]  [840/1724] loss: 1.134, ave_loss: 0.986
[44]  [860/1724] loss: 0.769, ave_loss: 0.981
[45]  [880/1724] loss: 0.986, ave_loss: 0.981
[46]  [900/1724] loss: 1.149, ave_loss: 0.985
[47]  [920/1724] loss: 0.816, ave_loss: 0.981
[48]  [940/1724] loss: 0.788, ave_loss: 0.977
[49]  [960/1724] loss: 0.880, ave_loss: 0.975
[50]  [980/1724] loss: 1.238, ave_loss: 0.980
[51]  [1000/1724] loss: 0.955, ave_loss: 0.980
[52]  [1020/1724] loss: 1.157, ave_loss: 0.983
[53]  [1040/1724] loss: 0.945, ave_loss: 0.982
[54]  [1060/1724] loss: 1.241, ave_loss: 0.987
[55]  [1080/1724] loss: 1.322, ave_loss: 0.993
[56]  [1100/1724] loss: 1.110, ave_loss: 0.995
[57]  [1120/1724] loss: 0.797, ave_loss: 0.992
[58]  [1140/1724] loss: 1.232, ave_loss: 0.996
[59]  [1160/1724] loss: 1.099, ave_loss: 0.998
[60]  [1180/1724] loss: 0.712, ave_loss: 0.993
[61]  [1200/1724] loss: 0.893, ave_loss: 0.991
[62]  [1220/1724] loss: 0.953, ave_loss: 0.991
[63]  [1240/1724] loss: 0.911, ave_loss: 0.990
[64]  [1260/1724] loss: 0.851, ave_loss: 0.987
[65]  [1280/1724] loss: 1.102, ave_loss: 0.989
[66]  [1300/1724] loss: 1.251, ave_loss: 0.993
[67]  [1320/1724] loss: 1.059, ave_loss: 0.994
[68]  [1340/1724] loss: 1.130, ave_loss: 0.996
[69]  [1360/1724] loss: 0.811, ave_loss: 0.993
[70]  [1380/1724] loss: 1.081, ave_loss: 0.995
[71]  [1400/1724] loss: 1.047, ave_loss: 0.995
[72]  [1420/1724] loss: 1.112, ave_loss: 0.997
[73]  [1440/1724] loss: 1.098, ave_loss: 0.998
[74]  [1460/1724] loss: 0.852, ave_loss: 0.996
[75]  [1480/1724] loss: 0.849, ave_loss: 0.994
[76]  [1500/1724] loss: 0.693, ave_loss: 0.990
[77]  [1520/1724] loss: 0.985, ave_loss: 0.990
[78]  [1540/1724] loss: 1.262, ave_loss: 0.994
[79]  [1560/1724] loss: 0.989, ave_loss: 0.994
[80]  [1580/1724] loss: 0.991, ave_loss: 0.994
[81]  [1600/1724] loss: 1.036, ave_loss: 0.994
[82]  [1620/1724] loss: 0.679, ave_loss: 0.990
[83]  [1640/1724] loss: 1.079, ave_loss: 0.992
[84]  [1660/1724] loss: 0.856, ave_loss: 0.990
[85]  [1680/1724] loss: 0.854, ave_loss: 0.988
[86]  [1700/1724] loss: 1.122, ave_loss: 0.990
[87]  [1720/1724] loss: 0.876, ave_loss: 0.989
[88]  [1740/1724] loss: 1.240, ave_loss: 0.991

Finished Training finishing at 2021-08-29 18:53:54.970109
printing_out epoch  4.083526682134571 learning rate: 0.0005153561248318907
0.00045624107190313527
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 9.914e-01
Validation Loss: 1.530e+06
Validation ROC: 0.4554
Saving model
24.916473317865428 epochs left to go

Training Epoch 4.083526682134571/30 starting at 2021-08-29 18:55:26.876524
[1]  [0/1724] loss: 0.958, ave_loss: 0.958
[2]  [20/1724] loss: 0.864, ave_loss: 0.911
[3]  [40/1724] loss: 1.074, ave_loss: 0.965
[4]  [60/1724] loss: 1.137, ave_loss: 1.008
[5]  [80/1724] loss: 0.952, ave_loss: 0.997
[6]  [100/1724] loss: 0.904, ave_loss: 0.982
[7]  [120/1724] loss: 0.869, ave_loss: 0.965
[8]  [140/1724] loss: 1.035, ave_loss: 0.974
[9]  [160/1724] loss: 1.032, ave_loss: 0.981
[10]  [180/1724] loss: 0.891, ave_loss: 0.972
[11]  [200/1724] loss: 0.927, ave_loss: 0.968
[12]  [220/1724] loss: 0.839, ave_loss: 0.957
[13]  [240/1724] loss: 0.881, ave_loss: 0.951
[14]  [260/1724] loss: 1.074, ave_loss: 0.960
[15]  [280/1724] loss: 0.907, ave_loss: 0.956
[16]  [300/1724] loss: 0.785, ave_loss: 0.946
[17]  [320/1724] loss: 0.938, ave_loss: 0.945
[18]  [340/1724] loss: 0.923, ave_loss: 0.944
[19]  [360/1724] loss: 0.964, ave_loss: 0.945
[20]  [380/1724] loss: 1.126, ave_loss: 0.954
[21]  [400/1724] loss: 0.738, ave_loss: 0.944
[22]  [420/1724] loss: 0.946, ave_loss: 0.944
[23]  [440/1724] loss: 0.952, ave_loss: 0.944
[24]  [460/1724] loss: 0.764, ave_loss: 0.937
[25]  [480/1724] loss: 0.844, ave_loss: 0.933
[26]  [500/1724] loss: 1.103, ave_loss: 0.939
[27]  [520/1724] loss: 1.058, ave_loss: 0.944
[28]  [540/1724] loss: 0.923, ave_loss: 0.943
[29]  [560/1724] loss: 0.752, ave_loss: 0.937
[30]  [580/1724] loss: 1.110, ave_loss: 0.942
[31]  [600/1724] loss: 0.926, ave_loss: 0.942
[32]  [620/1724] loss: 1.137, ave_loss: 0.948
[33]  [640/1724] loss: 1.094, ave_loss: 0.952
[34]  [660/1724] loss: 1.012, ave_loss: 0.954
[35]  [680/1724] loss: 0.816, ave_loss: 0.950
[36]  [700/1724] loss: 0.852, ave_loss: 0.947
[37]  [720/1724] loss: 0.949, ave_loss: 0.947
[38]  [740/1724] loss: 0.990, ave_loss: 0.949
[39]  [760/1724] loss: 0.739, ave_loss: 0.943
[40]  [780/1724] loss: 0.795, ave_loss: 0.939
[41]  [800/1724] loss: 1.015, ave_loss: 0.941
[42]  [820/1724] loss: 0.909, ave_loss: 0.941
[43]  [840/1724] loss: 0.896, ave_loss: 0.940
[44]  [860/1724] loss: 0.939, ave_loss: 0.939
[45]  [880/1724] loss: 0.961, ave_loss: 0.940
[46]  [900/1724] loss: 1.061, ave_loss: 0.943
[47]  [920/1724] loss: 1.159, ave_loss: 0.947
[48]  [940/1724] loss: 0.879, ave_loss: 0.946
[49]  [960/1724] loss: 1.099, ave_loss: 0.949
[50]  [980/1724] loss: 1.242, ave_loss: 0.955
[51]  [1000/1724] loss: 1.129, ave_loss: 0.958
[52]  [1020/1724] loss: 0.804, ave_loss: 0.955
[53]  [1040/1724] loss: 0.804, ave_loss: 0.952
[54]  [1060/1724] loss: 0.835, ave_loss: 0.950
[55]  [1080/1724] loss: 1.079, ave_loss: 0.953
[56]  [1100/1724] loss: 0.805, ave_loss: 0.950
[57]  [1120/1724] loss: 1.163, ave_loss: 0.954
[58]  [1140/1724] loss: 0.985, ave_loss: 0.954
[59]  [1160/1724] loss: 0.850, ave_loss: 0.952
[60]  [1180/1724] loss: 0.755, ave_loss: 0.949
[61]  [1200/1724] loss: 0.911, ave_loss: 0.949
[62]  [1220/1724] loss: 1.020, ave_loss: 0.950
[63]  [1240/1724] loss: 0.742, ave_loss: 0.946
[64]  [1260/1724] loss: 0.997, ave_loss: 0.947
[65]  [1280/1724] loss: 0.863, ave_loss: 0.946
[66]  [1300/1724] loss: 0.999, ave_loss: 0.947
[67]  [1320/1724] loss: 0.876, ave_loss: 0.946
[68]  [1340/1724] loss: 0.911, ave_loss: 0.945
[69]  [1360/1724] loss: 1.042, ave_loss: 0.947
[70]  [1380/1724] loss: 1.044, ave_loss: 0.948
[71]  [1400/1724] loss: 1.081, ave_loss: 0.950
[72]  [1420/1724] loss: 0.820, ave_loss: 0.948
[73]  [1440/1724] loss: 1.010, ave_loss: 0.949
[74]  [1460/1724] loss: 0.905, ave_loss: 0.948
[75]  [1480/1724] loss: 1.114, ave_loss: 0.950
[76]  [1500/1724] loss: 1.021, ave_loss: 0.951
[77]  [1520/1724] loss: 0.950, ave_loss: 0.951
[78]  [1540/1724] loss: 1.044, ave_loss: 0.953
[79]  [1560/1724] loss: 0.997, ave_loss: 0.953
[80]  [1580/1724] loss: 1.045, ave_loss: 0.954
[81]  [1600/1724] loss: 0.955, ave_loss: 0.954
[82]  [1620/1724] loss: 1.070, ave_loss: 0.956
[83]  [1640/1724] loss: 0.749, ave_loss: 0.953
[84]  [1660/1724] loss: 1.056, ave_loss: 0.954
[85]  [1680/1724] loss: 1.041, ave_loss: 0.955
[86]  [1700/1724] loss: 0.796, ave_loss: 0.954
[87]  [1720/1724] loss: 1.132, ave_loss: 0.956
[88]  [1740/1724] loss: 0.849, ave_loss: 0.954

Finished Training finishing at 2021-08-29 18:59:19.159720
printing_out epoch  5.104408352668213 learning rate: 0.0005153561248318907
0.0004425538397460412
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 9.544e-01
Validation Loss: 1.512e+06
Validation ROC: 0.4575
Saving model
23.895591647331788 epochs left to go

Training Epoch 5.104408352668213/30 starting at 2021-08-29 19:00:32.840371
[1]  [0/1724] loss: 0.597, ave_loss: 0.597
[2]  [20/1724] loss: 1.133, ave_loss: 0.865
[3]  [40/1724] loss: 0.865, ave_loss: 0.865
[4]  [60/1724] loss: 0.820, ave_loss: 0.854
[5]  [80/1724] loss: 0.902, ave_loss: 0.863
[6]  [100/1724] loss: 0.730, ave_loss: 0.841
[7]  [120/1724] loss: 0.920, ave_loss: 0.852
[8]  [140/1724] loss: 0.821, ave_loss: 0.848
[9]  [160/1724] loss: 0.928, ave_loss: 0.857
[10]  [180/1724] loss: 0.949, ave_loss: 0.866
[11]  [200/1724] loss: 0.922, ave_loss: 0.871
[12]  [220/1724] loss: 1.043, ave_loss: 0.886
[13]  [240/1724] loss: 0.912, ave_loss: 0.888
[14]  [260/1724] loss: 0.914, ave_loss: 0.890
[15]  [280/1724] loss: 1.155, ave_loss: 0.907
[16]  [300/1724] loss: 0.995, ave_loss: 0.913
[17]  [320/1724] loss: 0.831, ave_loss: 0.908
[18]  [340/1724] loss: 0.777, ave_loss: 0.901
[19]  [360/1724] loss: 0.863, ave_loss: 0.899
[20]  [380/1724] loss: 0.922, ave_loss: 0.900
[21]  [400/1724] loss: 0.940, ave_loss: 0.902
[22]  [420/1724] loss: 0.712, ave_loss: 0.893
[23]  [440/1724] loss: 0.865, ave_loss: 0.892
[24]  [460/1724] loss: 0.934, ave_loss: 0.894
[25]  [480/1724] loss: 0.823, ave_loss: 0.891
[26]  [500/1724] loss: 0.861, ave_loss: 0.890
[27]  [520/1724] loss: 0.825, ave_loss: 0.887
[28]  [540/1724] loss: 0.997, ave_loss: 0.891
[29]  [560/1724] loss: 0.827, ave_loss: 0.889
[30]  [580/1724] loss: 0.802, ave_loss: 0.886
[31]  [600/1724] loss: 0.904, ave_loss: 0.887
[32]  [620/1724] loss: 1.072, ave_loss: 0.892
[33]  [640/1724] loss: 0.893, ave_loss: 0.893
[34]  [660/1724] loss: 0.887, ave_loss: 0.892
[35]  [680/1724] loss: 0.975, ave_loss: 0.895
[36]  [700/1724] loss: 0.954, ave_loss: 0.896
[37]  [720/1724] loss: 0.755, ave_loss: 0.893
[38]  [740/1724] loss: 0.937, ave_loss: 0.894
[39]  [760/1724] loss: 0.815, ave_loss: 0.892
[40]  [780/1724] loss: 0.837, ave_loss: 0.890
[41]  [800/1724] loss: 0.899, ave_loss: 0.891
[42]  [820/1724] loss: 0.617, ave_loss: 0.884
[43]  [840/1724] loss: 0.997, ave_loss: 0.887
[44]  [860/1724] loss: 0.870, ave_loss: 0.886
[45]  [880/1724] loss: 1.022, ave_loss: 0.889
[46]  [900/1724] loss: 0.868, ave_loss: 0.889
[47]  [920/1724] loss: 0.579, ave_loss: 0.882
[48]  [940/1724] loss: 1.159, ave_loss: 0.888
[49]  [960/1724] loss: 0.857, ave_loss: 0.887
[50]  [980/1724] loss: 0.830, ave_loss: 0.886
[51]  [1000/1724] loss: 0.967, ave_loss: 0.888
[52]  [1020/1724] loss: 0.881, ave_loss: 0.888
[53]  [1040/1724] loss: 1.111, ave_loss: 0.892
[54]  [1060/1724] loss: 0.971, ave_loss: 0.893
[55]  [1080/1724] loss: 0.976, ave_loss: 0.895
[56]  [1100/1724] loss: 0.860, ave_loss: 0.894
[57]  [1120/1724] loss: 0.952, ave_loss: 0.895
[58]  [1140/1724] loss: 0.796, ave_loss: 0.894
[59]  [1160/1724] loss: 0.912, ave_loss: 0.894
[60]  [1180/1724] loss: 0.966, ave_loss: 0.895
[61]  [1200/1724] loss: 0.886, ave_loss: 0.895
[62]  [1220/1724] loss: 0.722, ave_loss: 0.892
[63]  [1240/1724] loss: 0.834, ave_loss: 0.891
[64]  [1260/1724] loss: 0.843, ave_loss: 0.890
[65]  [1280/1724] loss: 0.885, ave_loss: 0.890
[66]  [1300/1724] loss: 0.935, ave_loss: 0.891
[67]  [1320/1724] loss: 1.017, ave_loss: 0.893
[68]  [1340/1724] loss: 0.850, ave_loss: 0.892
[69]  [1360/1724] loss: 0.968, ave_loss: 0.893
[70]  [1380/1724] loss: 0.915, ave_loss: 0.894
[71]  [1400/1724] loss: 0.857, ave_loss: 0.893
[72]  [1420/1724] loss: 1.105, ave_loss: 0.896
[73]  [1440/1724] loss: 0.968, ave_loss: 0.897
[74]  [1460/1724] loss: 1.007, ave_loss: 0.899
[75]  [1480/1724] loss: 0.797, ave_loss: 0.897
[76]  [1500/1724] loss: 0.868, ave_loss: 0.897
[77]  [1520/1724] loss: 0.867, ave_loss: 0.896
[78]  [1540/1724] loss: 0.972, ave_loss: 0.897
[79]  [1560/1724] loss: 1.032, ave_loss: 0.899
[80]  [1580/1724] loss: 0.941, ave_loss: 0.900
[81]  [1600/1724] loss: 0.802, ave_loss: 0.898
[82]  [1620/1724] loss: 1.005, ave_loss: 0.900
[83]  [1640/1724] loss: 0.921, ave_loss: 0.900
[84]  [1660/1724] loss: 0.799, ave_loss: 0.899
[85]  [1680/1724] loss: 0.993, ave_loss: 0.900
[86]  [1700/1724] loss: 0.729, ave_loss: 0.898
[87]  [1720/1724] loss: 0.952, ave_loss: 0.899
[88]  [1740/1724] loss: 0.800, ave_loss: 0.897

Finished Training finishing at 2021-08-29 19:04:16.827081
printing_out epoch  6.125290023201856 learning rate: 0.0005153561248318907
0.00042927722455365994
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 8.974e-01
Validation Loss: 1.493e+06
Validation ROC: 0.4597
Saving model
22.874709976798144 epochs left to go

Training Epoch 6.125290023201856/30 starting at 2021-08-29 19:05:25.695145
[1]  [0/1724] loss: 0.855, ave_loss: 0.855
[2]  [20/1724] loss: 0.992, ave_loss: 0.924
[3]  [40/1724] loss: 0.707, ave_loss: 0.851
[4]  [60/1724] loss: 0.830, ave_loss: 0.846
[5]  [80/1724] loss: 0.533, ave_loss: 0.783
[6]  [100/1724] loss: 1.011, ave_loss: 0.821
[7]  [120/1724] loss: 0.992, ave_loss: 0.846
[8]  [140/1724] loss: 0.966, ave_loss: 0.861
[9]  [160/1724] loss: 0.804, ave_loss: 0.854
[10]  [180/1724] loss: 1.005, ave_loss: 0.870
[11]  [200/1724] loss: 0.953, ave_loss: 0.877
[12]  [220/1724] loss: 1.050, ave_loss: 0.892
[13]  [240/1724] loss: 0.952, ave_loss: 0.896
[14]  [260/1724] loss: 1.029, ave_loss: 0.906
[15]  [280/1724] loss: 0.661, ave_loss: 0.889
[16]  [300/1724] loss: 1.143, ave_loss: 0.905
[17]  [320/1724] loss: 1.120, ave_loss: 0.918
[18]  [340/1724] loss: 0.833, ave_loss: 0.913
[19]  [360/1724] loss: 0.900, ave_loss: 0.912
[20]  [380/1724] loss: 0.857, ave_loss: 0.910
[21]  [400/1724] loss: 0.941, ave_loss: 0.911
[22]  [420/1724] loss: 0.971, ave_loss: 0.914
[23]  [440/1724] loss: 0.850, ave_loss: 0.911
[24]  [460/1724] loss: 0.957, ave_loss: 0.913
[25]  [480/1724] loss: 0.987, ave_loss: 0.916
[26]  [500/1724] loss: 0.994, ave_loss: 0.919
[27]  [520/1724] loss: 1.011, ave_loss: 0.922
[28]  [540/1724] loss: 0.675, ave_loss: 0.914
[29]  [560/1724] loss: 0.807, ave_loss: 0.910
[30]  [580/1724] loss: 0.830, ave_loss: 0.907
[31]  [600/1724] loss: 1.013, ave_loss: 0.911
[32]  [620/1724] loss: 0.946, ave_loss: 0.912
[33]  [640/1724] loss: 0.964, ave_loss: 0.913
[34]  [660/1724] loss: 0.855, ave_loss: 0.912
[35]  [680/1724] loss: 1.053, ave_loss: 0.916
[36]  [700/1724] loss: 0.614, ave_loss: 0.907
[37]  [720/1724] loss: 0.775, ave_loss: 0.904
[38]  [740/1724] loss: 0.895, ave_loss: 0.903
[39]  [760/1724] loss: 0.986, ave_loss: 0.906
[40]  [780/1724] loss: 0.900, ave_loss: 0.905
[41]  [800/1724] loss: 0.860, ave_loss: 0.904
[42]  [820/1724] loss: 0.858, ave_loss: 0.903
[43]  [840/1724] loss: 0.846, ave_loss: 0.902
[44]  [860/1724] loss: 0.827, ave_loss: 0.900
[45]  [880/1724] loss: 0.660, ave_loss: 0.895
[46]  [900/1724] loss: 0.777, ave_loss: 0.892
[47]  [920/1724] loss: 0.655, ave_loss: 0.887
[48]  [940/1724] loss: 0.752, ave_loss: 0.884
[49]  [960/1724] loss: 0.872, ave_loss: 0.884
[50]  [980/1724] loss: 1.026, ave_loss: 0.887
[51]  [1000/1724] loss: 1.042, ave_loss: 0.890
[52]  [1020/1724] loss: 0.912, ave_loss: 0.890
[53]  [1040/1724] loss: 0.967, ave_loss: 0.892
[54]  [1060/1724] loss: 0.891, ave_loss: 0.892
[55]  [1080/1724] loss: 0.934, ave_loss: 0.893
[56]  [1100/1724] loss: 0.916, ave_loss: 0.893
[57]  [1120/1724] loss: 0.929, ave_loss: 0.894
[58]  [1140/1724] loss: 0.730, ave_loss: 0.891
[59]  [1160/1724] loss: 0.828, ave_loss: 0.890
[60]  [1180/1724] loss: 1.049, ave_loss: 0.892
[61]  [1200/1724] loss: 0.989, ave_loss: 0.894
[62]  [1220/1724] loss: 0.910, ave_loss: 0.894
[63]  [1240/1724] loss: 0.889, ave_loss: 0.894
[64]  [1260/1724] loss: 0.850, ave_loss: 0.894
[65]  [1280/1724] loss: 0.835, ave_loss: 0.893
[66]  [1300/1724] loss: 0.823, ave_loss: 0.892
[67]  [1320/1724] loss: 1.065, ave_loss: 0.894
[68]  [1340/1724] loss: 0.792, ave_loss: 0.893
[69]  [1360/1724] loss: 0.936, ave_loss: 0.893
[70]  [1380/1724] loss: 1.059, ave_loss: 0.896
[71]  [1400/1724] loss: 0.878, ave_loss: 0.895
[72]  [1420/1724] loss: 0.901, ave_loss: 0.895
[73]  [1440/1724] loss: 0.924, ave_loss: 0.896
[74]  [1460/1724] loss: 0.722, ave_loss: 0.893
[75]  [1480/1724] loss: 0.747, ave_loss: 0.892
[76]  [1500/1724] loss: 0.760, ave_loss: 0.890
[77]  [1520/1724] loss: 0.657, ave_loss: 0.887
[78]  [1540/1724] loss: 0.825, ave_loss: 0.886
[79]  [1560/1724] loss: 0.925, ave_loss: 0.886
[80]  [1580/1724] loss: 0.932, ave_loss: 0.887
[81]  [1600/1724] loss: 0.828, ave_loss: 0.886
[82]  [1620/1724] loss: 0.899, ave_loss: 0.886
[83]  [1640/1724] loss: 0.735, ave_loss: 0.885
[84]  [1660/1724] loss: 0.809, ave_loss: 0.884
[85]  [1680/1724] loss: 0.807, ave_loss: 0.883
[86]  [1700/1724] loss: 0.798, ave_loss: 0.882
[87]  [1720/1724] loss: 1.069, ave_loss: 0.884
[88]  [1740/1724] loss: 0.899, ave_loss: 0.884

Finished Training finishing at 2021-08-29 19:08:42.410577
printing_out epoch  7.146171693735499 learning rate: 0.0005153561248318907
0.0004163989078170501
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 8.842e-01
Validation Loss: 1.479e+06
Validation ROC: 0.4597
Saving model
21.8538283062645 epochs left to go

Training Epoch 7.146171693735499/30 starting at 2021-08-29 19:09:55.792931
[1]  [0/1724] loss: 1.000, ave_loss: 1.000
[2]  [20/1724] loss: 1.025, ave_loss: 1.013
[3]  [40/1724] loss: 0.611, ave_loss: 0.879
[4]  [60/1724] loss: 0.950, ave_loss: 0.897
[5]  [80/1724] loss: 0.911, ave_loss: 0.899
[6]  [100/1724] loss: 0.759, ave_loss: 0.876
[7]  [120/1724] loss: 1.043, ave_loss: 0.900
[8]  [140/1724] loss: 0.935, ave_loss: 0.904
[9]  [160/1724] loss: 0.956, ave_loss: 0.910
[10]  [180/1724] loss: 0.910, ave_loss: 0.910
[11]  [200/1724] loss: 0.980, ave_loss: 0.916
[12]  [220/1724] loss: 0.785, ave_loss: 0.905
[13]  [240/1724] loss: 0.801, ave_loss: 0.897
[14]  [260/1724] loss: 0.727, ave_loss: 0.885
[15]  [280/1724] loss: 0.694, ave_loss: 0.872
[16]  [300/1724] loss: 0.869, ave_loss: 0.872
[17]  [320/1724] loss: 0.771, ave_loss: 0.866
[18]  [340/1724] loss: 0.794, ave_loss: 0.862
[19]  [360/1724] loss: 0.842, ave_loss: 0.861
[20]  [380/1724] loss: 0.931, ave_loss: 0.865
[21]  [400/1724] loss: 0.844, ave_loss: 0.864
[22]  [420/1724] loss: 0.921, ave_loss: 0.866
[23]  [440/1724] loss: 0.858, ave_loss: 0.866
[24]  [460/1724] loss: 0.833, ave_loss: 0.865
[25]  [480/1724] loss: 0.805, ave_loss: 0.862
[26]  [500/1724] loss: 0.915, ave_loss: 0.864
[27]  [520/1724] loss: 0.703, ave_loss: 0.858
[28]  [540/1724] loss: 0.984, ave_loss: 0.863
[29]  [560/1724] loss: 0.935, ave_loss: 0.865
[30]  [580/1724] loss: 0.789, ave_loss: 0.863
[31]  [600/1724] loss: 0.714, ave_loss: 0.858
[32]  [620/1724] loss: 0.668, ave_loss: 0.852
[33]  [640/1724] loss: 0.819, ave_loss: 0.851
[34]  [660/1724] loss: 0.814, ave_loss: 0.850
[35]  [680/1724] loss: 0.748, ave_loss: 0.847
[36]  [700/1724] loss: 1.003, ave_loss: 0.851
[37]  [720/1724] loss: 0.825, ave_loss: 0.851
[38]  [740/1724] loss: 0.805, ave_loss: 0.849
[39]  [760/1724] loss: 0.960, ave_loss: 0.852
[40]  [780/1724] loss: 0.912, ave_loss: 0.854
[41]  [800/1724] loss: 0.736, ave_loss: 0.851
[42]  [820/1724] loss: 0.897, ave_loss: 0.852
[43]  [840/1724] loss: 0.915, ave_loss: 0.853
[44]  [860/1724] loss: 0.798, ave_loss: 0.852
[45]  [880/1724] loss: 0.936, ave_loss: 0.854
[46]  [900/1724] loss: 0.934, ave_loss: 0.856
[47]  [920/1724] loss: 0.935, ave_loss: 0.857
[48]  [940/1724] loss: 0.880, ave_loss: 0.858
[49]  [960/1724] loss: 0.861, ave_loss: 0.858
[50]  [980/1724] loss: 0.814, ave_loss: 0.857
[51]  [1000/1724] loss: 0.873, ave_loss: 0.857
[52]  [1020/1724] loss: 0.901, ave_loss: 0.858
[53]  [1040/1724] loss: 0.989, ave_loss: 0.861
[54]  [1060/1724] loss: 0.834, ave_loss: 0.860
[55]  [1080/1724] loss: 0.817, ave_loss: 0.859
[56]  [1100/1724] loss: 0.881, ave_loss: 0.860
[57]  [1120/1724] loss: 0.816, ave_loss: 0.859
[58]  [1140/1724] loss: 0.771, ave_loss: 0.858
[59]  [1160/1724] loss: 0.880, ave_loss: 0.858
[60]  [1180/1724] loss: 0.831, ave_loss: 0.857
[61]  [1200/1724] loss: 0.790, ave_loss: 0.856
[62]  [1220/1724] loss: 0.891, ave_loss: 0.857
[63]  [1240/1724] loss: 0.919, ave_loss: 0.858
[64]  [1260/1724] loss: 1.034, ave_loss: 0.861
[65]  [1280/1724] loss: 0.797, ave_loss: 0.860
[66]  [1300/1724] loss: 0.836, ave_loss: 0.859
[67]  [1320/1724] loss: 0.758, ave_loss: 0.858
[68]  [1340/1724] loss: 1.046, ave_loss: 0.861
[69]  [1360/1724] loss: 0.859, ave_loss: 0.861
[70]  [1380/1724] loss: 0.867, ave_loss: 0.861
[71]  [1400/1724] loss: 0.929, ave_loss: 0.862
[72]  [1420/1724] loss: 0.826, ave_loss: 0.861
[73]  [1440/1724] loss: 0.843, ave_loss: 0.861
[74]  [1460/1724] loss: 0.881, ave_loss: 0.861
[75]  [1480/1724] loss: 0.840, ave_loss: 0.861
[76]  [1500/1724] loss: 1.018, ave_loss: 0.863
[77]  [1520/1724] loss: 0.896, ave_loss: 0.863
[78]  [1540/1724] loss: 0.967, ave_loss: 0.865
[79]  [1560/1724] loss: 1.013, ave_loss: 0.867
[80]  [1580/1724] loss: 1.008, ave_loss: 0.868
[81]  [1600/1724] loss: 0.870, ave_loss: 0.868
[82]  [1620/1724] loss: 0.848, ave_loss: 0.868
[83]  [1640/1724] loss: 0.943, ave_loss: 0.869
[84]  [1660/1724] loss: 0.795, ave_loss: 0.868
[85]  [1680/1724] loss: 0.899, ave_loss: 0.869
[86]  [1700/1724] loss: 0.937, ave_loss: 0.869
[87]  [1720/1724] loss: 0.913, ave_loss: 0.870
[88]  [1740/1724] loss: 0.869, ave_loss: 0.870

Finished Training finishing at 2021-08-29 19:13:06.245436
printing_out epoch  8.167053364269142 learning rate: 0.0005153561248318907
0.0004039069405825386
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 8.698e-01
Validation Loss: 1.471e+06
Validation ROC: 0.4604
Saving model
20.832946635730856 epochs left to go

Training Epoch 8.167053364269142/30 starting at 2021-08-29 19:14:17.973278
[1]  [0/1724] loss: 0.853, ave_loss: 0.853
[2]  [20/1724] loss: 0.818, ave_loss: 0.836
[3]  [40/1724] loss: 0.768, ave_loss: 0.813
[4]  [60/1724] loss: 0.831, ave_loss: 0.817
[5]  [80/1724] loss: 0.792, ave_loss: 0.812
[6]  [100/1724] loss: 0.999, ave_loss: 0.843
[7]  [120/1724] loss: 0.920, ave_loss: 0.854
[8]  [140/1724] loss: 0.852, ave_loss: 0.854
[9]  [160/1724] loss: 0.760, ave_loss: 0.844
[10]  [180/1724] loss: 1.003, ave_loss: 0.860
[11]  [200/1724] loss: 0.858, ave_loss: 0.860
[12]  [220/1724] loss: 0.934, ave_loss: 0.866
[13]  [240/1724] loss: 0.757, ave_loss: 0.857
[14]  [260/1724] loss: 0.887, ave_loss: 0.859
[15]  [280/1724] loss: 0.867, ave_loss: 0.860
[16]  [300/1724] loss: 0.853, ave_loss: 0.860
[17]  [320/1724] loss: 0.865, ave_loss: 0.860
[18]  [340/1724] loss: 0.712, ave_loss: 0.852
[19]  [360/1724] loss: 0.971, ave_loss: 0.858
[20]  [380/1724] loss: 0.829, ave_loss: 0.856
[21]  [400/1724] loss: 0.851, ave_loss: 0.856
[22]  [420/1724] loss: 0.887, ave_loss: 0.858
[23]  [440/1724] loss: 0.856, ave_loss: 0.858
[24]  [460/1724] loss: 0.678, ave_loss: 0.850
[25]  [480/1724] loss: 0.808, ave_loss: 0.848
[26]  [500/1724] loss: 0.887, ave_loss: 0.850
[27]  [520/1724] loss: 0.761, ave_loss: 0.847
[28]  [540/1724] loss: 0.823, ave_loss: 0.846
[29]  [560/1724] loss: 0.813, ave_loss: 0.845
[30]  [580/1724] loss: 0.925, ave_loss: 0.847
[31]  [600/1724] loss: 0.688, ave_loss: 0.842
[32]  [620/1724] loss: 0.823, ave_loss: 0.842
[33]  [640/1724] loss: 0.822, ave_loss: 0.841
[34]  [660/1724] loss: 0.849, ave_loss: 0.841
[35]  [680/1724] loss: 0.778, ave_loss: 0.839
[36]  [700/1724] loss: 0.625, ave_loss: 0.833
[37]  [720/1724] loss: 0.707, ave_loss: 0.830
[38]  [740/1724] loss: 0.664, ave_loss: 0.826
[39]  [760/1724] loss: 0.773, ave_loss: 0.824
[40]  [780/1724] loss: 0.913, ave_loss: 0.827
[41]  [800/1724] loss: 0.823, ave_loss: 0.826
[42]  [820/1724] loss: 0.842, ave_loss: 0.827
[43]  [840/1724] loss: 0.907, ave_loss: 0.829
[44]  [860/1724] loss: 0.739, ave_loss: 0.827
[45]  [880/1724] loss: 0.943, ave_loss: 0.829
[46]  [900/1724] loss: 0.811, ave_loss: 0.829
[47]  [920/1724] loss: 1.026, ave_loss: 0.833
[48]  [940/1724] loss: 0.907, ave_loss: 0.835
[49]  [960/1724] loss: 0.934, ave_loss: 0.837
[50]  [980/1724] loss: 0.964, ave_loss: 0.839
[51]  [1000/1724] loss: 0.883, ave_loss: 0.840
[52]  [1020/1724] loss: 0.813, ave_loss: 0.840
[53]  [1040/1724] loss: 0.916, ave_loss: 0.841
[54]  [1060/1724] loss: 0.972, ave_loss: 0.843
[55]  [1080/1724] loss: 0.959, ave_loss: 0.845
[56]  [1100/1724] loss: 0.777, ave_loss: 0.844
[57]  [1120/1724] loss: 0.817, ave_loss: 0.844
[58]  [1140/1724] loss: 0.914, ave_loss: 0.845
[59]  [1160/1724] loss: 0.701, ave_loss: 0.843
[60]  [1180/1724] loss: 0.783, ave_loss: 0.842
[61]  [1200/1724] loss: 0.753, ave_loss: 0.840
[62]  [1220/1724] loss: 0.827, ave_loss: 0.840
[63]  [1240/1724] loss: 0.808, ave_loss: 0.839
[64]  [1260/1724] loss: 0.932, ave_loss: 0.841
[65]  [1280/1724] loss: 0.865, ave_loss: 0.841
[66]  [1300/1724] loss: 0.770, ave_loss: 0.840
[67]  [1320/1724] loss: 0.835, ave_loss: 0.840
[68]  [1340/1724] loss: 0.918, ave_loss: 0.841
[69]  [1360/1724] loss: 0.958, ave_loss: 0.843
[70]  [1380/1724] loss: 0.943, ave_loss: 0.844
[71]  [1400/1724] loss: 0.890, ave_loss: 0.845
[72]  [1420/1724] loss: 0.876, ave_loss: 0.845
[73]  [1440/1724] loss: 0.865, ave_loss: 0.846
[74]  [1460/1724] loss: 0.835, ave_loss: 0.846
[75]  [1480/1724] loss: 0.958, ave_loss: 0.847
[76]  [1500/1724] loss: 0.797, ave_loss: 0.846
[77]  [1520/1724] loss: 0.960, ave_loss: 0.848
[78]  [1540/1724] loss: 0.718, ave_loss: 0.846
[79]  [1560/1724] loss: 0.733, ave_loss: 0.845
[80]  [1580/1724] loss: 1.045, ave_loss: 0.847
[81]  [1600/1724] loss: 0.903, ave_loss: 0.848
[82]  [1620/1724] loss: 0.902, ave_loss: 0.849
[83]  [1640/1724] loss: 0.832, ave_loss: 0.848
[84]  [1660/1724] loss: 0.863, ave_loss: 0.849
[85]  [1680/1724] loss: 0.958, ave_loss: 0.850
[86]  [1700/1724] loss: 0.940, ave_loss: 0.851
[87]  [1720/1724] loss: 0.705, ave_loss: 0.849
[88]  [1740/1724] loss: 0.839, ave_loss: 0.849

Finished Training finishing at 2021-08-29 19:17:23.281864
printing_out epoch  9.187935034802784 learning rate: 0.0005153561248318907
0.00039178973236506245
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 8.491e-01
Validation Loss: 1.453e+06
Validation ROC: 0.4604
Saving model
19.812064965197216 epochs left to go

Training Epoch 9.187935034802784/30 starting at 2021-08-29 19:18:30.992051
[1]  [0/1724] loss: 0.721, ave_loss: 0.721
[2]  [20/1724] loss: 0.784, ave_loss: 0.752
[3]  [40/1724] loss: 0.911, ave_loss: 0.805
[4]  [60/1724] loss: 0.805, ave_loss: 0.805
[5]  [80/1724] loss: 0.744, ave_loss: 0.793
[6]  [100/1724] loss: 0.804, ave_loss: 0.795
[7]  [120/1724] loss: 0.740, ave_loss: 0.787
[8]  [140/1724] loss: 0.854, ave_loss: 0.795
[9]  [160/1724] loss: 0.913, ave_loss: 0.809
[10]  [180/1724] loss: 0.897, ave_loss: 0.817
[11]  [200/1724] loss: 0.928, ave_loss: 0.827
[12]  [220/1724] loss: 0.860, ave_loss: 0.830
[13]  [240/1724] loss: 0.661, ave_loss: 0.817
[14]  [260/1724] loss: 0.593, ave_loss: 0.801
[15]  [280/1724] loss: 0.674, ave_loss: 0.793
[16]  [300/1724] loss: 0.788, ave_loss: 0.792
[17]  [320/1724] loss: 0.806, ave_loss: 0.793
[18]  [340/1724] loss: 0.831, ave_loss: 0.795
[19]  [360/1724] loss: 0.822, ave_loss: 0.797
[20]  [380/1724] loss: 0.825, ave_loss: 0.798
[21]  [400/1724] loss: 0.912, ave_loss: 0.804
[22]  [420/1724] loss: 0.878, ave_loss: 0.807
[23]  [440/1724] loss: 0.772, ave_loss: 0.805
[24]  [460/1724] loss: 0.858, ave_loss: 0.808
[25]  [480/1724] loss: 0.815, ave_loss: 0.808
[26]  [500/1724] loss: 0.788, ave_loss: 0.807
[27]  [520/1724] loss: 0.862, ave_loss: 0.809
[28]  [540/1724] loss: 0.761, ave_loss: 0.807
[29]  [560/1724] loss: 0.875, ave_loss: 0.810
[30]  [580/1724] loss: 0.806, ave_loss: 0.810
[31]  [600/1724] loss: 0.766, ave_loss: 0.808
[32]  [620/1724] loss: 0.765, ave_loss: 0.807
[33]  [640/1724] loss: 0.788, ave_loss: 0.806
[34]  [660/1724] loss: 0.742, ave_loss: 0.804
[35]  [680/1724] loss: 0.963, ave_loss: 0.809
[36]  [700/1724] loss: 0.853, ave_loss: 0.810
[37]  [720/1724] loss: 0.880, ave_loss: 0.812
[38]  [740/1724] loss: 0.720, ave_loss: 0.810
[39]  [760/1724] loss: 0.899, ave_loss: 0.812
[40]  [780/1724] loss: 0.874, ave_loss: 0.813
[41]  [800/1724] loss: 0.842, ave_loss: 0.814
[42]  [820/1724] loss: 0.897, ave_loss: 0.816
[43]  [840/1724] loss: 0.816, ave_loss: 0.816
[44]  [860/1724] loss: 0.851, ave_loss: 0.817
[45]  [880/1724] loss: 0.886, ave_loss: 0.818
[46]  [900/1724] loss: 0.757, ave_loss: 0.817
[47]  [920/1724] loss: 0.786, ave_loss: 0.816
[48]  [940/1724] loss: 0.741, ave_loss: 0.815
[49]  [960/1724] loss: 0.816, ave_loss: 0.815
[50]  [980/1724] loss: 0.780, ave_loss: 0.814
[51]  [1000/1724] loss: 0.716, ave_loss: 0.812
[52]  [1020/1724] loss: 0.909, ave_loss: 0.814
[53]  [1040/1724] loss: 0.809, ave_loss: 0.814
[54]  [1060/1724] loss: 0.790, ave_loss: 0.814
[55]  [1080/1724] loss: 0.902, ave_loss: 0.815
[56]  [1100/1724] loss: 0.801, ave_loss: 0.815
[57]  [1120/1724] loss: 0.865, ave_loss: 0.816
[58]  [1140/1724] loss: 0.897, ave_loss: 0.817
[59]  [1160/1724] loss: 0.801, ave_loss: 0.817
[60]  [1180/1724] loss: 0.814, ave_loss: 0.817
[61]  [1200/1724] loss: 0.868, ave_loss: 0.818
[62]  [1220/1724] loss: 0.801, ave_loss: 0.817
[63]  [1240/1724] loss: 0.839, ave_loss: 0.818
[64]  [1260/1724] loss: 0.874, ave_loss: 0.819
[65]  [1280/1724] loss: 0.738, ave_loss: 0.817
[66]  [1300/1724] loss: 0.730, ave_loss: 0.816
[67]  [1320/1724] loss: 0.844, ave_loss: 0.817
[68]  [1340/1724] loss: 0.668, ave_loss: 0.814
[69]  [1360/1724] loss: 0.878, ave_loss: 0.815
[70]  [1380/1724] loss: 0.871, ave_loss: 0.816
[71]  [1400/1724] loss: 0.911, ave_loss: 0.817
[72]  [1420/1724] loss: 0.895, ave_loss: 0.819
[73]  [1440/1724] loss: 0.747, ave_loss: 0.818
[74]  [1460/1724] loss: 0.801, ave_loss: 0.817
[75]  [1480/1724] loss: 0.764, ave_loss: 0.817
[76]  [1500/1724] loss: 0.910, ave_loss: 0.818
[77]  [1520/1724] loss: 0.813, ave_loss: 0.818
[78]  [1540/1724] loss: 0.835, ave_loss: 0.818
[79]  [1560/1724] loss: 0.847, ave_loss: 0.818
[80]  [1580/1724] loss: 0.783, ave_loss: 0.818
[81]  [1600/1724] loss: 0.800, ave_loss: 0.818
[82]  [1620/1724] loss: 0.860, ave_loss: 0.818
[83]  [1640/1724] loss: 0.868, ave_loss: 0.819
[84]  [1660/1724] loss: 0.853, ave_loss: 0.819
[85]  [1680/1724] loss: 0.827, ave_loss: 0.819
[86]  [1700/1724] loss: 0.935, ave_loss: 0.821
[87]  [1720/1724] loss: 0.724, ave_loss: 0.820
[88]  [1740/1724] loss: 0.797, ave_loss: 0.819

Finished Training finishing at 2021-08-29 19:21:28.753240
printing_out epoch  10.208816705336426 learning rate: 0.0005153561248318907
0.0003800360403941106
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 8.193e-01
Validation Loss: 1.440e+06
Validation ROC: 0.4618
Saving model
18.791183294663576 epochs left to go

Training Epoch 10.208816705336426/30 starting at 2021-08-29 19:22:38.251355
[1]  [0/1724] loss: 0.633, ave_loss: 0.633
[2]  [20/1724] loss: 0.769, ave_loss: 0.701
[3]  [40/1724] loss: 0.841, ave_loss: 0.748
[4]  [60/1724] loss: 0.938, ave_loss: 0.795
[5]  [80/1724] loss: 0.829, ave_loss: 0.802
[6]  [100/1724] loss: 0.867, ave_loss: 0.813
[7]  [120/1724] loss: 0.813, ave_loss: 0.813
[8]  [140/1724] loss: 0.899, ave_loss: 0.824
[9]  [160/1724] loss: 0.838, ave_loss: 0.825
[10]  [180/1724] loss: 0.780, ave_loss: 0.821
[11]  [200/1724] loss: 0.730, ave_loss: 0.812
[12]  [220/1724] loss: 0.744, ave_loss: 0.807
[13]  [240/1724] loss: 0.783, ave_loss: 0.805
[14]  [260/1724] loss: 0.817, ave_loss: 0.806
[15]  [280/1724] loss: 0.903, ave_loss: 0.812
[16]  [300/1724] loss: 0.959, ave_loss: 0.821
[17]  [320/1724] loss: 0.739, ave_loss: 0.817
[18]  [340/1724] loss: 0.716, ave_loss: 0.811
[19]  [360/1724] loss: 0.875, ave_loss: 0.814
[20]  [380/1724] loss: 0.971, ave_loss: 0.822
[21]  [400/1724] loss: 0.793, ave_loss: 0.821
[22]  [420/1724] loss: 0.924, ave_loss: 0.825
[23]  [440/1724] loss: 1.047, ave_loss: 0.835
[24]  [460/1724] loss: 0.776, ave_loss: 0.833
[25]  [480/1724] loss: 0.907, ave_loss: 0.836
[26]  [500/1724] loss: 0.803, ave_loss: 0.834
[27]  [520/1724] loss: 0.760, ave_loss: 0.832
[28]  [540/1724] loss: 0.776, ave_loss: 0.830
[29]  [560/1724] loss: 0.903, ave_loss: 0.832
[30]  [580/1724] loss: 0.809, ave_loss: 0.831
[31]  [600/1724] loss: 0.745, ave_loss: 0.829
[32]  [620/1724] loss: 0.841, ave_loss: 0.829
[33]  [640/1724] loss: 0.891, ave_loss: 0.831
[34]  [660/1724] loss: 0.794, ave_loss: 0.830
[35]  [680/1724] loss: 0.885, ave_loss: 0.831
[36]  [700/1724] loss: 0.862, ave_loss: 0.832
[37]  [720/1724] loss: 0.791, ave_loss: 0.831
[38]  [740/1724] loss: 0.822, ave_loss: 0.831
[39]  [760/1724] loss: 0.878, ave_loss: 0.832
[40]  [780/1724] loss: 0.798, ave_loss: 0.831
[41]  [800/1724] loss: 0.828, ave_loss: 0.831
[42]  [820/1724] loss: 0.906, ave_loss: 0.833
[43]  [840/1724] loss: 0.938, ave_loss: 0.835
[44]  [860/1724] loss: 0.904, ave_loss: 0.837
[45]  [880/1724] loss: 0.754, ave_loss: 0.835
[46]  [900/1724] loss: 0.930, ave_loss: 0.837
[47]  [920/1724] loss: 0.862, ave_loss: 0.838
[48]  [940/1724] loss: 0.694, ave_loss: 0.835
[49]  [960/1724] loss: 0.730, ave_loss: 0.833
[50]  [980/1724] loss: 0.836, ave_loss: 0.833
[51]  [1000/1724] loss: 0.858, ave_loss: 0.833
[52]  [1020/1724] loss: 0.673, ave_loss: 0.830
[53]  [1040/1724] loss: 0.741, ave_loss: 0.828
[54]  [1060/1724] loss: 0.756, ave_loss: 0.827
[55]  [1080/1724] loss: 0.842, ave_loss: 0.827
[56]  [1100/1724] loss: 0.947, ave_loss: 0.829
[57]  [1120/1724] loss: 0.753, ave_loss: 0.828
[58]  [1140/1724] loss: 0.683, ave_loss: 0.826
[59]  [1160/1724] loss: 0.663, ave_loss: 0.823
[60]  [1180/1724] loss: 0.797, ave_loss: 0.822
[61]  [1200/1724] loss: 0.766, ave_loss: 0.821
[62]  [1220/1724] loss: 0.773, ave_loss: 0.821
[63]  [1240/1724] loss: 0.802, ave_loss: 0.820
[64]  [1260/1724] loss: 0.853, ave_loss: 0.821
[65]  [1280/1724] loss: 0.758, ave_loss: 0.820
[66]  [1300/1724] loss: 0.852, ave_loss: 0.820
[67]  [1320/1724] loss: 0.836, ave_loss: 0.821
[68]  [1340/1724] loss: 0.844, ave_loss: 0.821
[69]  [1360/1724] loss: 0.871, ave_loss: 0.822
[70]  [1380/1724] loss: 0.855, ave_loss: 0.822
[71]  [1400/1724] loss: 0.852, ave_loss: 0.823
[72]  [1420/1724] loss: 0.831, ave_loss: 0.823
[73]  [1440/1724] loss: 0.777, ave_loss: 0.822
[74]  [1460/1724] loss: 0.795, ave_loss: 0.822
[75]  [1480/1724] loss: 0.778, ave_loss: 0.821
[76]  [1500/1724] loss: 0.799, ave_loss: 0.821
[77]  [1520/1724] loss: 0.783, ave_loss: 0.820
[78]  [1540/1724] loss: 0.833, ave_loss: 0.821
[79]  [1560/1724] loss: 0.734, ave_loss: 0.819
[80]  [1580/1724] loss: 0.733, ave_loss: 0.818
[81]  [1600/1724] loss: 0.921, ave_loss: 0.820
[82]  [1620/1724] loss: 0.746, ave_loss: 0.819
[83]  [1640/1724] loss: 0.882, ave_loss: 0.819
[84]  [1660/1724] loss: 0.830, ave_loss: 0.820
[85]  [1680/1724] loss: 0.818, ave_loss: 0.820
[86]  [1700/1724] loss: 0.926, ave_loss: 0.821
[87]  [1720/1724] loss: 0.646, ave_loss: 0.819
[88]  [1740/1724] loss: 0.875, ave_loss: 0.819

Finished Training finishing at 2021-08-29 19:25:32.234881
printing_out epoch  11.22969837587007 learning rate: 0.0005153561248318907
0.00036863495918228726
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 8.194e-01
Validation Loss: 1.426e+06
Validation ROC: 0.4618
Saving model
17.770301624129928 epochs left to go

Training Epoch 11.22969837587007/30 starting at 2021-08-29 19:26:41.938139
[1]  [0/1724] loss: 0.787, ave_loss: 0.787
[2]  [20/1724] loss: 0.911, ave_loss: 0.849
[3]  [40/1724] loss: 0.853, ave_loss: 0.850
[4]  [60/1724] loss: 0.748, ave_loss: 0.825
[5]  [80/1724] loss: 0.820, ave_loss: 0.824
[6]  [100/1724] loss: 0.743, ave_loss: 0.810
[7]  [120/1724] loss: 0.816, ave_loss: 0.811
[8]  [140/1724] loss: 0.839, ave_loss: 0.815
[9]  [160/1724] loss: 0.857, ave_loss: 0.819
[10]  [180/1724] loss: 0.747, ave_loss: 0.812
[11]  [200/1724] loss: 0.891, ave_loss: 0.819
[12]  [220/1724] loss: 0.786, ave_loss: 0.816
[13]  [240/1724] loss: 0.899, ave_loss: 0.823
[14]  [260/1724] loss: 0.746, ave_loss: 0.817
[15]  [280/1724] loss: 0.766, ave_loss: 0.814
[16]  [300/1724] loss: 0.863, ave_loss: 0.817
[17]  [320/1724] loss: 0.684, ave_loss: 0.809
[18]  [340/1724] loss: 0.825, ave_loss: 0.810
[19]  [360/1724] loss: 0.814, ave_loss: 0.810
[20]  [380/1724] loss: 0.764, ave_loss: 0.808
[21]  [400/1724] loss: 0.771, ave_loss: 0.806
[22]  [420/1724] loss: 0.883, ave_loss: 0.810
[23]  [440/1724] loss: 0.803, ave_loss: 0.809
[24]  [460/1724] loss: 0.736, ave_loss: 0.806
[25]  [480/1724] loss: 0.884, ave_loss: 0.809
[26]  [500/1724] loss: 0.733, ave_loss: 0.807
[27]  [520/1724] loss: 0.864, ave_loss: 0.809
[28]  [540/1724] loss: 0.623, ave_loss: 0.802
[29]  [560/1724] loss: 0.681, ave_loss: 0.798
[30]  [580/1724] loss: 0.694, ave_loss: 0.794
[31]  [600/1724] loss: 0.655, ave_loss: 0.790
[32]  [620/1724] loss: 0.802, ave_loss: 0.790
[33]  [640/1724] loss: 0.739, ave_loss: 0.789
[34]  [660/1724] loss: 0.772, ave_loss: 0.788
[35]  [680/1724] loss: 0.805, ave_loss: 0.789
[36]  [700/1724] loss: 0.755, ave_loss: 0.788
[37]  [720/1724] loss: 0.904, ave_loss: 0.791
[38]  [740/1724] loss: 0.743, ave_loss: 0.790
[39]  [760/1724] loss: 0.799, ave_loss: 0.790
[40]  [780/1724] loss: 0.853, ave_loss: 0.791
[41]  [800/1724] loss: 0.812, ave_loss: 0.792
[42]  [820/1724] loss: 0.738, ave_loss: 0.791
[43]  [840/1724] loss: 0.678, ave_loss: 0.788
[44]  [860/1724] loss: 0.735, ave_loss: 0.787
[45]  [880/1724] loss: 0.712, ave_loss: 0.785
[46]  [900/1724] loss: 0.806, ave_loss: 0.786
[47]  [920/1724] loss: 0.748, ave_loss: 0.785
[48]  [940/1724] loss: 0.888, ave_loss: 0.787
[49]  [960/1724] loss: 0.822, ave_loss: 0.788
[50]  [980/1724] loss: 0.692, ave_loss: 0.786
[51]  [1000/1724] loss: 0.867, ave_loss: 0.787
[52]  [1020/1724] loss: 0.999, ave_loss: 0.791
[53]  [1040/1724] loss: 0.756, ave_loss: 0.791
[54]  [1060/1724] loss: 0.747, ave_loss: 0.790
[55]  [1080/1724] loss: 0.753, ave_loss: 0.789
[56]  [1100/1724] loss: 0.832, ave_loss: 0.790
[57]  [1120/1724] loss: 0.762, ave_loss: 0.790
[58]  [1140/1724] loss: 0.745, ave_loss: 0.789
[59]  [1160/1724] loss: 0.935, ave_loss: 0.791
[60]  [1180/1724] loss: 0.869, ave_loss: 0.793
[61]  [1200/1724] loss: 0.837, ave_loss: 0.793
[62]  [1220/1724] loss: 0.913, ave_loss: 0.795
[63]  [1240/1724] loss: 0.675, ave_loss: 0.793
[64]  [1260/1724] loss: 0.726, ave_loss: 0.792
[65]  [1280/1724] loss: 0.734, ave_loss: 0.791
[66]  [1300/1724] loss: 0.881, ave_loss: 0.793
[67]  [1320/1724] loss: 0.669, ave_loss: 0.791
[68]  [1340/1724] loss: 0.733, ave_loss: 0.790
[69]  [1360/1724] loss: 0.825, ave_loss: 0.791
[70]  [1380/1724] loss: 0.796, ave_loss: 0.791
[71]  [1400/1724] loss: 0.825, ave_loss: 0.791
[72]  [1420/1724] loss: 0.839, ave_loss: 0.792
[73]  [1440/1724] loss: 0.800, ave_loss: 0.792
[74]  [1460/1724] loss: 0.909, ave_loss: 0.793
[75]  [1480/1724] loss: 0.784, ave_loss: 0.793
[76]  [1500/1724] loss: 0.841, ave_loss: 0.794
[77]  [1520/1724] loss: 0.838, ave_loss: 0.795
[78]  [1540/1724] loss: 0.873, ave_loss: 0.796
[79]  [1560/1724] loss: 0.826, ave_loss: 0.796
[80]  [1580/1724] loss: 0.755, ave_loss: 0.795
[81]  [1600/1724] loss: 0.713, ave_loss: 0.794
[82]  [1620/1724] loss: 0.754, ave_loss: 0.794
[83]  [1640/1724] loss: 0.803, ave_loss: 0.794
[84]  [1660/1724] loss: 0.646, ave_loss: 0.792
[85]  [1680/1724] loss: 0.799, ave_loss: 0.792
[86]  [1700/1724] loss: 0.750, ave_loss: 0.792
[87]  [1720/1724] loss: 0.681, ave_loss: 0.791
[88]  [1740/1724] loss: 0.696, ave_loss: 0.790

Finished Training finishing at 2021-08-29 19:29:41.383204
printing_out epoch  12.250580046403712 learning rate: 0.0005153561248318907
0.0003575759104068186
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.895e-01
Validation Loss: 1.408e+06
Validation ROC: 0.4618
Saving model
16.749419953596288 epochs left to go

Training Epoch 12.250580046403712/30 starting at 2021-08-29 19:30:47.845194
[1]  [0/1724] loss: 0.857, ave_loss: 0.857
[2]  [20/1724] loss: 0.812, ave_loss: 0.835
[3]  [40/1724] loss: 0.619, ave_loss: 0.763
[4]  [60/1724] loss: 0.767, ave_loss: 0.764
[5]  [80/1724] loss: 0.811, ave_loss: 0.773
[6]  [100/1724] loss: 0.842, ave_loss: 0.785
[7]  [120/1724] loss: 0.828, ave_loss: 0.791
[8]  [140/1724] loss: 0.745, ave_loss: 0.785
[9]  [160/1724] loss: 0.795, ave_loss: 0.786
[10]  [180/1724] loss: 0.811, ave_loss: 0.789
[11]  [200/1724] loss: 0.887, ave_loss: 0.798
[12]  [220/1724] loss: 0.751, ave_loss: 0.794
[13]  [240/1724] loss: 0.744, ave_loss: 0.790
[14]  [260/1724] loss: 0.817, ave_loss: 0.792
[15]  [280/1724] loss: 0.777, ave_loss: 0.791
[16]  [300/1724] loss: 0.803, ave_loss: 0.792
[17]  [320/1724] loss: 0.857, ave_loss: 0.796
[18]  [340/1724] loss: 0.755, ave_loss: 0.793
[19]  [360/1724] loss: 0.752, ave_loss: 0.791
[20]  [380/1724] loss: 0.811, ave_loss: 0.792
[21]  [400/1724] loss: 0.715, ave_loss: 0.788
[22]  [420/1724] loss: 0.808, ave_loss: 0.789
[23]  [440/1724] loss: 0.766, ave_loss: 0.788
[24]  [460/1724] loss: 0.730, ave_loss: 0.786
[25]  [480/1724] loss: 0.809, ave_loss: 0.787
[26]  [500/1724] loss: 0.801, ave_loss: 0.787
[27]  [520/1724] loss: 0.767, ave_loss: 0.787
[28]  [540/1724] loss: 0.914, ave_loss: 0.791
[29]  [560/1724] loss: 0.824, ave_loss: 0.792
[30]  [580/1724] loss: 0.779, ave_loss: 0.792
[31]  [600/1724] loss: 0.822, ave_loss: 0.793
[32]  [620/1724] loss: 0.848, ave_loss: 0.795
[33]  [640/1724] loss: 0.895, ave_loss: 0.798
[34]  [660/1724] loss: 0.946, ave_loss: 0.802
[35]  [680/1724] loss: 0.761, ave_loss: 0.801
[36]  [700/1724] loss: 0.808, ave_loss: 0.801
[37]  [720/1724] loss: 0.918, ave_loss: 0.804
[38]  [740/1724] loss: 0.661, ave_loss: 0.800
[39]  [760/1724] loss: 0.786, ave_loss: 0.800
[40]  [780/1724] loss: 0.646, ave_loss: 0.796
[41]  [800/1724] loss: 0.818, ave_loss: 0.797
[42]  [820/1724] loss: 0.737, ave_loss: 0.795
[43]  [840/1724] loss: 0.848, ave_loss: 0.797
[44]  [860/1724] loss: 0.725, ave_loss: 0.795
[45]  [880/1724] loss: 0.883, ave_loss: 0.797
[46]  [900/1724] loss: 0.845, ave_loss: 0.798
[47]  [920/1724] loss: 0.818, ave_loss: 0.798
[48]  [940/1724] loss: 0.787, ave_loss: 0.798
[49]  [960/1724] loss: 0.806, ave_loss: 0.798
[50]  [980/1724] loss: 0.825, ave_loss: 0.799
[51]  [1000/1724] loss: 0.828, ave_loss: 0.799
[52]  [1020/1724] loss: 0.707, ave_loss: 0.798
[53]  [1040/1724] loss: 0.835, ave_loss: 0.798
[54]  [1060/1724] loss: 0.784, ave_loss: 0.798
[55]  [1080/1724] loss: 0.707, ave_loss: 0.796
[56]  [1100/1724] loss: 0.799, ave_loss: 0.796
[57]  [1120/1724] loss: 0.843, ave_loss: 0.797
[58]  [1140/1724] loss: 0.696, ave_loss: 0.795
[59]  [1160/1724] loss: 0.958, ave_loss: 0.798
[60]  [1180/1724] loss: 0.825, ave_loss: 0.799
[61]  [1200/1724] loss: 0.803, ave_loss: 0.799
[62]  [1220/1724] loss: 0.754, ave_loss: 0.798
[63]  [1240/1724] loss: 0.671, ave_loss: 0.796
[64]  [1260/1724] loss: 0.816, ave_loss: 0.796
[65]  [1280/1724] loss: 0.766, ave_loss: 0.796
[66]  [1300/1724] loss: 0.739, ave_loss: 0.795
[67]  [1320/1724] loss: 0.794, ave_loss: 0.795
[68]  [1340/1724] loss: 0.797, ave_loss: 0.795
[69]  [1360/1724] loss: 0.717, ave_loss: 0.794
[70]  [1380/1724] loss: 0.732, ave_loss: 0.793
[71]  [1400/1724] loss: 0.751, ave_loss: 0.792
[72]  [1420/1724] loss: 0.637, ave_loss: 0.790
[73]  [1440/1724] loss: 0.807, ave_loss: 0.790
[74]  [1460/1724] loss: 0.708, ave_loss: 0.789
[75]  [1480/1724] loss: 0.763, ave_loss: 0.789
[76]  [1500/1724] loss: 0.673, ave_loss: 0.788
[77]  [1520/1724] loss: 0.745, ave_loss: 0.787
[78]  [1540/1724] loss: 0.609, ave_loss: 0.785
[79]  [1560/1724] loss: 0.731, ave_loss: 0.784
[80]  [1580/1724] loss: 0.793, ave_loss: 0.784
[81]  [1600/1724] loss: 0.710, ave_loss: 0.783
[82]  [1620/1724] loss: 0.650, ave_loss: 0.782
[83]  [1640/1724] loss: 0.775, ave_loss: 0.781
[84]  [1660/1724] loss: 0.787, ave_loss: 0.782
[85]  [1680/1724] loss: 0.857, ave_loss: 0.782
[86]  [1700/1724] loss: 0.775, ave_loss: 0.782
[87]  [1720/1724] loss: 0.806, ave_loss: 0.783
[88]  [1740/1724] loss: 0.757, ave_loss: 0.782

Finished Training finishing at 2021-08-29 19:33:49.283905
printing_out epoch  13.271461716937354 learning rate: 0.0005153561248318907
0.00034684863309461403
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.823e-01
Validation Loss: 1.393e+06
Validation ROC: 0.4618
Saving model
15.728538283062646 epochs left to go

Training Epoch 13.271461716937354/30 starting at 2021-08-29 19:34:57.818090
[1]  [0/1724] loss: 0.761, ave_loss: 0.761
[2]  [20/1724] loss: 0.741, ave_loss: 0.751
[3]  [40/1724] loss: 0.835, ave_loss: 0.779
[4]  [60/1724] loss: 0.682, ave_loss: 0.755
[5]  [80/1724] loss: 0.818, ave_loss: 0.767
[6]  [100/1724] loss: 0.764, ave_loss: 0.767
[7]  [120/1724] loss: 1.026, ave_loss: 0.804
[8]  [140/1724] loss: 0.746, ave_loss: 0.797
[9]  [160/1724] loss: 0.804, ave_loss: 0.798
[10]  [180/1724] loss: 0.680, ave_loss: 0.786
[11]  [200/1724] loss: 0.864, ave_loss: 0.793
[12]  [220/1724] loss: 0.677, ave_loss: 0.783
[13]  [240/1724] loss: 0.890, ave_loss: 0.791
[14]  [260/1724] loss: 0.704, ave_loss: 0.785
[15]  [280/1724] loss: 0.754, ave_loss: 0.783
[16]  [300/1724] loss: 0.761, ave_loss: 0.782
[17]  [320/1724] loss: 0.781, ave_loss: 0.782
[18]  [340/1724] loss: 0.759, ave_loss: 0.780
[19]  [360/1724] loss: 0.813, ave_loss: 0.782
[20]  [380/1724] loss: 0.682, ave_loss: 0.777
[21]  [400/1724] loss: 0.747, ave_loss: 0.776
[22]  [420/1724] loss: 0.864, ave_loss: 0.780
[23]  [440/1724] loss: 0.700, ave_loss: 0.776
[24]  [460/1724] loss: 0.765, ave_loss: 0.776
[25]  [480/1724] loss: 0.799, ave_loss: 0.777
[26]  [500/1724] loss: 0.748, ave_loss: 0.776
[27]  [520/1724] loss: 0.795, ave_loss: 0.776
[28]  [540/1724] loss: 0.816, ave_loss: 0.778
[29]  [560/1724] loss: 0.790, ave_loss: 0.778
[30]  [580/1724] loss: 0.706, ave_loss: 0.776
[31]  [600/1724] loss: 0.734, ave_loss: 0.774
[32]  [620/1724] loss: 0.793, ave_loss: 0.775
[33]  [640/1724] loss: 0.843, ave_loss: 0.777
[34]  [660/1724] loss: 0.631, ave_loss: 0.773
[35]  [680/1724] loss: 0.764, ave_loss: 0.772
[36]  [700/1724] loss: 0.745, ave_loss: 0.772
[37]  [720/1724] loss: 0.744, ave_loss: 0.771
[38]  [740/1724] loss: 0.827, ave_loss: 0.772
[39]  [760/1724] loss: 0.771, ave_loss: 0.772
[40]  [780/1724] loss: 0.656, ave_loss: 0.770
[41]  [800/1724] loss: 0.687, ave_loss: 0.768
[42]  [820/1724] loss: 0.766, ave_loss: 0.767
[43]  [840/1724] loss: 0.740, ave_loss: 0.767
[44]  [860/1724] loss: 0.791, ave_loss: 0.767
[45]  [880/1724] loss: 0.688, ave_loss: 0.766
[46]  [900/1724] loss: 0.738, ave_loss: 0.765
[47]  [920/1724] loss: 0.770, ave_loss: 0.765
[48]  [940/1724] loss: 0.769, ave_loss: 0.765
[49]  [960/1724] loss: 0.833, ave_loss: 0.767
[50]  [980/1724] loss: 0.725, ave_loss: 0.766
[51]  [1000/1724] loss: 0.748, ave_loss: 0.765
[52]  [1020/1724] loss: 0.643, ave_loss: 0.763
[53]  [1040/1724] loss: 0.774, ave_loss: 0.763
[54]  [1060/1724] loss: 0.759, ave_loss: 0.763
[55]  [1080/1724] loss: 0.788, ave_loss: 0.764
[56]  [1100/1724] loss: 0.731, ave_loss: 0.763
[57]  [1120/1724] loss: 0.858, ave_loss: 0.765
[58]  [1140/1724] loss: 0.589, ave_loss: 0.762
[59]  [1160/1724] loss: 0.924, ave_loss: 0.764
[60]  [1180/1724] loss: 0.708, ave_loss: 0.764
[61]  [1200/1724] loss: 0.741, ave_loss: 0.763
[62]  [1220/1724] loss: 0.665, ave_loss: 0.762
[63]  [1240/1724] loss: 0.727, ave_loss: 0.761
[64]  [1260/1724] loss: 0.845, ave_loss: 0.762
[65]  [1280/1724] loss: 0.688, ave_loss: 0.761
[66]  [1300/1724] loss: 0.700, ave_loss: 0.760
[67]  [1320/1724] loss: 0.671, ave_loss: 0.759
[68]  [1340/1724] loss: 0.738, ave_loss: 0.759
[69]  [1360/1724] loss: 0.718, ave_loss: 0.758
[70]  [1380/1724] loss: 0.802, ave_loss: 0.759
[71]  [1400/1724] loss: 0.799, ave_loss: 0.759
[72]  [1420/1724] loss: 0.818, ave_loss: 0.760
[73]  [1440/1724] loss: 0.793, ave_loss: 0.760
[74]  [1460/1724] loss: 0.745, ave_loss: 0.760
[75]  [1480/1724] loss: 0.702, ave_loss: 0.760
[76]  [1500/1724] loss: 0.781, ave_loss: 0.760
[77]  [1520/1724] loss: 0.849, ave_loss: 0.761
[78]  [1540/1724] loss: 0.714, ave_loss: 0.760
[79]  [1560/1724] loss: 0.730, ave_loss: 0.760
[80]  [1580/1724] loss: 0.855, ave_loss: 0.761
[81]  [1600/1724] loss: 0.748, ave_loss: 0.761
[82]  [1620/1724] loss: 0.833, ave_loss: 0.762
[83]  [1640/1724] loss: 0.725, ave_loss: 0.761
[84]  [1660/1724] loss: 0.817, ave_loss: 0.762
[85]  [1680/1724] loss: 0.713, ave_loss: 0.762
[86]  [1700/1724] loss: 0.757, ave_loss: 0.761
[87]  [1720/1724] loss: 0.772, ave_loss: 0.762
[88]  [1740/1724] loss: 0.777, ave_loss: 0.762

Finished Training finishing at 2021-08-29 19:37:54.594551
printing_out epoch  14.292343387470998 learning rate: 0.0005153561248318907
0.0003364431741017756
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.618e-01
Validation Loss: 1.374e+06
Validation ROC: 0.4625
Saving model
14.707656612529002 epochs left to go

Training Epoch 14.292343387470998/30 starting at 2021-08-29 19:39:08.187145
[1]  [0/1724] loss: 0.611, ave_loss: 0.611
[2]  [20/1724] loss: 0.835, ave_loss: 0.723
[3]  [40/1724] loss: 0.765, ave_loss: 0.737
[4]  [60/1724] loss: 0.734, ave_loss: 0.736
[5]  [80/1724] loss: 0.760, ave_loss: 0.741
[6]  [100/1724] loss: 0.854, ave_loss: 0.760
[7]  [120/1724] loss: 0.743, ave_loss: 0.757
[8]  [140/1724] loss: 0.874, ave_loss: 0.772
[9]  [160/1724] loss: 0.700, ave_loss: 0.764
[10]  [180/1724] loss: 0.786, ave_loss: 0.766
[11]  [200/1724] loss: 0.723, ave_loss: 0.762
[12]  [220/1724] loss: 0.672, ave_loss: 0.755
[13]  [240/1724] loss: 0.695, ave_loss: 0.750
[14]  [260/1724] loss: 0.795, ave_loss: 0.753
[15]  [280/1724] loss: 0.771, ave_loss: 0.754
[16]  [300/1724] loss: 0.692, ave_loss: 0.751
[17]  [320/1724] loss: 0.826, ave_loss: 0.755
[18]  [340/1724] loss: 0.738, ave_loss: 0.754
[19]  [360/1724] loss: 0.703, ave_loss: 0.751
[20]  [380/1724] loss: 0.829, ave_loss: 0.755
[21]  [400/1724] loss: 0.759, ave_loss: 0.755
[22]  [420/1724] loss: 0.799, ave_loss: 0.757
[23]  [440/1724] loss: 0.819, ave_loss: 0.760
[24]  [460/1724] loss: 0.760, ave_loss: 0.760
[25]  [480/1724] loss: 0.743, ave_loss: 0.759
[26]  [500/1724] loss: 0.698, ave_loss: 0.757
[27]  [520/1724] loss: 0.681, ave_loss: 0.754
[28]  [540/1724] loss: 0.778, ave_loss: 0.755
[29]  [560/1724] loss: 0.804, ave_loss: 0.757
[30]  [580/1724] loss: 0.620, ave_loss: 0.752
[31]  [600/1724] loss: 0.842, ave_loss: 0.755
[32]  [620/1724] loss: 0.717, ave_loss: 0.754
[33]  [640/1724] loss: 0.810, ave_loss: 0.756
[34]  [660/1724] loss: 0.811, ave_loss: 0.757
[35]  [680/1724] loss: 0.653, ave_loss: 0.754
[36]  [700/1724] loss: 0.740, ave_loss: 0.754
[37]  [720/1724] loss: 0.670, ave_loss: 0.752
[38]  [740/1724] loss: 0.830, ave_loss: 0.754
[39]  [760/1724] loss: 0.663, ave_loss: 0.751
[40]  [780/1724] loss: 0.752, ave_loss: 0.751
[41]  [800/1724] loss: 0.699, ave_loss: 0.750
[42]  [820/1724] loss: 0.698, ave_loss: 0.749
[43]  [840/1724] loss: 0.666, ave_loss: 0.747
[44]  [860/1724] loss: 0.752, ave_loss: 0.747
[45]  [880/1724] loss: 0.740, ave_loss: 0.747
[46]  [900/1724] loss: 0.808, ave_loss: 0.748
[47]  [920/1724] loss: 0.719, ave_loss: 0.748
[48]  [940/1724] loss: 0.706, ave_loss: 0.747
[49]  [960/1724] loss: 0.801, ave_loss: 0.748
[50]  [980/1724] loss: 0.802, ave_loss: 0.749
[51]  [1000/1724] loss: 0.694, ave_loss: 0.748
[52]  [1020/1724] loss: 0.812, ave_loss: 0.749
[53]  [1040/1724] loss: 0.794, ave_loss: 0.750
[54]  [1060/1724] loss: 0.781, ave_loss: 0.750
[55]  [1080/1724] loss: 0.763, ave_loss: 0.751
[56]  [1100/1724] loss: 0.689, ave_loss: 0.750
[57]  [1120/1724] loss: 0.794, ave_loss: 0.750
[58]  [1140/1724] loss: 0.708, ave_loss: 0.750
[59]  [1160/1724] loss: 0.748, ave_loss: 0.750
[60]  [1180/1724] loss: 0.782, ave_loss: 0.750
[61]  [1200/1724] loss: 0.762, ave_loss: 0.750
[62]  [1220/1724] loss: 0.742, ave_loss: 0.750
[63]  [1240/1724] loss: 0.722, ave_loss: 0.750
[64]  [1260/1724] loss: 0.668, ave_loss: 0.748
[65]  [1280/1724] loss: 0.740, ave_loss: 0.748
[66]  [1300/1724] loss: 0.759, ave_loss: 0.748
[67]  [1320/1724] loss: 0.783, ave_loss: 0.749
[68]  [1340/1724] loss: 0.819, ave_loss: 0.750
[69]  [1360/1724] loss: 0.747, ave_loss: 0.750
[70]  [1380/1724] loss: 0.667, ave_loss: 0.749
[71]  [1400/1724] loss: 0.817, ave_loss: 0.750
[72]  [1420/1724] loss: 0.677, ave_loss: 0.749
[73]  [1440/1724] loss: 0.841, ave_loss: 0.750
[74]  [1460/1724] loss: 0.786, ave_loss: 0.750
[75]  [1480/1724] loss: 0.821, ave_loss: 0.751
[76]  [1500/1724] loss: 0.783, ave_loss: 0.752
[77]  [1520/1724] loss: 0.801, ave_loss: 0.752
[78]  [1540/1724] loss: 0.805, ave_loss: 0.753
[79]  [1560/1724] loss: 0.696, ave_loss: 0.752
[80]  [1580/1724] loss: 0.724, ave_loss: 0.752
[81]  [1600/1724] loss: 0.812, ave_loss: 0.753
[82]  [1620/1724] loss: 0.718, ave_loss: 0.752
[83]  [1640/1724] loss: 0.768, ave_loss: 0.753
[84]  [1660/1724] loss: 0.730, ave_loss: 0.752
[85]  [1680/1724] loss: 0.787, ave_loss: 0.753
[86]  [1700/1724] loss: 0.730, ave_loss: 0.752
[87]  [1720/1724] loss: 0.820, ave_loss: 0.753
[88]  [1740/1724] loss: 0.689, ave_loss: 0.753

Finished Training finishing at 2021-08-29 19:42:11.113673
printing_out epoch  15.31322505800464 learning rate: 0.0005153561248318907
0.0003263498788787223
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.525e-01
Validation Loss: 1.364e+06
Validation ROC: 0.4625
Saving model
13.68677494199536 epochs left to go

Training Epoch 15.31322505800464/30 starting at 2021-08-29 19:43:25.220546
[1]  [0/1724] loss: 0.739, ave_loss: 0.739
[2]  [20/1724] loss: 0.739, ave_loss: 0.739
[3]  [40/1724] loss: 0.789, ave_loss: 0.756
[4]  [60/1724] loss: 0.659, ave_loss: 0.732
[5]  [80/1724] loss: 0.770, ave_loss: 0.739
[6]  [100/1724] loss: 0.781, ave_loss: 0.746
[7]  [120/1724] loss: 0.722, ave_loss: 0.743
[8]  [140/1724] loss: 0.742, ave_loss: 0.743
[9]  [160/1724] loss: 0.700, ave_loss: 0.738
[10]  [180/1724] loss: 0.838, ave_loss: 0.748
[11]  [200/1724] loss: 0.814, ave_loss: 0.754
[12]  [220/1724] loss: 0.807, ave_loss: 0.758
[13]  [240/1724] loss: 0.744, ave_loss: 0.757
[14]  [260/1724] loss: 0.805, ave_loss: 0.761
[15]  [280/1724] loss: 0.763, ave_loss: 0.761
[16]  [300/1724] loss: 0.814, ave_loss: 0.764
[17]  [320/1724] loss: 0.799, ave_loss: 0.766
[18]  [340/1724] loss: 0.704, ave_loss: 0.763
[19]  [360/1724] loss: 0.770, ave_loss: 0.763
[20]  [380/1724] loss: 0.781, ave_loss: 0.764
[21]  [400/1724] loss: 0.862, ave_loss: 0.769
[22]  [420/1724] loss: 0.698, ave_loss: 0.766
[23]  [440/1724] loss: 0.660, ave_loss: 0.761
[24]  [460/1724] loss: 0.762, ave_loss: 0.761
[25]  [480/1724] loss: 0.644, ave_loss: 0.756
[26]  [500/1724] loss: 0.767, ave_loss: 0.757
[27]  [520/1724] loss: 0.740, ave_loss: 0.756
[28]  [540/1724] loss: 0.678, ave_loss: 0.753
[29]  [560/1724] loss: 0.762, ave_loss: 0.754
[30]  [580/1724] loss: 0.763, ave_loss: 0.754
[31]  [600/1724] loss: 0.725, ave_loss: 0.753
[32]  [620/1724] loss: 0.805, ave_loss: 0.755
[33]  [640/1724] loss: 0.710, ave_loss: 0.753
[34]  [660/1724] loss: 0.792, ave_loss: 0.754
[35]  [680/1724] loss: 0.725, ave_loss: 0.753
[36]  [700/1724] loss: 0.683, ave_loss: 0.752
[37]  [720/1724] loss: 0.717, ave_loss: 0.751
[38]  [740/1724] loss: 0.695, ave_loss: 0.749
[39]  [760/1724] loss: 0.731, ave_loss: 0.749
[40]  [780/1724] loss: 0.725, ave_loss: 0.748
[41]  [800/1724] loss: 0.808, ave_loss: 0.750
[42]  [820/1724] loss: 0.740, ave_loss: 0.749
[43]  [840/1724] loss: 0.821, ave_loss: 0.751
[44]  [860/1724] loss: 0.743, ave_loss: 0.751
[45]  [880/1724] loss: 0.694, ave_loss: 0.750
[46]  [900/1724] loss: 0.718, ave_loss: 0.749
[47]  [920/1724] loss: 0.748, ave_loss: 0.749
[48]  [940/1724] loss: 0.724, ave_loss: 0.748
[49]  [960/1724] loss: 0.752, ave_loss: 0.748
[50]  [980/1724] loss: 0.830, ave_loss: 0.750
[51]  [1000/1724] loss: 0.587, ave_loss: 0.747
[52]  [1020/1724] loss: 0.750, ave_loss: 0.747
[53]  [1040/1724] loss: 0.640, ave_loss: 0.745
[54]  [1060/1724] loss: 0.714, ave_loss: 0.744
[55]  [1080/1724] loss: 0.761, ave_loss: 0.745
[56]  [1100/1724] loss: 0.723, ave_loss: 0.744
[57]  [1120/1724] loss: 0.727, ave_loss: 0.744
[58]  [1140/1724] loss: 0.768, ave_loss: 0.744
[59]  [1160/1724] loss: 0.804, ave_loss: 0.745
[60]  [1180/1724] loss: 0.688, ave_loss: 0.744
[61]  [1200/1724] loss: 0.784, ave_loss: 0.745
[62]  [1220/1724] loss: 0.804, ave_loss: 0.746
[63]  [1240/1724] loss: 0.684, ave_loss: 0.745
[64]  [1260/1724] loss: 0.762, ave_loss: 0.745
[65]  [1280/1724] loss: 0.739, ave_loss: 0.745
[66]  [1300/1724] loss: 0.752, ave_loss: 0.745
[67]  [1320/1724] loss: 0.755, ave_loss: 0.745
[68]  [1340/1724] loss: 0.828, ave_loss: 0.747
[69]  [1360/1724] loss: 0.654, ave_loss: 0.745
[70]  [1380/1724] loss: 0.776, ave_loss: 0.746
[71]  [1400/1724] loss: 0.713, ave_loss: 0.745
[72]  [1420/1724] loss: 0.715, ave_loss: 0.745
[73]  [1440/1724] loss: 0.692, ave_loss: 0.744
[74]  [1460/1724] loss: 0.748, ave_loss: 0.744
[75]  [1480/1724] loss: 0.737, ave_loss: 0.744
[76]  [1500/1724] loss: 0.783, ave_loss: 0.745
[77]  [1520/1724] loss: 0.804, ave_loss: 0.745
[78]  [1540/1724] loss: 0.649, ave_loss: 0.744
[79]  [1560/1724] loss: 0.696, ave_loss: 0.744
[80]  [1580/1724] loss: 0.685, ave_loss: 0.743
[81]  [1600/1724] loss: 0.787, ave_loss: 0.743
[82]  [1620/1724] loss: 0.621, ave_loss: 0.742
[83]  [1640/1724] loss: 0.757, ave_loss: 0.742
[84]  [1660/1724] loss: 0.766, ave_loss: 0.742
[85]  [1680/1724] loss: 0.715, ave_loss: 0.742
[86]  [1700/1724] loss: 0.729, ave_loss: 0.742
[87]  [1720/1724] loss: 0.732, ave_loss: 0.742
[88]  [1740/1724] loss: 0.833, ave_loss: 0.743

Finished Training finishing at 2021-08-29 19:46:27.343381
printing_out epoch  16.334106728538284 learning rate: 0.0005153561248318907
0.00031655938251236066
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.427e-01
Validation Loss: 1.345e+06
Validation ROC: 0.4625
Saving model
12.665893271461716 epochs left to go

Training Epoch 16.334106728538284/30 starting at 2021-08-29 19:47:37.489119
[1]  [0/1724] loss: 0.666, ave_loss: 0.666
[2]  [20/1724] loss: 0.824, ave_loss: 0.745
[3]  [40/1724] loss: 0.694, ave_loss: 0.728
[4]  [60/1724] loss: 0.609, ave_loss: 0.698
[5]  [80/1724] loss: 0.659, ave_loss: 0.690
[6]  [100/1724] loss: 0.781, ave_loss: 0.705
[7]  [120/1724] loss: 0.832, ave_loss: 0.723
[8]  [140/1724] loss: 0.742, ave_loss: 0.726
[9]  [160/1724] loss: 0.715, ave_loss: 0.724
[10]  [180/1724] loss: 0.742, ave_loss: 0.726
[11]  [200/1724] loss: 0.787, ave_loss: 0.732
[12]  [220/1724] loss: 0.702, ave_loss: 0.729
[13]  [240/1724] loss: 0.712, ave_loss: 0.728
[14]  [260/1724] loss: 0.694, ave_loss: 0.726
[15]  [280/1724] loss: 0.705, ave_loss: 0.724
[16]  [300/1724] loss: 0.753, ave_loss: 0.726
[17]  [320/1724] loss: 0.779, ave_loss: 0.729
[18]  [340/1724] loss: 0.807, ave_loss: 0.734
[19]  [360/1724] loss: 0.756, ave_loss: 0.735
[20]  [380/1724] loss: 0.683, ave_loss: 0.732
[21]  [400/1724] loss: 0.656, ave_loss: 0.728
[22]  [420/1724] loss: 0.720, ave_loss: 0.728
[23]  [440/1724] loss: 0.638, ave_loss: 0.724
[24]  [460/1724] loss: 0.759, ave_loss: 0.726
[25]  [480/1724] loss: 0.714, ave_loss: 0.725
[26]  [500/1724] loss: 0.723, ave_loss: 0.725
[27]  [520/1724] loss: 0.740, ave_loss: 0.726
[28]  [540/1724] loss: 0.769, ave_loss: 0.727
[29]  [560/1724] loss: 0.620, ave_loss: 0.723
[30]  [580/1724] loss: 0.763, ave_loss: 0.725
[31]  [600/1724] loss: 0.740, ave_loss: 0.725
[32]  [620/1724] loss: 0.798, ave_loss: 0.728
[33]  [640/1724] loss: 0.699, ave_loss: 0.727
[34]  [660/1724] loss: 0.721, ave_loss: 0.727
[35]  [680/1724] loss: 0.698, ave_loss: 0.726
[36]  [700/1724] loss: 0.738, ave_loss: 0.726
[37]  [720/1724] loss: 0.767, ave_loss: 0.727
[38]  [740/1724] loss: 0.735, ave_loss: 0.727
[39]  [760/1724] loss: 0.776, ave_loss: 0.729
[40]  [780/1724] loss: 0.683, ave_loss: 0.727
[41]  [800/1724] loss: 0.742, ave_loss: 0.728
[42]  [820/1724] loss: 0.644, ave_loss: 0.726
[43]  [840/1724] loss: 0.769, ave_loss: 0.727
[44]  [860/1724] loss: 0.669, ave_loss: 0.726
[45]  [880/1724] loss: 0.654, ave_loss: 0.724
[46]  [900/1724] loss: 0.738, ave_loss: 0.724
[47]  [920/1724] loss: 0.723, ave_loss: 0.724
[48]  [940/1724] loss: 0.742, ave_loss: 0.725
[49]  [960/1724] loss: 0.683, ave_loss: 0.724
[50]  [980/1724] loss: 0.675, ave_loss: 0.723
[51]  [1000/1724] loss: 0.711, ave_loss: 0.723
[52]  [1020/1724] loss: 0.783, ave_loss: 0.724
[53]  [1040/1724] loss: 0.789, ave_loss: 0.725
[54]  [1060/1724] loss: 0.751, ave_loss: 0.725
[55]  [1080/1724] loss: 0.748, ave_loss: 0.726
[56]  [1100/1724] loss: 0.727, ave_loss: 0.726
[57]  [1120/1724] loss: 0.722, ave_loss: 0.726
[58]  [1140/1724] loss: 0.754, ave_loss: 0.726
[59]  [1160/1724] loss: 0.768, ave_loss: 0.727
[60]  [1180/1724] loss: 0.692, ave_loss: 0.726
[61]  [1200/1724] loss: 0.757, ave_loss: 0.727
[62]  [1220/1724] loss: 0.800, ave_loss: 0.728
[63]  [1240/1724] loss: 0.689, ave_loss: 0.727
[64]  [1260/1724] loss: 0.675, ave_loss: 0.727
[65]  [1280/1724] loss: 0.631, ave_loss: 0.725
[66]  [1300/1724] loss: 0.726, ave_loss: 0.725
[67]  [1320/1724] loss: 0.667, ave_loss: 0.724
[68]  [1340/1724] loss: 0.722, ave_loss: 0.724
[69]  [1360/1724] loss: 0.737, ave_loss: 0.724
[70]  [1380/1724] loss: 0.724, ave_loss: 0.724
[71]  [1400/1724] loss: 0.747, ave_loss: 0.725
[72]  [1420/1724] loss: 0.696, ave_loss: 0.724
[73]  [1440/1724] loss: 0.743, ave_loss: 0.725
[74]  [1460/1724] loss: 0.707, ave_loss: 0.724
[75]  [1480/1724] loss: 0.721, ave_loss: 0.724
[76]  [1500/1724] loss: 0.747, ave_loss: 0.725
[77]  [1520/1724] loss: 0.719, ave_loss: 0.725
[78]  [1540/1724] loss: 0.728, ave_loss: 0.725
[79]  [1560/1724] loss: 0.774, ave_loss: 0.725
[80]  [1580/1724] loss: 0.760, ave_loss: 0.726
[81]  [1600/1724] loss: 0.701, ave_loss: 0.725
[82]  [1620/1724] loss: 0.747, ave_loss: 0.726
[83]  [1640/1724] loss: 0.772, ave_loss: 0.726
[84]  [1660/1724] loss: 0.723, ave_loss: 0.726
[85]  [1680/1724] loss: 0.752, ave_loss: 0.726
[86]  [1700/1724] loss: 0.697, ave_loss: 0.726
[87]  [1720/1724] loss: 0.679, ave_loss: 0.726
[88]  [1740/1724] loss: 0.779, ave_loss: 0.726

Finished Training finishing at 2021-08-29 19:50:38.766468
printing_out epoch  17.354988399071924 learning rate: 0.0005153561248318907
0.00030706260103698985
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.262e-01
Validation Loss: 1.337e+06
Validation ROC: 0.4625
Saving model
11.645011600928076 epochs left to go

Training Epoch 17.354988399071924/30 starting at 2021-08-29 19:51:43.599639
[1]  [0/1724] loss: 0.720, ave_loss: 0.720
[2]  [20/1724] loss: 0.666, ave_loss: 0.693
[3]  [40/1724] loss: 0.697, ave_loss: 0.694
[4]  [60/1724] loss: 0.743, ave_loss: 0.706
[5]  [80/1724] loss: 0.655, ave_loss: 0.696
[6]  [100/1724] loss: 0.732, ave_loss: 0.702
[7]  [120/1724] loss: 0.687, ave_loss: 0.700
[8]  [140/1724] loss: 0.774, ave_loss: 0.709
[9]  [160/1724] loss: 0.755, ave_loss: 0.714
[10]  [180/1724] loss: 0.730, ave_loss: 0.716
[11]  [200/1724] loss: 0.721, ave_loss: 0.716
[12]  [220/1724] loss: 0.575, ave_loss: 0.705
[13]  [240/1724] loss: 0.664, ave_loss: 0.701
[14]  [260/1724] loss: 0.715, ave_loss: 0.702
[15]  [280/1724] loss: 0.726, ave_loss: 0.704
[16]  [300/1724] loss: 0.729, ave_loss: 0.706
[17]  [320/1724] loss: 0.687, ave_loss: 0.704
[18]  [340/1724] loss: 0.795, ave_loss: 0.709
[19]  [360/1724] loss: 0.753, ave_loss: 0.712
[20]  [380/1724] loss: 0.680, ave_loss: 0.710
[21]  [400/1724] loss: 0.715, ave_loss: 0.710
[22]  [420/1724] loss: 0.757, ave_loss: 0.713
[23]  [440/1724] loss: 0.739, ave_loss: 0.714
[24]  [460/1724] loss: 0.750, ave_loss: 0.715
[25]  [480/1724] loss: 0.723, ave_loss: 0.716
[26]  [500/1724] loss: 0.713, ave_loss: 0.715
[27]  [520/1724] loss: 0.686, ave_loss: 0.714
[28]  [540/1724] loss: 0.768, ave_loss: 0.716
[29]  [560/1724] loss: 0.727, ave_loss: 0.717
[30]  [580/1724] loss: 0.665, ave_loss: 0.715
[31]  [600/1724] loss: 0.691, ave_loss: 0.714
[32]  [620/1724] loss: 0.590, ave_loss: 0.710
[33]  [640/1724] loss: 0.764, ave_loss: 0.712
[34]  [660/1724] loss: 0.745, ave_loss: 0.713
[35]  [680/1724] loss: 0.715, ave_loss: 0.713
[36]  [700/1724] loss: 0.765, ave_loss: 0.714
[37]  [720/1724] loss: 0.736, ave_loss: 0.715
[38]  [740/1724] loss: 0.771, ave_loss: 0.716
[39]  [760/1724] loss: 0.653, ave_loss: 0.715
[40]  [780/1724] loss: 0.646, ave_loss: 0.713
[41]  [800/1724] loss: 0.727, ave_loss: 0.713
[42]  [820/1724] loss: 0.724, ave_loss: 0.714
[43]  [840/1724] loss: 0.793, ave_loss: 0.716
[44]  [860/1724] loss: 0.768, ave_loss: 0.717
[45]  [880/1724] loss: 0.641, ave_loss: 0.715
[46]  [900/1724] loss: 0.669, ave_loss: 0.714
[47]  [920/1724] loss: 0.734, ave_loss: 0.714
[48]  [940/1724] loss: 0.699, ave_loss: 0.714
[49]  [960/1724] loss: 0.684, ave_loss: 0.714
[50]  [980/1724] loss: 0.730, ave_loss: 0.714
[51]  [1000/1724] loss: 0.702, ave_loss: 0.714
[52]  [1020/1724] loss: 0.753, ave_loss: 0.714
[53]  [1040/1724] loss: 0.763, ave_loss: 0.715
[54]  [1060/1724] loss: 0.666, ave_loss: 0.714
[55]  [1080/1724] loss: 0.634, ave_loss: 0.713
[56]  [1100/1724] loss: 0.716, ave_loss: 0.713
[57]  [1120/1724] loss: 0.734, ave_loss: 0.713
[58]  [1140/1724] loss: 0.726, ave_loss: 0.714
[59]  [1160/1724] loss: 0.728, ave_loss: 0.714
[60]  [1180/1724] loss: 0.749, ave_loss: 0.714
[61]  [1200/1724] loss: 0.699, ave_loss: 0.714
[62]  [1220/1724] loss: 0.711, ave_loss: 0.714
[63]  [1240/1724] loss: 0.709, ave_loss: 0.714
[64]  [1260/1724] loss: 0.770, ave_loss: 0.715
[65]  [1280/1724] loss: 0.745, ave_loss: 0.715
[66]  [1300/1724] loss: 0.680, ave_loss: 0.715
[67]  [1320/1724] loss: 0.752, ave_loss: 0.715
[68]  [1340/1724] loss: 0.775, ave_loss: 0.716
[69]  [1360/1724] loss: 0.760, ave_loss: 0.717
[70]  [1380/1724] loss: 0.722, ave_loss: 0.717
[71]  [1400/1724] loss: 0.722, ave_loss: 0.717
[72]  [1420/1724] loss: 0.763, ave_loss: 0.718
[73]  [1440/1724] loss: 0.707, ave_loss: 0.718
[74]  [1460/1724] loss: 0.722, ave_loss: 0.718
[75]  [1480/1724] loss: 0.749, ave_loss: 0.718
[76]  [1500/1724] loss: 0.751, ave_loss: 0.718
[77]  [1520/1724] loss: 0.746, ave_loss: 0.719
[78]  [1540/1724] loss: 0.710, ave_loss: 0.719
[79]  [1560/1724] loss: 0.640, ave_loss: 0.718
[80]  [1580/1724] loss: 0.747, ave_loss: 0.718
[81]  [1600/1724] loss: 0.765, ave_loss: 0.719
[82]  [1620/1724] loss: 0.667, ave_loss: 0.718
[83]  [1640/1724] loss: 0.659, ave_loss: 0.717
[84]  [1660/1724] loss: 0.720, ave_loss: 0.717
[85]  [1680/1724] loss: 0.757, ave_loss: 0.718
[86]  [1700/1724] loss: 0.779, ave_loss: 0.719
[87]  [1720/1724] loss: 0.732, ave_loss: 0.719
[88]  [1740/1724] loss: 0.752, ave_loss: 0.719

Finished Training finishing at 2021-08-29 19:54:39.130656
printing_out epoch  18.37587006960557 learning rate: 0.0005153561248318907
0.00029785072300588016
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.191e-01
Validation Loss: 1.328e+06
Validation ROC: 0.4625
Saving model
10.624129930394432 epochs left to go

Training Epoch 18.37587006960557/30 starting at 2021-08-29 19:55:48.351741
[1]  [0/1724] loss: 0.778, ave_loss: 0.778
[2]  [20/1724] loss: 0.679, ave_loss: 0.729
[3]  [40/1724] loss: 0.708, ave_loss: 0.722
[4]  [60/1724] loss: 0.707, ave_loss: 0.718
[5]  [80/1724] loss: 0.747, ave_loss: 0.724
[6]  [100/1724] loss: 0.669, ave_loss: 0.715
[7]  [120/1724] loss: 0.684, ave_loss: 0.710
[8]  [140/1724] loss: 0.706, ave_loss: 0.710
[9]  [160/1724] loss: 0.725, ave_loss: 0.711
[10]  [180/1724] loss: 0.721, ave_loss: 0.712
[11]  [200/1724] loss: 0.719, ave_loss: 0.713
[12]  [220/1724] loss: 0.690, ave_loss: 0.711
[13]  [240/1724] loss: 0.787, ave_loss: 0.717
[14]  [260/1724] loss: 0.672, ave_loss: 0.714
[15]  [280/1724] loss: 0.728, ave_loss: 0.715
[16]  [300/1724] loss: 0.677, ave_loss: 0.712
[17]  [320/1724] loss: 0.694, ave_loss: 0.711
[18]  [340/1724] loss: 0.708, ave_loss: 0.711
[19]  [360/1724] loss: 0.698, ave_loss: 0.710
[20]  [380/1724] loss: 0.707, ave_loss: 0.710
[21]  [400/1724] loss: 0.661, ave_loss: 0.708
[22]  [420/1724] loss: 0.719, ave_loss: 0.708
[23]  [440/1724] loss: 0.719, ave_loss: 0.709
[24]  [460/1724] loss: 0.742, ave_loss: 0.710
[25]  [480/1724] loss: 0.720, ave_loss: 0.711
[26]  [500/1724] loss: 0.726, ave_loss: 0.711
[27]  [520/1724] loss: 0.707, ave_loss: 0.711
[28]  [540/1724] loss: 0.750, ave_loss: 0.712
[29]  [560/1724] loss: 0.708, ave_loss: 0.712
[30]  [580/1724] loss: 0.749, ave_loss: 0.713
[31]  [600/1724] loss: 0.704, ave_loss: 0.713
[32]  [620/1724] loss: 0.706, ave_loss: 0.713
[33]  [640/1724] loss: 0.738, ave_loss: 0.714
[34]  [660/1724] loss: 0.779, ave_loss: 0.716
[35]  [680/1724] loss: 0.721, ave_loss: 0.716
[36]  [700/1724] loss: 0.697, ave_loss: 0.715
[37]  [720/1724] loss: 0.774, ave_loss: 0.717
[38]  [740/1724] loss: 0.760, ave_loss: 0.718
[39]  [760/1724] loss: 0.742, ave_loss: 0.719
[40]  [780/1724] loss: 0.708, ave_loss: 0.718
[41]  [800/1724] loss: 0.661, ave_loss: 0.717
[42]  [820/1724] loss: 0.732, ave_loss: 0.717
[43]  [840/1724] loss: 0.767, ave_loss: 0.718
[44]  [860/1724] loss: 0.724, ave_loss: 0.719
[45]  [880/1724] loss: 0.669, ave_loss: 0.717
[46]  [900/1724] loss: 0.687, ave_loss: 0.717
[47]  [920/1724] loss: 0.746, ave_loss: 0.717
[48]  [940/1724] loss: 0.713, ave_loss: 0.717
[49]  [960/1724] loss: 0.669, ave_loss: 0.716
[50]  [980/1724] loss: 0.802, ave_loss: 0.718
[51]  [1000/1724] loss: 0.714, ave_loss: 0.718
[52]  [1020/1724] loss: 0.705, ave_loss: 0.718
[53]  [1040/1724] loss: 0.705, ave_loss: 0.717
[54]  [1060/1724] loss: 0.751, ave_loss: 0.718
[55]  [1080/1724] loss: 0.722, ave_loss: 0.718
[56]  [1100/1724] loss: 0.653, ave_loss: 0.717
[57]  [1120/1724] loss: 0.715, ave_loss: 0.717
[58]  [1140/1724] loss: 0.646, ave_loss: 0.716
[59]  [1160/1724] loss: 0.642, ave_loss: 0.714
[60]  [1180/1724] loss: 0.761, ave_loss: 0.715
[61]  [1200/1724] loss: 0.688, ave_loss: 0.715
[62]  [1220/1724] loss: 0.706, ave_loss: 0.715
[63]  [1240/1724] loss: 0.736, ave_loss: 0.715
[64]  [1260/1724] loss: 0.662, ave_loss: 0.714
[65]  [1280/1724] loss: 0.682, ave_loss: 0.714
[66]  [1300/1724] loss: 0.759, ave_loss: 0.714
[67]  [1320/1724] loss: 0.682, ave_loss: 0.714
[68]  [1340/1724] loss: 0.663, ave_loss: 0.713
[69]  [1360/1724] loss: 0.724, ave_loss: 0.713
[70]  [1380/1724] loss: 0.719, ave_loss: 0.713
[71]  [1400/1724] loss: 0.664, ave_loss: 0.713
[72]  [1420/1724] loss: 0.741, ave_loss: 0.713
[73]  [1440/1724] loss: 0.709, ave_loss: 0.713
[74]  [1460/1724] loss: 0.686, ave_loss: 0.713
[75]  [1480/1724] loss: 0.756, ave_loss: 0.713
[76]  [1500/1724] loss: 0.666, ave_loss: 0.713
[77]  [1520/1724] loss: 0.717, ave_loss: 0.713
[78]  [1540/1724] loss: 0.749, ave_loss: 0.713
[79]  [1560/1724] loss: 0.757, ave_loss: 0.714
[80]  [1580/1724] loss: 0.650, ave_loss: 0.713
[81]  [1600/1724] loss: 0.793, ave_loss: 0.714
[82]  [1620/1724] loss: 0.745, ave_loss: 0.714
[83]  [1640/1724] loss: 0.690, ave_loss: 0.714
[84]  [1660/1724] loss: 0.690, ave_loss: 0.714
[85]  [1680/1724] loss: 0.706, ave_loss: 0.714
[86]  [1700/1724] loss: 0.784, ave_loss: 0.714
[87]  [1720/1724] loss: 0.617, ave_loss: 0.713
[88]  [1740/1724] loss: 0.690, ave_loss: 0.713

Finished Training finishing at 2021-08-29 19:58:46.005118
printing_out epoch  19.396751740139212 learning rate: 0.0005153561248318907
0.00028891520131570374
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.130e-01
Validation Loss: 1.319e+06
Validation ROC: 0.4625
Saving model
9.603248259860788 epochs left to go

Training Epoch 19.396751740139212/30 starting at 2021-08-29 19:59:54.139628
[1]  [0/1724] loss: 0.742, ave_loss: 0.742
[2]  [20/1724] loss: 0.716, ave_loss: 0.729
[3]  [40/1724] loss: 0.747, ave_loss: 0.735
[4]  [60/1724] loss: 0.684, ave_loss: 0.722
[5]  [80/1724] loss: 0.721, ave_loss: 0.722
[6]  [100/1724] loss: 0.761, ave_loss: 0.728
[7]  [120/1724] loss: 0.681, ave_loss: 0.722
[8]  [140/1724] loss: 0.598, ave_loss: 0.706
[9]  [160/1724] loss: 0.672, ave_loss: 0.702
[10]  [180/1724] loss: 0.677, ave_loss: 0.700
[11]  [200/1724] loss: 0.691, ave_loss: 0.699
[12]  [220/1724] loss: 0.696, ave_loss: 0.699
[13]  [240/1724] loss: 0.700, ave_loss: 0.699
[14]  [260/1724] loss: 0.701, ave_loss: 0.699
[15]  [280/1724] loss: 0.733, ave_loss: 0.701
[16]  [300/1724] loss: 0.704, ave_loss: 0.702
[17]  [320/1724] loss: 0.664, ave_loss: 0.699
[18]  [340/1724] loss: 0.686, ave_loss: 0.699
[19]  [360/1724] loss: 0.742, ave_loss: 0.701
[20]  [380/1724] loss: 0.636, ave_loss: 0.698
[21]  [400/1724] loss: 0.716, ave_loss: 0.698
[22]  [420/1724] loss: 0.724, ave_loss: 0.700
[23]  [440/1724] loss: 0.704, ave_loss: 0.700
[24]  [460/1724] loss: 0.668, ave_loss: 0.698
[25]  [480/1724] loss: 0.768, ave_loss: 0.701
[26]  [500/1724] loss: 0.701, ave_loss: 0.701
[27]  [520/1724] loss: 0.698, ave_loss: 0.701
[28]  [540/1724] loss: 0.752, ave_loss: 0.703
[29]  [560/1724] loss: 0.718, ave_loss: 0.703
[30]  [580/1724] loss: 0.661, ave_loss: 0.702
[31]  [600/1724] loss: 0.766, ave_loss: 0.704
[32]  [620/1724] loss: 0.748, ave_loss: 0.705
[33]  [640/1724] loss: 0.708, ave_loss: 0.706
[34]  [660/1724] loss: 0.711, ave_loss: 0.706
[35]  [680/1724] loss: 0.742, ave_loss: 0.707
[36]  [700/1724] loss: 0.709, ave_loss: 0.707
[37]  [720/1724] loss: 0.768, ave_loss: 0.708
[38]  [740/1724] loss: 0.701, ave_loss: 0.708
[39]  [760/1724] loss: 0.697, ave_loss: 0.708
[40]  [780/1724] loss: 0.712, ave_loss: 0.708
[41]  [800/1724] loss: 0.688, ave_loss: 0.708
[42]  [820/1724] loss: 0.679, ave_loss: 0.707
[43]  [840/1724] loss: 0.741, ave_loss: 0.708
[44]  [860/1724] loss: 0.742, ave_loss: 0.708
[45]  [880/1724] loss: 0.703, ave_loss: 0.708
[46]  [900/1724] loss: 0.745, ave_loss: 0.709
[47]  [920/1724] loss: 0.721, ave_loss: 0.709
[48]  [940/1724] loss: 0.720, ave_loss: 0.710
[49]  [960/1724] loss: 0.692, ave_loss: 0.709
[50]  [980/1724] loss: 0.626, ave_loss: 0.708
[51]  [1000/1724] loss: 0.689, ave_loss: 0.707
[52]  [1020/1724] loss: 0.701, ave_loss: 0.707
[53]  [1040/1724] loss: 0.690, ave_loss: 0.707
[54]  [1060/1724] loss: 0.658, ave_loss: 0.706
[55]  [1080/1724] loss: 0.667, ave_loss: 0.705
[56]  [1100/1724] loss: 0.737, ave_loss: 0.706
[57]  [1120/1724] loss: 0.752, ave_loss: 0.707
[58]  [1140/1724] loss: 0.661, ave_loss: 0.706
[59]  [1160/1724] loss: 0.718, ave_loss: 0.706
[60]  [1180/1724] loss: 0.711, ave_loss: 0.706
[61]  [1200/1724] loss: 0.709, ave_loss: 0.706
[62]  [1220/1724] loss: 0.700, ave_loss: 0.706
[63]  [1240/1724] loss: 0.658, ave_loss: 0.705
[64]  [1260/1724] loss: 0.722, ave_loss: 0.706
[65]  [1280/1724] loss: 0.708, ave_loss: 0.706
[66]  [1300/1724] loss: 0.652, ave_loss: 0.705
[67]  [1320/1724] loss: 0.766, ave_loss: 0.706
[68]  [1340/1724] loss: 0.715, ave_loss: 0.706
[69]  [1360/1724] loss: 0.715, ave_loss: 0.706
[70]  [1380/1724] loss: 0.743, ave_loss: 0.706
[71]  [1400/1724] loss: 0.729, ave_loss: 0.707
[72]  [1420/1724] loss: 0.698, ave_loss: 0.707
[73]  [1440/1724] loss: 0.743, ave_loss: 0.707
[74]  [1460/1724] loss: 0.691, ave_loss: 0.707
[75]  [1480/1724] loss: 0.687, ave_loss: 0.707
[76]  [1500/1724] loss: 0.705, ave_loss: 0.707
[77]  [1520/1724] loss: 0.675, ave_loss: 0.706
[78]  [1540/1724] loss: 0.607, ave_loss: 0.705
[79]  [1560/1724] loss: 0.698, ave_loss: 0.705
[80]  [1580/1724] loss: 0.666, ave_loss: 0.704
[81]  [1600/1724] loss: 0.698, ave_loss: 0.704
[82]  [1620/1724] loss: 0.738, ave_loss: 0.705
[83]  [1640/1724] loss: 0.668, ave_loss: 0.704
[84]  [1660/1724] loss: 0.738, ave_loss: 0.705
[85]  [1680/1724] loss: 0.692, ave_loss: 0.705
[86]  [1700/1724] loss: 0.704, ave_loss: 0.705
[87]  [1720/1724] loss: 0.702, ave_loss: 0.704
[88]  [1740/1724] loss: 0.638, ave_loss: 0.704

Finished Training finishing at 2021-08-29 20:02:49.386667
printing_out epoch  20.417633410672853 learning rate: 0.0005153561248318907
0.0002802477452762326
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.037e-01
Validation Loss: 1.311e+06
Validation ROC: 0.4625
Saving model
8.582366589327147 epochs left to go

Training Epoch 20.417633410672853/30 starting at 2021-08-29 20:03:55.325170
[1]  [0/1724] loss: 0.701, ave_loss: 0.701
[2]  [20/1724] loss: 0.684, ave_loss: 0.692
[3]  [40/1724] loss: 0.710, ave_loss: 0.698
[4]  [60/1724] loss: 0.638, ave_loss: 0.683
[5]  [80/1724] loss: 0.782, ave_loss: 0.703
[6]  [100/1724] loss: 0.702, ave_loss: 0.703
[7]  [120/1724] loss: 0.818, ave_loss: 0.719
[8]  [140/1724] loss: 0.726, ave_loss: 0.720
[9]  [160/1724] loss: 0.707, ave_loss: 0.719
[10]  [180/1724] loss: 0.685, ave_loss: 0.715
[11]  [200/1724] loss: 0.698, ave_loss: 0.714
[12]  [220/1724] loss: 0.673, ave_loss: 0.710
[13]  [240/1724] loss: 0.695, ave_loss: 0.709
[14]  [260/1724] loss: 0.664, ave_loss: 0.706
[15]  [280/1724] loss: 0.716, ave_loss: 0.707
[16]  [300/1724] loss: 0.747, ave_loss: 0.709
[17]  [320/1724] loss: 0.711, ave_loss: 0.709
[18]  [340/1724] loss: 0.696, ave_loss: 0.709
[19]  [360/1724] loss: 0.746, ave_loss: 0.710
[20]  [380/1724] loss: 0.661, ave_loss: 0.708
[21]  [400/1724] loss: 0.721, ave_loss: 0.709
[22]  [420/1724] loss: 0.711, ave_loss: 0.709
[23]  [440/1724] loss: 0.630, ave_loss: 0.705
[24]  [460/1724] loss: 0.775, ave_loss: 0.708
[25]  [480/1724] loss: 0.715, ave_loss: 0.708
[26]  [500/1724] loss: 0.716, ave_loss: 0.709
[27]  [520/1724] loss: 0.692, ave_loss: 0.708
[28]  [540/1724] loss: 0.650, ave_loss: 0.706
[29]  [560/1724] loss: 0.680, ave_loss: 0.705
[30]  [580/1724] loss: 0.724, ave_loss: 0.706
[31]  [600/1724] loss: 0.734, ave_loss: 0.707
[32]  [620/1724] loss: 0.721, ave_loss: 0.707
[33]  [640/1724] loss: 0.687, ave_loss: 0.707
[34]  [660/1724] loss: 0.679, ave_loss: 0.706
[35]  [680/1724] loss: 0.731, ave_loss: 0.707
[36]  [700/1724] loss: 0.691, ave_loss: 0.706
[37]  [720/1724] loss: 0.720, ave_loss: 0.706
[38]  [740/1724] loss: 0.683, ave_loss: 0.706
[39]  [760/1724] loss: 0.759, ave_loss: 0.707
[40]  [780/1724] loss: 0.698, ave_loss: 0.707
[41]  [800/1724] loss: 0.661, ave_loss: 0.706
[42]  [820/1724] loss: 0.739, ave_loss: 0.707
[43]  [840/1724] loss: 0.692, ave_loss: 0.706
[44]  [860/1724] loss: 0.712, ave_loss: 0.706
[45]  [880/1724] loss: 0.691, ave_loss: 0.706
[46]  [900/1724] loss: 0.724, ave_loss: 0.706
[47]  [920/1724] loss: 0.618, ave_loss: 0.705
[48]  [940/1724] loss: 0.699, ave_loss: 0.704
[49]  [960/1724] loss: 0.662, ave_loss: 0.704
[50]  [980/1724] loss: 0.727, ave_loss: 0.704
[51]  [1000/1724] loss: 0.758, ave_loss: 0.705
[52]  [1020/1724] loss: 0.719, ave_loss: 0.705
[53]  [1040/1724] loss: 0.748, ave_loss: 0.706
[54]  [1060/1724] loss: 0.703, ave_loss: 0.706
[55]  [1080/1724] loss: 0.670, ave_loss: 0.706
[56]  [1100/1724] loss: 0.727, ave_loss: 0.706
[57]  [1120/1724] loss: 0.681, ave_loss: 0.705
[58]  [1140/1724] loss: 0.749, ave_loss: 0.706
[59]  [1160/1724] loss: 0.696, ave_loss: 0.706
[60]  [1180/1724] loss: 0.741, ave_loss: 0.707
[61]  [1200/1724] loss: 0.664, ave_loss: 0.706
[62]  [1220/1724] loss: 0.737, ave_loss: 0.706
[63]  [1240/1724] loss: 0.686, ave_loss: 0.706
[64]  [1260/1724] loss: 0.717, ave_loss: 0.706
[65]  [1280/1724] loss: 0.687, ave_loss: 0.706
[66]  [1300/1724] loss: 0.649, ave_loss: 0.705
[67]  [1320/1724] loss: 0.641, ave_loss: 0.704
[68]  [1340/1724] loss: 0.685, ave_loss: 0.704
[69]  [1360/1724] loss: 0.671, ave_loss: 0.703
[70]  [1380/1724] loss: 0.682, ave_loss: 0.703
[71]  [1400/1724] loss: 0.669, ave_loss: 0.703
[72]  [1420/1724] loss: 0.702, ave_loss: 0.703
[73]  [1440/1724] loss: 0.650, ave_loss: 0.702
[74]  [1460/1724] loss: 0.721, ave_loss: 0.702
[75]  [1480/1724] loss: 0.729, ave_loss: 0.703
[76]  [1500/1724] loss: 0.666, ave_loss: 0.702
[77]  [1520/1724] loss: 0.660, ave_loss: 0.701
[78]  [1540/1724] loss: 0.671, ave_loss: 0.701
[79]  [1560/1724] loss: 0.694, ave_loss: 0.701
[80]  [1580/1724] loss: 0.705, ave_loss: 0.701
[81]  [1600/1724] loss: 0.703, ave_loss: 0.701
[82]  [1620/1724] loss: 0.682, ave_loss: 0.701
[83]  [1640/1724] loss: 0.745, ave_loss: 0.701
[84]  [1660/1724] loss: 0.716, ave_loss: 0.702
[85]  [1680/1724] loss: 0.787, ave_loss: 0.703
[86]  [1700/1724] loss: 0.715, ave_loss: 0.703
[87]  [1720/1724] loss: 0.695, ave_loss: 0.703
[88]  [1740/1724] loss: 0.736, ave_loss: 0.703

Finished Training finishing at 2021-08-29 20:06:59.500908
printing_out epoch  21.438515081206496 learning rate: 0.0005153561248318907
0.00027184031291794565
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 7.030e-01
Validation Loss: 1.296e+06
Validation ROC: 0.4625
Saving model
7.561484918793504 epochs left to go

Training Epoch 21.438515081206496/30 starting at 2021-08-29 20:08:12.417056
[1]  [0/1724] loss: 0.691, ave_loss: 0.691
[2]  [20/1724] loss: 0.666, ave_loss: 0.679
[3]  [40/1724] loss: 0.738, ave_loss: 0.699
[4]  [60/1724] loss: 0.698, ave_loss: 0.698
[5]  [80/1724] loss: 0.669, ave_loss: 0.692
[6]  [100/1724] loss: 0.717, ave_loss: 0.697
[7]  [120/1724] loss: 0.736, ave_loss: 0.702
[8]  [140/1724] loss: 0.719, ave_loss: 0.704
[9]  [160/1724] loss: 0.700, ave_loss: 0.704
[10]  [180/1724] loss: 0.648, ave_loss: 0.698
[11]  [200/1724] loss: 0.724, ave_loss: 0.701
[12]  [220/1724] loss: 0.790, ave_loss: 0.708
[13]  [240/1724] loss: 0.687, ave_loss: 0.706
[14]  [260/1724] loss: 0.755, ave_loss: 0.710
[15]  [280/1724] loss: 0.729, ave_loss: 0.711
[16]  [300/1724] loss: 0.640, ave_loss: 0.707
[17]  [320/1724] loss: 0.685, ave_loss: 0.705
[18]  [340/1724] loss: 0.705, ave_loss: 0.705
[19]  [360/1724] loss: 0.679, ave_loss: 0.704
[20]  [380/1724] loss: 0.766, ave_loss: 0.707
[21]  [400/1724] loss: 0.673, ave_loss: 0.706
[22]  [420/1724] loss: 0.688, ave_loss: 0.705
[23]  [440/1724] loss: 0.675, ave_loss: 0.703
[24]  [460/1724] loss: 0.705, ave_loss: 0.704
[25]  [480/1724] loss: 0.637, ave_loss: 0.701
[26]  [500/1724] loss: 0.747, ave_loss: 0.703
[27]  [520/1724] loss: 0.611, ave_loss: 0.699
[28]  [540/1724] loss: 0.718, ave_loss: 0.700
[29]  [560/1724] loss: 0.690, ave_loss: 0.700
[30]  [580/1724] loss: 0.640, ave_loss: 0.698
[31]  [600/1724] loss: 0.699, ave_loss: 0.698
[32]  [620/1724] loss: 0.687, ave_loss: 0.697
[33]  [640/1724] loss: 0.717, ave_loss: 0.698
[34]  [660/1724] loss: 0.679, ave_loss: 0.697
[35]  [680/1724] loss: 0.731, ave_loss: 0.698
[36]  [700/1724] loss: 0.654, ave_loss: 0.697
[37]  [720/1724] loss: 0.737, ave_loss: 0.698
[38]  [740/1724] loss: 0.735, ave_loss: 0.699
[39]  [760/1724] loss: 0.694, ave_loss: 0.699
[40]  [780/1724] loss: 0.678, ave_loss: 0.698
[41]  [800/1724] loss: 0.690, ave_loss: 0.698
[42]  [820/1724] loss: 0.698, ave_loss: 0.698
[43]  [840/1724] loss: 0.676, ave_loss: 0.698
[44]  [860/1724] loss: 0.676, ave_loss: 0.697
[45]  [880/1724] loss: 0.688, ave_loss: 0.697
[46]  [900/1724] loss: 0.642, ave_loss: 0.696
[47]  [920/1724] loss: 0.692, ave_loss: 0.696
[48]  [940/1724] loss: 0.647, ave_loss: 0.695
[49]  [960/1724] loss: 0.648, ave_loss: 0.694
[50]  [980/1724] loss: 0.663, ave_loss: 0.693
[51]  [1000/1724] loss: 0.676, ave_loss: 0.693
[52]  [1020/1724] loss: 0.694, ave_loss: 0.693
[53]  [1040/1724] loss: 0.696, ave_loss: 0.693
[54]  [1060/1724] loss: 0.728, ave_loss: 0.694
[55]  [1080/1724] loss: 0.676, ave_loss: 0.693
[56]  [1100/1724] loss: 0.716, ave_loss: 0.694
[57]  [1120/1724] loss: 0.619, ave_loss: 0.692
[58]  [1140/1724] loss: 0.710, ave_loss: 0.693
[59]  [1160/1724] loss: 0.687, ave_loss: 0.693
[60]  [1180/1724] loss: 0.674, ave_loss: 0.692
[61]  [1200/1724] loss: 0.684, ave_loss: 0.692
[62]  [1220/1724] loss: 0.693, ave_loss: 0.692
[63]  [1240/1724] loss: 0.682, ave_loss: 0.692
[64]  [1260/1724] loss: 0.685, ave_loss: 0.692
[65]  [1280/1724] loss: 0.674, ave_loss: 0.692
[66]  [1300/1724] loss: 0.691, ave_loss: 0.692
[67]  [1320/1724] loss: 0.693, ave_loss: 0.692
[68]  [1340/1724] loss: 0.707, ave_loss: 0.692
[69]  [1360/1724] loss: 0.687, ave_loss: 0.692
[70]  [1380/1724] loss: 0.706, ave_loss: 0.692
[71]  [1400/1724] loss: 0.645, ave_loss: 0.691
[72]  [1420/1724] loss: 0.691, ave_loss: 0.691
[73]  [1440/1724] loss: 0.729, ave_loss: 0.692
[74]  [1460/1724] loss: 0.692, ave_loss: 0.692
[75]  [1480/1724] loss: 0.683, ave_loss: 0.692
[76]  [1500/1724] loss: 0.704, ave_loss: 0.692
[77]  [1520/1724] loss: 0.703, ave_loss: 0.692
[78]  [1540/1724] loss: 0.721, ave_loss: 0.692
[79]  [1560/1724] loss: 0.713, ave_loss: 0.693
[80]  [1580/1724] loss: 0.666, ave_loss: 0.692
[81]  [1600/1724] loss: 0.653, ave_loss: 0.692
[82]  [1620/1724] loss: 0.689, ave_loss: 0.692
[83]  [1640/1724] loss: 0.670, ave_loss: 0.692
[84]  [1660/1724] loss: 0.683, ave_loss: 0.691
[85]  [1680/1724] loss: 0.702, ave_loss: 0.692
[86]  [1700/1724] loss: 0.667, ave_loss: 0.691
[87]  [1720/1724] loss: 0.700, ave_loss: 0.691
[88]  [1740/1724] loss: 0.681, ave_loss: 0.691

Finished Training finishing at 2021-08-29 20:11:11.121072
printing_out epoch  22.45939675174014 learning rate: 0.0005153561248318907
0.0002636851035304073
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.913e-01
Validation Loss: 1.279e+06
Validation ROC: 0.4625
Saving model
6.54060324825986 epochs left to go

Training Epoch 22.45939675174014/30 starting at 2021-08-29 20:12:25.313292
[1]  [0/1724] loss: 0.663, ave_loss: 0.663
[2]  [20/1724] loss: 0.688, ave_loss: 0.675
[3]  [40/1724] loss: 0.658, ave_loss: 0.670
[4]  [60/1724] loss: 0.682, ave_loss: 0.673
[5]  [80/1724] loss: 0.730, ave_loss: 0.684
[6]  [100/1724] loss: 0.677, ave_loss: 0.683
[7]  [120/1724] loss: 0.647, ave_loss: 0.678
[8]  [140/1724] loss: 0.661, ave_loss: 0.676
[9]  [160/1724] loss: 0.689, ave_loss: 0.677
[10]  [180/1724] loss: 0.736, ave_loss: 0.683
[11]  [200/1724] loss: 0.650, ave_loss: 0.680
[12]  [220/1724] loss: 0.665, ave_loss: 0.679
[13]  [240/1724] loss: 0.654, ave_loss: 0.677
[14]  [260/1724] loss: 0.674, ave_loss: 0.677
[15]  [280/1724] loss: 0.696, ave_loss: 0.678
[16]  [300/1724] loss: 0.709, ave_loss: 0.680
[17]  [320/1724] loss: 0.728, ave_loss: 0.683
[18]  [340/1724] loss: 0.693, ave_loss: 0.683
[19]  [360/1724] loss: 0.673, ave_loss: 0.683
[20]  [380/1724] loss: 0.718, ave_loss: 0.685
[21]  [400/1724] loss: 0.659, ave_loss: 0.683
[22]  [420/1724] loss: 0.671, ave_loss: 0.683
[23]  [440/1724] loss: 0.704, ave_loss: 0.684
[24]  [460/1724] loss: 0.696, ave_loss: 0.684
[25]  [480/1724] loss: 0.713, ave_loss: 0.685
[26]  [500/1724] loss: 0.680, ave_loss: 0.685
[27]  [520/1724] loss: 0.680, ave_loss: 0.685
[28]  [540/1724] loss: 0.690, ave_loss: 0.685
[29]  [560/1724] loss: 0.718, ave_loss: 0.686
[30]  [580/1724] loss: 0.680, ave_loss: 0.686
[31]  [600/1724] loss: 0.743, ave_loss: 0.688
[32]  [620/1724] loss: 0.670, ave_loss: 0.687
[33]  [640/1724] loss: 0.670, ave_loss: 0.687
[34]  [660/1724] loss: 0.661, ave_loss: 0.686
[35]  [680/1724] loss: 0.703, ave_loss: 0.687
[36]  [700/1724] loss: 0.682, ave_loss: 0.686
[37]  [720/1724] loss: 0.693, ave_loss: 0.687
[38]  [740/1724] loss: 0.714, ave_loss: 0.687
[39]  [760/1724] loss: 0.683, ave_loss: 0.687
[40]  [780/1724] loss: 0.677, ave_loss: 0.687
[41]  [800/1724] loss: 0.693, ave_loss: 0.687
[42]  [820/1724] loss: 0.696, ave_loss: 0.687
[43]  [840/1724] loss: 0.675, ave_loss: 0.687
[44]  [860/1724] loss: 0.689, ave_loss: 0.687
[45]  [880/1724] loss: 0.692, ave_loss: 0.687
[46]  [900/1724] loss: 0.712, ave_loss: 0.688
[47]  [920/1724] loss: 0.706, ave_loss: 0.688
[48]  [940/1724] loss: 0.621, ave_loss: 0.687
[49]  [960/1724] loss: 0.671, ave_loss: 0.686
[50]  [980/1724] loss: 0.711, ave_loss: 0.687
[51]  [1000/1724] loss: 0.680, ave_loss: 0.687
[52]  [1020/1724] loss: 0.711, ave_loss: 0.687
[53]  [1040/1724] loss: 0.669, ave_loss: 0.687
[54]  [1060/1724] loss: 0.640, ave_loss: 0.686
[55]  [1080/1724] loss: 0.648, ave_loss: 0.685
[56]  [1100/1724] loss: 0.664, ave_loss: 0.685
[57]  [1120/1724] loss: 0.674, ave_loss: 0.685
[58]  [1140/1724] loss: 0.690, ave_loss: 0.685
[59]  [1160/1724] loss: 0.691, ave_loss: 0.685
[60]  [1180/1724] loss: 0.684, ave_loss: 0.685
[61]  [1200/1724] loss: 0.667, ave_loss: 0.685
[62]  [1220/1724] loss: 0.674, ave_loss: 0.684
[63]  [1240/1724] loss: 0.664, ave_loss: 0.684
[64]  [1260/1724] loss: 0.707, ave_loss: 0.685
[65]  [1280/1724] loss: 0.637, ave_loss: 0.684
[66]  [1300/1724] loss: 0.683, ave_loss: 0.684
[67]  [1320/1724] loss: 0.662, ave_loss: 0.683
[68]  [1340/1724] loss: 0.668, ave_loss: 0.683
[69]  [1360/1724] loss: 0.671, ave_loss: 0.683
[70]  [1380/1724] loss: 0.675, ave_loss: 0.683
[71]  [1400/1724] loss: 0.660, ave_loss: 0.683
[72]  [1420/1724] loss: 0.709, ave_loss: 0.683
[73]  [1440/1724] loss: 0.716, ave_loss: 0.683
[74]  [1460/1724] loss: 0.663, ave_loss: 0.683
[75]  [1480/1724] loss: 0.622, ave_loss: 0.682
[76]  [1500/1724] loss: 0.660, ave_loss: 0.682
[77]  [1520/1724] loss: 0.706, ave_loss: 0.682
[78]  [1540/1724] loss: 0.708, ave_loss: 0.683
[79]  [1560/1724] loss: 0.667, ave_loss: 0.682
[80]  [1580/1724] loss: 0.624, ave_loss: 0.682
[81]  [1600/1724] loss: 0.697, ave_loss: 0.682
[82]  [1620/1724] loss: 0.708, ave_loss: 0.682
[83]  [1640/1724] loss: 0.684, ave_loss: 0.682
[84]  [1660/1724] loss: 0.665, ave_loss: 0.682
[85]  [1680/1724] loss: 0.707, ave_loss: 0.682
[86]  [1700/1724] loss: 0.651, ave_loss: 0.682
[87]  [1720/1724] loss: 0.640, ave_loss: 0.682
[88]  [1740/1724] loss: 0.673, ave_loss: 0.681

Finished Training finishing at 2021-08-29 20:15:36.056691
printing_out epoch  23.48027842227378 learning rate: 0.0005153561248318907
0.00025577455042449505
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.814e-01
Validation Loss: 1.272e+06
Validation ROC: 0.4625
Saving model
5.519721577726219 epochs left to go

Training Epoch 23.48027842227378/30 starting at 2021-08-29 20:16:46.463388
[1]  [0/1724] loss: 0.668, ave_loss: 0.668
[2]  [20/1724] loss: 0.651, ave_loss: 0.660
[3]  [40/1724] loss: 0.663, ave_loss: 0.661
[4]  [60/1724] loss: 0.662, ave_loss: 0.661
[5]  [80/1724] loss: 0.685, ave_loss: 0.666
[6]  [100/1724] loss: 0.665, ave_loss: 0.666
[7]  [120/1724] loss: 0.662, ave_loss: 0.665
[8]  [140/1724] loss: 0.666, ave_loss: 0.665
[9]  [160/1724] loss: 0.679, ave_loss: 0.667
[10]  [180/1724] loss: 0.705, ave_loss: 0.671
[11]  [200/1724] loss: 0.705, ave_loss: 0.674
[12]  [220/1724] loss: 0.664, ave_loss: 0.673
[13]  [240/1724] loss: 0.670, ave_loss: 0.673
[14]  [260/1724] loss: 0.674, ave_loss: 0.673
[15]  [280/1724] loss: 0.661, ave_loss: 0.672
[16]  [300/1724] loss: 0.645, ave_loss: 0.670
[17]  [320/1724] loss: 0.736, ave_loss: 0.674
[18]  [340/1724] loss: 0.705, ave_loss: 0.676
[19]  [360/1724] loss: 0.678, ave_loss: 0.676
[20]  [380/1724] loss: 0.672, ave_loss: 0.676
[21]  [400/1724] loss: 0.692, ave_loss: 0.677
[22]  [420/1724] loss: 0.690, ave_loss: 0.677
[23]  [440/1724] loss: 0.731, ave_loss: 0.679
[24]  [460/1724] loss: 0.592, ave_loss: 0.676
[25]  [480/1724] loss: 0.621, ave_loss: 0.674
[26]  [500/1724] loss: 0.707, ave_loss: 0.675
[27]  [520/1724] loss: 0.680, ave_loss: 0.675
[28]  [540/1724] loss: 0.692, ave_loss: 0.676
[29]  [560/1724] loss: 0.666, ave_loss: 0.675
[30]  [580/1724] loss: 0.662, ave_loss: 0.675
[31]  [600/1724] loss: 0.724, ave_loss: 0.677
[32]  [620/1724] loss: 0.687, ave_loss: 0.677
[33]  [640/1724] loss: 0.673, ave_loss: 0.677
[34]  [660/1724] loss: 0.673, ave_loss: 0.677
[35]  [680/1724] loss: 0.635, ave_loss: 0.675
[36]  [700/1724] loss: 0.693, ave_loss: 0.676
[37]  [720/1724] loss: 0.682, ave_loss: 0.676
[38]  [740/1724] loss: 0.746, ave_loss: 0.678
[39]  [760/1724] loss: 0.634, ave_loss: 0.677
[40]  [780/1724] loss: 0.669, ave_loss: 0.677
[41]  [800/1724] loss: 0.666, ave_loss: 0.676
[42]  [820/1724] loss: 0.644, ave_loss: 0.676
[43]  [840/1724] loss: 0.654, ave_loss: 0.675
[44]  [860/1724] loss: 0.715, ave_loss: 0.676
[45]  [880/1724] loss: 0.767, ave_loss: 0.678
[46]  [900/1724] loss: 0.719, ave_loss: 0.679
[47]  [920/1724] loss: 0.690, ave_loss: 0.679
[48]  [940/1724] loss: 0.706, ave_loss: 0.680
[49]  [960/1724] loss: 0.673, ave_loss: 0.680
[50]  [980/1724] loss: 0.677, ave_loss: 0.680
[51]  [1000/1724] loss: 0.704, ave_loss: 0.680
[52]  [1020/1724] loss: 0.659, ave_loss: 0.680
[53]  [1040/1724] loss: 0.666, ave_loss: 0.679
[54]  [1060/1724] loss: 0.659, ave_loss: 0.679
[55]  [1080/1724] loss: 0.687, ave_loss: 0.679
[56]  [1100/1724] loss: 0.662, ave_loss: 0.679
[57]  [1120/1724] loss: 0.687, ave_loss: 0.679
[58]  [1140/1724] loss: 0.684, ave_loss: 0.679
[59]  [1160/1724] loss: 0.647, ave_loss: 0.678
[60]  [1180/1724] loss: 0.646, ave_loss: 0.678
[61]  [1200/1724] loss: 0.682, ave_loss: 0.678
[62]  [1220/1724] loss: 0.637, ave_loss: 0.677
[63]  [1240/1724] loss: 0.695, ave_loss: 0.678
[64]  [1260/1724] loss: 0.663, ave_loss: 0.677
[65]  [1280/1724] loss: 0.675, ave_loss: 0.677
[66]  [1300/1724] loss: 0.714, ave_loss: 0.678
[67]  [1320/1724] loss: 0.714, ave_loss: 0.678
[68]  [1340/1724] loss: 0.662, ave_loss: 0.678
[69]  [1360/1724] loss: 0.684, ave_loss: 0.678
[70]  [1380/1724] loss: 0.599, ave_loss: 0.677
[71]  [1400/1724] loss: 0.689, ave_loss: 0.677
[72]  [1420/1724] loss: 0.635, ave_loss: 0.677
[73]  [1440/1724] loss: 0.657, ave_loss: 0.676
[74]  [1460/1724] loss: 0.668, ave_loss: 0.676
[75]  [1480/1724] loss: 0.694, ave_loss: 0.677
[76]  [1500/1724] loss: 0.672, ave_loss: 0.677
[77]  [1520/1724] loss: 0.675, ave_loss: 0.677
[78]  [1540/1724] loss: 0.726, ave_loss: 0.677
[79]  [1560/1724] loss: 0.661, ave_loss: 0.677
[80]  [1580/1724] loss: 0.679, ave_loss: 0.677
[81]  [1600/1724] loss: 0.687, ave_loss: 0.677
[82]  [1620/1724] loss: 0.698, ave_loss: 0.677
[83]  [1640/1724] loss: 0.686, ave_loss: 0.677
[84]  [1660/1724] loss: 0.678, ave_loss: 0.677
[85]  [1680/1724] loss: 0.678, ave_loss: 0.677
[86]  [1700/1724] loss: 0.654, ave_loss: 0.677
[87]  [1720/1724] loss: 0.705, ave_loss: 0.678
[88]  [1740/1724] loss: 0.692, ave_loss: 0.678

Finished Training finishing at 2021-08-29 20:20:02.117640
printing_out epoch  24.501160092807424 learning rate: 0.0005153561248318907
0.0002481013139117602
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.777e-01
Validation Loss: 1.265e+06
Validation ROC: 0.4625
Saving model
4.4988399071925755 epochs left to go

Training Epoch 24.501160092807424/30 starting at 2021-08-29 20:21:19.704450
[1]  [0/1724] loss: 0.703, ave_loss: 0.703
[2]  [20/1724] loss: 0.674, ave_loss: 0.689
[3]  [40/1724] loss: 0.638, ave_loss: 0.672
[4]  [60/1724] loss: 0.690, ave_loss: 0.676
[5]  [80/1724] loss: 0.686, ave_loss: 0.678
[6]  [100/1724] loss: 0.722, ave_loss: 0.686
[7]  [120/1724] loss: 0.676, ave_loss: 0.684
[8]  [140/1724] loss: 0.706, ave_loss: 0.687
[9]  [160/1724] loss: 0.679, ave_loss: 0.686
[10]  [180/1724] loss: 0.640, ave_loss: 0.681
[11]  [200/1724] loss: 0.596, ave_loss: 0.674
[12]  [220/1724] loss: 0.679, ave_loss: 0.674
[13]  [240/1724] loss: 0.622, ave_loss: 0.670
[14]  [260/1724] loss: 0.693, ave_loss: 0.672
[15]  [280/1724] loss: 0.679, ave_loss: 0.672
[16]  [300/1724] loss: 0.674, ave_loss: 0.672
[17]  [320/1724] loss: 0.608, ave_loss: 0.669
[18]  [340/1724] loss: 0.655, ave_loss: 0.668
[19]  [360/1724] loss: 0.701, ave_loss: 0.669
[20]  [380/1724] loss: 0.732, ave_loss: 0.673
[21]  [400/1724] loss: 0.651, ave_loss: 0.672
[22]  [420/1724] loss: 0.719, ave_loss: 0.674
[23]  [440/1724] loss: 0.636, ave_loss: 0.672
[24]  [460/1724] loss: 0.701, ave_loss: 0.673
[25]  [480/1724] loss: 0.675, ave_loss: 0.673
[26]  [500/1724] loss: 0.674, ave_loss: 0.673
[27]  [520/1724] loss: 0.729, ave_loss: 0.675
[28]  [540/1724] loss: 0.644, ave_loss: 0.674
[29]  [560/1724] loss: 0.691, ave_loss: 0.675
[30]  [580/1724] loss: 0.727, ave_loss: 0.677
[31]  [600/1724] loss: 0.692, ave_loss: 0.677
[32]  [620/1724] loss: 0.663, ave_loss: 0.677
[33]  [640/1724] loss: 0.685, ave_loss: 0.677
[34]  [660/1724] loss: 0.660, ave_loss: 0.677
[35]  [680/1724] loss: 0.611, ave_loss: 0.675
[36]  [700/1724] loss: 0.704, ave_loss: 0.675
[37]  [720/1724] loss: 0.694, ave_loss: 0.676
[38]  [740/1724] loss: 0.649, ave_loss: 0.675
[39]  [760/1724] loss: 0.688, ave_loss: 0.676
[40]  [780/1724] loss: 0.663, ave_loss: 0.675
[41]  [800/1724] loss: 0.702, ave_loss: 0.676
[42]  [820/1724] loss: 0.711, ave_loss: 0.677
[43]  [840/1724] loss: 0.701, ave_loss: 0.677
[44]  [860/1724] loss: 0.690, ave_loss: 0.678
[45]  [880/1724] loss: 0.725, ave_loss: 0.679
[46]  [900/1724] loss: 0.664, ave_loss: 0.678
[47]  [920/1724] loss: 0.697, ave_loss: 0.679
[48]  [940/1724] loss: 0.713, ave_loss: 0.679
[49]  [960/1724] loss: 0.652, ave_loss: 0.679
[50]  [980/1724] loss: 0.693, ave_loss: 0.679
[51]  [1000/1724] loss: 0.648, ave_loss: 0.679
[52]  [1020/1724] loss: 0.670, ave_loss: 0.678
[53]  [1040/1724] loss: 0.680, ave_loss: 0.678
[54]  [1060/1724] loss: 0.690, ave_loss: 0.679
[55]  [1080/1724] loss: 0.686, ave_loss: 0.679
[56]  [1100/1724] loss: 0.647, ave_loss: 0.678
[57]  [1120/1724] loss: 0.633, ave_loss: 0.677
[58]  [1140/1724] loss: 0.711, ave_loss: 0.678
[59]  [1160/1724] loss: 0.657, ave_loss: 0.678
[60]  [1180/1724] loss: 0.673, ave_loss: 0.678
[61]  [1200/1724] loss: 0.684, ave_loss: 0.678
[62]  [1220/1724] loss: 0.658, ave_loss: 0.677
[63]  [1240/1724] loss: 0.645, ave_loss: 0.677
[64]  [1260/1724] loss: 0.655, ave_loss: 0.677
[65]  [1280/1724] loss: 0.665, ave_loss: 0.676
[66]  [1300/1724] loss: 0.664, ave_loss: 0.676
[67]  [1320/1724] loss: 0.707, ave_loss: 0.677
[68]  [1340/1724] loss: 0.642, ave_loss: 0.676
[69]  [1360/1724] loss: 0.624, ave_loss: 0.675
[70]  [1380/1724] loss: 0.677, ave_loss: 0.675
[71]  [1400/1724] loss: 0.681, ave_loss: 0.675
[72]  [1420/1724] loss: 0.689, ave_loss: 0.676
[73]  [1440/1724] loss: 0.681, ave_loss: 0.676
[74]  [1460/1724] loss: 0.693, ave_loss: 0.676
[75]  [1480/1724] loss: 0.627, ave_loss: 0.675
[76]  [1500/1724] loss: 0.669, ave_loss: 0.675
[77]  [1520/1724] loss: 0.684, ave_loss: 0.675
[78]  [1540/1724] loss: 0.652, ave_loss: 0.675
[79]  [1560/1724] loss: 0.666, ave_loss: 0.675
[80]  [1580/1724] loss: 0.663, ave_loss: 0.675
[81]  [1600/1724] loss: 0.638, ave_loss: 0.674
[82]  [1620/1724] loss: 0.662, ave_loss: 0.674
[83]  [1640/1724] loss: 0.699, ave_loss: 0.674
[84]  [1660/1724] loss: 0.649, ave_loss: 0.674
[85]  [1680/1724] loss: 0.693, ave_loss: 0.674
[86]  [1700/1724] loss: 0.617, ave_loss: 0.674
[87]  [1720/1724] loss: 0.647, ave_loss: 0.673
[88]  [1740/1724] loss: 0.689, ave_loss: 0.674

Finished Training finishing at 2021-08-29 20:24:30.388889
printing_out epoch  25.52204176334107 learning rate: 0.0005153561248318907
0.00024065827449440741
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.736e-01
Validation Loss: 1.257e+06
Validation ROC: 0.4625
Saving model
3.4779582366589317 epochs left to go

Training Epoch 25.52204176334107/30 starting at 2021-08-29 20:25:42.810595
[1]  [0/1724] loss: 0.651, ave_loss: 0.651
[2]  [20/1724] loss: 0.642, ave_loss: 0.646
[3]  [40/1724] loss: 0.738, ave_loss: 0.677
[4]  [60/1724] loss: 0.671, ave_loss: 0.675
[5]  [80/1724] loss: 0.693, ave_loss: 0.679
[6]  [100/1724] loss: 0.624, ave_loss: 0.670
[7]  [120/1724] loss: 0.733, ave_loss: 0.679
[8]  [140/1724] loss: 0.656, ave_loss: 0.676
[9]  [160/1724] loss: 0.684, ave_loss: 0.677
[10]  [180/1724] loss: 0.645, ave_loss: 0.674
[11]  [200/1724] loss: 0.656, ave_loss: 0.672
[12]  [220/1724] loss: 0.617, ave_loss: 0.668
[13]  [240/1724] loss: 0.610, ave_loss: 0.663
[14]  [260/1724] loss: 0.702, ave_loss: 0.666
[15]  [280/1724] loss: 0.675, ave_loss: 0.666
[16]  [300/1724] loss: 0.675, ave_loss: 0.667
[17]  [320/1724] loss: 0.651, ave_loss: 0.666
[18]  [340/1724] loss: 0.651, ave_loss: 0.665
[19]  [360/1724] loss: 0.654, ave_loss: 0.665
[20]  [380/1724] loss: 0.662, ave_loss: 0.665
[21]  [400/1724] loss: 0.665, ave_loss: 0.665
[22]  [420/1724] loss: 0.684, ave_loss: 0.665
[23]  [440/1724] loss: 0.671, ave_loss: 0.666
[24]  [460/1724] loss: 0.678, ave_loss: 0.666
[25]  [480/1724] loss: 0.693, ave_loss: 0.667
[26]  [500/1724] loss: 0.603, ave_loss: 0.665
[27]  [520/1724] loss: 0.698, ave_loss: 0.666
[28]  [540/1724] loss: 0.664, ave_loss: 0.666
[29]  [560/1724] loss: 0.613, ave_loss: 0.664
[30]  [580/1724] loss: 0.681, ave_loss: 0.665
[31]  [600/1724] loss: 0.694, ave_loss: 0.666
[32]  [620/1724] loss: 0.698, ave_loss: 0.667
[33]  [640/1724] loss: 0.648, ave_loss: 0.666
[34]  [660/1724] loss: 0.711, ave_loss: 0.667
[35]  [680/1724] loss: 0.651, ave_loss: 0.667
[36]  [700/1724] loss: 0.679, ave_loss: 0.667
[37]  [720/1724] loss: 0.634, ave_loss: 0.666
[38]  [740/1724] loss: 0.699, ave_loss: 0.667
[39]  [760/1724] loss: 0.662, ave_loss: 0.667
[40]  [780/1724] loss: 0.687, ave_loss: 0.668
[41]  [800/1724] loss: 0.707, ave_loss: 0.669
[42]  [820/1724] loss: 0.664, ave_loss: 0.668
[43]  [840/1724] loss: 0.708, ave_loss: 0.669
[44]  [860/1724] loss: 0.642, ave_loss: 0.669
[45]  [880/1724] loss: 0.664, ave_loss: 0.669
[46]  [900/1724] loss: 0.634, ave_loss: 0.668
[47]  [920/1724] loss: 0.713, ave_loss: 0.669
[48]  [940/1724] loss: 0.630, ave_loss: 0.668
[49]  [960/1724] loss: 0.740, ave_loss: 0.670
[50]  [980/1724] loss: 0.651, ave_loss: 0.669
[51]  [1000/1724] loss: 0.705, ave_loss: 0.670
[52]  [1020/1724] loss: 0.658, ave_loss: 0.670
[53]  [1040/1724] loss: 0.675, ave_loss: 0.670
[54]  [1060/1724] loss: 0.656, ave_loss: 0.669
[55]  [1080/1724] loss: 0.663, ave_loss: 0.669
[56]  [1100/1724] loss: 0.657, ave_loss: 0.669
[57]  [1120/1724] loss: 0.689, ave_loss: 0.669
[58]  [1140/1724] loss: 0.677, ave_loss: 0.670
[59]  [1160/1724] loss: 0.650, ave_loss: 0.669
[60]  [1180/1724] loss: 0.682, ave_loss: 0.669
[61]  [1200/1724] loss: 0.662, ave_loss: 0.669
[62]  [1220/1724] loss: 0.653, ave_loss: 0.669
[63]  [1240/1724] loss: 0.668, ave_loss: 0.669
[64]  [1260/1724] loss: 0.710, ave_loss: 0.670
[65]  [1280/1724] loss: 0.712, ave_loss: 0.670
[66]  [1300/1724] loss: 0.684, ave_loss: 0.671
[67]  [1320/1724] loss: 0.643, ave_loss: 0.670
[68]  [1340/1724] loss: 0.696, ave_loss: 0.671
[69]  [1360/1724] loss: 0.679, ave_loss: 0.671
[70]  [1380/1724] loss: 0.661, ave_loss: 0.671
[71]  [1400/1724] loss: 0.725, ave_loss: 0.671
[72]  [1420/1724] loss: 0.686, ave_loss: 0.671
[73]  [1440/1724] loss: 0.635, ave_loss: 0.671
[74]  [1460/1724] loss: 0.637, ave_loss: 0.671
[75]  [1480/1724] loss: 0.640, ave_loss: 0.670
[76]  [1500/1724] loss: 0.619, ave_loss: 0.669
[77]  [1520/1724] loss: 0.687, ave_loss: 0.670
[78]  [1540/1724] loss: 0.664, ave_loss: 0.670
[79]  [1560/1724] loss: 0.676, ave_loss: 0.670
[80]  [1580/1724] loss: 0.670, ave_loss: 0.670
[81]  [1600/1724] loss: 0.704, ave_loss: 0.670
[82]  [1620/1724] loss: 0.677, ave_loss: 0.670
[83]  [1640/1724] loss: 0.677, ave_loss: 0.670
[84]  [1660/1724] loss: 0.673, ave_loss: 0.670
[85]  [1680/1724] loss: 0.667, ave_loss: 0.670
[86]  [1700/1724] loss: 0.705, ave_loss: 0.671
[87]  [1720/1724] loss: 0.673, ave_loss: 0.671
[88]  [1740/1724] loss: 0.639, ave_loss: 0.670

Finished Training finishing at 2021-08-29 20:28:57.257495
printing_out epoch  26.54292343387471 learning rate: 0.0005153561248318907
0.00023343852625957518
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.704e-01
Validation Loss: 1.246e+06
Validation ROC: 0.4625
Saving model
2.4570765661252914 epochs left to go

Training Epoch 26.54292343387471/30 starting at 2021-08-29 20:30:08.602091
[1]  [0/1724] loss: 0.714, ave_loss: 0.714
[2]  [20/1724] loss: 0.718, ave_loss: 0.716
[3]  [40/1724] loss: 0.788, ave_loss: 0.740
[4]  [60/1724] loss: 0.640, ave_loss: 0.715
[5]  [80/1724] loss: 0.668, ave_loss: 0.706
[6]  [100/1724] loss: 0.690, ave_loss: 0.703
[7]  [120/1724] loss: 0.643, ave_loss: 0.694
[8]  [140/1724] loss: 0.656, ave_loss: 0.690
[9]  [160/1724] loss: 0.638, ave_loss: 0.684
[10]  [180/1724] loss: 0.659, ave_loss: 0.681
[11]  [200/1724] loss: 0.624, ave_loss: 0.676
[12]  [220/1724] loss: 0.644, ave_loss: 0.674
[13]  [240/1724] loss: 0.668, ave_loss: 0.673
[14]  [260/1724] loss: 0.615, ave_loss: 0.669
[15]  [280/1724] loss: 0.656, ave_loss: 0.668
[16]  [300/1724] loss: 0.659, ave_loss: 0.668
[17]  [320/1724] loss: 0.680, ave_loss: 0.668
[18]  [340/1724] loss: 0.686, ave_loss: 0.669
[19]  [360/1724] loss: 0.652, ave_loss: 0.668
[20]  [380/1724] loss: 0.640, ave_loss: 0.667
[21]  [400/1724] loss: 0.682, ave_loss: 0.668
[22]  [420/1724] loss: 0.627, ave_loss: 0.666
[23]  [440/1724] loss: 0.645, ave_loss: 0.665
[24]  [460/1724] loss: 0.613, ave_loss: 0.663
[25]  [480/1724] loss: 0.642, ave_loss: 0.662
[26]  [500/1724] loss: 0.667, ave_loss: 0.662
[27]  [520/1724] loss: 0.641, ave_loss: 0.661
[28]  [540/1724] loss: 0.654, ave_loss: 0.661
[29]  [560/1724] loss: 0.689, ave_loss: 0.662
[30]  [580/1724] loss: 0.650, ave_loss: 0.662
[31]  [600/1724] loss: 0.666, ave_loss: 0.662
[32]  [620/1724] loss: 0.705, ave_loss: 0.663
[33]  [640/1724] loss: 0.659, ave_loss: 0.663
[34]  [660/1724] loss: 0.662, ave_loss: 0.663
[35]  [680/1724] loss: 0.662, ave_loss: 0.663
[36]  [700/1724] loss: 0.689, ave_loss: 0.664
[37]  [720/1724] loss: 0.641, ave_loss: 0.663
[38]  [740/1724] loss: 0.621, ave_loss: 0.662
[39]  [760/1724] loss: 0.657, ave_loss: 0.662
[40]  [780/1724] loss: 0.653, ave_loss: 0.662
[41]  [800/1724] loss: 0.692, ave_loss: 0.662
[42]  [820/1724] loss: 0.675, ave_loss: 0.663
[43]  [840/1724] loss: 0.669, ave_loss: 0.663
[44]  [860/1724] loss: 0.660, ave_loss: 0.663
[45]  [880/1724] loss: 0.658, ave_loss: 0.663
[46]  [900/1724] loss: 0.663, ave_loss: 0.663
[47]  [920/1724] loss: 0.674, ave_loss: 0.663
[48]  [940/1724] loss: 0.659, ave_loss: 0.663
[49]  [960/1724] loss: 0.656, ave_loss: 0.663
[50]  [980/1724] loss: 0.662, ave_loss: 0.663
[51]  [1000/1724] loss: 0.661, ave_loss: 0.663
[52]  [1020/1724] loss: 0.692, ave_loss: 0.663
[53]  [1040/1724] loss: 0.664, ave_loss: 0.663
[54]  [1060/1724] loss: 0.636, ave_loss: 0.663
[55]  [1080/1724] loss: 0.652, ave_loss: 0.663
[56]  [1100/1724] loss: 0.650, ave_loss: 0.662
[57]  [1120/1724] loss: 0.695, ave_loss: 0.663
[58]  [1140/1724] loss: 0.625, ave_loss: 0.662
[59]  [1160/1724] loss: 0.626, ave_loss: 0.662
[60]  [1180/1724] loss: 0.705, ave_loss: 0.662
[61]  [1200/1724] loss: 0.683, ave_loss: 0.663
[62]  [1220/1724] loss: 0.624, ave_loss: 0.662
[63]  [1240/1724] loss: 0.610, ave_loss: 0.661
[64]  [1260/1724] loss: 0.634, ave_loss: 0.661
[65]  [1280/1724] loss: 0.671, ave_loss: 0.661
[66]  [1300/1724] loss: 0.680, ave_loss: 0.661
[67]  [1320/1724] loss: 0.651, ave_loss: 0.661
[68]  [1340/1724] loss: 0.654, ave_loss: 0.661
[69]  [1360/1724] loss: 0.701, ave_loss: 0.662
[70]  [1380/1724] loss: 0.703, ave_loss: 0.662
[71]  [1400/1724] loss: 0.690, ave_loss: 0.663
[72]  [1420/1724] loss: 0.693, ave_loss: 0.663
[73]  [1440/1724] loss: 0.637, ave_loss: 0.663
[74]  [1460/1724] loss: 0.685, ave_loss: 0.663
[75]  [1480/1724] loss: 0.677, ave_loss: 0.663
[76]  [1500/1724] loss: 0.650, ave_loss: 0.663
[77]  [1520/1724] loss: 0.659, ave_loss: 0.663
[78]  [1540/1724] loss: 0.721, ave_loss: 0.664
[79]  [1560/1724] loss: 0.645, ave_loss: 0.663
[80]  [1580/1724] loss: 0.648, ave_loss: 0.663
[81]  [1600/1724] loss: 0.649, ave_loss: 0.663
[82]  [1620/1724] loss: 0.675, ave_loss: 0.663
[83]  [1640/1724] loss: 0.624, ave_loss: 0.663
[84]  [1660/1724] loss: 0.643, ave_loss: 0.662
[85]  [1680/1724] loss: 0.683, ave_loss: 0.663
[86]  [1700/1724] loss: 0.706, ave_loss: 0.663
[87]  [1720/1724] loss: 0.718, ave_loss: 0.664
[88]  [1740/1724] loss: 0.638, ave_loss: 0.664

Finished Training finishing at 2021-08-29 20:33:15.280422
printing_out epoch  27.563805104408353 learning rate: 0.0005153561248318907
0.00022643537047178791
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.636e-01
Validation Loss: 1.240e+06
Validation ROC: 0.4625
Saving model
1.4361948955916475 epochs left to go

Training Epoch 27.563805104408353/30 starting at 2021-08-29 20:34:30.918382
[1]  [0/1724] loss: 0.640, ave_loss: 0.640
[2]  [20/1724] loss: 0.718, ave_loss: 0.679
[3]  [40/1724] loss: 0.637, ave_loss: 0.665
[4]  [60/1724] loss: 0.656, ave_loss: 0.663
[5]  [80/1724] loss: 0.685, ave_loss: 0.667
[6]  [100/1724] loss: 0.689, ave_loss: 0.671
[7]  [120/1724] loss: 0.625, ave_loss: 0.664
[8]  [140/1724] loss: 0.673, ave_loss: 0.665
[9]  [160/1724] loss: 0.633, ave_loss: 0.662
[10]  [180/1724] loss: 0.767, ave_loss: 0.672
[11]  [200/1724] loss: 0.688, ave_loss: 0.674
[12]  [220/1724] loss: 0.718, ave_loss: 0.677
[13]  [240/1724] loss: 0.646, ave_loss: 0.675
[14]  [260/1724] loss: 0.647, ave_loss: 0.673
[15]  [280/1724] loss: 0.736, ave_loss: 0.677
[16]  [300/1724] loss: 0.625, ave_loss: 0.674
[17]  [320/1724] loss: 0.716, ave_loss: 0.676
[18]  [340/1724] loss: 0.661, ave_loss: 0.676
[19]  [360/1724] loss: 0.656, ave_loss: 0.675
[20]  [380/1724] loss: 0.663, ave_loss: 0.674
[21]  [400/1724] loss: 0.631, ave_loss: 0.672
[22]  [420/1724] loss: 0.689, ave_loss: 0.673
[23]  [440/1724] loss: 0.689, ave_loss: 0.673
[24]  [460/1724] loss: 0.676, ave_loss: 0.674
[25]  [480/1724] loss: 0.648, ave_loss: 0.673
[26]  [500/1724] loss: 0.633, ave_loss: 0.671
[27]  [520/1724] loss: 0.689, ave_loss: 0.672
[28]  [540/1724] loss: 0.620, ave_loss: 0.670
[29]  [560/1724] loss: 0.691, ave_loss: 0.671
[30]  [580/1724] loss: 0.688, ave_loss: 0.671
[31]  [600/1724] loss: 0.704, ave_loss: 0.672
[32]  [620/1724] loss: 0.685, ave_loss: 0.673
[33]  [640/1724] loss: 0.660, ave_loss: 0.672
[34]  [660/1724] loss: 0.723, ave_loss: 0.674
[35]  [680/1724] loss: 0.713, ave_loss: 0.675
[36]  [700/1724] loss: 0.655, ave_loss: 0.674
[37]  [720/1724] loss: 0.663, ave_loss: 0.674
[38]  [740/1724] loss: 0.683, ave_loss: 0.674
[39]  [760/1724] loss: 0.652, ave_loss: 0.674
[40]  [780/1724] loss: 0.642, ave_loss: 0.673
[41]  [800/1724] loss: 0.670, ave_loss: 0.673
[42]  [820/1724] loss: 0.645, ave_loss: 0.672
[43]  [840/1724] loss: 0.704, ave_loss: 0.673
[44]  [860/1724] loss: 0.661, ave_loss: 0.673
[45]  [880/1724] loss: 0.651, ave_loss: 0.672
[46]  [900/1724] loss: 0.703, ave_loss: 0.673
[47]  [920/1724] loss: 0.731, ave_loss: 0.674
[48]  [940/1724] loss: 0.664, ave_loss: 0.674
[49]  [960/1724] loss: 0.626, ave_loss: 0.673
[50]  [980/1724] loss: 0.681, ave_loss: 0.673
[51]  [1000/1724] loss: 0.687, ave_loss: 0.673
[52]  [1020/1724] loss: 0.668, ave_loss: 0.673
[53]  [1040/1724] loss: 0.619, ave_loss: 0.672
[54]  [1060/1724] loss: 0.677, ave_loss: 0.672
[55]  [1080/1724] loss: 0.655, ave_loss: 0.672
[56]  [1100/1724] loss: 0.675, ave_loss: 0.672
[57]  [1120/1724] loss: 0.668, ave_loss: 0.672
[58]  [1140/1724] loss: 0.650, ave_loss: 0.672
[59]  [1160/1724] loss: 0.666, ave_loss: 0.671
[60]  [1180/1724] loss: 0.669, ave_loss: 0.671
[61]  [1200/1724] loss: 0.685, ave_loss: 0.672
[62]  [1220/1724] loss: 0.661, ave_loss: 0.671
[63]  [1240/1724] loss: 0.663, ave_loss: 0.671
[64]  [1260/1724] loss: 0.628, ave_loss: 0.671
[65]  [1280/1724] loss: 0.718, ave_loss: 0.671
[66]  [1300/1724] loss: 0.666, ave_loss: 0.671
[67]  [1320/1724] loss: 0.642, ave_loss: 0.671
[68]  [1340/1724] loss: 0.678, ave_loss: 0.671
[69]  [1360/1724] loss: 0.642, ave_loss: 0.671
[70]  [1380/1724] loss: 0.620, ave_loss: 0.670
[71]  [1400/1724] loss: 0.648, ave_loss: 0.670
[72]  [1420/1724] loss: 0.626, ave_loss: 0.669
[73]  [1440/1724] loss: 0.645, ave_loss: 0.669
[74]  [1460/1724] loss: 0.698, ave_loss: 0.669
[75]  [1480/1724] loss: 0.657, ave_loss: 0.669
[76]  [1500/1724] loss: 0.631, ave_loss: 0.668
[77]  [1520/1724] loss: 0.692, ave_loss: 0.669
[78]  [1540/1724] loss: 0.696, ave_loss: 0.669
[79]  [1560/1724] loss: 0.631, ave_loss: 0.668
[80]  [1580/1724] loss: 0.628, ave_loss: 0.668
[81]  [1600/1724] loss: 0.685, ave_loss: 0.668
[82]  [1620/1724] loss: 0.659, ave_loss: 0.668
[83]  [1640/1724] loss: 0.644, ave_loss: 0.668
[84]  [1660/1724] loss: 0.645, ave_loss: 0.668
[85]  [1680/1724] loss: 0.669, ave_loss: 0.668
[86]  [1700/1724] loss: 0.646, ave_loss: 0.667
[87]  [1720/1724] loss: 0.685, ave_loss: 0.668
[88]  [1740/1724] loss: 0.706, ave_loss: 0.668

Finished Training finishing at 2021-08-29 20:37:42.555242
printing_out epoch  28.584686774941996 learning rate: 0.0005153561248318907
0.00021964230935763427
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.679e-01
Validation Loss: 1.230e+06
Validation ROC: 0.4625
Saving model
0.4153132250580036 epochs left to go

Training Epoch 28.584686774941996/30 starting at 2021-08-29 20:38:57.296668
[1]  [0/1724] loss: 0.658, ave_loss: 0.658
[2]  [20/1724] loss: 0.651, ave_loss: 0.654
[3]  [40/1724] loss: 0.607, ave_loss: 0.639
[4]  [60/1724] loss: 0.660, ave_loss: 0.644
[5]  [80/1724] loss: 0.706, ave_loss: 0.656
[6]  [100/1724] loss: 0.675, ave_loss: 0.659
[7]  [120/1724] loss: 0.670, ave_loss: 0.661
[8]  [140/1724] loss: 0.635, ave_loss: 0.658
[9]  [160/1724] loss: 0.676, ave_loss: 0.660
[10]  [180/1724] loss: 0.692, ave_loss: 0.663
[11]  [200/1724] loss: 0.649, ave_loss: 0.662
[12]  [220/1724] loss: 0.614, ave_loss: 0.658
[13]  [240/1724] loss: 0.621, ave_loss: 0.655
[14]  [260/1724] loss: 0.721, ave_loss: 0.660
[15]  [280/1724] loss: 0.658, ave_loss: 0.659
[16]  [300/1724] loss: 0.664, ave_loss: 0.660
[17]  [320/1724] loss: 0.631, ave_loss: 0.658
[18]  [340/1724] loss: 0.691, ave_loss: 0.660
[19]  [360/1724] loss: 0.665, ave_loss: 0.660
[20]  [380/1724] loss: 0.627, ave_loss: 0.659
[21]  [400/1724] loss: 0.663, ave_loss: 0.659
[22]  [420/1724] loss: 0.638, ave_loss: 0.658
[23]  [440/1724] loss: 0.636, ave_loss: 0.657
[24]  [460/1724] loss: 0.659, ave_loss: 0.657
[25]  [480/1724] loss: 0.636, ave_loss: 0.656
[26]  [500/1724] loss: 0.623, ave_loss: 0.655
[27]  [520/1724] loss: 0.665, ave_loss: 0.655
[28]  [540/1724] loss: 0.628, ave_loss: 0.654
[29]  [560/1724] loss: 0.652, ave_loss: 0.654
[30]  [580/1724] loss: 0.641, ave_loss: 0.654
[31]  [600/1724] loss: 0.692, ave_loss: 0.655
[32]  [620/1724] loss: 0.698, ave_loss: 0.656
[33]  [640/1724] loss: 0.662, ave_loss: 0.656
[34]  [660/1724] loss: 0.617, ave_loss: 0.655
[35]  [680/1724] loss: 0.674, ave_loss: 0.656
[36]  [700/1724] loss: 0.624, ave_loss: 0.655
[37]  [720/1724] loss: 0.708, ave_loss: 0.656
[38]  [740/1724] loss: 0.662, ave_loss: 0.657
[39]  [760/1724] loss: 0.682, ave_loss: 0.657
[40]  [780/1724] loss: 0.658, ave_loss: 0.657
[41]  [800/1724] loss: 0.636, ave_loss: 0.657
[42]  [820/1724] loss: 0.663, ave_loss: 0.657
[43]  [840/1724] loss: 0.641, ave_loss: 0.656
[44]  [860/1724] loss: 0.675, ave_loss: 0.657
[45]  [880/1724] loss: 0.692, ave_loss: 0.658
[46]  [900/1724] loss: 0.631, ave_loss: 0.657
[47]  [920/1724] loss: 0.686, ave_loss: 0.658
[48]  [940/1724] loss: 0.668, ave_loss: 0.658
[49]  [960/1724] loss: 0.674, ave_loss: 0.658
[50]  [980/1724] loss: 0.676, ave_loss: 0.659
[51]  [1000/1724] loss: 0.668, ave_loss: 0.659
[52]  [1020/1724] loss: 0.667, ave_loss: 0.659
[53]  [1040/1724] loss: 0.681, ave_loss: 0.659
[54]  [1060/1724] loss: 0.699, ave_loss: 0.660
[55]  [1080/1724] loss: 0.668, ave_loss: 0.660
[56]  [1100/1724] loss: 0.615, ave_loss: 0.659
[57]  [1120/1724] loss: 0.661, ave_loss: 0.659
[58]  [1140/1724] loss: 0.626, ave_loss: 0.659
[59]  [1160/1724] loss: 0.707, ave_loss: 0.660
[60]  [1180/1724] loss: 0.648, ave_loss: 0.659
[61]  [1200/1724] loss: 0.686, ave_loss: 0.660
[62]  [1220/1724] loss: 0.641, ave_loss: 0.660
[63]  [1240/1724] loss: 0.650, ave_loss: 0.659
[64]  [1260/1724] loss: 0.705, ave_loss: 0.660
[65]  [1280/1724] loss: 0.678, ave_loss: 0.660
[66]  [1300/1724] loss: 0.628, ave_loss: 0.660
[67]  [1320/1724] loss: 0.656, ave_loss: 0.660
[68]  [1340/1724] loss: 0.660, ave_loss: 0.660
[69]  [1360/1724] loss: 0.680, ave_loss: 0.660
[70]  [1380/1724] loss: 0.613, ave_loss: 0.659
[71]  [1400/1724] loss: 0.622, ave_loss: 0.659
[72]  [1420/1724] loss: 0.743, ave_loss: 0.660
[73]  [1440/1724] loss: 0.605, ave_loss: 0.659
[74]  [1460/1724] loss: 0.639, ave_loss: 0.659
[75]  [1480/1724] loss: 0.609, ave_loss: 0.658
[76]  [1500/1724] loss: 0.641, ave_loss: 0.658
[77]  [1520/1724] loss: 0.660, ave_loss: 0.658
[78]  [1540/1724] loss: 0.665, ave_loss: 0.658
[79]  [1560/1724] loss: 0.624, ave_loss: 0.658
[80]  [1580/1724] loss: 0.638, ave_loss: 0.658
[81]  [1600/1724] loss: 0.669, ave_loss: 0.658
[82]  [1620/1724] loss: 0.654, ave_loss: 0.658
[83]  [1640/1724] loss: 0.662, ave_loss: 0.658
[84]  [1660/1724] loss: 0.649, ave_loss: 0.658
[85]  [1680/1724] loss: 0.646, ave_loss: 0.658
[86]  [1700/1724] loss: 0.697, ave_loss: 0.658
[87]  [1720/1724] loss: 0.652, ave_loss: 0.658
[88]  [1740/1724] loss: 0.645, ave_loss: 0.658

Finished Training finishing at 2021-08-29 20:42:13.753194
printing_out epoch  29.605568445475637 learning rate: 0.0005153561248318907
0.00021305304007690525
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.578e-01
Validation Loss: 1.222e+06
Validation ROC: 0.4625
Saving model
saving results

reading from multiple data folder!**********************************************
Selected signals (determines which signals are used for training):
[q95 safety factor, internal inductance, plasma current, Locked mode amplitude, Normalized Beta, stored energy, Plasma density, Radiated Power Core, Radiated Power Edge, Input Power (beam for d3d), Input Beam Torque, plasma current direction, plasma current target, plasma current error, Electron temperature profile, Electron density profile]
...done
Training on 1724 shots, testing on 857 shots
n_scalars,n_profiles,profile_size= 14 2 64
Classical convolution with channels  2 4
Classical convolution with channels  4 3
InputBlock parameters:  14 2 64 ['c4', 'c3'] 3 10 0.08 2
TCN parameters:  17 1 [20, 20, 20, 20, 20] 11 0.08
Using single GPU..........................................
99 epochs left to go

Training Epoch 0/100 starting at 2021-08-24 19:04:07.656205
[1]  [0/1724] loss: 1.072, ave_loss: 1.072
[2]  [20/1724] loss: 1.485, ave_loss: 1.278
[3]  [40/1724] loss: 1.479, ave_loss: 1.345
[4]  [60/1724] loss: 1.407, ave_loss: 1.361
[5]  [80/1724] loss: 1.418, ave_loss: 1.372
[6]  [100/1724] loss: 1.170, ave_loss: 1.338
[7]  [120/1724] loss: 0.957, ave_loss: 1.284
[8]  [140/1724] loss: 1.160, ave_loss: 1.268
[9]  [160/1724] loss: 0.833, ave_loss: 1.220
[10]  [180/1724] loss: 0.997, ave_loss: 1.198
[11]  [200/1724] loss: 0.777, ave_loss: 1.159
[12]  [220/1724] loss: 0.757, ave_loss: 1.126
[13]  [240/1724] loss: 0.612, ave_loss: 1.086
[14]  [260/1724] loss: 0.653, ave_loss: 1.055
[15]  [280/1724] loss: 0.702, ave_loss: 1.032
[16]  [300/1724] loss: 0.538, ave_loss: 1.001
[17]  [320/1724] loss: 1.055, ave_loss: 1.004
[18]  [340/1724] loss: 0.535, ave_loss: 0.978
[19]  [360/1724] loss: 0.977, ave_loss: 0.978
[20]  [380/1724] loss: 0.747, ave_loss: 0.966
[21]  [400/1724] loss: 0.716, ave_loss: 0.955
[22]  [420/1724] loss: 0.696, ave_loss: 0.943
[23]  [440/1724] loss: 0.693, ave_loss: 0.932
[24]  [460/1724] loss: 0.750, ave_loss: 0.924
[25]  [480/1724] loss: 0.692, ave_loss: 0.915
[26]  [500/1724] loss: 0.704, ave_loss: 0.907
[27]  [520/1724] loss: 0.729, ave_loss: 0.900
[28]  [540/1724] loss: 0.660, ave_loss: 0.892
[29]  [560/1724] loss: 0.660, ave_loss: 0.884
[30]  [580/1724] loss: 0.704, ave_loss: 0.878
[31]  [600/1724] loss: 0.662, ave_loss: 0.871
[32]  [620/1724] loss: 0.674, ave_loss: 0.865
[33]  [640/1724] loss: 0.613, ave_loss: 0.857
[34]  [660/1724] loss: 0.627, ave_loss: 0.850
[35]  [680/1724] loss: 0.723, ave_loss: 0.847
[36]  [700/1724] loss: 0.637, ave_loss: 0.841
[37]  [720/1724] loss: 0.584, ave_loss: 0.834
[38]  [740/1724] loss: 0.808, ave_loss: 0.833
[39]  [760/1724] loss: 0.489, ave_loss: 0.824
[40]  [780/1724] loss: 0.685, ave_loss: 0.821
[41]  [800/1724] loss: 0.409, ave_loss: 0.811
[42]  [820/1724] loss: 0.722, ave_loss: 0.809
[43]  [840/1724] loss: 0.590, ave_loss: 0.804
[44]  [860/1724] loss: 0.837, ave_loss: 0.804
[45]  [880/1724] loss: 0.617, ave_loss: 0.800
[46]  [900/1724] loss: 0.580, ave_loss: 0.795
[47]  [920/1724] loss: 0.592, ave_loss: 0.791
[48]  [940/1724] loss: 0.625, ave_loss: 0.788
[49]  [960/1724] loss: 0.746, ave_loss: 0.787
[50]  [980/1724] loss: 0.595, ave_loss: 0.783
[51]  [1000/1724] loss: 0.677, ave_loss: 0.781
[52]  [1020/1724] loss: 0.619, ave_loss: 0.778
[53]  [1040/1724] loss: 0.584, ave_loss: 0.774
[54]  [1060/1724] loss: 0.601, ave_loss: 0.771
[55]  [1080/1724] loss: 0.725, ave_loss: 0.770
[56]  [1100/1724] loss: 0.601, ave_loss: 0.767
[57]  [1120/1724] loss: 0.488, ave_loss: 0.762
[58]  [1140/1724] loss: 0.487, ave_loss: 0.757
[59]  [1160/1724] loss: 0.592, ave_loss: 0.755
[60]  [1180/1724] loss: 0.662, ave_loss: 0.753
[61]  [1200/1724] loss: 0.498, ave_loss: 0.749
[62]  [1220/1724] loss: 0.543, ave_loss: 0.746
[63]  [1240/1724] loss: 0.608, ave_loss: 0.743
[64]  [1260/1724] loss: 0.517, ave_loss: 0.740
[65]  [1280/1724] loss: 0.443, ave_loss: 0.735
[66]  [1300/1724] loss: 0.522, ave_loss: 0.732
[67]  [1320/1724] loss: 0.459, ave_loss: 0.728
[68]  [1340/1724] loss: 0.633, ave_loss: 0.727
[69]  [1360/1724] loss: 0.651, ave_loss: 0.725
[70]  [1380/1724] loss: 0.541, ave_loss: 0.723
[71]  [1400/1724] loss: 0.581, ave_loss: 0.721
[72]  [1420/1724] loss: 0.553, ave_loss: 0.719
[73]  [1440/1724] loss: 0.639, ave_loss: 0.717
[74]  [1460/1724] loss: 0.499, ave_loss: 0.714
[75]  [1480/1724] loss: 0.508, ave_loss: 0.712
[76]  [1500/1724] loss: 0.518, ave_loss: 0.709
[77]  [1520/1724] loss: 0.563, ave_loss: 0.707
[78]  [1540/1724] loss: 0.606, ave_loss: 0.706
[79]  [1560/1724] loss: 0.501, ave_loss: 0.703
[80]  [1580/1724] loss: 0.533, ave_loss: 0.701
[81]  [1600/1724] loss: 0.659, ave_loss: 0.701
[82]  [1620/1724] loss: 0.504, ave_loss: 0.698
[83]  [1640/1724] loss: 0.517, ave_loss: 0.696
[84]  [1660/1724] loss: 0.532, ave_loss: 0.694
[85]  [1680/1724] loss: 0.679, ave_loss: 0.694
[86]  [1700/1724] loss: 0.507, ave_loss: 0.692
[87]  [1720/1724] loss: 0.626, ave_loss: 0.691
[88]  [1740/1724] loss: 0.669, ave_loss: 0.691

Finished Training finishing at 2021-08-24 19:07:52.130607
printing_out epoch  1.0208816705336428 learning rate: 0.0005153561248318907
0.000499895441086934
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 6.908e-01
Validation Loss: 8.560e+03
Validation ROC: 0.6716
Saving model
97.97911832946636 epochs left to go

Training Epoch 1.0208816705336428/100 starting at 2021-08-24 19:10:14.201618
[1]  [0/1724] loss: 0.610, ave_loss: 0.610
[2]  [20/1724] loss: 0.635, ave_loss: 0.623
[3]  [40/1724] loss: 0.597, ave_loss: 0.614
[4]  [60/1724] loss: 0.571, ave_loss: 0.603
[5]  [80/1724] loss: 0.479, ave_loss: 0.578
[6]  [100/1724] loss: 0.585, ave_loss: 0.580
[7]  [120/1724] loss: 0.586, ave_loss: 0.580
[8]  [140/1724] loss: 0.508, ave_loss: 0.571
[9]  [160/1724] loss: 0.443, ave_loss: 0.557
[10]  [180/1724] loss: 0.380, ave_loss: 0.539
[11]  [200/1724] loss: 0.396, ave_loss: 0.526
[12]  [220/1724] loss: 0.590, ave_loss: 0.532
[13]  [240/1724] loss: 0.391, ave_loss: 0.521
[14]  [260/1724] loss: 0.581, ave_loss: 0.525
[15]  [280/1724] loss: 0.611, ave_loss: 0.531
[16]  [300/1724] loss: 0.589, ave_loss: 0.535
[17]  [320/1724] loss: 0.540, ave_loss: 0.535
[18]  [340/1724] loss: 0.500, ave_loss: 0.533
[19]  [360/1724] loss: 0.621, ave_loss: 0.538
[20]  [380/1724] loss: 0.537, ave_loss: 0.538
[21]  [400/1724] loss: 0.728, ave_loss: 0.547
[22]  [420/1724] loss: 0.547, ave_loss: 0.547
[23]  [440/1724] loss: 0.641, ave_loss: 0.551
[24]  [460/1724] loss: 0.490, ave_loss: 0.548
[25]  [480/1724] loss: 0.597, ave_loss: 0.550
[26]  [500/1724] loss: 0.678, ave_loss: 0.555
[27]  [520/1724] loss: 0.714, ave_loss: 0.561
[28]  [540/1724] loss: 0.426, ave_loss: 0.556
[29]  [560/1724] loss: 0.618, ave_loss: 0.558
[30]  [580/1724] loss: 0.497, ave_loss: 0.556
[31]  [600/1724] loss: 0.420, ave_loss: 0.552
[32]  [620/1724] loss: 0.514, ave_loss: 0.551
[33]  [640/1724] loss: 0.585, ave_loss: 0.552
[34]  [660/1724] loss: 0.609, ave_loss: 0.553
[35]  [680/1724] loss: 0.552, ave_loss: 0.553
[36]  [700/1724] loss: 0.497, ave_loss: 0.552
[37]  [720/1724] loss: 0.561, ave_loss: 0.552
[38]  [740/1724] loss: 0.508, ave_loss: 0.551
[39]  [760/1724] loss: 0.531, ave_loss: 0.550
[40]  [780/1724] loss: 0.557, ave_loss: 0.550
[41]  [800/1724] loss: 0.553, ave_loss: 0.551
[42]  [820/1724] loss: 0.573, ave_loss: 0.551
[43]  [840/1724] loss: 0.428, ave_loss: 0.548
[44]  [860/1724] loss: 0.527, ave_loss: 0.548
[45]  [880/1724] loss: 0.533, ave_loss: 0.547
[46]  [900/1724] loss: 0.452, ave_loss: 0.545
[47]  [920/1724] loss: 0.505, ave_loss: 0.544
[48]  [940/1724] loss: 0.508, ave_loss: 0.544
[49]  [960/1724] loss: 0.604, ave_loss: 0.545
[50]  [980/1724] loss: 0.459, ave_loss: 0.543
[51]  [1000/1724] loss: 0.338, ave_loss: 0.539
[52]  [1020/1724] loss: 0.429, ave_loss: 0.537
[53]  [1040/1724] loss: 0.482, ave_loss: 0.536
[54]  [1060/1724] loss: 0.686, ave_loss: 0.539
[55]  [1080/1724] loss: 0.668, ave_loss: 0.541
[56]  [1100/1724] loss: 0.488, ave_loss: 0.540
[57]  [1120/1724] loss: 0.588, ave_loss: 0.541
[58]  [1140/1724] loss: 0.557, ave_loss: 0.541
[59]  [1160/1724] loss: 0.516, ave_loss: 0.541
[60]  [1180/1724] loss: 0.499, ave_loss: 0.540
[61]  [1200/1724] loss: 0.566, ave_loss: 0.541
[62]  [1220/1724] loss: 0.482, ave_loss: 0.540
[63]  [1240/1724] loss: 0.610, ave_loss: 0.541
[64]  [1260/1724] loss: 0.487, ave_loss: 0.540
[65]  [1280/1724] loss: 0.462, ave_loss: 0.539
[66]  [1300/1724] loss: 0.596, ave_loss: 0.540
[67]  [1320/1724] loss: 0.637, ave_loss: 0.541
[68]  [1340/1724] loss: 0.490, ave_loss: 0.540
[69]  [1360/1724] loss: 0.522, ave_loss: 0.540
[70]  [1380/1724] loss: 0.574, ave_loss: 0.541
[71]  [1400/1724] loss: 0.364, ave_loss: 0.538
[72]  [1420/1724] loss: 0.508, ave_loss: 0.538
[73]  [1440/1724] loss: 0.618, ave_loss: 0.539
[74]  [1460/1724] loss: 0.425, ave_loss: 0.537
[75]  [1480/1724] loss: 0.432, ave_loss: 0.536
[76]  [1500/1724] loss: 0.504, ave_loss: 0.535
[77]  [1520/1724] loss: 0.423, ave_loss: 0.534
[78]  [1540/1724] loss: 0.543, ave_loss: 0.534
[79]  [1560/1724] loss: 0.464, ave_loss: 0.533
[80]  [1580/1724] loss: 0.498, ave_loss: 0.533
[81]  [1600/1724] loss: 0.454, ave_loss: 0.532
[82]  [1620/1724] loss: 0.410, ave_loss: 0.530
[83]  [1640/1724] loss: 0.437, ave_loss: 0.529
[84]  [1660/1724] loss: 0.526, ave_loss: 0.529
[85]  [1680/1724] loss: 0.522, ave_loss: 0.529
[86]  [1700/1724] loss: 0.607, ave_loss: 0.530
[87]  [1720/1724] loss: 0.590, ave_loss: 0.531
[88]  [1740/1724] loss: 0.546, ave_loss: 0.531

Finished Training finishing at 2021-08-24 19:12:43.057679
printing_out epoch  2.0417633410672855 learning rate: 0.0005153561248318907
0.00048489857785432596
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 5.308e-01
Validation Loss: 1.050e+04
Validation ROC: 0.7271
Saving model
96.95823665893272 epochs left to go

Training Epoch 2.0417633410672855/100 starting at 2021-08-24 19:13:11.634601
[1]  [0/1724] loss: 0.607, ave_loss: 0.607
[2]  [20/1724] loss: 0.488, ave_loss: 0.548
[3]  [40/1724] loss: 0.470, ave_loss: 0.522
[4]  [60/1724] loss: 0.532, ave_loss: 0.524
[5]  [80/1724] loss: 0.456, ave_loss: 0.511
[6]  [100/1724] loss: 0.487, ave_loss: 0.507
[7]  [120/1724] loss: 0.491, ave_loss: 0.505
[8]  [140/1724] loss: 0.577, ave_loss: 0.514
[9]  [160/1724] loss: 0.437, ave_loss: 0.505
[10]  [180/1724] loss: 0.554, ave_loss: 0.510
[11]  [200/1724] loss: 0.514, ave_loss: 0.510
[12]  [220/1724] loss: 0.523, ave_loss: 0.511
[13]  [240/1724] loss: 0.702, ave_loss: 0.526
[14]  [260/1724] loss: 0.471, ave_loss: 0.522
[15]  [280/1724] loss: 0.526, ave_loss: 0.522
[16]  [300/1724] loss: 0.455, ave_loss: 0.518
[17]  [320/1724] loss: 0.369, ave_loss: 0.509
[18]  [340/1724] loss: 0.557, ave_loss: 0.512
[19]  [360/1724] loss: 0.495, ave_loss: 0.511
[20]  [380/1724] loss: 0.525, ave_loss: 0.512
[21]  [400/1724] loss: 0.534, ave_loss: 0.513
[22]  [420/1724] loss: 0.551, ave_loss: 0.515
[23]  [440/1724] loss: 0.439, ave_loss: 0.511
[24]  [460/1724] loss: 0.463, ave_loss: 0.509
[25]  [480/1724] loss: 0.463, ave_loss: 0.508
[26]  [500/1724] loss: 0.445, ave_loss: 0.505
[27]  [520/1724] loss: 0.493, ave_loss: 0.505
[28]  [540/1724] loss: 0.416, ave_loss: 0.501
[29]  [560/1724] loss: 0.677, ave_loss: 0.508
[30]  [580/1724] loss: 0.417, ave_loss: 0.504
[31]  [600/1724] loss: 0.521, ave_loss: 0.505
[32]  [620/1724] loss: 0.692, ave_loss: 0.511
[33]  [640/1724] loss: 0.433, ave_loss: 0.509
[34]  [660/1724] loss: 0.383, ave_loss: 0.505
[35]  [680/1724] loss: 0.536, ave_loss: 0.506
[36]  [700/1724] loss: 0.557, ave_loss: 0.507
[37]  [720/1724] loss: 0.406, ave_loss: 0.504
[38]  [740/1724] loss: 0.404, ave_loss: 0.502
[39]  [760/1724] loss: 0.476, ave_loss: 0.501
[40]  [780/1724] loss: 0.544, ave_loss: 0.502
[41]  [800/1724] loss: 0.700, ave_loss: 0.507
[42]  [820/1724] loss: 0.500, ave_loss: 0.507
[43]  [840/1724] loss: 0.530, ave_loss: 0.507
[44]  [860/1724] loss: 0.653, ave_loss: 0.511
[45]  [880/1724] loss: 0.470, ave_loss: 0.510
[46]  [900/1724] loss: 0.367, ave_loss: 0.507
[47]  [920/1724] loss: 0.439, ave_loss: 0.505
[48]  [940/1724] loss: 0.474, ave_loss: 0.505
[49]  [960/1724] loss: 0.476, ave_loss: 0.504
[50]  [980/1724] loss: 0.395, ave_loss: 0.502
[51]  [1000/1724] loss: 0.415, ave_loss: 0.500
[52]  [1020/1724] loss: 0.638, ave_loss: 0.503
[53]  [1040/1724] loss: 0.510, ave_loss: 0.503
[54]  [1060/1724] loss: 0.538, ave_loss: 0.504
[55]  [1080/1724] loss: 0.503, ave_loss: 0.504
[56]  [1100/1724] loss: 0.492, ave_loss: 0.503
[57]  [1120/1724] loss: 0.484, ave_loss: 0.503
[58]  [1140/1724] loss: 0.547, ave_loss: 0.504
[59]  [1160/1724] loss: 0.421, ave_loss: 0.502
[60]  [1180/1724] loss: 0.405, ave_loss: 0.501
[61]  [1200/1724] loss: 0.422, ave_loss: 0.499
[62]  [1220/1724] loss: 0.596, ave_loss: 0.501
[63]  [1240/1724] loss: 0.500, ave_loss: 0.501
[64]  [1260/1724] loss: 0.452, ave_loss: 0.500
[65]  [1280/1724] loss: 0.469, ave_loss: 0.500
[66]  [1300/1724] loss: 0.615, ave_loss: 0.501
[67]  [1320/1724] loss: 0.425, ave_loss: 0.500
[68]  [1340/1724] loss: 0.536, ave_loss: 0.501
[69]  [1360/1724] loss: 0.546, ave_loss: 0.502
[70]  [1380/1724] loss: 0.461, ave_loss: 0.501
[71]  [1400/1724] loss: 0.615, ave_loss: 0.503
[72]  [1420/1724] loss: 0.627, ave_loss: 0.504
[73]  [1440/1724] loss: 0.513, ave_loss: 0.504
[74]  [1460/1724] loss: 0.509, ave_loss: 0.504
[75]  [1480/1724] loss: 0.401, ave_loss: 0.503
[76]  [1500/1724] loss: 0.464, ave_loss: 0.503
[77]  [1520/1724] loss: 0.450, ave_loss: 0.502
[78]  [1540/1724] loss: 0.421, ave_loss: 0.501
[79]  [1560/1724] loss: 0.573, ave_loss: 0.502
[80]  [1580/1724] loss: 0.546, ave_loss: 0.502
[81]  [1600/1724] loss: 0.490, ave_loss: 0.502
[82]  [1620/1724] loss: 0.374, ave_loss: 0.501
[83]  [1640/1724] loss: 0.548, ave_loss: 0.501
[84]  [1660/1724] loss: 0.714, ave_loss: 0.504
[85]  [1680/1724] loss: 0.576, ave_loss: 0.505
[86]  [1700/1724] loss: 0.495, ave_loss: 0.504
[87]  [1720/1724] loss: 0.585, ave_loss: 0.505
[88]  [1740/1724] loss: 0.491, ave_loss: 0.505

Finished Training finishing at 2021-08-24 19:15:26.856764
printing_out epoch  3.062645011600928 learning rate: 0.0005153561248318907
0.00047035162051869614
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 5.052e-01
Validation Loss: 1.296e+04
Validation ROC: 0.7520
Saving model
95.93735498839908 epochs left to go

Training Epoch 3.062645011600928/100 starting at 2021-08-24 19:15:54.458705
[1]  [0/1724] loss: 0.489, ave_loss: 0.489
[2]  [20/1724] loss: 0.479, ave_loss: 0.484
[3]  [40/1724] loss: 0.490, ave_loss: 0.486
[4]  [60/1724] loss: 0.619, ave_loss: 0.519
[5]  [80/1724] loss: 0.530, ave_loss: 0.522
[6]  [100/1724] loss: 0.560, ave_loss: 0.528
[7]  [120/1724] loss: 0.571, ave_loss: 0.534
[8]  [140/1724] loss: 0.414, ave_loss: 0.519
[9]  [160/1724] loss: 0.587, ave_loss: 0.527
[10]  [180/1724] loss: 0.533, ave_loss: 0.527
[11]  [200/1724] loss: 0.657, ave_loss: 0.539
[12]  [220/1724] loss: 0.561, ave_loss: 0.541
[13]  [240/1724] loss: 0.650, ave_loss: 0.549
[14]  [260/1724] loss: 0.552, ave_loss: 0.550
[15]  [280/1724] loss: 0.481, ave_loss: 0.545
[16]  [300/1724] loss: 0.449, ave_loss: 0.539
[17]  [320/1724] loss: 0.709, ave_loss: 0.549
[18]  [340/1724] loss: 0.629, ave_loss: 0.553
[19]  [360/1724] loss: 0.437, ave_loss: 0.547
[20]  [380/1724] loss: 0.583, ave_loss: 0.549
[21]  [400/1724] loss: 0.518, ave_loss: 0.548
[22]  [420/1724] loss: 0.498, ave_loss: 0.545
[23]  [440/1724] loss: 0.525, ave_loss: 0.544
[24]  [460/1724] loss: 0.571, ave_loss: 0.546
[25]  [480/1724] loss: 0.490, ave_loss: 0.543
[26]  [500/1724] loss: 0.623, ave_loss: 0.546
[27]  [520/1724] loss: 0.438, ave_loss: 0.542
[28]  [540/1724] loss: 0.481, ave_loss: 0.540
[29]  [560/1724] loss: 0.707, ave_loss: 0.546
[30]  [580/1724] loss: 0.468, ave_loss: 0.543
[31]  [600/1724] loss: 0.431, ave_loss: 0.540
[32]  [620/1724] loss: 0.418, ave_loss: 0.536
[33]  [640/1724] loss: 0.452, ave_loss: 0.533
[34]  [660/1724] loss: 0.552, ave_loss: 0.534
[35]  [680/1724] loss: 0.345, ave_loss: 0.528
[36]  [700/1724] loss: 0.468, ave_loss: 0.527
[37]  [720/1724] loss: 0.581, ave_loss: 0.528
[38]  [740/1724] loss: 0.517, ave_loss: 0.528
[39]  [760/1724] loss: 0.415, ave_loss: 0.525
[40]  [780/1724] loss: 0.610, ave_loss: 0.527
[41]  [800/1724] loss: 0.455, ave_loss: 0.525
[42]  [820/1724] loss: 0.442, ave_loss: 0.523
[43]  [840/1724] loss: 0.381, ave_loss: 0.520
[44]  [860/1724] loss: 0.580, ave_loss: 0.522
[45]  [880/1724] loss: 0.533, ave_loss: 0.522
[46]  [900/1724] loss: 0.396, ave_loss: 0.519
[47]  [920/1724] loss: 0.546, ave_loss: 0.520
[48]  [940/1724] loss: 0.512, ave_loss: 0.519
[49]  [960/1724] loss: 0.432, ave_loss: 0.518
[50]  [980/1724] loss: 0.414, ave_loss: 0.516
[51]  [1000/1724] loss: 0.599, ave_loss: 0.517
[52]  [1020/1724] loss: 0.484, ave_loss: 0.517
[53]  [1040/1724] loss: 0.464, ave_loss: 0.516
[54]  [1060/1724] loss: 0.415, ave_loss: 0.514
[55]  [1080/1724] loss: 0.487, ave_loss: 0.513
[56]  [1100/1724] loss: 0.435, ave_loss: 0.512
[57]  [1120/1724] loss: 0.543, ave_loss: 0.512
[58]  [1140/1724] loss: 0.336, ave_loss: 0.509
[59]  [1160/1724] loss: 0.370, ave_loss: 0.507
[60]  [1180/1724] loss: 0.682, ave_loss: 0.510
[61]  [1200/1724] loss: 0.427, ave_loss: 0.509
[62]  [1220/1724] loss: 0.545, ave_loss: 0.509
[63]  [1240/1724] loss: 0.457, ave_loss: 0.508
[64]  [1260/1724] loss: 0.454, ave_loss: 0.507
[65]  [1280/1724] loss: 0.450, ave_loss: 0.507
[66]  [1300/1724] loss: 0.617, ave_loss: 0.508
[67]  [1320/1724] loss: 0.409, ave_loss: 0.507
[68]  [1340/1724] loss: 0.453, ave_loss: 0.506
[69]  [1360/1724] loss: 0.395, ave_loss: 0.504
[70]  [1380/1724] loss: 0.462, ave_loss: 0.504
[71]  [1400/1724] loss: 0.282, ave_loss: 0.501
[72]  [1420/1724] loss: 0.534, ave_loss: 0.501
[73]  [1440/1724] loss: 0.465, ave_loss: 0.501
[74]  [1460/1724] loss: 0.451, ave_loss: 0.500
[75]  [1480/1724] loss: 0.534, ave_loss: 0.500
[76]  [1500/1724] loss: 0.496, ave_loss: 0.500
[77]  [1520/1724] loss: 0.577, ave_loss: 0.501
[78]  [1540/1724] loss: 0.473, ave_loss: 0.501
[79]  [1560/1724] loss: 0.536, ave_loss: 0.501
[80]  [1580/1724] loss: 0.352, ave_loss: 0.500
[81]  [1600/1724] loss: 0.408, ave_loss: 0.498
[82]  [1620/1724] loss: 0.621, ave_loss: 0.500
[83]  [1640/1724] loss: 0.510, ave_loss: 0.500
[84]  [1660/1724] loss: 0.413, ave_loss: 0.499
[85]  [1680/1724] loss: 0.478, ave_loss: 0.499
[86]  [1700/1724] loss: 0.475, ave_loss: 0.498
[87]  [1720/1724] loss: 0.392, ave_loss: 0.497
[88]  [1740/1724] loss: 0.368, ave_loss: 0.496

Finished Training finishing at 2021-08-24 19:18:05.832933
printing_out epoch  4.083526682134571 learning rate: 0.0005153561248318907
0.00045624107190313527
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.958e-01
Validation Loss: 1.524e+04
Validation ROC: 0.7541
Saving model
94.91647331786542 epochs left to go

Training Epoch 4.083526682134571/100 starting at 2021-08-24 19:18:32.423159
[1]  [0/1724] loss: 0.460, ave_loss: 0.460
[2]  [20/1724] loss: 0.597, ave_loss: 0.528
[3]  [40/1724] loss: 0.372, ave_loss: 0.476
[4]  [60/1724] loss: 0.504, ave_loss: 0.483
[5]  [80/1724] loss: 0.429, ave_loss: 0.472
[6]  [100/1724] loss: 0.434, ave_loss: 0.466
[7]  [120/1724] loss: 0.481, ave_loss: 0.468
[8]  [140/1724] loss: 0.601, ave_loss: 0.485
[9]  [160/1724] loss: 0.386, ave_loss: 0.474
[10]  [180/1724] loss: 0.404, ave_loss: 0.467
[11]  [200/1724] loss: 0.497, ave_loss: 0.470
[12]  [220/1724] loss: 0.518, ave_loss: 0.474
[13]  [240/1724] loss: 0.523, ave_loss: 0.477
[14]  [260/1724] loss: 0.474, ave_loss: 0.477
[15]  [280/1724] loss: 0.557, ave_loss: 0.482
[16]  [300/1724] loss: 0.405, ave_loss: 0.478
[17]  [320/1724] loss: 0.468, ave_loss: 0.477
[18]  [340/1724] loss: 0.471, ave_loss: 0.477
[19]  [360/1724] loss: 0.421, ave_loss: 0.474
[20]  [380/1724] loss: 0.657, ave_loss: 0.483
[21]  [400/1724] loss: 0.671, ave_loss: 0.492
[22]  [420/1724] loss: 0.494, ave_loss: 0.492
[23]  [440/1724] loss: 0.525, ave_loss: 0.493
[24]  [460/1724] loss: 0.583, ave_loss: 0.497
[25]  [480/1724] loss: 0.575, ave_loss: 0.500
[26]  [500/1724] loss: 0.461, ave_loss: 0.499
[27]  [520/1724] loss: 0.489, ave_loss: 0.498
[28]  [540/1724] loss: 0.495, ave_loss: 0.498
[29]  [560/1724] loss: 0.534, ave_loss: 0.499
[30]  [580/1724] loss: 0.486, ave_loss: 0.499
[31]  [600/1724] loss: 0.559, ave_loss: 0.501
[32]  [620/1724] loss: 0.362, ave_loss: 0.497
[33]  [640/1724] loss: 0.367, ave_loss: 0.493
[34]  [660/1724] loss: 0.552, ave_loss: 0.494
[35]  [680/1724] loss: 0.468, ave_loss: 0.494
[36]  [700/1724] loss: 0.508, ave_loss: 0.494
[37]  [720/1724] loss: 0.434, ave_loss: 0.492
[38]  [740/1724] loss: 0.454, ave_loss: 0.491
[39]  [760/1724] loss: 0.506, ave_loss: 0.492
[40]  [780/1724] loss: 0.622, ave_loss: 0.495
[41]  [800/1724] loss: 0.460, ave_loss: 0.494
[42]  [820/1724] loss: 0.476, ave_loss: 0.494
[43]  [840/1724] loss: 0.557, ave_loss: 0.495
[44]  [860/1724] loss: 0.445, ave_loss: 0.494
[45]  [880/1724] loss: 0.390, ave_loss: 0.492
[46]  [900/1724] loss: 0.438, ave_loss: 0.491
[47]  [920/1724] loss: 0.398, ave_loss: 0.489
[48]  [940/1724] loss: 0.512, ave_loss: 0.489
[49]  [960/1724] loss: 0.404, ave_loss: 0.487
[50]  [980/1724] loss: 0.439, ave_loss: 0.486
[51]  [1000/1724] loss: 0.426, ave_loss: 0.485
[52]  [1020/1724] loss: 0.701, ave_loss: 0.489
[53]  [1040/1724] loss: 0.697, ave_loss: 0.493
[54]  [1060/1724] loss: 0.609, ave_loss: 0.495
[55]  [1080/1724] loss: 0.425, ave_loss: 0.494
[56]  [1100/1724] loss: 0.423, ave_loss: 0.493
[57]  [1120/1724] loss: 0.433, ave_loss: 0.492
[58]  [1140/1724] loss: 0.447, ave_loss: 0.491
[59]  [1160/1724] loss: 0.439, ave_loss: 0.490
[60]  [1180/1724] loss: 0.569, ave_loss: 0.491
[61]  [1200/1724] loss: 0.493, ave_loss: 0.492
[62]  [1220/1724] loss: 0.556, ave_loss: 0.493
[63]  [1240/1724] loss: 0.466, ave_loss: 0.492
[64]  [1260/1724] loss: 0.524, ave_loss: 0.493
[65]  [1280/1724] loss: 0.376, ave_loss: 0.491
[66]  [1300/1724] loss: 0.618, ave_loss: 0.493
[67]  [1320/1724] loss: 0.508, ave_loss: 0.493
[68]  [1340/1724] loss: 0.465, ave_loss: 0.493
[69]  [1360/1724] loss: 0.479, ave_loss: 0.492
[70]  [1380/1724] loss: 0.472, ave_loss: 0.492
[71]  [1400/1724] loss: 0.455, ave_loss: 0.492
[72]  [1420/1724] loss: 0.418, ave_loss: 0.491
[73]  [1440/1724] loss: 0.441, ave_loss: 0.490
[74]  [1460/1724] loss: 0.544, ave_loss: 0.491
[75]  [1480/1724] loss: 0.339, ave_loss: 0.489
[76]  [1500/1724] loss: 0.465, ave_loss: 0.488
[77]  [1520/1724] loss: 0.437, ave_loss: 0.488
[78]  [1540/1724] loss: 0.380, ave_loss: 0.486
[79]  [1560/1724] loss: 0.540, ave_loss: 0.487
[80]  [1580/1724] loss: 0.599, ave_loss: 0.488
[81]  [1600/1724] loss: 0.506, ave_loss: 0.489
[82]  [1620/1724] loss: 0.446, ave_loss: 0.488
[83]  [1640/1724] loss: 0.442, ave_loss: 0.487
[84]  [1660/1724] loss: 0.560, ave_loss: 0.488
[85]  [1680/1724] loss: 0.450, ave_loss: 0.488
[86]  [1700/1724] loss: 0.409, ave_loss: 0.487
[87]  [1720/1724] loss: 0.464, ave_loss: 0.487
[88]  [1740/1724] loss: 0.533, ave_loss: 0.487

Finished Training finishing at 2021-08-24 19:20:31.260646
printing_out epoch  5.104408352668213 learning rate: 0.0005153561248318907
0.0004425538397460412
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.872e-01
Validation Loss: 1.479e+04
Validation ROC: 0.7496
No improvement, still saving model
93.89559164733178 epochs left to go

Training Epoch 5.104408352668213/100 starting at 2021-08-24 19:21:11.496451
[1]  [0/1724] loss: 0.574, ave_loss: 0.574
[2]  [20/1724] loss: 0.399, ave_loss: 0.486
[3]  [40/1724] loss: 0.547, ave_loss: 0.506
[4]  [60/1724] loss: 0.411, ave_loss: 0.483
[5]  [80/1724] loss: 0.534, ave_loss: 0.493
[6]  [100/1724] loss: 0.510, ave_loss: 0.496
[7]  [120/1724] loss: 0.407, ave_loss: 0.483
[8]  [140/1724] loss: 0.464, ave_loss: 0.481
[9]  [160/1724] loss: 0.397, ave_loss: 0.471
[10]  [180/1724] loss: 0.535, ave_loss: 0.478
[11]  [200/1724] loss: 0.346, ave_loss: 0.466
[12]  [220/1724] loss: 0.301, ave_loss: 0.452
[13]  [240/1724] loss: 0.465, ave_loss: 0.453
[14]  [260/1724] loss: 0.474, ave_loss: 0.455
[15]  [280/1724] loss: 0.503, ave_loss: 0.458
[16]  [300/1724] loss: 0.408, ave_loss: 0.455
[17]  [320/1724] loss: 0.524, ave_loss: 0.459
[18]  [340/1724] loss: 0.619, ave_loss: 0.468
[19]  [360/1724] loss: 0.435, ave_loss: 0.466
[20]  [380/1724] loss: 0.443, ave_loss: 0.465
[21]  [400/1724] loss: 0.434, ave_loss: 0.463
[22]  [420/1724] loss: 0.593, ave_loss: 0.469
[23]  [440/1724] loss: 0.458, ave_loss: 0.469
[24]  [460/1724] loss: 0.399, ave_loss: 0.466
[25]  [480/1724] loss: 0.481, ave_loss: 0.466
[26]  [500/1724] loss: 0.645, ave_loss: 0.473
[27]  [520/1724] loss: 0.410, ave_loss: 0.471
[28]  [540/1724] loss: 0.599, ave_loss: 0.476
[29]  [560/1724] loss: 0.534, ave_loss: 0.478
[30]  [580/1724] loss: 0.504, ave_loss: 0.478
[31]  [600/1724] loss: 0.548, ave_loss: 0.481
[32]  [620/1724] loss: 0.465, ave_loss: 0.480
[33]  [640/1724] loss: 0.416, ave_loss: 0.478
[34]  [660/1724] loss: 0.551, ave_loss: 0.480
[35]  [680/1724] loss: 0.422, ave_loss: 0.479
[36]  [700/1724] loss: 0.560, ave_loss: 0.481
[37]  [720/1724] loss: 0.542, ave_loss: 0.483
[38]  [740/1724] loss: 0.479, ave_loss: 0.483
[39]  [760/1724] loss: 0.562, ave_loss: 0.485
[40]  [780/1724] loss: 0.498, ave_loss: 0.485
[41]  [800/1724] loss: 0.406, ave_loss: 0.483
[42]  [820/1724] loss: 0.439, ave_loss: 0.482
[43]  [840/1724] loss: 0.482, ave_loss: 0.482
[44]  [860/1724] loss: 0.457, ave_loss: 0.481
[45]  [880/1724] loss: 0.376, ave_loss: 0.479
[46]  [900/1724] loss: 0.679, ave_loss: 0.483
[47]  [920/1724] loss: 0.490, ave_loss: 0.484
[48]  [940/1724] loss: 0.429, ave_loss: 0.482
[49]  [960/1724] loss: 0.717, ave_loss: 0.487
[50]  [980/1724] loss: 0.459, ave_loss: 0.487
[51]  [1000/1724] loss: 0.560, ave_loss: 0.488
[52]  [1020/1724] loss: 0.417, ave_loss: 0.487
[53]  [1040/1724] loss: 0.408, ave_loss: 0.485
[54]  [1060/1724] loss: 0.429, ave_loss: 0.484
[55]  [1080/1724] loss: 0.362, ave_loss: 0.482
[56]  [1100/1724] loss: 0.533, ave_loss: 0.483
[57]  [1120/1724] loss: 0.428, ave_loss: 0.482
[58]  [1140/1724] loss: 0.540, ave_loss: 0.483
[59]  [1160/1724] loss: 0.574, ave_loss: 0.484
[60]  [1180/1724] loss: 0.378, ave_loss: 0.483
[61]  [1200/1724] loss: 0.404, ave_loss: 0.481
[62]  [1220/1724] loss: 0.514, ave_loss: 0.482
[63]  [1240/1724] loss: 0.400, ave_loss: 0.481
[64]  [1260/1724] loss: 0.525, ave_loss: 0.481
[65]  [1280/1724] loss: 0.521, ave_loss: 0.482
[66]  [1300/1724] loss: 0.512, ave_loss: 0.482
[67]  [1320/1724] loss: 0.481, ave_loss: 0.482
[68]  [1340/1724] loss: 0.467, ave_loss: 0.482
[69]  [1360/1724] loss: 0.373, ave_loss: 0.480
[70]  [1380/1724] loss: 0.470, ave_loss: 0.480
[71]  [1400/1724] loss: 0.501, ave_loss: 0.481
[72]  [1420/1724] loss: 0.463, ave_loss: 0.480
[73]  [1440/1724] loss: 0.355, ave_loss: 0.479
[74]  [1460/1724] loss: 0.432, ave_loss: 0.478
[75]  [1480/1724] loss: 0.454, ave_loss: 0.478
[76]  [1500/1724] loss: 0.465, ave_loss: 0.478
[77]  [1520/1724] loss: 0.318, ave_loss: 0.475
[78]  [1540/1724] loss: 0.469, ave_loss: 0.475
[79]  [1560/1724] loss: 0.449, ave_loss: 0.475
[80]  [1580/1724] loss: 0.482, ave_loss: 0.475
[81]  [1600/1724] loss: 0.534, ave_loss: 0.476
[82]  [1620/1724] loss: 0.525, ave_loss: 0.476
[83]  [1640/1724] loss: 0.543, ave_loss: 0.477
[84]  [1660/1724] loss: 0.463, ave_loss: 0.477
[85]  [1680/1724] loss: 0.386, ave_loss: 0.476
[86]  [1700/1724] loss: 0.414, ave_loss: 0.475
[87]  [1720/1724] loss: 0.459, ave_loss: 0.475
[88]  [1740/1724] loss: 0.576, ave_loss: 0.476

Finished Training finishing at 2021-08-24 19:23:13.400421
printing_out epoch  6.125290023201856 learning rate: 0.0005153561248318907
0.00042927722455365994
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.763e-01
Validation Loss: 1.561e+04
Validation ROC: 0.7478
No improvement, still saving model
92.87470997679814 epochs left to go

Training Epoch 6.125290023201856/100 starting at 2021-08-24 19:23:48.673026
[1]  [0/1724] loss: 0.555, ave_loss: 0.555
[2]  [20/1724] loss: 0.362, ave_loss: 0.458
[3]  [40/1724] loss: 0.353, ave_loss: 0.423
[4]  [60/1724] loss: 0.523, ave_loss: 0.448
[5]  [80/1724] loss: 0.491, ave_loss: 0.457
[6]  [100/1724] loss: 0.429, ave_loss: 0.452
[7]  [120/1724] loss: 0.435, ave_loss: 0.450
[8]  [140/1724] loss: 0.385, ave_loss: 0.442
[9]  [160/1724] loss: 0.460, ave_loss: 0.444
[10]  [180/1724] loss: 0.541, ave_loss: 0.453
[11]  [200/1724] loss: 0.503, ave_loss: 0.458
[12]  [220/1724] loss: 0.428, ave_loss: 0.455
[13]  [240/1724] loss: 0.376, ave_loss: 0.449
[14]  [260/1724] loss: 0.425, ave_loss: 0.448
[15]  [280/1724] loss: 0.508, ave_loss: 0.452
[16]  [300/1724] loss: 0.362, ave_loss: 0.446
[17]  [320/1724] loss: 0.378, ave_loss: 0.442
[18]  [340/1724] loss: 0.422, ave_loss: 0.441
[19]  [360/1724] loss: 0.557, ave_loss: 0.447
[20]  [380/1724] loss: 0.372, ave_loss: 0.443
[21]  [400/1724] loss: 0.426, ave_loss: 0.442
[22]  [420/1724] loss: 0.421, ave_loss: 0.441
[23]  [440/1724] loss: 0.445, ave_loss: 0.442
[24]  [460/1724] loss: 0.498, ave_loss: 0.444
[25]  [480/1724] loss: 0.396, ave_loss: 0.442
[26]  [500/1724] loss: 0.390, ave_loss: 0.440
[27]  [520/1724] loss: 0.475, ave_loss: 0.441
[28]  [540/1724] loss: 0.477, ave_loss: 0.443
[29]  [560/1724] loss: 0.504, ave_loss: 0.445
[30]  [580/1724] loss: 0.531, ave_loss: 0.448
[31]  [600/1724] loss: 0.580, ave_loss: 0.452
[32]  [620/1724] loss: 0.482, ave_loss: 0.453
[33]  [640/1724] loss: 0.447, ave_loss: 0.453
[34]  [660/1724] loss: 0.423, ave_loss: 0.452
[35]  [680/1724] loss: 0.395, ave_loss: 0.450
[36]  [700/1724] loss: 0.506, ave_loss: 0.452
[37]  [720/1724] loss: 0.516, ave_loss: 0.453
[38]  [740/1724] loss: 0.551, ave_loss: 0.456
[39]  [760/1724] loss: 0.420, ave_loss: 0.455
[40]  [780/1724] loss: 0.502, ave_loss: 0.456
[41]  [800/1724] loss: 0.407, ave_loss: 0.455
[42]  [820/1724] loss: 0.521, ave_loss: 0.457
[43]  [840/1724] loss: 0.403, ave_loss: 0.455
[44]  [860/1724] loss: 0.447, ave_loss: 0.455
[45]  [880/1724] loss: 0.455, ave_loss: 0.455
[46]  [900/1724] loss: 0.477, ave_loss: 0.456
[47]  [920/1724] loss: 0.346, ave_loss: 0.453
[48]  [940/1724] loss: 0.514, ave_loss: 0.455
[49]  [960/1724] loss: 0.467, ave_loss: 0.455
[50]  [980/1724] loss: 0.457, ave_loss: 0.455
[51]  [1000/1724] loss: 0.421, ave_loss: 0.454
[52]  [1020/1724] loss: 0.426, ave_loss: 0.454
[53]  [1040/1724] loss: 0.355, ave_loss: 0.452
[54]  [1060/1724] loss: 0.517, ave_loss: 0.453
[55]  [1080/1724] loss: 0.515, ave_loss: 0.454
[56]  [1100/1724] loss: 0.455, ave_loss: 0.454
[57]  [1120/1724] loss: 0.561, ave_loss: 0.456
[58]  [1140/1724] loss: 0.592, ave_loss: 0.458
[59]  [1160/1724] loss: 0.503, ave_loss: 0.459
[60]  [1180/1724] loss: 0.525, ave_loss: 0.460
[61]  [1200/1724] loss: 0.433, ave_loss: 0.460
[62]  [1220/1724] loss: 0.402, ave_loss: 0.459
[63]  [1240/1724] loss: 0.319, ave_loss: 0.457
[64]  [1260/1724] loss: 0.494, ave_loss: 0.457
[65]  [1280/1724] loss: 0.554, ave_loss: 0.459
[66]  [1300/1724] loss: 0.536, ave_loss: 0.460
[67]  [1320/1724] loss: 0.371, ave_loss: 0.459
[68]  [1340/1724] loss: 0.477, ave_loss: 0.459
[69]  [1360/1724] loss: 0.483, ave_loss: 0.459
[70]  [1380/1724] loss: 0.480, ave_loss: 0.460
[71]  [1400/1724] loss: 0.416, ave_loss: 0.459
[72]  [1420/1724] loss: 0.615, ave_loss: 0.461
[73]  [1440/1724] loss: 0.553, ave_loss: 0.462
[74]  [1460/1724] loss: 0.608, ave_loss: 0.464
[75]  [1480/1724] loss: 0.693, ave_loss: 0.467
[76]  [1500/1724] loss: 0.392, ave_loss: 0.466
[77]  [1520/1724] loss: 0.362, ave_loss: 0.465
[78]  [1540/1724] loss: 0.411, ave_loss: 0.464
[79]  [1560/1724] loss: 0.315, ave_loss: 0.462
[80]  [1580/1724] loss: 0.550, ave_loss: 0.463
[81]  [1600/1724] loss: 0.521, ave_loss: 0.464
[82]  [1620/1724] loss: 0.500, ave_loss: 0.465
[83]  [1640/1724] loss: 0.419, ave_loss: 0.464
[84]  [1660/1724] loss: 0.298, ave_loss: 0.462
[85]  [1680/1724] loss: 0.551, ave_loss: 0.463
[86]  [1700/1724] loss: 0.527, ave_loss: 0.464
[87]  [1720/1724] loss: 0.617, ave_loss: 0.466
[88]  [1740/1724] loss: 0.753, ave_loss: 0.469

Finished Training finishing at 2021-08-24 19:25:34.872362
printing_out epoch  7.146171693735499 learning rate: 0.0005153561248318907
0.0004163989078170501
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.689e-01
Validation Loss: 1.399e+04
Validation ROC: 0.7484
No improvement, still saving model
91.8538283062645 epochs left to go

Training Epoch 7.146171693735499/100 starting at 2021-08-24 19:26:32.503060
[1]  [0/1724] loss: 0.340, ave_loss: 0.340
[2]  [20/1724] loss: 0.375, ave_loss: 0.357
[3]  [40/1724] loss: 0.672, ave_loss: 0.462
[4]  [60/1724] loss: 0.616, ave_loss: 0.501
[5]  [80/1724] loss: 0.450, ave_loss: 0.490
[6]  [100/1724] loss: 0.523, ave_loss: 0.496
[7]  [120/1724] loss: 0.270, ave_loss: 0.463
[8]  [140/1724] loss: 0.471, ave_loss: 0.464
[9]  [160/1724] loss: 0.453, ave_loss: 0.463
[10]  [180/1724] loss: 0.494, ave_loss: 0.466
[11]  [200/1724] loss: 0.450, ave_loss: 0.465
[12]  [220/1724] loss: 0.544, ave_loss: 0.471
[13]  [240/1724] loss: 0.463, ave_loss: 0.471
[14]  [260/1724] loss: 0.463, ave_loss: 0.470
[15]  [280/1724] loss: 0.448, ave_loss: 0.469
[16]  [300/1724] loss: 0.534, ave_loss: 0.473
[17]  [320/1724] loss: 0.614, ave_loss: 0.481
[18]  [340/1724] loss: 0.476, ave_loss: 0.481
[19]  [360/1724] loss: 0.526, ave_loss: 0.483
[20]  [380/1724] loss: 0.550, ave_loss: 0.487
[21]  [400/1724] loss: 0.436, ave_loss: 0.484
[22]  [420/1724] loss: 0.505, ave_loss: 0.485
[23]  [440/1724] loss: 0.512, ave_loss: 0.486
[24]  [460/1724] loss: 0.347, ave_loss: 0.480
[25]  [480/1724] loss: 0.459, ave_loss: 0.480
[26]  [500/1724] loss: 0.469, ave_loss: 0.479
[27]  [520/1724] loss: 0.422, ave_loss: 0.477
[28]  [540/1724] loss: 0.315, ave_loss: 0.471
[29]  [560/1724] loss: 0.417, ave_loss: 0.469
[30]  [580/1724] loss: 0.449, ave_loss: 0.469
[31]  [600/1724] loss: 0.612, ave_loss: 0.473
[32]  [620/1724] loss: 0.362, ave_loss: 0.470
[33]  [640/1724] loss: 0.529, ave_loss: 0.472
[34]  [660/1724] loss: 0.405, ave_loss: 0.470
[35]  [680/1724] loss: 0.453, ave_loss: 0.469
[36]  [700/1724] loss: 0.514, ave_loss: 0.470
[37]  [720/1724] loss: 0.495, ave_loss: 0.471
[38]  [740/1724] loss: 0.439, ave_loss: 0.470
[39]  [760/1724] loss: 0.325, ave_loss: 0.467
[40]  [780/1724] loss: 0.414, ave_loss: 0.465
[41]  [800/1724] loss: 0.355, ave_loss: 0.463
[42]  [820/1724] loss: 0.409, ave_loss: 0.461
[43]  [840/1724] loss: 0.483, ave_loss: 0.462
[44]  [860/1724] loss: 0.433, ave_loss: 0.461
[45]  [880/1724] loss: 0.457, ave_loss: 0.461
[46]  [900/1724] loss: 0.364, ave_loss: 0.459
[47]  [920/1724] loss: 0.545, ave_loss: 0.461
[48]  [940/1724] loss: 0.370, ave_loss: 0.459
[49]  [960/1724] loss: 0.661, ave_loss: 0.463
[50]  [980/1724] loss: 0.344, ave_loss: 0.461
[51]  [1000/1724] loss: 0.465, ave_loss: 0.461
[52]  [1020/1724] loss: 0.579, ave_loss: 0.463
[53]  [1040/1724] loss: 0.362, ave_loss: 0.461
[54]  [1060/1724] loss: 0.490, ave_loss: 0.462
[55]  [1080/1724] loss: 0.591, ave_loss: 0.464
[56]  [1100/1724] loss: 0.285, ave_loss: 0.461
[57]  [1120/1724] loss: 0.730, ave_loss: 0.465
[58]  [1140/1724] loss: 0.490, ave_loss: 0.466
[59]  [1160/1724] loss: 0.419, ave_loss: 0.465
[60]  [1180/1724] loss: 0.437, ave_loss: 0.465
[61]  [1200/1724] loss: 0.428, ave_loss: 0.464
[62]  [1220/1724] loss: 0.455, ave_loss: 0.464
[63]  [1240/1724] loss: 0.420, ave_loss: 0.463
[64]  [1260/1724] loss: 0.487, ave_loss: 0.464
[65]  [1280/1724] loss: 0.501, ave_loss: 0.464
[66]  [1300/1724] loss: 0.527, ave_loss: 0.465
[67]  [1320/1724] loss: 0.502, ave_loss: 0.466
[68]  [1340/1724] loss: 0.360, ave_loss: 0.464
[69]  [1360/1724] loss: 0.345, ave_loss: 0.462
[70]  [1380/1724] loss: 0.356, ave_loss: 0.461
[71]  [1400/1724] loss: 0.515, ave_loss: 0.462
[72]  [1420/1724] loss: 0.512, ave_loss: 0.462
[73]  [1440/1724] loss: 0.362, ave_loss: 0.461
[74]  [1460/1724] loss: 0.459, ave_loss: 0.461
[75]  [1480/1724] loss: 0.415, ave_loss: 0.460
[76]  [1500/1724] loss: 0.427, ave_loss: 0.460
[77]  [1520/1724] loss: 0.494, ave_loss: 0.460
[78]  [1540/1724] loss: 0.521, ave_loss: 0.461
[79]  [1560/1724] loss: 0.405, ave_loss: 0.460
[80]  [1580/1724] loss: 0.359, ave_loss: 0.459
[81]  [1600/1724] loss: 0.528, ave_loss: 0.460
[82]  [1620/1724] loss: 0.371, ave_loss: 0.459
[83]  [1640/1724] loss: 0.423, ave_loss: 0.458
[84]  [1660/1724] loss: 0.398, ave_loss: 0.458
[85]  [1680/1724] loss: 0.357, ave_loss: 0.457
[86]  [1700/1724] loss: 0.494, ave_loss: 0.457
[87]  [1720/1724] loss: 0.393, ave_loss: 0.456
[88]  [1740/1724] loss: 0.440, ave_loss: 0.456

Finished Training finishing at 2021-08-24 19:28:38.894950
printing_out epoch  8.167053364269142 learning rate: 0.0005153561248318907
0.0004039069405825386
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.561e-01
Validation Loss: 1.319e+04
Validation ROC: 0.7567
Saving model
90.83294663573086 epochs left to go

Training Epoch 8.167053364269142/100 starting at 2021-08-24 19:29:08.595856
[1]  [0/1724] loss: 0.322, ave_loss: 0.322
[2]  [20/1724] loss: 0.472, ave_loss: 0.397
[3]  [40/1724] loss: 0.400, ave_loss: 0.398
[4]  [60/1724] loss: 0.273, ave_loss: 0.367
[5]  [80/1724] loss: 0.445, ave_loss: 0.382
[6]  [100/1724] loss: 0.645, ave_loss: 0.426
[7]  [120/1724] loss: 0.374, ave_loss: 0.419
[8]  [140/1724] loss: 0.443, ave_loss: 0.422
[9]  [160/1724] loss: 0.453, ave_loss: 0.425
[10]  [180/1724] loss: 0.370, ave_loss: 0.420
[11]  [200/1724] loss: 0.319, ave_loss: 0.411
[12]  [220/1724] loss: 0.513, ave_loss: 0.419
[13]  [240/1724] loss: 0.431, ave_loss: 0.420
[14]  [260/1724] loss: 0.448, ave_loss: 0.422
[15]  [280/1724] loss: 0.393, ave_loss: 0.420
[16]  [300/1724] loss: 0.369, ave_loss: 0.417
[17]  [320/1724] loss: 0.314, ave_loss: 0.411
[18]  [340/1724] loss: 0.484, ave_loss: 0.415
[19]  [360/1724] loss: 0.489, ave_loss: 0.419
[20]  [380/1724] loss: 0.438, ave_loss: 0.420
[21]  [400/1724] loss: 0.377, ave_loss: 0.418
[22]  [420/1724] loss: 0.369, ave_loss: 0.416
[23]  [440/1724] loss: 0.453, ave_loss: 0.417
[24]  [460/1724] loss: 0.455, ave_loss: 0.419
[25]  [480/1724] loss: 0.375, ave_loss: 0.417
[26]  [500/1724] loss: 0.456, ave_loss: 0.419
[27]  [520/1724] loss: 0.513, ave_loss: 0.422
[28]  [540/1724] loss: 0.354, ave_loss: 0.420
[29]  [560/1724] loss: 0.383, ave_loss: 0.418
[30]  [580/1724] loss: 0.357, ave_loss: 0.416
[31]  [600/1724] loss: 0.475, ave_loss: 0.418
[32]  [620/1724] loss: 0.402, ave_loss: 0.418
[33]  [640/1724] loss: 0.445, ave_loss: 0.419
[34]  [660/1724] loss: 0.439, ave_loss: 0.419
[35]  [680/1724] loss: 0.399, ave_loss: 0.419
[36]  [700/1724] loss: 0.339, ave_loss: 0.416
[37]  [720/1724] loss: 0.357, ave_loss: 0.415
[38]  [740/1724] loss: 0.451, ave_loss: 0.416
[39]  [760/1724] loss: 0.258, ave_loss: 0.412
[40]  [780/1724] loss: 0.528, ave_loss: 0.415
[41]  [800/1724] loss: 0.507, ave_loss: 0.417
[42]  [820/1724] loss: 0.403, ave_loss: 0.416
[43]  [840/1724] loss: 0.269, ave_loss: 0.413
[44]  [860/1724] loss: 0.335, ave_loss: 0.411
[45]  [880/1724] loss: 0.449, ave_loss: 0.412
[46]  [900/1724] loss: 0.305, ave_loss: 0.410
[47]  [920/1724] loss: 0.542, ave_loss: 0.413
[48]  [940/1724] loss: 0.329, ave_loss: 0.411
[49]  [960/1724] loss: 0.421, ave_loss: 0.411
[50]  [980/1724] loss: 0.504, ave_loss: 0.413
[51]  [1000/1724] loss: 0.584, ave_loss: 0.416
[52]  [1020/1724] loss: 0.344, ave_loss: 0.415
[53]  [1040/1724] loss: 0.445, ave_loss: 0.415
[54]  [1060/1724] loss: 0.455, ave_loss: 0.416
[55]  [1080/1724] loss: 0.316, ave_loss: 0.414
[56]  [1100/1724] loss: 0.405, ave_loss: 0.414
[57]  [1120/1724] loss: 0.363, ave_loss: 0.413
[58]  [1140/1724] loss: 0.580, ave_loss: 0.416
[59]  [1160/1724] loss: 0.684, ave_loss: 0.421
[60]  [1180/1724] loss: 0.480, ave_loss: 0.422
[61]  [1200/1724] loss: 0.470, ave_loss: 0.423
[62]  [1220/1724] loss: 0.661, ave_loss: 0.426
[63]  [1240/1724] loss: 0.520, ave_loss: 0.428
[64]  [1260/1724] loss: 0.442, ave_loss: 0.428
[65]  [1280/1724] loss: 0.492, ave_loss: 0.429
[66]  [1300/1724] loss: 0.543, ave_loss: 0.431
[67]  [1320/1724] loss: 0.467, ave_loss: 0.431
[68]  [1340/1724] loss: 0.581, ave_loss: 0.434
[69]  [1360/1724] loss: 0.471, ave_loss: 0.434
[70]  [1380/1724] loss: 0.421, ave_loss: 0.434
[71]  [1400/1724] loss: 0.495, ave_loss: 0.435
[72]  [1420/1724] loss: 0.442, ave_loss: 0.435
[73]  [1440/1724] loss: 0.353, ave_loss: 0.434
[74]  [1460/1724] loss: 0.490, ave_loss: 0.434
[75]  [1480/1724] loss: 0.443, ave_loss: 0.435
[76]  [1500/1724] loss: 0.524, ave_loss: 0.436
[77]  [1520/1724] loss: 0.446, ave_loss: 0.436
[78]  [1540/1724] loss: 0.557, ave_loss: 0.437
[79]  [1560/1724] loss: 0.632, ave_loss: 0.440
[80]  [1580/1724] loss: 0.411, ave_loss: 0.440
[81]  [1600/1724] loss: 0.347, ave_loss: 0.438
[82]  [1620/1724] loss: 0.289, ave_loss: 0.437
[83]  [1640/1724] loss: 0.539, ave_loss: 0.438
[84]  [1660/1724] loss: 0.539, ave_loss: 0.439
[85]  [1680/1724] loss: 0.494, ave_loss: 0.440
[86]  [1700/1724] loss: 0.534, ave_loss: 0.441
[87]  [1720/1724] loss: 0.293, ave_loss: 0.439
[88]  [1740/1724] loss: 0.458, ave_loss: 0.439

Finished Training finishing at 2021-08-24 19:31:11.840525
printing_out epoch  9.187935034802784 learning rate: 0.0005153561248318907
0.00039178973236506245
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.393e-01
Validation Loss: 1.151e+04
Validation ROC: 0.7532
No improvement, still saving model
89.81206496519721 epochs left to go

Training Epoch 9.187935034802784/100 starting at 2021-08-24 19:31:39.718091
[1]  [0/1724] loss: 0.576, ave_loss: 0.576
[2]  [20/1724] loss: 0.446, ave_loss: 0.511
[3]  [40/1724] loss: 0.443, ave_loss: 0.488
[4]  [60/1724] loss: 0.522, ave_loss: 0.497
[5]  [80/1724] loss: 0.400, ave_loss: 0.477
[6]  [100/1724] loss: 0.355, ave_loss: 0.457
[7]  [120/1724] loss: 0.393, ave_loss: 0.448
[8]  [140/1724] loss: 0.452, ave_loss: 0.448
[9]  [160/1724] loss: 0.595, ave_loss: 0.464
[10]  [180/1724] loss: 0.296, ave_loss: 0.448
[11]  [200/1724] loss: 0.420, ave_loss: 0.445
[12]  [220/1724] loss: 0.318, ave_loss: 0.435
[13]  [240/1724] loss: 0.367, ave_loss: 0.429
[14]  [260/1724] loss: 0.550, ave_loss: 0.438
[15]  [280/1724] loss: 0.573, ave_loss: 0.447
[16]  [300/1724] loss: 0.304, ave_loss: 0.438
[17]  [320/1724] loss: 0.534, ave_loss: 0.444
[18]  [340/1724] loss: 0.553, ave_loss: 0.450
[19]  [360/1724] loss: 0.538, ave_loss: 0.454
[20]  [380/1724] loss: 0.533, ave_loss: 0.458
[21]  [400/1724] loss: 0.372, ave_loss: 0.454
[22]  [420/1724] loss: 0.391, ave_loss: 0.451
[23]  [440/1724] loss: 0.405, ave_loss: 0.449
[24]  [460/1724] loss: 0.497, ave_loss: 0.451
[25]  [480/1724] loss: 0.562, ave_loss: 0.456
[26]  [500/1724] loss: 0.443, ave_loss: 0.455
[27]  [520/1724] loss: 0.646, ave_loss: 0.462
[28]  [540/1724] loss: 0.420, ave_loss: 0.461
[29]  [560/1724] loss: 0.348, ave_loss: 0.457
[30]  [580/1724] loss: 0.510, ave_loss: 0.459
[31]  [600/1724] loss: 0.425, ave_loss: 0.458
[32]  [620/1724] loss: 0.625, ave_loss: 0.463
[33]  [640/1724] loss: 0.531, ave_loss: 0.465
[34]  [660/1724] loss: 0.452, ave_loss: 0.465
[35]  [680/1724] loss: 0.499, ave_loss: 0.465
[36]  [700/1724] loss: 0.341, ave_loss: 0.462
[37]  [720/1724] loss: 0.401, ave_loss: 0.460
[38]  [740/1724] loss: 0.566, ave_loss: 0.463
[39]  [760/1724] loss: 0.656, ave_loss: 0.468
[40]  [780/1724] loss: 0.494, ave_loss: 0.469
[41]  [800/1724] loss: 0.330, ave_loss: 0.465
[42]  [820/1724] loss: 0.434, ave_loss: 0.465
[43]  [840/1724] loss: 0.345, ave_loss: 0.462
[44]  [860/1724] loss: 0.417, ave_loss: 0.461
[45]  [880/1724] loss: 0.469, ave_loss: 0.461
[46]  [900/1724] loss: 0.629, ave_loss: 0.465
[47]  [920/1724] loss: 0.489, ave_loss: 0.465
[48]  [940/1724] loss: 0.474, ave_loss: 0.465
[49]  [960/1724] loss: 0.526, ave_loss: 0.467
[50]  [980/1724] loss: 0.479, ave_loss: 0.467
[51]  [1000/1724] loss: 0.424, ave_loss: 0.466
[52]  [1020/1724] loss: 0.532, ave_loss: 0.467
[53]  [1040/1724] loss: 0.396, ave_loss: 0.466
[54]  [1060/1724] loss: 0.500, ave_loss: 0.467
[55]  [1080/1724] loss: 0.460, ave_loss: 0.466
[56]  [1100/1724] loss: 0.272, ave_loss: 0.463
[57]  [1120/1724] loss: 0.466, ave_loss: 0.463
[58]  [1140/1724] loss: 0.438, ave_loss: 0.463
[59]  [1160/1724] loss: 0.466, ave_loss: 0.463
[60]  [1180/1724] loss: 0.557, ave_loss: 0.464
[61]  [1200/1724] loss: 0.577, ave_loss: 0.466
[62]  [1220/1724] loss: 0.307, ave_loss: 0.464
[63]  [1240/1724] loss: 0.443, ave_loss: 0.463
[64]  [1260/1724] loss: 0.358, ave_loss: 0.462
[65]  [1280/1724] loss: 0.514, ave_loss: 0.462
[66]  [1300/1724] loss: 0.430, ave_loss: 0.462
[67]  [1320/1724] loss: 0.376, ave_loss: 0.461
[68]  [1340/1724] loss: 0.465, ave_loss: 0.461
[69]  [1360/1724] loss: 0.501, ave_loss: 0.461
[70]  [1380/1724] loss: 0.448, ave_loss: 0.461
[71]  [1400/1724] loss: 0.557, ave_loss: 0.462
[72]  [1420/1724] loss: 0.471, ave_loss: 0.463
[73]  [1440/1724] loss: 0.405, ave_loss: 0.462
[74]  [1460/1724] loss: 0.444, ave_loss: 0.461
[75]  [1480/1724] loss: 0.409, ave_loss: 0.461
[76]  [1500/1724] loss: 0.343, ave_loss: 0.459
[77]  [1520/1724] loss: 0.386, ave_loss: 0.458
[78]  [1540/1724] loss: 0.402, ave_loss: 0.458
[79]  [1560/1724] loss: 0.402, ave_loss: 0.457
[80]  [1580/1724] loss: 0.426, ave_loss: 0.456
[81]  [1600/1724] loss: 0.484, ave_loss: 0.457
[82]  [1620/1724] loss: 0.401, ave_loss: 0.456
[83]  [1640/1724] loss: 0.348, ave_loss: 0.455
[84]  [1660/1724] loss: 0.488, ave_loss: 0.455
[85]  [1680/1724] loss: 0.381, ave_loss: 0.454
[86]  [1700/1724] loss: 0.454, ave_loss: 0.454
[87]  [1720/1724] loss: 0.498, ave_loss: 0.455
[88]  [1740/1724] loss: 0.470, ave_loss: 0.455

Finished Training finishing at 2021-08-24 19:33:42.298099
printing_out epoch  10.208816705336426 learning rate: 0.0005153561248318907
0.0003800360403941106
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.550e-01
Validation Loss: 1.135e+04
Validation ROC: 0.7545
No improvement, still saving model
88.79118329466357 epochs left to go

Training Epoch 10.208816705336426/100 starting at 2021-08-24 19:34:14.813221
[1]  [0/1724] loss: 0.599, ave_loss: 0.599
[2]  [20/1724] loss: 0.537, ave_loss: 0.568
[3]  [40/1724] loss: 0.468, ave_loss: 0.535
[4]  [60/1724] loss: 0.661, ave_loss: 0.566
[5]  [80/1724] loss: 0.377, ave_loss: 0.528
[6]  [100/1724] loss: 0.378, ave_loss: 0.503
[7]  [120/1724] loss: 0.365, ave_loss: 0.484
[8]  [140/1724] loss: 0.349, ave_loss: 0.467
[9]  [160/1724] loss: 0.440, ave_loss: 0.464
[10]  [180/1724] loss: 0.586, ave_loss: 0.476
[11]  [200/1724] loss: 0.391, ave_loss: 0.468
[12]  [220/1724] loss: 0.375, ave_loss: 0.461
[13]  [240/1724] loss: 0.360, ave_loss: 0.453
[14]  [260/1724] loss: 0.352, ave_loss: 0.446
[15]  [280/1724] loss: 0.326, ave_loss: 0.438
[16]  [300/1724] loss: 0.340, ave_loss: 0.432
[17]  [320/1724] loss: 0.476, ave_loss: 0.434
[18]  [340/1724] loss: 0.534, ave_loss: 0.440
[19]  [360/1724] loss: 0.318, ave_loss: 0.433
[20]  [380/1724] loss: 0.424, ave_loss: 0.433
[21]  [400/1724] loss: 0.555, ave_loss: 0.439
[22]  [420/1724] loss: 0.344, ave_loss: 0.434
[23]  [440/1724] loss: 0.389, ave_loss: 0.432
[24]  [460/1724] loss: 0.382, ave_loss: 0.430
[25]  [480/1724] loss: 0.590, ave_loss: 0.437
[26]  [500/1724] loss: 0.368, ave_loss: 0.434
[27]  [520/1724] loss: 0.620, ave_loss: 0.441
[28]  [540/1724] loss: 0.489, ave_loss: 0.443
[29]  [560/1724] loss: 0.420, ave_loss: 0.442
[30]  [580/1724] loss: 0.302, ave_loss: 0.437
[31]  [600/1724] loss: 0.324, ave_loss: 0.434
[32]  [620/1724] loss: 0.459, ave_loss: 0.434
[33]  [640/1724] loss: 0.538, ave_loss: 0.438
[34]  [660/1724] loss: 0.414, ave_loss: 0.437
[35]  [680/1724] loss: 0.493, ave_loss: 0.438
[36]  [700/1724] loss: 0.469, ave_loss: 0.439
[37]  [720/1724] loss: 0.486, ave_loss: 0.441
[38]  [740/1724] loss: 0.378, ave_loss: 0.439
[39]  [760/1724] loss: 0.480, ave_loss: 0.440
[40]  [780/1724] loss: 0.422, ave_loss: 0.440
[41]  [800/1724] loss: 0.496, ave_loss: 0.441
[42]  [820/1724] loss: 0.529, ave_loss: 0.443
[43]  [840/1724] loss: 0.317, ave_loss: 0.440
[44]  [860/1724] loss: 0.273, ave_loss: 0.436
[45]  [880/1724] loss: 0.421, ave_loss: 0.436
[46]  [900/1724] loss: 0.413, ave_loss: 0.435
[47]  [920/1724] loss: 0.477, ave_loss: 0.436
[48]  [940/1724] loss: 0.403, ave_loss: 0.436
[49]  [960/1724] loss: 0.420, ave_loss: 0.435
[50]  [980/1724] loss: 0.519, ave_loss: 0.437
[51]  [1000/1724] loss: 0.307, ave_loss: 0.434
[52]  [1020/1724] loss: 0.517, ave_loss: 0.436
[53]  [1040/1724] loss: 0.448, ave_loss: 0.436
[54]  [1060/1724] loss: 0.592, ave_loss: 0.439
[55]  [1080/1724] loss: 0.469, ave_loss: 0.440
[56]  [1100/1724] loss: 0.331, ave_loss: 0.438
[57]  [1120/1724] loss: 0.401, ave_loss: 0.437
[58]  [1140/1724] loss: 0.524, ave_loss: 0.439
[59]  [1160/1724] loss: 0.508, ave_loss: 0.440
[60]  [1180/1724] loss: 0.481, ave_loss: 0.440
[61]  [1200/1724] loss: 0.304, ave_loss: 0.438
[62]  [1220/1724] loss: 0.384, ave_loss: 0.437
[63]  [1240/1724] loss: 0.514, ave_loss: 0.439
[64]  [1260/1724] loss: 0.589, ave_loss: 0.441
[65]  [1280/1724] loss: 0.405, ave_loss: 0.440
[66]  [1300/1724] loss: 0.349, ave_loss: 0.439
[67]  [1320/1724] loss: 0.396, ave_loss: 0.438
[68]  [1340/1724] loss: 0.442, ave_loss: 0.438
[69]  [1360/1724] loss: 0.407, ave_loss: 0.438
[70]  [1380/1724] loss: 0.475, ave_loss: 0.438
[71]  [1400/1724] loss: 0.402, ave_loss: 0.438
[72]  [1420/1724] loss: 0.435, ave_loss: 0.438
[73]  [1440/1724] loss: 0.517, ave_loss: 0.439
[74]  [1460/1724] loss: 0.406, ave_loss: 0.439
[75]  [1480/1724] loss: 0.317, ave_loss: 0.437
[76]  [1500/1724] loss: 0.420, ave_loss: 0.437
[77]  [1520/1724] loss: 0.384, ave_loss: 0.436
[78]  [1540/1724] loss: 0.322, ave_loss: 0.435
[79]  [1560/1724] loss: 0.402, ave_loss: 0.434
[80]  [1580/1724] loss: 0.389, ave_loss: 0.434
[81]  [1600/1724] loss: 0.540, ave_loss: 0.435
[82]  [1620/1724] loss: 0.526, ave_loss: 0.436
[83]  [1640/1724] loss: 0.663, ave_loss: 0.439
[84]  [1660/1724] loss: 0.520, ave_loss: 0.440
[85]  [1680/1724] loss: 0.410, ave_loss: 0.439
[86]  [1700/1724] loss: 0.385, ave_loss: 0.439
[87]  [1720/1724] loss: 0.489, ave_loss: 0.439
[88]  [1740/1724] loss: 0.409, ave_loss: 0.439

Finished Training finishing at 2021-08-24 19:36:08.670270
printing_out epoch  11.22969837587007 learning rate: 0.0005153561248318907
0.00036863495918228726
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.390e-01
Validation Loss: 1.353e+04
Validation ROC: 0.7683
Saving model
87.77030162412993 epochs left to go

Training Epoch 11.22969837587007/100 starting at 2021-08-24 19:36:39.896058
[1]  [0/1724] loss: 0.589, ave_loss: 0.589
[2]  [20/1724] loss: 0.469, ave_loss: 0.529
[3]  [40/1724] loss: 0.342, ave_loss: 0.467
[4]  [60/1724] loss: 0.390, ave_loss: 0.447
[5]  [80/1724] loss: 0.375, ave_loss: 0.433
[6]  [100/1724] loss: 0.535, ave_loss: 0.450
[7]  [120/1724] loss: 0.454, ave_loss: 0.451
[8]  [140/1724] loss: 0.552, ave_loss: 0.463
[9]  [160/1724] loss: 0.345, ave_loss: 0.450
[10]  [180/1724] loss: 0.466, ave_loss: 0.452
[11]  [200/1724] loss: 0.390, ave_loss: 0.446
[12]  [220/1724] loss: 0.348, ave_loss: 0.438
[13]  [240/1724] loss: 0.370, ave_loss: 0.433
[14]  [260/1724] loss: 0.479, ave_loss: 0.436
[15]  [280/1724] loss: 0.321, ave_loss: 0.428
[16]  [300/1724] loss: 0.388, ave_loss: 0.426
[17]  [320/1724] loss: 0.515, ave_loss: 0.431
[18]  [340/1724] loss: 0.468, ave_loss: 0.433
[19]  [360/1724] loss: 0.285, ave_loss: 0.425
[20]  [380/1724] loss: 0.375, ave_loss: 0.423
[21]  [400/1724] loss: 0.313, ave_loss: 0.418
[22]  [420/1724] loss: 0.468, ave_loss: 0.420
[23]  [440/1724] loss: 0.513, ave_loss: 0.424
[24]  [460/1724] loss: 0.418, ave_loss: 0.424
[25]  [480/1724] loss: 0.347, ave_loss: 0.421
[26]  [500/1724] loss: 0.430, ave_loss: 0.421
[27]  [520/1724] loss: 0.386, ave_loss: 0.420
[28]  [540/1724] loss: 0.394, ave_loss: 0.419
[29]  [560/1724] loss: 0.457, ave_loss: 0.420
[30]  [580/1724] loss: 0.421, ave_loss: 0.420
[31]  [600/1724] loss: 0.483, ave_loss: 0.422
[32]  [620/1724] loss: 0.291, ave_loss: 0.418
[33]  [640/1724] loss: 0.350, ave_loss: 0.416
[34]  [660/1724] loss: 0.524, ave_loss: 0.419
[35]  [680/1724] loss: 0.371, ave_loss: 0.418
[36]  [700/1724] loss: 0.551, ave_loss: 0.421
[37]  [720/1724] loss: 0.500, ave_loss: 0.424
[38]  [740/1724] loss: 0.449, ave_loss: 0.424
[39]  [760/1724] loss: 0.338, ave_loss: 0.422
[40]  [780/1724] loss: 0.268, ave_loss: 0.418
[41]  [800/1724] loss: 0.330, ave_loss: 0.416
[42]  [820/1724] loss: 0.452, ave_loss: 0.417
[43]  [840/1724] loss: 0.499, ave_loss: 0.419
[44]  [860/1724] loss: 0.614, ave_loss: 0.423
[45]  [880/1724] loss: 0.450, ave_loss: 0.424
[46]  [900/1724] loss: 0.435, ave_loss: 0.424
[47]  [920/1724] loss: 0.476, ave_loss: 0.425
[48]  [940/1724] loss: 0.352, ave_loss: 0.424
[49]  [960/1724] loss: 0.372, ave_loss: 0.423
[50]  [980/1724] loss: 0.369, ave_loss: 0.422
[51]  [1000/1724] loss: 0.581, ave_loss: 0.425
[52]  [1020/1724] loss: 0.398, ave_loss: 0.424
[53]  [1040/1724] loss: 0.442, ave_loss: 0.424
[54]  [1060/1724] loss: 0.348, ave_loss: 0.423
[55]  [1080/1724] loss: 0.460, ave_loss: 0.424
[56]  [1100/1724] loss: 0.337, ave_loss: 0.422
[57]  [1120/1724] loss: 0.409, ave_loss: 0.422
[58]  [1140/1724] loss: 0.492, ave_loss: 0.423
[59]  [1160/1724] loss: 0.394, ave_loss: 0.423
[60]  [1180/1724] loss: 0.343, ave_loss: 0.421
[61]  [1200/1724] loss: 0.448, ave_loss: 0.422
[62]  [1220/1724] loss: 0.305, ave_loss: 0.420
[63]  [1240/1724] loss: 0.448, ave_loss: 0.420
[64]  [1260/1724] loss: 0.467, ave_loss: 0.421
[65]  [1280/1724] loss: 0.505, ave_loss: 0.422
[66]  [1300/1724] loss: 0.324, ave_loss: 0.421
[67]  [1320/1724] loss: 0.407, ave_loss: 0.421
[68]  [1340/1724] loss: 0.314, ave_loss: 0.419
[69]  [1360/1724] loss: 0.274, ave_loss: 0.417
[70]  [1380/1724] loss: 0.404, ave_loss: 0.417
[71]  [1400/1724] loss: 0.395, ave_loss: 0.416
[72]  [1420/1724] loss: 0.388, ave_loss: 0.416
[73]  [1440/1724] loss: 0.480, ave_loss: 0.417
[74]  [1460/1724] loss: 0.287, ave_loss: 0.415
[75]  [1480/1724] loss: 0.316, ave_loss: 0.414
[76]  [1500/1724] loss: 0.486, ave_loss: 0.415
[77]  [1520/1724] loss: 0.457, ave_loss: 0.415
[78]  [1540/1724] loss: 0.357, ave_loss: 0.415
[79]  [1560/1724] loss: 0.437, ave_loss: 0.415
[80]  [1580/1724] loss: 0.523, ave_loss: 0.416
[81]  [1600/1724] loss: 0.509, ave_loss: 0.417
[82]  [1620/1724] loss: 0.574, ave_loss: 0.419
[83]  [1640/1724] loss: 0.411, ave_loss: 0.419
[84]  [1660/1724] loss: 0.423, ave_loss: 0.419
[85]  [1680/1724] loss: 0.393, ave_loss: 0.419
[86]  [1700/1724] loss: 0.574, ave_loss: 0.421
[87]  [1720/1724] loss: 0.682, ave_loss: 0.424
[88]  [1740/1724] loss: 0.368, ave_loss: 0.423

Finished Training finishing at 2021-08-24 19:38:32.912747
printing_out epoch  12.250580046403712 learning rate: 0.0005153561248318907
0.0003575759104068186
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.231e-01
Validation Loss: 7.369e+03
Validation ROC: 0.7594
No improvement, still saving model
86.74941995359629 epochs left to go

Training Epoch 12.250580046403712/100 starting at 2021-08-24 19:40:01.162704
[1]  [0/1724] loss: 0.825, ave_loss: 0.825
[2]  [20/1724] loss: 0.468, ave_loss: 0.646
[3]  [40/1724] loss: 0.360, ave_loss: 0.551
[4]  [60/1724] loss: 0.431, ave_loss: 0.521
[5]  [80/1724] loss: 0.446, ave_loss: 0.506
[6]  [100/1724] loss: 0.457, ave_loss: 0.498
[7]  [120/1724] loss: 0.349, ave_loss: 0.477
[8]  [140/1724] loss: 0.324, ave_loss: 0.458
[9]  [160/1724] loss: 0.513, ave_loss: 0.464
[10]  [180/1724] loss: 0.519, ave_loss: 0.469
[11]  [200/1724] loss: 0.348, ave_loss: 0.458
[12]  [220/1724] loss: 0.504, ave_loss: 0.462
[13]  [240/1724] loss: 0.518, ave_loss: 0.466
[14]  [260/1724] loss: 0.389, ave_loss: 0.461
[15]  [280/1724] loss: 0.533, ave_loss: 0.466
[16]  [300/1724] loss: 0.430, ave_loss: 0.463
[17]  [320/1724] loss: 0.471, ave_loss: 0.464
[18]  [340/1724] loss: 0.366, ave_loss: 0.458
[19]  [360/1724] loss: 0.563, ave_loss: 0.464
[20]  [380/1724] loss: 0.358, ave_loss: 0.459
[21]  [400/1724] loss: 0.424, ave_loss: 0.457
[22]  [420/1724] loss: 0.374, ave_loss: 0.453
[23]  [440/1724] loss: 0.318, ave_loss: 0.447
[24]  [460/1724] loss: 0.328, ave_loss: 0.442
[25]  [480/1724] loss: 0.314, ave_loss: 0.437
[26]  [500/1724] loss: 0.671, ave_loss: 0.446
[27]  [520/1724] loss: 0.456, ave_loss: 0.447
[28]  [540/1724] loss: 0.555, ave_loss: 0.450
[29]  [560/1724] loss: 0.311, ave_loss: 0.446
[30]  [580/1724] loss: 0.648, ave_loss: 0.452
[31]  [600/1724] loss: 0.519, ave_loss: 0.455
[32]  [620/1724] loss: 0.361, ave_loss: 0.452
[33]  [640/1724] loss: 0.370, ave_loss: 0.449
[34]  [660/1724] loss: 0.245, ave_loss: 0.443
[35]  [680/1724] loss: 0.363, ave_loss: 0.441
[36]  [700/1724] loss: 0.472, ave_loss: 0.442
[37]  [720/1724] loss: 0.298, ave_loss: 0.438
[38]  [740/1724] loss: 0.592, ave_loss: 0.442
[39]  [760/1724] loss: 0.476, ave_loss: 0.443
[40]  [780/1724] loss: 0.387, ave_loss: 0.441
[41]  [800/1724] loss: 0.370, ave_loss: 0.440
[42]  [820/1724] loss: 0.372, ave_loss: 0.438
[43]  [840/1724] loss: 0.338, ave_loss: 0.436
[44]  [860/1724] loss: 0.521, ave_loss: 0.438
[45]  [880/1724] loss: 0.520, ave_loss: 0.439
[46]  [900/1724] loss: 0.493, ave_loss: 0.441
[47]  [920/1724] loss: 0.448, ave_loss: 0.441
[48]  [940/1724] loss: 0.406, ave_loss: 0.440
[49]  [960/1724] loss: 0.418, ave_loss: 0.440
[50]  [980/1724] loss: 0.354, ave_loss: 0.438
[51]  [1000/1724] loss: 0.373, ave_loss: 0.437
[52]  [1020/1724] loss: 0.437, ave_loss: 0.437
[53]  [1040/1724] loss: 0.454, ave_loss: 0.437
[54]  [1060/1724] loss: 0.474, ave_loss: 0.438
[55]  [1080/1724] loss: 0.420, ave_loss: 0.437
[56]  [1100/1724] loss: 0.599, ave_loss: 0.440
[57]  [1120/1724] loss: 0.398, ave_loss: 0.439
[58]  [1140/1724] loss: 0.436, ave_loss: 0.439
[59]  [1160/1724] loss: 0.355, ave_loss: 0.438
[60]  [1180/1724] loss: 0.353, ave_loss: 0.437
[61]  [1200/1724] loss: 0.367, ave_loss: 0.435
[62]  [1220/1724] loss: 0.412, ave_loss: 0.435
[63]  [1240/1724] loss: 0.438, ave_loss: 0.435
[64]  [1260/1724] loss: 0.483, ave_loss: 0.436
[65]  [1280/1724] loss: 0.350, ave_loss: 0.435
[66]  [1300/1724] loss: 0.377, ave_loss: 0.434
[67]  [1320/1724] loss: 0.438, ave_loss: 0.434
[68]  [1340/1724] loss: 0.423, ave_loss: 0.434
[69]  [1360/1724] loss: 0.418, ave_loss: 0.433
[70]  [1380/1724] loss: 0.425, ave_loss: 0.433
[71]  [1400/1724] loss: 0.514, ave_loss: 0.434
[72]  [1420/1724] loss: 0.475, ave_loss: 0.435
[73]  [1440/1724] loss: 0.433, ave_loss: 0.435
[74]  [1460/1724] loss: 0.347, ave_loss: 0.434
[75]  [1480/1724] loss: 0.526, ave_loss: 0.435
[76]  [1500/1724] loss: 0.359, ave_loss: 0.434
[77]  [1520/1724] loss: 0.382, ave_loss: 0.433
[78]  [1540/1724] loss: 0.317, ave_loss: 0.432
[79]  [1560/1724] loss: 0.277, ave_loss: 0.430
[80]  [1580/1724] loss: 0.484, ave_loss: 0.430
[81]  [1600/1724] loss: 0.317, ave_loss: 0.429
[82]  [1620/1724] loss: 0.421, ave_loss: 0.429
[83]  [1640/1724] loss: 0.262, ave_loss: 0.427
[84]  [1660/1724] loss: 0.414, ave_loss: 0.427
[85]  [1680/1724] loss: 0.415, ave_loss: 0.427
[86]  [1700/1724] loss: 0.475, ave_loss: 0.427
[87]  [1720/1724] loss: 0.381, ave_loss: 0.427
[88]  [1740/1724] loss: 0.566, ave_loss: 0.428

Finished Training finishing at 2021-08-24 19:42:15.721242
printing_out epoch  13.271461716937354 learning rate: 0.00046850556802899155
0.0004544504009881218
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.283e-01
Validation Loss: 8.327e+03
Validation ROC: 0.7585
No improvement, still saving model
85.72853828306265 epochs left to go

Training Epoch 13.271461716937354/100 starting at 2021-08-24 19:42:44.874478
[1]  [0/1724] loss: 0.503, ave_loss: 0.503
[2]  [20/1724] loss: 0.177, ave_loss: 0.340
[3]  [40/1724] loss: 0.228, ave_loss: 0.303
[4]  [60/1724] loss: 0.565, ave_loss: 0.368
[5]  [80/1724] loss: 0.415, ave_loss: 0.378
[6]  [100/1724] loss: 0.442, ave_loss: 0.388
[7]  [120/1724] loss: 0.555, ave_loss: 0.412
[8]  [140/1724] loss: 0.545, ave_loss: 0.429
[9]  [160/1724] loss: 0.487, ave_loss: 0.435
[10]  [180/1724] loss: 0.498, ave_loss: 0.442
[11]  [200/1724] loss: 0.585, ave_loss: 0.455
[12]  [220/1724] loss: 0.406, ave_loss: 0.451
[13]  [240/1724] loss: 0.387, ave_loss: 0.446
[14]  [260/1724] loss: 0.532, ave_loss: 0.452
[15]  [280/1724] loss: 0.339, ave_loss: 0.444
[16]  [300/1724] loss: 0.400, ave_loss: 0.442
[17]  [320/1724] loss: 0.585, ave_loss: 0.450
[18]  [340/1724] loss: 0.314, ave_loss: 0.442
[19]  [360/1724] loss: 0.454, ave_loss: 0.443
[20]  [380/1724] loss: 0.440, ave_loss: 0.443
[21]  [400/1724] loss: 0.288, ave_loss: 0.436
[22]  [420/1724] loss: 0.323, ave_loss: 0.430
[23]  [440/1724] loss: 0.342, ave_loss: 0.427
[24]  [460/1724] loss: 0.514, ave_loss: 0.430
[25]  [480/1724] loss: 0.464, ave_loss: 0.432
[26]  [500/1724] loss: 0.455, ave_loss: 0.432
[27]  [520/1724] loss: 0.551, ave_loss: 0.437
[28]  [540/1724] loss: 0.368, ave_loss: 0.434
[29]  [560/1724] loss: 0.366, ave_loss: 0.432
[30]  [580/1724] loss: 0.555, ave_loss: 0.436
[31]  [600/1724] loss: 0.515, ave_loss: 0.439
[32]  [620/1724] loss: 0.319, ave_loss: 0.435
[33]  [640/1724] loss: 0.361, ave_loss: 0.433
[34]  [660/1724] loss: 0.430, ave_loss: 0.433
[35]  [680/1724] loss: 0.286, ave_loss: 0.428
[36]  [700/1724] loss: 0.440, ave_loss: 0.429
[37]  [720/1724] loss: 0.539, ave_loss: 0.432
[38]  [740/1724] loss: 0.518, ave_loss: 0.434
[39]  [760/1724] loss: 0.569, ave_loss: 0.438
[40]  [780/1724] loss: 0.307, ave_loss: 0.434
[41]  [800/1724] loss: 0.383, ave_loss: 0.433
[42]  [820/1724] loss: 0.322, ave_loss: 0.430
[43]  [840/1724] loss: 0.468, ave_loss: 0.431
[44]  [860/1724] loss: 0.311, ave_loss: 0.429
[45]  [880/1724] loss: 0.364, ave_loss: 0.427
[46]  [900/1724] loss: 0.378, ave_loss: 0.426
[47]  [920/1724] loss: 0.294, ave_loss: 0.423
[48]  [940/1724] loss: 0.390, ave_loss: 0.423
[49]  [960/1724] loss: 0.498, ave_loss: 0.424
[50]  [980/1724] loss: 0.408, ave_loss: 0.424
[51]  [1000/1724] loss: 0.438, ave_loss: 0.424
[52]  [1020/1724] loss: 0.445, ave_loss: 0.424
[53]  [1040/1724] loss: 0.468, ave_loss: 0.425
[54]  [1060/1724] loss: 0.349, ave_loss: 0.424
[55]  [1080/1724] loss: 0.375, ave_loss: 0.423
[56]  [1100/1724] loss: 0.688, ave_loss: 0.428
[57]  [1120/1724] loss: 0.384, ave_loss: 0.427
[58]  [1140/1724] loss: 0.488, ave_loss: 0.428
[59]  [1160/1724] loss: 0.336, ave_loss: 0.426
[60]  [1180/1724] loss: 0.504, ave_loss: 0.428
[61]  [1200/1724] loss: 0.476, ave_loss: 0.429
[62]  [1220/1724] loss: 0.287, ave_loss: 0.426
[63]  [1240/1724] loss: 0.422, ave_loss: 0.426
[64]  [1260/1724] loss: 0.339, ave_loss: 0.425
[65]  [1280/1724] loss: 0.466, ave_loss: 0.425
[66]  [1300/1724] loss: 0.505, ave_loss: 0.427
[67]  [1320/1724] loss: 0.519, ave_loss: 0.428
[68]  [1340/1724] loss: 0.425, ave_loss: 0.428
[69]  [1360/1724] loss: 0.302, ave_loss: 0.426
[70]  [1380/1724] loss: 0.328, ave_loss: 0.425
[71]  [1400/1724] loss: 0.385, ave_loss: 0.424
[72]  [1420/1724] loss: 0.382, ave_loss: 0.424
[73]  [1440/1724] loss: 0.296, ave_loss: 0.422
[74]  [1460/1724] loss: 0.416, ave_loss: 0.422
[75]  [1480/1724] loss: 0.528, ave_loss: 0.423
[76]  [1500/1724] loss: 0.281, ave_loss: 0.421
[77]  [1520/1724] loss: 0.348, ave_loss: 0.420
[78]  [1540/1724] loss: 0.455, ave_loss: 0.421
[79]  [1560/1724] loss: 0.562, ave_loss: 0.423
[80]  [1580/1724] loss: 0.354, ave_loss: 0.422
[81]  [1600/1724] loss: 0.599, ave_loss: 0.424
[82]  [1620/1724] loss: 0.339, ave_loss: 0.423
[83]  [1640/1724] loss: 0.477, ave_loss: 0.424
[84]  [1660/1724] loss: 0.449, ave_loss: 0.424
[85]  [1680/1724] loss: 0.446, ave_loss: 0.424
[86]  [1700/1724] loss: 0.323, ave_loss: 0.423
[87]  [1720/1724] loss: 0.413, ave_loss: 0.423
[88]  [1740/1724] loss: 0.522, ave_loss: 0.424

Finished Training finishing at 2021-08-24 19:44:49.637544
printing_out epoch  14.292343387470998 learning rate: 0.00042591415275362865
0.0004131367281710198
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.239e-01
Validation Loss: 5.164e+03
Validation ROC: 0.7667
No improvement, still saving model
84.70765661252901 epochs left to go

Training Epoch 14.292343387470998/100 starting at 2021-08-24 19:45:38.307414
[1]  [0/1724] loss: 0.502, ave_loss: 0.502
[2]  [20/1724] loss: 0.464, ave_loss: 0.483
[3]  [40/1724] loss: 0.375, ave_loss: 0.447
[4]  [60/1724] loss: 0.325, ave_loss: 0.416
[5]  [80/1724] loss: 0.403, ave_loss: 0.414
[6]  [100/1724] loss: 0.541, ave_loss: 0.435
[7]  [120/1724] loss: 0.623, ave_loss: 0.462
[8]  [140/1724] loss: 0.210, ave_loss: 0.430
[9]  [160/1724] loss: 0.405, ave_loss: 0.427
[10]  [180/1724] loss: 0.340, ave_loss: 0.419
[11]  [200/1724] loss: 0.407, ave_loss: 0.418
[12]  [220/1724] loss: 0.416, ave_loss: 0.418
[13]  [240/1724] loss: 0.516, ave_loss: 0.425
[14]  [260/1724] loss: 0.375, ave_loss: 0.421
[15]  [280/1724] loss: 0.356, ave_loss: 0.417
[16]  [300/1724] loss: 0.375, ave_loss: 0.414
[17]  [320/1724] loss: 0.298, ave_loss: 0.408
[18]  [340/1724] loss: 0.454, ave_loss: 0.410
[19]  [360/1724] loss: 0.446, ave_loss: 0.412
[20]  [380/1724] loss: 0.371, ave_loss: 0.410
[21]  [400/1724] loss: 0.497, ave_loss: 0.414
[22]  [420/1724] loss: 0.471, ave_loss: 0.417
[23]  [440/1724] loss: 0.449, ave_loss: 0.418
[24]  [460/1724] loss: 0.332, ave_loss: 0.415
[25]  [480/1724] loss: 0.503, ave_loss: 0.418
[26]  [500/1724] loss: 0.513, ave_loss: 0.422
[27]  [520/1724] loss: 0.398, ave_loss: 0.421
[28]  [540/1724] loss: 0.308, ave_loss: 0.417
[29]  [560/1724] loss: 0.452, ave_loss: 0.418
[30]  [580/1724] loss: 0.425, ave_loss: 0.418
[31]  [600/1724] loss: 0.311, ave_loss: 0.415
[32]  [620/1724] loss: 0.316, ave_loss: 0.412
[33]  [640/1724] loss: 0.380, ave_loss: 0.411
[34]  [660/1724] loss: 0.336, ave_loss: 0.409
[35]  [680/1724] loss: 0.333, ave_loss: 0.406
[36]  [700/1724] loss: 0.438, ave_loss: 0.407
[37]  [720/1724] loss: 0.502, ave_loss: 0.410
[38]  [740/1724] loss: 0.453, ave_loss: 0.411
[39]  [760/1724] loss: 0.394, ave_loss: 0.411
[40]  [780/1724] loss: 0.358, ave_loss: 0.409
[41]  [800/1724] loss: 0.560, ave_loss: 0.413
[42]  [820/1724] loss: 0.434, ave_loss: 0.413
[43]  [840/1724] loss: 0.330, ave_loss: 0.411
[44]  [860/1724] loss: 0.551, ave_loss: 0.415
[45]  [880/1724] loss: 0.565, ave_loss: 0.418
[46]  [900/1724] loss: 0.361, ave_loss: 0.417
[47]  [920/1724] loss: 0.656, ave_loss: 0.422
[48]  [940/1724] loss: 0.509, ave_loss: 0.424
[49]  [960/1724] loss: 0.459, ave_loss: 0.424
[50]  [980/1724] loss: 0.415, ave_loss: 0.424
[51]  [1000/1724] loss: 0.375, ave_loss: 0.423
[52]  [1020/1724] loss: 0.360, ave_loss: 0.422
[53]  [1040/1724] loss: 0.307, ave_loss: 0.420
[54]  [1060/1724] loss: 0.425, ave_loss: 0.420
[55]  [1080/1724] loss: 0.333, ave_loss: 0.418
[56]  [1100/1724] loss: 0.421, ave_loss: 0.418
[57]  [1120/1724] loss: 0.341, ave_loss: 0.417
[58]  [1140/1724] loss: 0.567, ave_loss: 0.420
[59]  [1160/1724] loss: 0.314, ave_loss: 0.418
[60]  [1180/1724] loss: 0.323, ave_loss: 0.416
[61]  [1200/1724] loss: 0.416, ave_loss: 0.416
[62]  [1220/1724] loss: 0.368, ave_loss: 0.415
[63]  [1240/1724] loss: 0.325, ave_loss: 0.414
[64]  [1260/1724] loss: 0.404, ave_loss: 0.414
[65]  [1280/1724] loss: 0.465, ave_loss: 0.415
[66]  [1300/1724] loss: 0.482, ave_loss: 0.416
[67]  [1320/1724] loss: 0.394, ave_loss: 0.415
[68]  [1340/1724] loss: 0.392, ave_loss: 0.415
[69]  [1360/1724] loss: 0.393, ave_loss: 0.415
[70]  [1380/1724] loss: 0.370, ave_loss: 0.414
[71]  [1400/1724] loss: 0.402, ave_loss: 0.414
[72]  [1420/1724] loss: 0.310, ave_loss: 0.412
[73]  [1440/1724] loss: 0.393, ave_loss: 0.412
[74]  [1460/1724] loss: 0.378, ave_loss: 0.412
[75]  [1480/1724] loss: 0.326, ave_loss: 0.411
[76]  [1500/1724] loss: 0.382, ave_loss: 0.410
[77]  [1520/1724] loss: 0.317, ave_loss: 0.409
[78]  [1540/1724] loss: 0.272, ave_loss: 0.407
[79]  [1560/1724] loss: 0.386, ave_loss: 0.407
[80]  [1580/1724] loss: 0.395, ave_loss: 0.407
[81]  [1600/1724] loss: 0.349, ave_loss: 0.406
[82]  [1620/1724] loss: 0.429, ave_loss: 0.406
[83]  [1640/1724] loss: 0.371, ave_loss: 0.406
[84]  [1660/1724] loss: 0.327, ave_loss: 0.405
[85]  [1680/1724] loss: 0.415, ave_loss: 0.405
[86]  [1700/1724] loss: 0.483, ave_loss: 0.406
[87]  [1720/1724] loss: 0.381, ave_loss: 0.406
[88]  [1740/1724] loss: 0.467, ave_loss: 0.406

Finished Training finishing at 2021-08-24 19:47:44.290014
printing_out epoch  15.31322505800464 learning rate: 0.00038719468432148055
0.0003755788437918361
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.064e-01
Validation Loss: 5.265e+03
Validation ROC: 0.7675
No improvement, still saving model
83.68677494199537 epochs left to go

Training Epoch 15.31322505800464/100 starting at 2021-08-24 19:48:22.970304
[1]  [0/1724] loss: 0.526, ave_loss: 0.526
[2]  [20/1724] loss: 0.427, ave_loss: 0.477
[3]  [40/1724] loss: 0.417, ave_loss: 0.457
[4]  [60/1724] loss: 0.536, ave_loss: 0.476
[5]  [80/1724] loss: 0.426, ave_loss: 0.466
[6]  [100/1724] loss: 0.418, ave_loss: 0.458
[7]  [120/1724] loss: 0.609, ave_loss: 0.480
[8]  [140/1724] loss: 0.393, ave_loss: 0.469
[9]  [160/1724] loss: 0.302, ave_loss: 0.450
[10]  [180/1724] loss: 0.363, ave_loss: 0.442
[11]  [200/1724] loss: 0.443, ave_loss: 0.442
[12]  [220/1724] loss: 0.277, ave_loss: 0.428
[13]  [240/1724] loss: 0.585, ave_loss: 0.440
[14]  [260/1724] loss: 0.421, ave_loss: 0.439
[15]  [280/1724] loss: 0.466, ave_loss: 0.440
[16]  [300/1724] loss: 0.260, ave_loss: 0.429
[17]  [320/1724] loss: 0.310, ave_loss: 0.422
[18]  [340/1724] loss: 0.408, ave_loss: 0.421
[19]  [360/1724] loss: 0.408, ave_loss: 0.421
[20]  [380/1724] loss: 0.415, ave_loss: 0.420
[21]  [400/1724] loss: 0.362, ave_loss: 0.418
[22]  [420/1724] loss: 0.555, ave_loss: 0.424
[23]  [440/1724] loss: 0.368, ave_loss: 0.421
[24]  [460/1724] loss: 0.492, ave_loss: 0.424
[25]  [480/1724] loss: 0.439, ave_loss: 0.425
[26]  [500/1724] loss: 0.373, ave_loss: 0.423
[27]  [520/1724] loss: 0.590, ave_loss: 0.429
[28]  [540/1724] loss: 0.474, ave_loss: 0.431
[29]  [560/1724] loss: 0.392, ave_loss: 0.429
[30]  [580/1724] loss: 0.576, ave_loss: 0.434
[31]  [600/1724] loss: 0.395, ave_loss: 0.433
[32]  [620/1724] loss: 0.423, ave_loss: 0.433
[33]  [640/1724] loss: 0.356, ave_loss: 0.430
[34]  [660/1724] loss: 0.389, ave_loss: 0.429
[35]  [680/1724] loss: 0.438, ave_loss: 0.429
[36]  [700/1724] loss: 0.345, ave_loss: 0.427
[37]  [720/1724] loss: 0.413, ave_loss: 0.427
[38]  [740/1724] loss: 0.449, ave_loss: 0.427
[39]  [760/1724] loss: 0.468, ave_loss: 0.428
[40]  [780/1724] loss: 0.519, ave_loss: 0.431
[41]  [800/1724] loss: 0.357, ave_loss: 0.429
[42]  [820/1724] loss: 0.393, ave_loss: 0.428
[43]  [840/1724] loss: 0.374, ave_loss: 0.427
[44]  [860/1724] loss: 0.364, ave_loss: 0.425
[45]  [880/1724] loss: 0.308, ave_loss: 0.423
[46]  [900/1724] loss: 0.475, ave_loss: 0.424
[47]  [920/1724] loss: 0.367, ave_loss: 0.423
[48]  [940/1724] loss: 0.445, ave_loss: 0.423
[49]  [960/1724] loss: 0.383, ave_loss: 0.422
[50]  [980/1724] loss: 0.584, ave_loss: 0.425
[51]  [1000/1724] loss: 0.395, ave_loss: 0.425
[52]  [1020/1724] loss: 0.312, ave_loss: 0.423
[53]  [1040/1724] loss: 0.290, ave_loss: 0.420
[54]  [1060/1724] loss: 0.500, ave_loss: 0.422
[55]  [1080/1724] loss: 0.407, ave_loss: 0.421
[56]  [1100/1724] loss: 0.471, ave_loss: 0.422
[57]  [1120/1724] loss: 0.589, ave_loss: 0.425
[58]  [1140/1724] loss: 0.306, ave_loss: 0.423
[59]  [1160/1724] loss: 0.281, ave_loss: 0.421
[60]  [1180/1724] loss: 0.346, ave_loss: 0.420
[61]  [1200/1724] loss: 0.398, ave_loss: 0.419
[62]  [1220/1724] loss: 0.265, ave_loss: 0.417
[63]  [1240/1724] loss: 0.262, ave_loss: 0.414
[64]  [1260/1724] loss: 0.388, ave_loss: 0.414
[65]  [1280/1724] loss: 0.386, ave_loss: 0.413
[66]  [1300/1724] loss: 0.431, ave_loss: 0.414
[67]  [1320/1724] loss: 0.350, ave_loss: 0.413
[68]  [1340/1724] loss: 0.373, ave_loss: 0.412
[69]  [1360/1724] loss: 0.315, ave_loss: 0.411
[70]  [1380/1724] loss: 0.318, ave_loss: 0.409
[71]  [1400/1724] loss: 0.322, ave_loss: 0.408
[72]  [1420/1724] loss: 0.415, ave_loss: 0.408
[73]  [1440/1724] loss: 0.437, ave_loss: 0.409
[74]  [1460/1724] loss: 0.435, ave_loss: 0.409
[75]  [1480/1724] loss: 0.392, ave_loss: 0.409
[76]  [1500/1724] loss: 0.441, ave_loss: 0.409
[77]  [1520/1724] loss: 0.330, ave_loss: 0.408
[78]  [1540/1724] loss: 0.380, ave_loss: 0.408
[79]  [1560/1724] loss: 0.339, ave_loss: 0.407
[80]  [1580/1724] loss: 0.333, ave_loss: 0.406
[81]  [1600/1724] loss: 0.388, ave_loss: 0.406
[82]  [1620/1724] loss: 0.466, ave_loss: 0.407
[83]  [1640/1724] loss: 0.370, ave_loss: 0.406
[84]  [1660/1724] loss: 0.333, ave_loss: 0.405
[85]  [1680/1724] loss: 0.470, ave_loss: 0.406
[86]  [1700/1724] loss: 0.352, ave_loss: 0.405
[87]  [1720/1724] loss: 0.388, ave_loss: 0.405
[88]  [1740/1724] loss: 0.356, ave_loss: 0.405

Finished Training finishing at 2021-08-24 19:50:34.562469
printing_out epoch  16.334106728538284 learning rate: 0.0003519951675649823
0.00034143531253803285
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.046e-01
Validation Loss: 4.807e+03
Validation ROC: 0.7655
No improvement, still saving model
82.66589327146171 epochs left to go

Training Epoch 16.334106728538284/100 starting at 2021-08-24 19:51:23.849970
[1]  [0/1724] loss: 0.774, ave_loss: 0.774
[2]  [20/1724] loss: 0.226, ave_loss: 0.500
[3]  [40/1724] loss: 0.432, ave_loss: 0.477
[4]  [60/1724] loss: 0.456, ave_loss: 0.472
[5]  [80/1724] loss: 0.384, ave_loss: 0.455
[6]  [100/1724] loss: 0.552, ave_loss: 0.471
[7]  [120/1724] loss: 0.383, ave_loss: 0.458
[8]  [140/1724] loss: 0.304, ave_loss: 0.439
[9]  [160/1724] loss: 0.537, ave_loss: 0.450
[10]  [180/1724] loss: 0.397, ave_loss: 0.445
[11]  [200/1724] loss: 0.433, ave_loss: 0.444
[12]  [220/1724] loss: 0.383, ave_loss: 0.438
[13]  [240/1724] loss: 0.430, ave_loss: 0.438
[14]  [260/1724] loss: 0.386, ave_loss: 0.434
[15]  [280/1724] loss: 0.340, ave_loss: 0.428
[16]  [300/1724] loss: 0.535, ave_loss: 0.435
[17]  [320/1724] loss: 0.504, ave_loss: 0.439
[18]  [340/1724] loss: 0.545, ave_loss: 0.445
[19]  [360/1724] loss: 0.294, ave_loss: 0.437
[20]  [380/1724] loss: 0.508, ave_loss: 0.440
[21]  [400/1724] loss: 0.382, ave_loss: 0.437
[22]  [420/1724] loss: 0.377, ave_loss: 0.435
[23]  [440/1724] loss: 0.353, ave_loss: 0.431
[24]  [460/1724] loss: 0.299, ave_loss: 0.426
[25]  [480/1724] loss: 0.513, ave_loss: 0.429
[26]  [500/1724] loss: 0.597, ave_loss: 0.436
[27]  [520/1724] loss: 0.483, ave_loss: 0.437
[28]  [540/1724] loss: 0.367, ave_loss: 0.435
[29]  [560/1724] loss: 0.375, ave_loss: 0.433
[30]  [580/1724] loss: 0.669, ave_loss: 0.441
[31]  [600/1724] loss: 0.332, ave_loss: 0.437
[32]  [620/1724] loss: 0.370, ave_loss: 0.435
[33]  [640/1724] loss: 0.417, ave_loss: 0.435
[34]  [660/1724] loss: 0.365, ave_loss: 0.432
[35]  [680/1724] loss: 0.566, ave_loss: 0.436
[36]  [700/1724] loss: 0.282, ave_loss: 0.432
[37]  [720/1724] loss: 0.313, ave_loss: 0.429
[38]  [740/1724] loss: 0.274, ave_loss: 0.425
[39]  [760/1724] loss: 0.427, ave_loss: 0.425
[40]  [780/1724] loss: 0.359, ave_loss: 0.423
[41]  [800/1724] loss: 0.449, ave_loss: 0.424
[42]  [820/1724] loss: 0.357, ave_loss: 0.422
[43]  [840/1724] loss: 0.277, ave_loss: 0.419
[44]  [860/1724] loss: 0.408, ave_loss: 0.419
[45]  [880/1724] loss: 0.349, ave_loss: 0.417
[46]  [900/1724] loss: 0.254, ave_loss: 0.413
[47]  [920/1724] loss: 0.504, ave_loss: 0.415
[48]  [940/1724] loss: 0.306, ave_loss: 0.413
[49]  [960/1724] loss: 0.417, ave_loss: 0.413
[50]  [980/1724] loss: 0.358, ave_loss: 0.412
[51]  [1000/1724] loss: 0.298, ave_loss: 0.410
[52]  [1020/1724] loss: 0.459, ave_loss: 0.411
[53]  [1040/1724] loss: 0.281, ave_loss: 0.408
[54]  [1060/1724] loss: 0.370, ave_loss: 0.408
[55]  [1080/1724] loss: 0.456, ave_loss: 0.409
[56]  [1100/1724] loss: 0.199, ave_loss: 0.405
[57]  [1120/1724] loss: 0.468, ave_loss: 0.406
[58]  [1140/1724] loss: 0.264, ave_loss: 0.403
[59]  [1160/1724] loss: 0.308, ave_loss: 0.402
[60]  [1180/1724] loss: 0.358, ave_loss: 0.401
[61]  [1200/1724] loss: 0.268, ave_loss: 0.399
[62]  [1220/1724] loss: 0.280, ave_loss: 0.397
[63]  [1240/1724] loss: 0.240, ave_loss: 0.395
[64]  [1260/1724] loss: 0.236, ave_loss: 0.392
[65]  [1280/1724] loss: 0.421, ave_loss: 0.393
[66]  [1300/1724] loss: 0.279, ave_loss: 0.391
[67]  [1320/1724] loss: 0.539, ave_loss: 0.393
[68]  [1340/1724] loss: 0.315, ave_loss: 0.392
[69]  [1360/1724] loss: 0.374, ave_loss: 0.392
[70]  [1380/1724] loss: 0.501, ave_loss: 0.393
[71]  [1400/1724] loss: 0.582, ave_loss: 0.396
[72]  [1420/1724] loss: 0.307, ave_loss: 0.395
[73]  [1440/1724] loss: 0.482, ave_loss: 0.396
[74]  [1460/1724] loss: 0.620, ave_loss: 0.399
[75]  [1480/1724] loss: 0.384, ave_loss: 0.399
[76]  [1500/1724] loss: 0.367, ave_loss: 0.398
[77]  [1520/1724] loss: 0.437, ave_loss: 0.399
[78]  [1540/1724] loss: 0.313, ave_loss: 0.398
[79]  [1560/1724] loss: 0.391, ave_loss: 0.398
[80]  [1580/1724] loss: 0.522, ave_loss: 0.399
[81]  [1600/1724] loss: 0.549, ave_loss: 0.401
[82]  [1620/1724] loss: 0.361, ave_loss: 0.400
[83]  [1640/1724] loss: 0.369, ave_loss: 0.400
[84]  [1660/1724] loss: 0.387, ave_loss: 0.400
[85]  [1680/1724] loss: 0.485, ave_loss: 0.401
[86]  [1700/1724] loss: 0.439, ave_loss: 0.401
[87]  [1720/1724] loss: 0.342, ave_loss: 0.401
[88]  [1740/1724] loss: 0.444, ave_loss: 0.401

Finished Training finishing at 2021-08-24 19:53:29.772737
printing_out epoch  17.354988399071924 learning rate: 0.0003199956068772566
0.0003103957386709389
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.012e-01
Validation Loss: 4.181e+03
Validation ROC: 0.7671
No improvement, still saving model
81.64501160092807 epochs left to go

Training Epoch 17.354988399071924/100 starting at 2021-08-24 19:54:44.268248
[1]  [0/1724] loss: 0.438, ave_loss: 0.438
[2]  [20/1724] loss: 0.365, ave_loss: 0.402
[3]  [40/1724] loss: 0.390, ave_loss: 0.398
[4]  [60/1724] loss: 0.400, ave_loss: 0.398
[5]  [80/1724] loss: 0.476, ave_loss: 0.414
[6]  [100/1724] loss: 0.485, ave_loss: 0.426
[7]  [120/1724] loss: 0.414, ave_loss: 0.424
[8]  [140/1724] loss: 0.404, ave_loss: 0.421
[9]  [160/1724] loss: 0.452, ave_loss: 0.425
[10]  [180/1724] loss: 0.365, ave_loss: 0.419
[11]  [200/1724] loss: 0.328, ave_loss: 0.411
[12]  [220/1724] loss: 0.393, ave_loss: 0.409
[13]  [240/1724] loss: 0.565, ave_loss: 0.421
[14]  [260/1724] loss: 0.330, ave_loss: 0.415
[15]  [280/1724] loss: 0.436, ave_loss: 0.416
[16]  [300/1724] loss: 0.312, ave_loss: 0.409
[17]  [320/1724] loss: 0.411, ave_loss: 0.410
[18]  [340/1724] loss: 0.350, ave_loss: 0.406
[19]  [360/1724] loss: 0.503, ave_loss: 0.411
[20]  [380/1724] loss: 0.294, ave_loss: 0.405
[21]  [400/1724] loss: 0.418, ave_loss: 0.406
[22]  [420/1724] loss: 0.326, ave_loss: 0.402
[23]  [440/1724] loss: 0.426, ave_loss: 0.403
[24]  [460/1724] loss: 0.448, ave_loss: 0.405
[25]  [480/1724] loss: 0.421, ave_loss: 0.406
[26]  [500/1724] loss: 0.322, ave_loss: 0.403
[27]  [520/1724] loss: 0.479, ave_loss: 0.406
[28]  [540/1724] loss: 0.456, ave_loss: 0.407
[29]  [560/1724] loss: 0.323, ave_loss: 0.404
[30]  [580/1724] loss: 0.451, ave_loss: 0.406
[31]  [600/1724] loss: 0.393, ave_loss: 0.406
[32]  [620/1724] loss: 0.410, ave_loss: 0.406
[33]  [640/1724] loss: 0.426, ave_loss: 0.406
[34]  [660/1724] loss: 0.465, ave_loss: 0.408
[35]  [680/1724] loss: 0.331, ave_loss: 0.406
[36]  [700/1724] loss: 0.358, ave_loss: 0.404
[37]  [720/1724] loss: 0.297, ave_loss: 0.402
[38]  [740/1724] loss: 0.443, ave_loss: 0.403
[39]  [760/1724] loss: 0.337, ave_loss: 0.401
[40]  [780/1724] loss: 0.328, ave_loss: 0.399
[41]  [800/1724] loss: 0.288, ave_loss: 0.396
[42]  [820/1724] loss: 0.296, ave_loss: 0.394
[43]  [840/1724] loss: 0.336, ave_loss: 0.393
[44]  [860/1724] loss: 0.378, ave_loss: 0.392
[45]  [880/1724] loss: 0.306, ave_loss: 0.390
[46]  [900/1724] loss: 0.615, ave_loss: 0.395
[47]  [920/1724] loss: 0.438, ave_loss: 0.396
[48]  [940/1724] loss: 0.384, ave_loss: 0.396
[49]  [960/1724] loss: 0.410, ave_loss: 0.396
[50]  [980/1724] loss: 0.374, ave_loss: 0.396
[51]  [1000/1724] loss: 0.380, ave_loss: 0.396
[52]  [1020/1724] loss: 0.329, ave_loss: 0.394
[53]  [1040/1724] loss: 0.311, ave_loss: 0.393
[54]  [1060/1724] loss: 0.285, ave_loss: 0.391
[55]  [1080/1724] loss: 0.454, ave_loss: 0.392
[56]  [1100/1724] loss: 0.496, ave_loss: 0.394
[57]  [1120/1724] loss: 0.404, ave_loss: 0.394
[58]  [1140/1724] loss: 0.834, ave_loss: 0.401
[59]  [1160/1724] loss: 0.504, ave_loss: 0.403
[60]  [1180/1724] loss: 0.484, ave_loss: 0.405
[61]  [1200/1724] loss: 0.359, ave_loss: 0.404
[62]  [1220/1724] loss: 0.256, ave_loss: 0.401
[63]  [1240/1724] loss: 0.319, ave_loss: 0.400
[64]  [1260/1724] loss: 0.339, ave_loss: 0.399
[65]  [1280/1724] loss: 0.512, ave_loss: 0.401
[66]  [1300/1724] loss: 0.302, ave_loss: 0.399
[67]  [1320/1724] loss: 0.280, ave_loss: 0.398
[68]  [1340/1724] loss: 0.285, ave_loss: 0.396
[69]  [1360/1724] loss: 0.303, ave_loss: 0.395
[70]  [1380/1724] loss: 0.290, ave_loss: 0.393
[71]  [1400/1724] loss: 0.289, ave_loss: 0.392
[72]  [1420/1724] loss: 0.329, ave_loss: 0.391
[73]  [1440/1724] loss: 0.305, ave_loss: 0.390
[74]  [1460/1724] loss: 0.284, ave_loss: 0.388
[75]  [1480/1724] loss: 0.317, ave_loss: 0.387
[76]  [1500/1724] loss: 0.359, ave_loss: 0.387
[77]  [1520/1724] loss: 0.352, ave_loss: 0.386
[78]  [1540/1724] loss: 0.400, ave_loss: 0.387
[79]  [1560/1724] loss: 0.473, ave_loss: 0.388
[80]  [1580/1724] loss: 0.554, ave_loss: 0.390
[81]  [1600/1724] loss: 0.217, ave_loss: 0.388
[82]  [1620/1724] loss: 0.620, ave_loss: 0.390
[83]  [1640/1724] loss: 0.385, ave_loss: 0.390
[84]  [1660/1724] loss: 0.583, ave_loss: 0.393
[85]  [1680/1724] loss: 0.324, ave_loss: 0.392
[86]  [1700/1724] loss: 0.412, ave_loss: 0.392
[87]  [1720/1724] loss: 0.363, ave_loss: 0.392
[88]  [1740/1724] loss: 0.299, ave_loss: 0.391

Finished Training finishing at 2021-08-24 19:57:02.704216
printing_out epoch  18.37587006960557 learning rate: 0.00029090509716114235
0.0002821779442463081
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.907e-01
Validation Loss: 3.175e+03
Validation ROC: 0.7664
No improvement, still saving model
80.62412993039443 epochs left to go

Training Epoch 18.37587006960557/100 starting at 2021-08-24 19:57:30.466385
[1]  [0/1724] loss: 0.625, ave_loss: 0.625
[2]  [20/1724] loss: 0.468, ave_loss: 0.547
[3]  [40/1724] loss: 0.356, ave_loss: 0.483
[4]  [60/1724] loss: 0.395, ave_loss: 0.461
[5]  [80/1724] loss: 0.324, ave_loss: 0.434
[6]  [100/1724] loss: 0.440, ave_loss: 0.435
[7]  [120/1724] loss: 0.435, ave_loss: 0.435
[8]  [140/1724] loss: 0.363, ave_loss: 0.426
[9]  [160/1724] loss: 0.346, ave_loss: 0.417
[10]  [180/1724] loss: 0.415, ave_loss: 0.417
[11]  [200/1724] loss: 0.460, ave_loss: 0.421
[12]  [220/1724] loss: 0.392, ave_loss: 0.418
[13]  [240/1724] loss: 0.340, ave_loss: 0.412
[14]  [260/1724] loss: 0.319, ave_loss: 0.406
[15]  [280/1724] loss: 0.401, ave_loss: 0.405
[16]  [300/1724] loss: 0.272, ave_loss: 0.397
[17]  [320/1724] loss: 0.399, ave_loss: 0.397
[18]  [340/1724] loss: 0.466, ave_loss: 0.401
[19]  [360/1724] loss: 0.368, ave_loss: 0.399
[20]  [380/1724] loss: 0.422, ave_loss: 0.400
[21]  [400/1724] loss: 0.605, ave_loss: 0.410
[22]  [420/1724] loss: 0.431, ave_loss: 0.411
[23]  [440/1724] loss: 0.562, ave_loss: 0.417
[24]  [460/1724] loss: 0.316, ave_loss: 0.413
[25]  [480/1724] loss: 0.327, ave_loss: 0.410
[26]  [500/1724] loss: 0.439, ave_loss: 0.411
[27]  [520/1724] loss: 0.562, ave_loss: 0.417
[28]  [540/1724] loss: 0.417, ave_loss: 0.417
[29]  [560/1724] loss: 0.329, ave_loss: 0.414
[30]  [580/1724] loss: 0.516, ave_loss: 0.417
[31]  [600/1724] loss: 0.315, ave_loss: 0.414
[32]  [620/1724] loss: 0.401, ave_loss: 0.413
[33]  [640/1724] loss: 0.543, ave_loss: 0.417
[34]  [660/1724] loss: 0.331, ave_loss: 0.415
[35]  [680/1724] loss: 0.420, ave_loss: 0.415
[36]  [700/1724] loss: 0.393, ave_loss: 0.414
[37]  [720/1724] loss: 0.428, ave_loss: 0.415
[38]  [740/1724] loss: 0.287, ave_loss: 0.411
[39]  [760/1724] loss: 0.393, ave_loss: 0.411
[40]  [780/1724] loss: 0.357, ave_loss: 0.409
[41]  [800/1724] loss: 0.402, ave_loss: 0.409
[42]  [820/1724] loss: 0.233, ave_loss: 0.405
[43]  [840/1724] loss: 0.246, ave_loss: 0.401
[44]  [860/1724] loss: 0.252, ave_loss: 0.398
[45]  [880/1724] loss: 0.595, ave_loss: 0.402
[46]  [900/1724] loss: 0.319, ave_loss: 0.400
[47]  [920/1724] loss: 0.508, ave_loss: 0.403
[48]  [940/1724] loss: 0.327, ave_loss: 0.401
[49]  [960/1724] loss: 0.388, ave_loss: 0.401
[50]  [980/1724] loss: 0.295, ave_loss: 0.399
[51]  [1000/1724] loss: 0.456, ave_loss: 0.400
[52]  [1020/1724] loss: 0.373, ave_loss: 0.399
[53]  [1040/1724] loss: 0.520, ave_loss: 0.402
[54]  [1060/1724] loss: 0.264, ave_loss: 0.399
[55]  [1080/1724] loss: 0.418, ave_loss: 0.399
[56]  [1100/1724] loss: 0.298, ave_loss: 0.398
[57]  [1120/1724] loss: 0.358, ave_loss: 0.397
[58]  [1140/1724] loss: 0.418, ave_loss: 0.397
[59]  [1160/1724] loss: 0.621, ave_loss: 0.401
[60]  [1180/1724] loss: 0.322, ave_loss: 0.400
[61]  [1200/1724] loss: 0.436, ave_loss: 0.400
[62]  [1220/1724] loss: 0.388, ave_loss: 0.400
[63]  [1240/1724] loss: 0.271, ave_loss: 0.398
[64]  [1260/1724] loss: 0.411, ave_loss: 0.398
[65]  [1280/1724] loss: 0.349, ave_loss: 0.398
[66]  [1300/1724] loss: 0.601, ave_loss: 0.401
[67]  [1320/1724] loss: 0.526, ave_loss: 0.403
[68]  [1340/1724] loss: 0.289, ave_loss: 0.401
[69]  [1360/1724] loss: 0.328, ave_loss: 0.400
[70]  [1380/1724] loss: 0.317, ave_loss: 0.399
[71]  [1400/1724] loss: 0.339, ave_loss: 0.398
[72]  [1420/1724] loss: 0.312, ave_loss: 0.397
[73]  [1440/1724] loss: 0.310, ave_loss: 0.395
[74]  [1460/1724] loss: 0.315, ave_loss: 0.394
[75]  [1480/1724] loss: 0.289, ave_loss: 0.393
[76]  [1500/1724] loss: 0.341, ave_loss: 0.392
[77]  [1520/1724] loss: 0.274, ave_loss: 0.391
[78]  [1540/1724] loss: 0.502, ave_loss: 0.392
[79]  [1560/1724] loss: 0.272, ave_loss: 0.391
[80]  [1580/1724] loss: 0.406, ave_loss: 0.391
[81]  [1600/1724] loss: 0.461, ave_loss: 0.392
[82]  [1620/1724] loss: 0.467, ave_loss: 0.393
[83]  [1640/1724] loss: 0.287, ave_loss: 0.391
[84]  [1660/1724] loss: 0.692, ave_loss: 0.395
[85]  [1680/1724] loss: 0.318, ave_loss: 0.394
[86]  [1700/1724] loss: 0.300, ave_loss: 0.393
[87]  [1720/1724] loss: 0.343, ave_loss: 0.392
[88]  [1740/1724] loss: 0.355, ave_loss: 0.392

Finished Training finishing at 2021-08-24 19:59:33.935898
printing_out epoch  19.396751740139212 learning rate: 0.00026445917923740214
0.0002565254038602801
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.919e-01
Validation Loss: 4.065e+03
Validation ROC: 0.7681
No improvement, still saving model
79.60324825986079 epochs left to go

Training Epoch 19.396751740139212/100 starting at 2021-08-24 20:00:12.272586
[1]  [0/1724] loss: 0.573, ave_loss: 0.573
[2]  [20/1724] loss: 0.434, ave_loss: 0.503
[3]  [40/1724] loss: 0.273, ave_loss: 0.427
[4]  [60/1724] loss: 0.546, ave_loss: 0.457
[5]  [80/1724] loss: 0.188, ave_loss: 0.403
[6]  [100/1724] loss: 0.248, ave_loss: 0.377
[7]  [120/1724] loss: 0.452, ave_loss: 0.388
[8]  [140/1724] loss: 0.371, ave_loss: 0.386
[9]  [160/1724] loss: 0.427, ave_loss: 0.390
[10]  [180/1724] loss: 0.337, ave_loss: 0.385
[11]  [200/1724] loss: 0.416, ave_loss: 0.388
[12]  [220/1724] loss: 0.412, ave_loss: 0.390
[13]  [240/1724] loss: 0.403, ave_loss: 0.391
[14]  [260/1724] loss: 0.311, ave_loss: 0.385
[15]  [280/1724] loss: 0.444, ave_loss: 0.389
[16]  [300/1724] loss: 0.469, ave_loss: 0.394
[17]  [320/1724] loss: 0.200, ave_loss: 0.383
[18]  [340/1724] loss: 0.274, ave_loss: 0.377
[19]  [360/1724] loss: 0.478, ave_loss: 0.382
[20]  [380/1724] loss: 0.386, ave_loss: 0.382
[21]  [400/1724] loss: 0.344, ave_loss: 0.380
[22]  [420/1724] loss: 0.368, ave_loss: 0.380
[23]  [440/1724] loss: 0.474, ave_loss: 0.384
[24]  [460/1724] loss: 0.638, ave_loss: 0.394
[25]  [480/1724] loss: 0.423, ave_loss: 0.396
[26]  [500/1724] loss: 0.301, ave_loss: 0.392
[27]  [520/1724] loss: 0.240, ave_loss: 0.386
[28]  [540/1724] loss: 0.285, ave_loss: 0.383
[29]  [560/1724] loss: 0.487, ave_loss: 0.386
[30]  [580/1724] loss: 0.357, ave_loss: 0.385
[31]  [600/1724] loss: 0.497, ave_loss: 0.389
[32]  [620/1724] loss: 0.543, ave_loss: 0.394
[33]  [640/1724] loss: 0.436, ave_loss: 0.395
[34]  [660/1724] loss: 0.317, ave_loss: 0.393
[35]  [680/1724] loss: 0.446, ave_loss: 0.394
[36]  [700/1724] loss: 0.351, ave_loss: 0.393
[37]  [720/1724] loss: 0.275, ave_loss: 0.390
[38]  [740/1724] loss: 0.413, ave_loss: 0.390
[39]  [760/1724] loss: 0.366, ave_loss: 0.390
[40]  [780/1724] loss: 0.348, ave_loss: 0.389
[41]  [800/1724] loss: 0.460, ave_loss: 0.391
[42]  [820/1724] loss: 0.370, ave_loss: 0.390
[43]  [840/1724] loss: 0.446, ave_loss: 0.391
[44]  [860/1724] loss: 0.568, ave_loss: 0.395
[45]  [880/1724] loss: 0.356, ave_loss: 0.394
[46]  [900/1724] loss: 0.581, ave_loss: 0.399
[47]  [920/1724] loss: 0.417, ave_loss: 0.399
[48]  [940/1724] loss: 0.366, ave_loss: 0.398
[49]  [960/1724] loss: 0.238, ave_loss: 0.395
[50]  [980/1724] loss: 0.304, ave_loss: 0.393
[51]  [1000/1724] loss: 0.357, ave_loss: 0.392
[52]  [1020/1724] loss: 0.394, ave_loss: 0.392
[53]  [1040/1724] loss: 0.453, ave_loss: 0.394
[54]  [1060/1724] loss: 0.365, ave_loss: 0.393
[55]  [1080/1724] loss: 0.394, ave_loss: 0.393
[56]  [1100/1724] loss: 0.457, ave_loss: 0.394
[57]  [1120/1724] loss: 0.484, ave_loss: 0.396
[58]  [1140/1724] loss: 0.400, ave_loss: 0.396
[59]  [1160/1724] loss: 0.467, ave_loss: 0.397
[60]  [1180/1724] loss: 0.378, ave_loss: 0.397
[61]  [1200/1724] loss: 0.367, ave_loss: 0.396
[62]  [1220/1724] loss: 0.302, ave_loss: 0.395
[63]  [1240/1724] loss: 0.335, ave_loss: 0.394
[64]  [1260/1724] loss: 0.447, ave_loss: 0.395
[65]  [1280/1724] loss: 0.437, ave_loss: 0.395
[66]  [1300/1724] loss: 0.219, ave_loss: 0.393
[67]  [1320/1724] loss: 0.320, ave_loss: 0.392
[68]  [1340/1724] loss: 0.477, ave_loss: 0.393
[69]  [1360/1724] loss: 0.386, ave_loss: 0.393
[70]  [1380/1724] loss: 0.350, ave_loss: 0.392
[71]  [1400/1724] loss: 0.283, ave_loss: 0.391
[72]  [1420/1724] loss: 0.404, ave_loss: 0.391
[73]  [1440/1724] loss: 0.258, ave_loss: 0.389
[74]  [1460/1724] loss: 0.157, ave_loss: 0.386
[75]  [1480/1724] loss: 0.315, ave_loss: 0.385
[76]  [1500/1724] loss: 0.345, ave_loss: 0.384
[77]  [1520/1724] loss: 0.338, ave_loss: 0.384
[78]  [1540/1724] loss: 0.549, ave_loss: 0.386
[79]  [1560/1724] loss: 0.631, ave_loss: 0.389
[80]  [1580/1724] loss: 0.466, ave_loss: 0.390
[81]  [1600/1724] loss: 0.229, ave_loss: 0.388
[82]  [1620/1724] loss: 0.280, ave_loss: 0.387
[83]  [1640/1724] loss: 0.521, ave_loss: 0.388
[84]  [1660/1724] loss: 0.329, ave_loss: 0.388
[85]  [1680/1724] loss: 0.361, ave_loss: 0.387
[86]  [1700/1724] loss: 0.538, ave_loss: 0.389
[87]  [1720/1724] loss: 0.617, ave_loss: 0.392
[88]  [1740/1724] loss: 0.413, ave_loss: 0.392

Finished Training finishing at 2021-08-24 20:02:28.032403
printing_out epoch  20.417633410672853 learning rate: 0.00024041743567036557
0.0002332049126002546
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.918e-01
Validation Loss: 2.720e+03
Validation ROC: 0.7659
No improvement, still saving model
78.58236658932715 epochs left to go

Training Epoch 20.417633410672853/100 starting at 2021-08-24 20:03:09.136061
[1]  [0/1724] loss: 0.397, ave_loss: 0.397
[2]  [20/1724] loss: 0.385, ave_loss: 0.391
[3]  [40/1724] loss: 0.423, ave_loss: 0.402
[4]  [60/1724] loss: 0.457, ave_loss: 0.415
[5]  [80/1724] loss: 0.351, ave_loss: 0.402
[6]  [100/1724] loss: 0.424, ave_loss: 0.406
[7]  [120/1724] loss: 0.471, ave_loss: 0.415
[8]  [140/1724] loss: 0.282, ave_loss: 0.399
[9]  [160/1724] loss: 0.589, ave_loss: 0.420
[10]  [180/1724] loss: 0.343, ave_loss: 0.412
[11]  [200/1724] loss: 0.259, ave_loss: 0.398
[12]  [220/1724] loss: 0.489, ave_loss: 0.406
[13]  [240/1724] loss: 0.466, ave_loss: 0.410
[14]  [260/1724] loss: 0.394, ave_loss: 0.409
[15]  [280/1724] loss: 0.304, ave_loss: 0.402
[16]  [300/1724] loss: 0.289, ave_loss: 0.395
[17]  [320/1724] loss: 0.429, ave_loss: 0.397
[18]  [340/1724] loss: 0.446, ave_loss: 0.400
[19]  [360/1724] loss: 0.368, ave_loss: 0.398
[20]  [380/1724] loss: 0.362, ave_loss: 0.396
[21]  [400/1724] loss: 0.302, ave_loss: 0.392
[22]  [420/1724] loss: 0.487, ave_loss: 0.396
[23]  [440/1724] loss: 0.496, ave_loss: 0.401
[24]  [460/1724] loss: 0.424, ave_loss: 0.402
[25]  [480/1724] loss: 0.260, ave_loss: 0.396
[26]  [500/1724] loss: 0.363, ave_loss: 0.395
[27]  [520/1724] loss: 0.311, ave_loss: 0.391
[28]  [540/1724] loss: 0.514, ave_loss: 0.396
[29]  [560/1724] loss: 0.504, ave_loss: 0.400
[30]  [580/1724] loss: 0.319, ave_loss: 0.397
[31]  [600/1724] loss: 0.354, ave_loss: 0.396
[32]  [620/1724] loss: 0.435, ave_loss: 0.397
[33]  [640/1724] loss: 0.368, ave_loss: 0.396
[34]  [660/1724] loss: 0.317, ave_loss: 0.394
[35]  [680/1724] loss: 0.396, ave_loss: 0.394
[36]  [700/1724] loss: 0.363, ave_loss: 0.393
[37]  [720/1724] loss: 0.329, ave_loss: 0.391
[38]  [740/1724] loss: 0.351, ave_loss: 0.390
[39]  [760/1724] loss: 0.522, ave_loss: 0.393
[40]  [780/1724] loss: 0.375, ave_loss: 0.393
[41]  [800/1724] loss: 0.326, ave_loss: 0.391
[42]  [820/1724] loss: 0.367, ave_loss: 0.391
[43]  [840/1724] loss: 0.291, ave_loss: 0.388
[44]  [860/1724] loss: 0.327, ave_loss: 0.387
[45]  [880/1724] loss: 0.369, ave_loss: 0.387
[46]  [900/1724] loss: 0.452, ave_loss: 0.388
[47]  [920/1724] loss: 0.356, ave_loss: 0.387
[48]  [940/1724] loss: 0.349, ave_loss: 0.387
[49]  [960/1724] loss: 0.373, ave_loss: 0.386
[50]  [980/1724] loss: 0.592, ave_loss: 0.390
[51]  [1000/1724] loss: 0.395, ave_loss: 0.391
[52]  [1020/1724] loss: 0.589, ave_loss: 0.394
[53]  [1040/1724] loss: 0.271, ave_loss: 0.392
[54]  [1060/1724] loss: 0.603, ave_loss: 0.396
[55]  [1080/1724] loss: 0.401, ave_loss: 0.396
[56]  [1100/1724] loss: 0.388, ave_loss: 0.396
[57]  [1120/1724] loss: 0.442, ave_loss: 0.397
[58]  [1140/1724] loss: 0.379, ave_loss: 0.396
[59]  [1160/1724] loss: 0.426, ave_loss: 0.397
[60]  [1180/1724] loss: 0.503, ave_loss: 0.399
[61]  [1200/1724] loss: 0.337, ave_loss: 0.398
[62]  [1220/1724] loss: 0.316, ave_loss: 0.396
[63]  [1240/1724] loss: 0.415, ave_loss: 0.397
[64]  [1260/1724] loss: 0.418, ave_loss: 0.397
[65]  [1280/1724] loss: 0.257, ave_loss: 0.395
[66]  [1300/1724] loss: 0.437, ave_loss: 0.395
[67]  [1320/1724] loss: 0.415, ave_loss: 0.396
[68]  [1340/1724] loss: 0.381, ave_loss: 0.395
[69]  [1360/1724] loss: 0.294, ave_loss: 0.394
[70]  [1380/1724] loss: 0.289, ave_loss: 0.393
[71]  [1400/1724] loss: 0.496, ave_loss: 0.394
[72]  [1420/1724] loss: 0.326, ave_loss: 0.393
[73]  [1440/1724] loss: 0.341, ave_loss: 0.392
[74]  [1460/1724] loss: 0.397, ave_loss: 0.392
[75]  [1480/1724] loss: 0.429, ave_loss: 0.393
[76]  [1500/1724] loss: 0.332, ave_loss: 0.392
[77]  [1520/1724] loss: 0.367, ave_loss: 0.392
[78]  [1540/1724] loss: 0.456, ave_loss: 0.393
[79]  [1560/1724] loss: 0.407, ave_loss: 0.393
[80]  [1580/1724] loss: 0.280, ave_loss: 0.391
[81]  [1600/1724] loss: 0.496, ave_loss: 0.393
[82]  [1620/1724] loss: 0.401, ave_loss: 0.393
[83]  [1640/1724] loss: 0.424, ave_loss: 0.393
[84]  [1660/1724] loss: 0.430, ave_loss: 0.394
[85]  [1680/1724] loss: 0.364, ave_loss: 0.393
[86]  [1700/1724] loss: 0.281, ave_loss: 0.392
[87]  [1720/1724] loss: 0.372, ave_loss: 0.392
[88]  [1740/1724] loss: 0.422, ave_loss: 0.392

Finished Training finishing at 2021-08-24 20:05:08.114319
printing_out epoch  21.438515081206496 learning rate: 0.00021856130515487778
0.00021200446600023144
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.920e-01
Validation Loss: 3.294e+03
Validation ROC: 0.7737
Saving model
77.5614849187935 epochs left to go

Training Epoch 21.438515081206496/100 starting at 2021-08-24 20:06:04.966779
[1]  [0/1724] loss: 0.369, ave_loss: 0.369
[2]  [20/1724] loss: 0.434, ave_loss: 0.401
[3]  [40/1724] loss: 0.290, ave_loss: 0.364
[4]  [60/1724] loss: 0.500, ave_loss: 0.398
[5]  [80/1724] loss: 0.450, ave_loss: 0.409
[6]  [100/1724] loss: 0.394, ave_loss: 0.406
[7]  [120/1724] loss: 0.220, ave_loss: 0.380
[8]  [140/1724] loss: 0.365, ave_loss: 0.378
[9]  [160/1724] loss: 0.387, ave_loss: 0.379
[10]  [180/1724] loss: 0.561, ave_loss: 0.397
[11]  [200/1724] loss: 0.244, ave_loss: 0.383
[12]  [220/1724] loss: 0.303, ave_loss: 0.376
[13]  [240/1724] loss: 0.398, ave_loss: 0.378
[14]  [260/1724] loss: 0.263, ave_loss: 0.370
[15]  [280/1724] loss: 0.238, ave_loss: 0.361
[16]  [300/1724] loss: 0.395, ave_loss: 0.363
[17]  [320/1724] loss: 0.361, ave_loss: 0.363
[18]  [340/1724] loss: 0.481, ave_loss: 0.370
[19]  [360/1724] loss: 0.343, ave_loss: 0.368
[20]  [380/1724] loss: 0.525, ave_loss: 0.376
[21]  [400/1724] loss: 0.523, ave_loss: 0.383
[22]  [420/1724] loss: 0.378, ave_loss: 0.383
[23]  [440/1724] loss: 0.405, ave_loss: 0.384
[24]  [460/1724] loss: 0.438, ave_loss: 0.386
[25]  [480/1724] loss: 0.390, ave_loss: 0.386
[26]  [500/1724] loss: 0.318, ave_loss: 0.384
[27]  [520/1724] loss: 0.338, ave_loss: 0.382
[28]  [540/1724] loss: 0.358, ave_loss: 0.381
[29]  [560/1724] loss: 0.371, ave_loss: 0.381
[30]  [580/1724] loss: 0.379, ave_loss: 0.381
[31]  [600/1724] loss: 0.458, ave_loss: 0.383
[32]  [620/1724] loss: 0.258, ave_loss: 0.379
[33]  [640/1724] loss: 0.310, ave_loss: 0.377
[34]  [660/1724] loss: 0.406, ave_loss: 0.378
[35]  [680/1724] loss: 0.257, ave_loss: 0.375
[36]  [700/1724] loss: 0.469, ave_loss: 0.377
[37]  [720/1724] loss: 0.377, ave_loss: 0.377
[38]  [740/1724] loss: 0.320, ave_loss: 0.376
[39]  [760/1724] loss: 0.305, ave_loss: 0.374
[40]  [780/1724] loss: 0.262, ave_loss: 0.371
[41]  [800/1724] loss: 0.401, ave_loss: 0.372
[42]  [820/1724] loss: 0.322, ave_loss: 0.371
[43]  [840/1724] loss: 0.484, ave_loss: 0.373
[44]  [860/1724] loss: 0.470, ave_loss: 0.375
[45]  [880/1724] loss: 0.580, ave_loss: 0.380
[46]  [900/1724] loss: 0.510, ave_loss: 0.383
[47]  [920/1724] loss: 0.686, ave_loss: 0.389
[48]  [940/1724] loss: 0.277, ave_loss: 0.387
[49]  [960/1724] loss: 0.285, ave_loss: 0.385
[50]  [980/1724] loss: 0.378, ave_loss: 0.385
[51]  [1000/1724] loss: 0.592, ave_loss: 0.389
[52]  [1020/1724] loss: 0.415, ave_loss: 0.389
[53]  [1040/1724] loss: 0.481, ave_loss: 0.391
[54]  [1060/1724] loss: 0.183, ave_loss: 0.387
[55]  [1080/1724] loss: 0.427, ave_loss: 0.388
[56]  [1100/1724] loss: 0.325, ave_loss: 0.387
[57]  [1120/1724] loss: 0.326, ave_loss: 0.386
[58]  [1140/1724] loss: 0.442, ave_loss: 0.387
[59]  [1160/1724] loss: 0.272, ave_loss: 0.385
[60]  [1180/1724] loss: 0.324, ave_loss: 0.384
[61]  [1200/1724] loss: 0.365, ave_loss: 0.383
[62]  [1220/1724] loss: 0.399, ave_loss: 0.384
[63]  [1240/1724] loss: 0.428, ave_loss: 0.384
[64]  [1260/1724] loss: 0.276, ave_loss: 0.383
[65]  [1280/1724] loss: 0.287, ave_loss: 0.381
[66]  [1300/1724] loss: 0.374, ave_loss: 0.381
[67]  [1320/1724] loss: 0.501, ave_loss: 0.383
[68]  [1340/1724] loss: 0.435, ave_loss: 0.384
[69]  [1360/1724] loss: 0.365, ave_loss: 0.383
[70]  [1380/1724] loss: 0.395, ave_loss: 0.384
[71]  [1400/1724] loss: 0.397, ave_loss: 0.384
[72]  [1420/1724] loss: 0.361, ave_loss: 0.383
[73]  [1440/1724] loss: 0.330, ave_loss: 0.383
[74]  [1460/1724] loss: 0.393, ave_loss: 0.383
[75]  [1480/1724] loss: 0.370, ave_loss: 0.383
[76]  [1500/1724] loss: 0.456, ave_loss: 0.384
[77]  [1520/1724] loss: 0.308, ave_loss: 0.383
[78]  [1540/1724] loss: 0.286, ave_loss: 0.381
[79]  [1560/1724] loss: 0.212, ave_loss: 0.379
[80]  [1580/1724] loss: 0.495, ave_loss: 0.381
[81]  [1600/1724] loss: 0.312, ave_loss: 0.380
[82]  [1620/1724] loss: 0.424, ave_loss: 0.380
[83]  [1640/1724] loss: 0.458, ave_loss: 0.381
[84]  [1660/1724] loss: 0.485, ave_loss: 0.383
[85]  [1680/1724] loss: 0.355, ave_loss: 0.382
[86]  [1700/1724] loss: 0.272, ave_loss: 0.381
[87]  [1720/1724] loss: 0.344, ave_loss: 0.381
[88]  [1740/1724] loss: 0.324, ave_loss: 0.380

Finished Training finishing at 2021-08-24 20:08:06.107296
printing_out epoch  22.45939675174014 learning rate: 0.00021856130515487778
0.0002056443320202245
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.799e-01
Validation Loss: 3.055e+03
Validation ROC: 0.7758
Saving model
76.54060324825986 epochs left to go

Training Epoch 22.45939675174014/100 starting at 2021-08-24 20:09:18.587623
[1]  [0/1724] loss: 0.303, ave_loss: 0.303
[2]  [20/1724] loss: 0.450, ave_loss: 0.377
[3]  [40/1724] loss: 0.307, ave_loss: 0.353
[4]  [60/1724] loss: 0.281, ave_loss: 0.335
[5]  [80/1724] loss: 0.528, ave_loss: 0.374
[6]  [100/1724] loss: 0.329, ave_loss: 0.366
[7]  [120/1724] loss: 0.459, ave_loss: 0.380
[8]  [140/1724] loss: 0.342, ave_loss: 0.375
[9]  [160/1724] loss: 0.215, ave_loss: 0.357
[10]  [180/1724] loss: 0.426, ave_loss: 0.364
[11]  [200/1724] loss: 0.483, ave_loss: 0.375
[12]  [220/1724] loss: 0.316, ave_loss: 0.370
[13]  [240/1724] loss: 0.268, ave_loss: 0.362
[14]  [260/1724] loss: 0.364, ave_loss: 0.362
[15]  [280/1724] loss: 0.371, ave_loss: 0.363
[16]  [300/1724] loss: 0.490, ave_loss: 0.371
[17]  [320/1724] loss: 0.258, ave_loss: 0.364
[18]  [340/1724] loss: 0.528, ave_loss: 0.373
[19]  [360/1724] loss: 0.538, ave_loss: 0.382
[20]  [380/1724] loss: 0.515, ave_loss: 0.389
[21]  [400/1724] loss: 0.450, ave_loss: 0.391
[22]  [420/1724] loss: 0.364, ave_loss: 0.390
[23]  [440/1724] loss: 0.518, ave_loss: 0.396
[24]  [460/1724] loss: 0.483, ave_loss: 0.399
[25]  [480/1724] loss: 0.411, ave_loss: 0.400
[26]  [500/1724] loss: 0.463, ave_loss: 0.402
[27]  [520/1724] loss: 0.324, ave_loss: 0.399
[28]  [540/1724] loss: 0.432, ave_loss: 0.401
[29]  [560/1724] loss: 0.419, ave_loss: 0.401
[30]  [580/1724] loss: 0.404, ave_loss: 0.401
[31]  [600/1724] loss: 0.402, ave_loss: 0.401
[32]  [620/1724] loss: 0.461, ave_loss: 0.403
[33]  [640/1724] loss: 0.293, ave_loss: 0.400
[34]  [660/1724] loss: 0.401, ave_loss: 0.400
[35]  [680/1724] loss: 0.331, ave_loss: 0.398
[36]  [700/1724] loss: 0.362, ave_loss: 0.397
[37]  [720/1724] loss: 0.293, ave_loss: 0.394
[38]  [740/1724] loss: 0.418, ave_loss: 0.395
[39]  [760/1724] loss: 0.389, ave_loss: 0.395
[40]  [780/1724] loss: 0.313, ave_loss: 0.393
[41]  [800/1724] loss: 0.637, ave_loss: 0.398
[42]  [820/1724] loss: 0.435, ave_loss: 0.399
[43]  [840/1724] loss: 0.388, ave_loss: 0.399
[44]  [860/1724] loss: 0.305, ave_loss: 0.397
[45]  [880/1724] loss: 0.318, ave_loss: 0.395
[46]  [900/1724] loss: 0.361, ave_loss: 0.394
[47]  [920/1724] loss: 0.212, ave_loss: 0.391
[48]  [940/1724] loss: 0.411, ave_loss: 0.391
[49]  [960/1724] loss: 0.426, ave_loss: 0.392
[50]  [980/1724] loss: 0.370, ave_loss: 0.391
[51]  [1000/1724] loss: 0.404, ave_loss: 0.392
[52]  [1020/1724] loss: 0.577, ave_loss: 0.395
[53]  [1040/1724] loss: 0.416, ave_loss: 0.395
[54]  [1060/1724] loss: 0.424, ave_loss: 0.396
[55]  [1080/1724] loss: 0.392, ave_loss: 0.396
[56]  [1100/1724] loss: 0.466, ave_loss: 0.397
[57]  [1120/1724] loss: 0.427, ave_loss: 0.398
[58]  [1140/1724] loss: 0.451, ave_loss: 0.399
[59]  [1160/1724] loss: 0.264, ave_loss: 0.396
[60]  [1180/1724] loss: 0.415, ave_loss: 0.397
[61]  [1200/1724] loss: 0.363, ave_loss: 0.396
[62]  [1220/1724] loss: 0.245, ave_loss: 0.394
[63]  [1240/1724] loss: 0.432, ave_loss: 0.394
[64]  [1260/1724] loss: 0.293, ave_loss: 0.393
[65]  [1280/1724] loss: 0.423, ave_loss: 0.393
[66]  [1300/1724] loss: 0.451, ave_loss: 0.394
[67]  [1320/1724] loss: 0.384, ave_loss: 0.394
[68]  [1340/1724] loss: 0.419, ave_loss: 0.394
[69]  [1360/1724] loss: 0.366, ave_loss: 0.394
[70]  [1380/1724] loss: 0.417, ave_loss: 0.394
[71]  [1400/1724] loss: 0.526, ave_loss: 0.396
[72]  [1420/1724] loss: 0.385, ave_loss: 0.396
[73]  [1440/1724] loss: 0.365, ave_loss: 0.395
[74]  [1460/1724] loss: 0.458, ave_loss: 0.396
[75]  [1480/1724] loss: 0.462, ave_loss: 0.397
[76]  [1500/1724] loss: 0.389, ave_loss: 0.397
[77]  [1520/1724] loss: 0.388, ave_loss: 0.397
[78]  [1540/1724] loss: 0.285, ave_loss: 0.396
[79]  [1560/1724] loss: 0.317, ave_loss: 0.395
[80]  [1580/1724] loss: 0.344, ave_loss: 0.394
[81]  [1600/1724] loss: 0.224, ave_loss: 0.392
[82]  [1620/1724] loss: 0.369, ave_loss: 0.392
[83]  [1640/1724] loss: 0.267, ave_loss: 0.390
[84]  [1660/1724] loss: 0.390, ave_loss: 0.390
[85]  [1680/1724] loss: 0.322, ave_loss: 0.389
[86]  [1700/1724] loss: 0.407, ave_loss: 0.389
[87]  [1720/1724] loss: 0.345, ave_loss: 0.389
[88]  [1740/1724] loss: 0.308, ave_loss: 0.388

Finished Training finishing at 2021-08-24 20:11:40.598577
printing_out epoch  23.48027842227378 learning rate: 0.00021856130515487778
0.00019947500205961776
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.880e-01
Validation Loss: 1.890e+03
Validation ROC: 0.7761
Saving model
75.51972157772622 epochs left to go

Training Epoch 23.48027842227378/100 starting at 2021-08-24 20:12:07.539131
[1]  [0/1724] loss: 0.568, ave_loss: 0.568
[2]  [20/1724] loss: 0.572, ave_loss: 0.570
[3]  [40/1724] loss: 0.392, ave_loss: 0.510
[4]  [60/1724] loss: 0.352, ave_loss: 0.471
[5]  [80/1724] loss: 0.333, ave_loss: 0.443
[6]  [100/1724] loss: 0.289, ave_loss: 0.418
[7]  [120/1724] loss: 0.218, ave_loss: 0.389
[8]  [140/1724] loss: 0.482, ave_loss: 0.401
[9]  [160/1724] loss: 0.367, ave_loss: 0.397
[10]  [180/1724] loss: 0.164, ave_loss: 0.374
[11]  [200/1724] loss: 0.440, ave_loss: 0.380
[12]  [220/1724] loss: 0.292, ave_loss: 0.372
[13]  [240/1724] loss: 0.385, ave_loss: 0.373
[14]  [260/1724] loss: 0.226, ave_loss: 0.363
[15]  [280/1724] loss: 0.529, ave_loss: 0.374
[16]  [300/1724] loss: 0.334, ave_loss: 0.371
[17]  [320/1724] loss: 0.481, ave_loss: 0.378
[18]  [340/1724] loss: 0.395, ave_loss: 0.379
[19]  [360/1724] loss: 0.511, ave_loss: 0.386
[20]  [380/1724] loss: 0.275, ave_loss: 0.380
[21]  [400/1724] loss: 0.352, ave_loss: 0.379
[22]  [420/1724] loss: 0.525, ave_loss: 0.385
[23]  [440/1724] loss: 0.303, ave_loss: 0.382
[24]  [460/1724] loss: 0.656, ave_loss: 0.393
[25]  [480/1724] loss: 0.399, ave_loss: 0.394
[26]  [500/1724] loss: 0.468, ave_loss: 0.396
[27]  [520/1724] loss: 0.314, ave_loss: 0.393
[28]  [540/1724] loss: 0.441, ave_loss: 0.395
[29]  [560/1724] loss: 0.482, ave_loss: 0.398
[30]  [580/1724] loss: 0.240, ave_loss: 0.393
[31]  [600/1724] loss: 0.412, ave_loss: 0.393
[32]  [620/1724] loss: 0.361, ave_loss: 0.392
[33]  [640/1724] loss: 0.479, ave_loss: 0.395
[34]  [660/1724] loss: 0.307, ave_loss: 0.392
[35]  [680/1724] loss: 0.408, ave_loss: 0.393
[36]  [700/1724] loss: 0.281, ave_loss: 0.390
[37]  [720/1724] loss: 0.230, ave_loss: 0.385
[38]  [740/1724] loss: 0.373, ave_loss: 0.385
[39]  [760/1724] loss: 0.583, ave_loss: 0.390
[40]  [780/1724] loss: 0.282, ave_loss: 0.387
[41]  [800/1724] loss: 0.518, ave_loss: 0.391
[42]  [820/1724] loss: 0.431, ave_loss: 0.392
[43]  [840/1724] loss: 0.283, ave_loss: 0.389
[44]  [860/1724] loss: 0.324, ave_loss: 0.388
[45]  [880/1724] loss: 0.532, ave_loss: 0.391
[46]  [900/1724] loss: 0.497, ave_loss: 0.393
[47]  [920/1724] loss: 0.366, ave_loss: 0.393
[48]  [940/1724] loss: 0.303, ave_loss: 0.391
[49]  [960/1724] loss: 0.595, ave_loss: 0.395
[50]  [980/1724] loss: 0.310, ave_loss: 0.393
[51]  [1000/1724] loss: 0.415, ave_loss: 0.394
[52]  [1020/1724] loss: 0.289, ave_loss: 0.392
[53]  [1040/1724] loss: 0.379, ave_loss: 0.391
[54]  [1060/1724] loss: 0.412, ave_loss: 0.392
[55]  [1080/1724] loss: 0.281, ave_loss: 0.390
[56]  [1100/1724] loss: 0.554, ave_loss: 0.393
[57]  [1120/1724] loss: 0.311, ave_loss: 0.391
[58]  [1140/1724] loss: 0.296, ave_loss: 0.390
[59]  [1160/1724] loss: 0.324, ave_loss: 0.388
[60]  [1180/1724] loss: 0.269, ave_loss: 0.386
[61]  [1200/1724] loss: 0.562, ave_loss: 0.389
[62]  [1220/1724] loss: 0.635, ave_loss: 0.393
[63]  [1240/1724] loss: 0.310, ave_loss: 0.392
[64]  [1260/1724] loss: 0.346, ave_loss: 0.391
[65]  [1280/1724] loss: 0.250, ave_loss: 0.389
[66]  [1300/1724] loss: 0.432, ave_loss: 0.390
[67]  [1320/1724] loss: 0.434, ave_loss: 0.390
[68]  [1340/1724] loss: 0.298, ave_loss: 0.389
[69]  [1360/1724] loss: 0.353, ave_loss: 0.389
[70]  [1380/1724] loss: 0.357, ave_loss: 0.388
[71]  [1400/1724] loss: 0.250, ave_loss: 0.386
[72]  [1420/1724] loss: 0.432, ave_loss: 0.387
[73]  [1440/1724] loss: 0.290, ave_loss: 0.385
[74]  [1460/1724] loss: 0.304, ave_loss: 0.384
[75]  [1480/1724] loss: 0.384, ave_loss: 0.384
[76]  [1500/1724] loss: 0.346, ave_loss: 0.384
[77]  [1520/1724] loss: 0.453, ave_loss: 0.385
[78]  [1540/1724] loss: 0.371, ave_loss: 0.385
[79]  [1560/1724] loss: 0.302, ave_loss: 0.384
[80]  [1580/1724] loss: 0.521, ave_loss: 0.385
[81]  [1600/1724] loss: 0.302, ave_loss: 0.384
[82]  [1620/1724] loss: 0.407, ave_loss: 0.384
[83]  [1640/1724] loss: 0.382, ave_loss: 0.384
[84]  [1660/1724] loss: 0.398, ave_loss: 0.385
[85]  [1680/1724] loss: 0.309, ave_loss: 0.384
[86]  [1700/1724] loss: 0.290, ave_loss: 0.383
[87]  [1720/1724] loss: 0.441, ave_loss: 0.383
[88]  [1740/1724] loss: 0.353, ave_loss: 0.383

Finished Training finishing at 2021-08-24 20:14:31.678366
printing_out epoch  24.501160092807424 learning rate: 0.00021856130515487778
0.00019349075199782923
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.829e-01
Validation Loss: 2.145e+03
Validation ROC: 0.7737
No improvement, still saving model
74.49883990719258 epochs left to go

Training Epoch 24.501160092807424/100 starting at 2021-08-24 20:15:14.269803
[1]  [0/1724] loss: 0.546, ave_loss: 0.546
[2]  [20/1724] loss: 0.362, ave_loss: 0.454
[3]  [40/1724] loss: 0.436, ave_loss: 0.448
[4]  [60/1724] loss: 0.368, ave_loss: 0.428
[5]  [80/1724] loss: 0.450, ave_loss: 0.432
[6]  [100/1724] loss: 0.377, ave_loss: 0.423
[7]  [120/1724] loss: 0.269, ave_loss: 0.401
[8]  [140/1724] loss: 0.463, ave_loss: 0.409
[9]  [160/1724] loss: 0.353, ave_loss: 0.403
[10]  [180/1724] loss: 0.359, ave_loss: 0.398
[11]  [200/1724] loss: 0.404, ave_loss: 0.399
[12]  [220/1724] loss: 0.317, ave_loss: 0.392
[13]  [240/1724] loss: 0.540, ave_loss: 0.404
[14]  [260/1724] loss: 0.325, ave_loss: 0.398
[15]  [280/1724] loss: 0.346, ave_loss: 0.395
[16]  [300/1724] loss: 0.418, ave_loss: 0.396
[17]  [320/1724] loss: 0.281, ave_loss: 0.389
[18]  [340/1724] loss: 0.332, ave_loss: 0.386
[19]  [360/1724] loss: 0.508, ave_loss: 0.392
[20]  [380/1724] loss: 0.419, ave_loss: 0.394
[21]  [400/1724] loss: 0.246, ave_loss: 0.387
[22]  [420/1724] loss: 0.336, ave_loss: 0.384
[23]  [440/1724] loss: 0.378, ave_loss: 0.384
[24]  [460/1724] loss: 0.517, ave_loss: 0.390
[25]  [480/1724] loss: 0.200, ave_loss: 0.382
[26]  [500/1724] loss: 0.247, ave_loss: 0.377
[27]  [520/1724] loss: 0.501, ave_loss: 0.381
[28]  [540/1724] loss: 0.498, ave_loss: 0.386
[29]  [560/1724] loss: 0.381, ave_loss: 0.385
[30]  [580/1724] loss: 0.409, ave_loss: 0.386
[31]  [600/1724] loss: 0.345, ave_loss: 0.385
[32]  [620/1724] loss: 0.497, ave_loss: 0.388
[33]  [640/1724] loss: 0.429, ave_loss: 0.390
[34]  [660/1724] loss: 0.267, ave_loss: 0.386
[35]  [680/1724] loss: 0.373, ave_loss: 0.386
[36]  [700/1724] loss: 0.457, ave_loss: 0.388
[37]  [720/1724] loss: 0.490, ave_loss: 0.390
[38]  [740/1724] loss: 0.271, ave_loss: 0.387
[39]  [760/1724] loss: 0.316, ave_loss: 0.385
[40]  [780/1724] loss: 0.402, ave_loss: 0.386
[41]  [800/1724] loss: 0.243, ave_loss: 0.382
[42]  [820/1724] loss: 0.399, ave_loss: 0.383
[43]  [840/1724] loss: 0.348, ave_loss: 0.382
[44]  [860/1724] loss: 0.301, ave_loss: 0.380
[45]  [880/1724] loss: 0.307, ave_loss: 0.378
[46]  [900/1724] loss: 0.309, ave_loss: 0.377
[47]  [920/1724] loss: 0.222, ave_loss: 0.374
[48]  [940/1724] loss: 0.554, ave_loss: 0.377
[49]  [960/1724] loss: 0.221, ave_loss: 0.374
[50]  [980/1724] loss: 0.449, ave_loss: 0.376
[51]  [1000/1724] loss: 0.548, ave_loss: 0.379
[52]  [1020/1724] loss: 0.399, ave_loss: 0.380
[53]  [1040/1724] loss: 0.536, ave_loss: 0.382
[54]  [1060/1724] loss: 0.419, ave_loss: 0.383
[55]  [1080/1724] loss: 0.315, ave_loss: 0.382
[56]  [1100/1724] loss: 0.386, ave_loss: 0.382
[57]  [1120/1724] loss: 0.397, ave_loss: 0.382
[58]  [1140/1724] loss: 0.417, ave_loss: 0.383
[59]  [1160/1724] loss: 0.386, ave_loss: 0.383
[60]  [1180/1724] loss: 0.267, ave_loss: 0.381
[61]  [1200/1724] loss: 0.428, ave_loss: 0.382
[62]  [1220/1724] loss: 0.299, ave_loss: 0.380
[63]  [1240/1724] loss: 0.399, ave_loss: 0.381
[64]  [1260/1724] loss: 0.355, ave_loss: 0.380
[65]  [1280/1724] loss: 0.403, ave_loss: 0.381
[66]  [1300/1724] loss: 0.439, ave_loss: 0.382
[67]  [1320/1724] loss: 0.300, ave_loss: 0.380
[68]  [1340/1724] loss: 0.400, ave_loss: 0.381
[69]  [1360/1724] loss: 0.428, ave_loss: 0.381
[70]  [1380/1724] loss: 0.371, ave_loss: 0.381
[71]  [1400/1724] loss: 0.368, ave_loss: 0.381
[72]  [1420/1724] loss: 0.341, ave_loss: 0.380
[73]  [1440/1724] loss: 0.274, ave_loss: 0.379
[74]  [1460/1724] loss: 0.394, ave_loss: 0.379
[75]  [1480/1724] loss: 0.323, ave_loss: 0.378
[76]  [1500/1724] loss: 0.303, ave_loss: 0.377
[77]  [1520/1724] loss: 0.402, ave_loss: 0.378
[78]  [1540/1724] loss: 0.424, ave_loss: 0.378
[79]  [1560/1724] loss: 0.347, ave_loss: 0.378
[80]  [1580/1724] loss: 0.502, ave_loss: 0.379
[81]  [1600/1724] loss: 0.266, ave_loss: 0.378
[82]  [1620/1724] loss: 0.295, ave_loss: 0.377
[83]  [1640/1724] loss: 0.389, ave_loss: 0.377
[84]  [1660/1724] loss: 0.403, ave_loss: 0.377
[85]  [1680/1724] loss: 0.466, ave_loss: 0.379
[86]  [1700/1724] loss: 0.233, ave_loss: 0.377
[87]  [1720/1724] loss: 0.332, ave_loss: 0.376
[88]  [1740/1724] loss: 0.272, ave_loss: 0.375

Finished Training finishing at 2021-08-24 20:17:34.594052
printing_out epoch  25.52204176334107 learning rate: 0.00019869209559534342
0.00019273133272748312
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.751e-01
Validation Loss: 1.804e+03
Validation ROC: 0.7757
No improvement, still saving model
73.47795823665894 epochs left to go

Training Epoch 25.52204176334107/100 starting at 2021-08-24 20:18:13.076993
[1]  [0/1724] loss: 0.500, ave_loss: 0.500
[2]  [20/1724] loss: 0.454, ave_loss: 0.477
[3]  [40/1724] loss: 0.564, ave_loss: 0.506
[4]  [60/1724] loss: 0.307, ave_loss: 0.456
[5]  [80/1724] loss: 0.405, ave_loss: 0.446
[6]  [100/1724] loss: 0.408, ave_loss: 0.440
[7]  [120/1724] loss: 0.491, ave_loss: 0.447
[8]  [140/1724] loss: 0.287, ave_loss: 0.427
[9]  [160/1724] loss: 0.487, ave_loss: 0.434
[10]  [180/1724] loss: 0.543, ave_loss: 0.445
[11]  [200/1724] loss: 0.365, ave_loss: 0.438
[12]  [220/1724] loss: 0.360, ave_loss: 0.431
[13]  [240/1724] loss: 0.245, ave_loss: 0.417
[14]  [260/1724] loss: 0.480, ave_loss: 0.421
[15]  [280/1724] loss: 0.507, ave_loss: 0.427
[16]  [300/1724] loss: 0.659, ave_loss: 0.442
[17]  [320/1724] loss: 0.290, ave_loss: 0.433
[18]  [340/1724] loss: 0.459, ave_loss: 0.434
[19]  [360/1724] loss: 0.346, ave_loss: 0.429
[20]  [380/1724] loss: 0.329, ave_loss: 0.424
[21]  [400/1724] loss: 0.449, ave_loss: 0.426
[22]  [420/1724] loss: 0.359, ave_loss: 0.423
[23]  [440/1724] loss: 0.404, ave_loss: 0.422
[24]  [460/1724] loss: 0.262, ave_loss: 0.415
[25]  [480/1724] loss: 0.381, ave_loss: 0.414
[26]  [500/1724] loss: 0.306, ave_loss: 0.410
[27]  [520/1724] loss: 0.561, ave_loss: 0.415
[28]  [540/1724] loss: 0.420, ave_loss: 0.415
[29]  [560/1724] loss: 0.457, ave_loss: 0.417
[30]  [580/1724] loss: 0.527, ave_loss: 0.420
[31]  [600/1724] loss: 0.435, ave_loss: 0.421
[32]  [620/1724] loss: 0.445, ave_loss: 0.422
[33]  [640/1724] loss: 0.392, ave_loss: 0.421
[34]  [660/1724] loss: 0.328, ave_loss: 0.418
[35]  [680/1724] loss: 0.418, ave_loss: 0.418
[36]  [700/1724] loss: 0.370, ave_loss: 0.417
[37]  [720/1724] loss: 0.307, ave_loss: 0.414
[38]  [740/1724] loss: 0.295, ave_loss: 0.411
[39]  [760/1724] loss: 0.243, ave_loss: 0.406
[40]  [780/1724] loss: 0.292, ave_loss: 0.404
[41]  [800/1724] loss: 0.453, ave_loss: 0.405
[42]  [820/1724] loss: 0.491, ave_loss: 0.407
[43]  [840/1724] loss: 0.315, ave_loss: 0.405
[44]  [860/1724] loss: 0.459, ave_loss: 0.406
[45]  [880/1724] loss: 0.449, ave_loss: 0.407
[46]  [900/1724] loss: 0.359, ave_loss: 0.406
[47]  [920/1724] loss: 0.320, ave_loss: 0.404
[48]  [940/1724] loss: 0.362, ave_loss: 0.403
[49]  [960/1724] loss: 0.383, ave_loss: 0.403
[50]  [980/1724] loss: 0.251, ave_loss: 0.400
[51]  [1000/1724] loss: 0.353, ave_loss: 0.399
[52]  [1020/1724] loss: 0.486, ave_loss: 0.400
[53]  [1040/1724] loss: 0.272, ave_loss: 0.398
[54]  [1060/1724] loss: 0.246, ave_loss: 0.395
[55]  [1080/1724] loss: 0.276, ave_loss: 0.393
[56]  [1100/1724] loss: 0.448, ave_loss: 0.394
[57]  [1120/1724] loss: 0.401, ave_loss: 0.394
[58]  [1140/1724] loss: 0.499, ave_loss: 0.396
[59]  [1160/1724] loss: 0.414, ave_loss: 0.396
[60]  [1180/1724] loss: 0.589, ave_loss: 0.399
[61]  [1200/1724] loss: 0.507, ave_loss: 0.401
[62]  [1220/1724] loss: 0.502, ave_loss: 0.403
[63]  [1240/1724] loss: 0.345, ave_loss: 0.402
[64]  [1260/1724] loss: 0.437, ave_loss: 0.402
[65]  [1280/1724] loss: 0.399, ave_loss: 0.402
[66]  [1300/1724] loss: 0.309, ave_loss: 0.401
[67]  [1320/1724] loss: 0.376, ave_loss: 0.401
[68]  [1340/1724] loss: 0.405, ave_loss: 0.401
[69]  [1360/1724] loss: 0.398, ave_loss: 0.401
[70]  [1380/1724] loss: 0.390, ave_loss: 0.401
[71]  [1400/1724] loss: 0.342, ave_loss: 0.400
[72]  [1420/1724] loss: 0.422, ave_loss: 0.400
[73]  [1440/1724] loss: 0.332, ave_loss: 0.399
[74]  [1460/1724] loss: 0.391, ave_loss: 0.399
[75]  [1480/1724] loss: 0.334, ave_loss: 0.398
[76]  [1500/1724] loss: 0.254, ave_loss: 0.396
[77]  [1520/1724] loss: 0.386, ave_loss: 0.396
[78]  [1540/1724] loss: 0.643, ave_loss: 0.399
[79]  [1560/1724] loss: 0.399, ave_loss: 0.399
[80]  [1580/1724] loss: 0.400, ave_loss: 0.399
[81]  [1600/1724] loss: 0.321, ave_loss: 0.398
[82]  [1620/1724] loss: 0.354, ave_loss: 0.398
[83]  [1640/1724] loss: 0.494, ave_loss: 0.399
[84]  [1660/1724] loss: 0.618, ave_loss: 0.402
[85]  [1680/1724] loss: 0.374, ave_loss: 0.401
[86]  [1700/1724] loss: 0.361, ave_loss: 0.401
[87]  [1720/1724] loss: 0.349, ave_loss: 0.400
[88]  [1740/1724] loss: 0.472, ave_loss: 0.401

Finished Training finishing at 2021-08-24 20:20:19.095448
printing_out epoch  26.54292343387471 learning rate: 0.00018062917781394856
0.0001752103024795301
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 4.009e-01
Validation Loss: 1.425e+03
Validation ROC: 0.7770
Saving model
72.4570765661253 epochs left to go

Training Epoch 26.54292343387471/100 starting at 2021-08-24 20:21:20.513821
[1]  [0/1724] loss: 0.723, ave_loss: 0.723
[2]  [20/1724] loss: 0.401, ave_loss: 0.562
[3]  [40/1724] loss: 0.474, ave_loss: 0.533
[4]  [60/1724] loss: 0.276, ave_loss: 0.469
[5]  [80/1724] loss: 0.387, ave_loss: 0.452
[6]  [100/1724] loss: 0.351, ave_loss: 0.435
[7]  [120/1724] loss: 0.239, ave_loss: 0.407
[8]  [140/1724] loss: 0.375, ave_loss: 0.403
[9]  [160/1724] loss: 0.323, ave_loss: 0.394
[10]  [180/1724] loss: 0.415, ave_loss: 0.396
[11]  [200/1724] loss: 0.387, ave_loss: 0.395
[12]  [220/1724] loss: 0.239, ave_loss: 0.382
[13]  [240/1724] loss: 0.406, ave_loss: 0.384
[14]  [260/1724] loss: 0.458, ave_loss: 0.390
[15]  [280/1724] loss: 0.287, ave_loss: 0.383
[16]  [300/1724] loss: 0.350, ave_loss: 0.381
[17]  [320/1724] loss: 0.359, ave_loss: 0.379
[18]  [340/1724] loss: 0.376, ave_loss: 0.379
[19]  [360/1724] loss: 0.275, ave_loss: 0.374
[20]  [380/1724] loss: 0.322, ave_loss: 0.371
[21]  [400/1724] loss: 0.397, ave_loss: 0.372
[22]  [420/1724] loss: 0.441, ave_loss: 0.375
[23]  [440/1724] loss: 0.720, ave_loss: 0.390
[24]  [460/1724] loss: 0.292, ave_loss: 0.386
[25]  [480/1724] loss: 0.327, ave_loss: 0.384
[26]  [500/1724] loss: 0.409, ave_loss: 0.385
[27]  [520/1724] loss: 0.214, ave_loss: 0.379
[28]  [540/1724] loss: 0.515, ave_loss: 0.384
[29]  [560/1724] loss: 0.581, ave_loss: 0.390
[30]  [580/1724] loss: 0.335, ave_loss: 0.388
[31]  [600/1724] loss: 0.279, ave_loss: 0.385
[32]  [620/1724] loss: 0.254, ave_loss: 0.381
[33]  [640/1724] loss: 0.508, ave_loss: 0.385
[34]  [660/1724] loss: 0.453, ave_loss: 0.387
[35]  [680/1724] loss: 0.342, ave_loss: 0.385
[36]  [700/1724] loss: 0.447, ave_loss: 0.387
[37]  [720/1724] loss: 0.376, ave_loss: 0.387
[38]  [740/1724] loss: 0.453, ave_loss: 0.389
[39]  [760/1724] loss: 0.489, ave_loss: 0.391
[40]  [780/1724] loss: 0.255, ave_loss: 0.388
[41]  [800/1724] loss: 0.528, ave_loss: 0.391
[42]  [820/1724] loss: 0.405, ave_loss: 0.392
[43]  [840/1724] loss: 0.298, ave_loss: 0.389
[44]  [860/1724] loss: 0.382, ave_loss: 0.389
[45]  [880/1724] loss: 0.296, ave_loss: 0.387
[46]  [900/1724] loss: 0.469, ave_loss: 0.389
[47]  [920/1724] loss: 0.391, ave_loss: 0.389
[48]  [940/1724] loss: 0.260, ave_loss: 0.386
[49]  [960/1724] loss: 0.381, ave_loss: 0.386
[50]  [980/1724] loss: 0.299, ave_loss: 0.384
[51]  [1000/1724] loss: 0.497, ave_loss: 0.387
[52]  [1020/1724] loss: 0.316, ave_loss: 0.385
[53]  [1040/1724] loss: 0.375, ave_loss: 0.385
[54]  [1060/1724] loss: 0.207, ave_loss: 0.382
[55]  [1080/1724] loss: 0.445, ave_loss: 0.383
[56]  [1100/1724] loss: 0.567, ave_loss: 0.386
[57]  [1120/1724] loss: 0.250, ave_loss: 0.384
[58]  [1140/1724] loss: 0.273, ave_loss: 0.382
[59]  [1160/1724] loss: 0.358, ave_loss: 0.382
[60]  [1180/1724] loss: 0.247, ave_loss: 0.379
[61]  [1200/1724] loss: 0.655, ave_loss: 0.384
[62]  [1220/1724] loss: 0.333, ave_loss: 0.383
[63]  [1240/1724] loss: 0.256, ave_loss: 0.381
[64]  [1260/1724] loss: 0.422, ave_loss: 0.382
[65]  [1280/1724] loss: 0.369, ave_loss: 0.381
[66]  [1300/1724] loss: 0.427, ave_loss: 0.382
[67]  [1320/1724] loss: 0.279, ave_loss: 0.381
[68]  [1340/1724] loss: 0.412, ave_loss: 0.381
[69]  [1360/1724] loss: 0.365, ave_loss: 0.381
[70]  [1380/1724] loss: 0.357, ave_loss: 0.380
[71]  [1400/1724] loss: 0.391, ave_loss: 0.381
[72]  [1420/1724] loss: 0.369, ave_loss: 0.380
[73]  [1440/1724] loss: 0.390, ave_loss: 0.381
[74]  [1460/1724] loss: 0.439, ave_loss: 0.381
[75]  [1480/1724] loss: 0.379, ave_loss: 0.381
[76]  [1500/1724] loss: 0.405, ave_loss: 0.382
[77]  [1520/1724] loss: 0.446, ave_loss: 0.382
[78]  [1540/1724] loss: 0.368, ave_loss: 0.382
[79]  [1560/1724] loss: 0.355, ave_loss: 0.382
[80]  [1580/1724] loss: 0.438, ave_loss: 0.383
[81]  [1600/1724] loss: 0.319, ave_loss: 0.382
[82]  [1620/1724] loss: 0.380, ave_loss: 0.382
[83]  [1640/1724] loss: 0.293, ave_loss: 0.381
[84]  [1660/1724] loss: 0.368, ave_loss: 0.381
[85]  [1680/1724] loss: 0.389, ave_loss: 0.381
[86]  [1700/1724] loss: 0.360, ave_loss: 0.380
[87]  [1720/1724] loss: 0.302, ave_loss: 0.380
[88]  [1740/1724] loss: 0.340, ave_loss: 0.379

Finished Training finishing at 2021-08-24 20:23:25.274502
printing_out epoch  27.563805104408353 learning rate: 0.00018062917781394856
0.0001699539934051442
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.791e-01
Validation Loss: 1.870e+03
Validation ROC: 0.7776
Saving model
71.43619489559165 epochs left to go

Training Epoch 27.563805104408353/100 starting at 2021-08-24 20:24:36.999812
[1]  [0/1724] loss: 0.206, ave_loss: 0.206
[2]  [20/1724] loss: 0.561, ave_loss: 0.383
[3]  [40/1724] loss: 0.258, ave_loss: 0.342
[4]  [60/1724] loss: 0.340, ave_loss: 0.341
[5]  [80/1724] loss: 0.128, ave_loss: 0.299
[6]  [100/1724] loss: 0.522, ave_loss: 0.336
[7]  [120/1724] loss: 0.327, ave_loss: 0.334
[8]  [140/1724] loss: 0.250, ave_loss: 0.324
[9]  [160/1724] loss: 0.339, ave_loss: 0.326
[10]  [180/1724] loss: 0.444, ave_loss: 0.337
[11]  [200/1724] loss: 0.608, ave_loss: 0.362
[12]  [220/1724] loss: 0.423, ave_loss: 0.367
[13]  [240/1724] loss: 0.268, ave_loss: 0.360
[14]  [260/1724] loss: 0.511, ave_loss: 0.370
[15]  [280/1724] loss: 0.345, ave_loss: 0.369
[16]  [300/1724] loss: 0.354, ave_loss: 0.368
[17]  [320/1724] loss: 0.487, ave_loss: 0.375
[18]  [340/1724] loss: 0.323, ave_loss: 0.372
[19]  [360/1724] loss: 0.288, ave_loss: 0.367
[20]  [380/1724] loss: 0.405, ave_loss: 0.369
[21]  [400/1724] loss: 0.271, ave_loss: 0.365
[22]  [420/1724] loss: 0.312, ave_loss: 0.362
[23]  [440/1724] loss: 0.342, ave_loss: 0.361
[24]  [460/1724] loss: 0.370, ave_loss: 0.362
[25]  [480/1724] loss: 0.227, ave_loss: 0.356
[26]  [500/1724] loss: 0.349, ave_loss: 0.356
[27]  [520/1724] loss: 0.385, ave_loss: 0.357
[28]  [540/1724] loss: 0.363, ave_loss: 0.357
[29]  [560/1724] loss: 0.272, ave_loss: 0.354
[30]  [580/1724] loss: 0.382, ave_loss: 0.355
[31]  [600/1724] loss: 0.366, ave_loss: 0.356
[32]  [620/1724] loss: 0.475, ave_loss: 0.359
[33]  [640/1724] loss: 0.276, ave_loss: 0.357
[34]  [660/1724] loss: 0.454, ave_loss: 0.360
[35]  [680/1724] loss: 0.465, ave_loss: 0.363
[36]  [700/1724] loss: 0.224, ave_loss: 0.359
[37]  [720/1724] loss: 0.569, ave_loss: 0.365
[38]  [740/1724] loss: 0.461, ave_loss: 0.367
[39]  [760/1724] loss: 0.287, ave_loss: 0.365
[40]  [780/1724] loss: 0.299, ave_loss: 0.363
[41]  [800/1724] loss: 0.369, ave_loss: 0.363
[42]  [820/1724] loss: 0.465, ave_loss: 0.366
[43]  [840/1724] loss: 0.387, ave_loss: 0.366
[44]  [860/1724] loss: 0.338, ave_loss: 0.366
[45]  [880/1724] loss: 0.530, ave_loss: 0.369
[46]  [900/1724] loss: 0.344, ave_loss: 0.369
[47]  [920/1724] loss: 0.379, ave_loss: 0.369
[48]  [940/1724] loss: 0.229, ave_loss: 0.366
[49]  [960/1724] loss: 0.337, ave_loss: 0.366
[50]  [980/1724] loss: 0.426, ave_loss: 0.367
[51]  [1000/1724] loss: 0.449, ave_loss: 0.368
[52]  [1020/1724] loss: 0.541, ave_loss: 0.372
[53]  [1040/1724] loss: 0.414, ave_loss: 0.372
[54]  [1060/1724] loss: 0.221, ave_loss: 0.370
[55]  [1080/1724] loss: 0.257, ave_loss: 0.368
[56]  [1100/1724] loss: 0.468, ave_loss: 0.369
[57]  [1120/1724] loss: 0.243, ave_loss: 0.367
[58]  [1140/1724] loss: 0.334, ave_loss: 0.367
[59]  [1160/1724] loss: 0.278, ave_loss: 0.365
[60]  [1180/1724] loss: 0.336, ave_loss: 0.365
[61]  [1200/1724] loss: 0.316, ave_loss: 0.364
[62]  [1220/1724] loss: 0.519, ave_loss: 0.366
[63]  [1240/1724] loss: 0.202, ave_loss: 0.364
[64]  [1260/1724] loss: 0.444, ave_loss: 0.365
[65]  [1280/1724] loss: 0.449, ave_loss: 0.366
[66]  [1300/1724] loss: 0.288, ave_loss: 0.365
[67]  [1320/1724] loss: 0.384, ave_loss: 0.365
[68]  [1340/1724] loss: 0.243, ave_loss: 0.364
[69]  [1360/1724] loss: 0.338, ave_loss: 0.363
[70]  [1380/1724] loss: 0.331, ave_loss: 0.363
[71]  [1400/1724] loss: 0.567, ave_loss: 0.366
[72]  [1420/1724] loss: 0.270, ave_loss: 0.364
[73]  [1440/1724] loss: 0.400, ave_loss: 0.365
[74]  [1460/1724] loss: 0.455, ave_loss: 0.366
[75]  [1480/1724] loss: 0.425, ave_loss: 0.367
[76]  [1500/1724] loss: 0.392, ave_loss: 0.367
[77]  [1520/1724] loss: 0.565, ave_loss: 0.370
[78]  [1540/1724] loss: 0.581, ave_loss: 0.372
[79]  [1560/1724] loss: 0.319, ave_loss: 0.372
[80]  [1580/1724] loss: 0.309, ave_loss: 0.371
[81]  [1600/1724] loss: 0.271, ave_loss: 0.370
[82]  [1620/1724] loss: 0.481, ave_loss: 0.371
[83]  [1640/1724] loss: 0.347, ave_loss: 0.371
[84]  [1660/1724] loss: 0.277, ave_loss: 0.370
[85]  [1680/1724] loss: 0.405, ave_loss: 0.370
[86]  [1700/1724] loss: 0.459, ave_loss: 0.371
[87]  [1720/1724] loss: 0.433, ave_loss: 0.372
[88]  [1740/1724] loss: 0.347, ave_loss: 0.372

Finished Training finishing at 2021-08-24 20:26:35.204666
printing_out epoch  28.584686774941996 learning rate: 0.00018062917781394856
0.00016485537360298987
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.716e-01
Validation Loss: 1.567e+03
Validation ROC: 0.7773
No improvement, still saving model
70.415313225058 epochs left to go

Training Epoch 28.584686774941996/100 starting at 2021-08-24 20:27:01.424817
[1]  [0/1724] loss: 0.444, ave_loss: 0.444
[2]  [20/1724] loss: 0.360, ave_loss: 0.402
[3]  [40/1724] loss: 0.428, ave_loss: 0.411
[4]  [60/1724] loss: 0.314, ave_loss: 0.387
[5]  [80/1724] loss: 0.252, ave_loss: 0.360
[6]  [100/1724] loss: 0.239, ave_loss: 0.339
[7]  [120/1724] loss: 0.427, ave_loss: 0.352
[8]  [140/1724] loss: 0.269, ave_loss: 0.342
[9]  [160/1724] loss: 0.496, ave_loss: 0.359
[10]  [180/1724] loss: 0.343, ave_loss: 0.357
[11]  [200/1724] loss: 0.463, ave_loss: 0.367
[12]  [220/1724] loss: 0.504, ave_loss: 0.378
[13]  [240/1724] loss: 0.492, ave_loss: 0.387
[14]  [260/1724] loss: 0.437, ave_loss: 0.391
[15]  [280/1724] loss: 0.288, ave_loss: 0.384
[16]  [300/1724] loss: 0.354, ave_loss: 0.382
[17]  [320/1724] loss: 0.254, ave_loss: 0.374
[18]  [340/1724] loss: 0.398, ave_loss: 0.376
[19]  [360/1724] loss: 0.361, ave_loss: 0.375
[20]  [380/1724] loss: 0.426, ave_loss: 0.377
[21]  [400/1724] loss: 0.410, ave_loss: 0.379
[22]  [420/1724] loss: 0.366, ave_loss: 0.378
[23]  [440/1724] loss: 0.298, ave_loss: 0.375
[24]  [460/1724] loss: 0.297, ave_loss: 0.372
[25]  [480/1724] loss: 0.245, ave_loss: 0.367
[26]  [500/1724] loss: 0.428, ave_loss: 0.369
[27]  [520/1724] loss: 0.357, ave_loss: 0.369
[28]  [540/1724] loss: 0.265, ave_loss: 0.365
[29]  [560/1724] loss: 0.287, ave_loss: 0.362
[30]  [580/1724] loss: 0.444, ave_loss: 0.365
[31]  [600/1724] loss: 0.320, ave_loss: 0.363
[32]  [620/1724] loss: 0.422, ave_loss: 0.365
[33]  [640/1724] loss: 0.475, ave_loss: 0.369
[34]  [660/1724] loss: 0.215, ave_loss: 0.364
[35]  [680/1724] loss: 0.464, ave_loss: 0.367
[36]  [700/1724] loss: 0.417, ave_loss: 0.368
[37]  [720/1724] loss: 0.318, ave_loss: 0.367
[38]  [740/1724] loss: 0.254, ave_loss: 0.364
[39]  [760/1724] loss: 0.338, ave_loss: 0.363
[40]  [780/1724] loss: 0.397, ave_loss: 0.364
[41]  [800/1724] loss: 0.247, ave_loss: 0.361
[42]  [820/1724] loss: 0.393, ave_loss: 0.362
[43]  [840/1724] loss: 0.550, ave_loss: 0.366
[44]  [860/1724] loss: 0.271, ave_loss: 0.364
[45]  [880/1724] loss: 0.420, ave_loss: 0.365
[46]  [900/1724] loss: 0.234, ave_loss: 0.363
[47]  [920/1724] loss: 0.346, ave_loss: 0.362
[48]  [940/1724] loss: 0.623, ave_loss: 0.368
[49]  [960/1724] loss: 0.333, ave_loss: 0.367
[50]  [980/1724] loss: 0.321, ave_loss: 0.366
[51]  [1000/1724] loss: 0.330, ave_loss: 0.365
[52]  [1020/1724] loss: 0.429, ave_loss: 0.367
[53]  [1040/1724] loss: 0.207, ave_loss: 0.364
[54]  [1060/1724] loss: 0.387, ave_loss: 0.364
[55]  [1080/1724] loss: 0.304, ave_loss: 0.363
[56]  [1100/1724] loss: 0.325, ave_loss: 0.362
[57]  [1120/1724] loss: 0.364, ave_loss: 0.362
[58]  [1140/1724] loss: 0.236, ave_loss: 0.360
[59]  [1160/1724] loss: 0.341, ave_loss: 0.360
[60]  [1180/1724] loss: 0.537, ave_loss: 0.363
[61]  [1200/1724] loss: 0.425, ave_loss: 0.364
[62]  [1220/1724] loss: 0.251, ave_loss: 0.362
[63]  [1240/1724] loss: 0.355, ave_loss: 0.362
[64]  [1260/1724] loss: 0.396, ave_loss: 0.362
[65]  [1280/1724] loss: 0.478, ave_loss: 0.364
[66]  [1300/1724] loss: 0.260, ave_loss: 0.363
[67]  [1320/1724] loss: 0.446, ave_loss: 0.364
[68]  [1340/1724] loss: 0.305, ave_loss: 0.363
[69]  [1360/1724] loss: 0.224, ave_loss: 0.361
[70]  [1380/1724] loss: 0.342, ave_loss: 0.361
[71]  [1400/1724] loss: 0.372, ave_loss: 0.361
[72]  [1420/1724] loss: 0.524, ave_loss: 0.363
[73]  [1440/1724] loss: 0.352, ave_loss: 0.363
[74]  [1460/1724] loss: 0.308, ave_loss: 0.362
[75]  [1480/1724] loss: 0.271, ave_loss: 0.361
[76]  [1500/1724] loss: 0.257, ave_loss: 0.360
[77]  [1520/1724] loss: 0.262, ave_loss: 0.358
[78]  [1540/1724] loss: 0.393, ave_loss: 0.359
[79]  [1560/1724] loss: 0.456, ave_loss: 0.360
[80]  [1580/1724] loss: 0.233, ave_loss: 0.358
[81]  [1600/1724] loss: 0.431, ave_loss: 0.359
[82]  [1620/1724] loss: 0.297, ave_loss: 0.359
[83]  [1640/1724] loss: 0.253, ave_loss: 0.357
[84]  [1660/1724] loss: 0.415, ave_loss: 0.358
[85]  [1680/1724] loss: 0.241, ave_loss: 0.357
[86]  [1700/1724] loss: 0.429, ave_loss: 0.357
[87]  [1720/1724] loss: 0.353, ave_loss: 0.357
[88]  [1740/1724] loss: 0.416, ave_loss: 0.358

Finished Training finishing at 2021-08-24 20:29:07.261906
printing_out epoch  29.605568445475637 learning rate: 0.00016420834346722596
0.00015928209316320917
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.581e-01
Validation Loss: 1.378e+03
Validation ROC: 0.7741
No improvement, still saving model
69.39443155452436 epochs left to go

Training Epoch 29.605568445475637/100 starting at 2021-08-24 20:29:44.087300
[1]  [0/1724] loss: 0.692, ave_loss: 0.692
[2]  [20/1724] loss: 0.387, ave_loss: 0.539
[3]  [40/1724] loss: 0.169, ave_loss: 0.416
[4]  [60/1724] loss: 0.365, ave_loss: 0.403
[5]  [80/1724] loss: 0.534, ave_loss: 0.429
[6]  [100/1724] loss: 0.371, ave_loss: 0.420
[7]  [120/1724] loss: 0.582, ave_loss: 0.443
[8]  [140/1724] loss: 0.344, ave_loss: 0.430
[9]  [160/1724] loss: 0.417, ave_loss: 0.429
[10]  [180/1724] loss: 0.404, ave_loss: 0.426
[11]  [200/1724] loss: 0.246, ave_loss: 0.410
[12]  [220/1724] loss: 0.346, ave_loss: 0.405
[13]  [240/1724] loss: 0.258, ave_loss: 0.393
[14]  [260/1724] loss: 0.334, ave_loss: 0.389
[15]  [280/1724] loss: 0.330, ave_loss: 0.385
[16]  [300/1724] loss: 0.321, ave_loss: 0.381
[17]  [320/1724] loss: 0.337, ave_loss: 0.379
[18]  [340/1724] loss: 0.320, ave_loss: 0.375
[19]  [360/1724] loss: 0.334, ave_loss: 0.373
[20]  [380/1724] loss: 0.404, ave_loss: 0.375
[21]  [400/1724] loss: 0.245, ave_loss: 0.369
[22]  [420/1724] loss: 0.489, ave_loss: 0.374
[23]  [440/1724] loss: 0.408, ave_loss: 0.376
[24]  [460/1724] loss: 0.245, ave_loss: 0.370
[25]  [480/1724] loss: 0.343, ave_loss: 0.369
[26]  [500/1724] loss: 0.333, ave_loss: 0.368
[27]  [520/1724] loss: 0.240, ave_loss: 0.363
[28]  [540/1724] loss: 0.397, ave_loss: 0.364
[29]  [560/1724] loss: 0.380, ave_loss: 0.365
[30]  [580/1724] loss: 0.213, ave_loss: 0.360
[31]  [600/1724] loss: 0.425, ave_loss: 0.362
[32]  [620/1724] loss: 0.355, ave_loss: 0.361
[33]  [640/1724] loss: 0.568, ave_loss: 0.368
[34]  [660/1724] loss: 0.453, ave_loss: 0.370
[35]  [680/1724] loss: 0.410, ave_loss: 0.371
[36]  [700/1724] loss: 0.362, ave_loss: 0.371
[37]  [720/1724] loss: 0.264, ave_loss: 0.368
[38]  [740/1724] loss: 0.637, ave_loss: 0.375
[39]  [760/1724] loss: 0.509, ave_loss: 0.379
[40]  [780/1724] loss: 0.286, ave_loss: 0.376
[41]  [800/1724] loss: 0.298, ave_loss: 0.375
[42]  [820/1724] loss: 0.258, ave_loss: 0.372
[43]  [840/1724] loss: 0.450, ave_loss: 0.374
[44]  [860/1724] loss: 0.417, ave_loss: 0.375
[45]  [880/1724] loss: 0.423, ave_loss: 0.376
[46]  [900/1724] loss: 0.583, ave_loss: 0.380
[47]  [920/1724] loss: 0.407, ave_loss: 0.381
[48]  [940/1724] loss: 0.247, ave_loss: 0.378
[49]  [960/1724] loss: 0.342, ave_loss: 0.377
[50]  [980/1724] loss: 0.456, ave_loss: 0.379
[51]  [1000/1724] loss: 0.501, ave_loss: 0.381
[52]  [1020/1724] loss: 0.497, ave_loss: 0.383
[53]  [1040/1724] loss: 0.314, ave_loss: 0.382
[54]  [1060/1724] loss: 0.378, ave_loss: 0.382
[55]  [1080/1724] loss: 0.366, ave_loss: 0.382
[56]  [1100/1724] loss: 0.239, ave_loss: 0.379
[57]  [1120/1724] loss: 0.292, ave_loss: 0.378
[58]  [1140/1724] loss: 0.324, ave_loss: 0.377
[59]  [1160/1724] loss: 0.309, ave_loss: 0.376
[60]  [1180/1724] loss: 0.443, ave_loss: 0.377
[61]  [1200/1724] loss: 0.308, ave_loss: 0.376
[62]  [1220/1724] loss: 0.419, ave_loss: 0.376
[63]  [1240/1724] loss: 0.416, ave_loss: 0.377
[64]  [1260/1724] loss: 0.258, ave_loss: 0.375
[65]  [1280/1724] loss: 0.382, ave_loss: 0.375
[66]  [1300/1724] loss: 0.189, ave_loss: 0.372
[67]  [1320/1724] loss: 0.310, ave_loss: 0.371
[68]  [1340/1724] loss: 0.446, ave_loss: 0.372
[69]  [1360/1724] loss: 0.274, ave_loss: 0.371
[70]  [1380/1724] loss: 0.356, ave_loss: 0.371
[71]  [1400/1724] loss: 0.269, ave_loss: 0.369
[72]  [1420/1724] loss: 0.299, ave_loss: 0.368
[73]  [1440/1724] loss: 0.323, ave_loss: 0.368
[74]  [1460/1724] loss: 0.410, ave_loss: 0.368
[75]  [1480/1724] loss: 0.440, ave_loss: 0.369
[76]  [1500/1724] loss: 0.250, ave_loss: 0.368
[77]  [1520/1724] loss: 0.525, ave_loss: 0.370
[78]  [1540/1724] loss: 0.404, ave_loss: 0.370
[79]  [1560/1724] loss: 0.442, ave_loss: 0.371
[80]  [1580/1724] loss: 0.475, ave_loss: 0.372
[81]  [1600/1724] loss: 0.508, ave_loss: 0.374
[82]  [1620/1724] loss: 0.241, ave_loss: 0.372
[83]  [1640/1724] loss: 0.323, ave_loss: 0.372
[84]  [1660/1724] loss: 0.440, ave_loss: 0.373
[85]  [1680/1724] loss: 0.369, ave_loss: 0.373
[86]  [1700/1724] loss: 0.402, ave_loss: 0.373
[87]  [1720/1724] loss: 0.466, ave_loss: 0.374
[88]  [1740/1724] loss: 0.236, ave_loss: 0.373

Finished Training finishing at 2021-08-24 20:31:41.517668
printing_out epoch  30.62645011600928 learning rate: 0.0001492803122429327
0.0001448019028756447
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.725e-01
Validation Loss: 1.287e+03
Validation ROC: 0.7790
Saving model
68.37354988399072 epochs left to go

Training Epoch 30.62645011600928/100 starting at 2021-08-24 20:32:22.086534
[1]  [0/1724] loss: 0.626, ave_loss: 0.626
[2]  [20/1724] loss: 0.331, ave_loss: 0.479
[3]  [40/1724] loss: 0.433, ave_loss: 0.463
[4]  [60/1724] loss: 0.377, ave_loss: 0.442
[5]  [80/1724] loss: 0.440, ave_loss: 0.441
[6]  [100/1724] loss: 0.352, ave_loss: 0.427
[7]  [120/1724] loss: 0.322, ave_loss: 0.412
[8]  [140/1724] loss: 0.400, ave_loss: 0.410
[9]  [160/1724] loss: 0.443, ave_loss: 0.414
[10]  [180/1724] loss: 0.611, ave_loss: 0.433
[11]  [200/1724] loss: 0.397, ave_loss: 0.430
[12]  [220/1724] loss: 0.344, ave_loss: 0.423
[13]  [240/1724] loss: 0.549, ave_loss: 0.433
[14]  [260/1724] loss: 0.300, ave_loss: 0.423
[15]  [280/1724] loss: 0.441, ave_loss: 0.424
[16]  [300/1724] loss: 0.385, ave_loss: 0.422
[17]  [320/1724] loss: 0.354, ave_loss: 0.418
[18]  [340/1724] loss: 0.324, ave_loss: 0.413
[19]  [360/1724] loss: 0.272, ave_loss: 0.405
[20]  [380/1724] loss: 0.431, ave_loss: 0.407
[21]  [400/1724] loss: 0.340, ave_loss: 0.403
[22]  [420/1724] loss: 0.367, ave_loss: 0.402
[23]  [440/1724] loss: 0.451, ave_loss: 0.404
[24]  [460/1724] loss: 0.239, ave_loss: 0.397
[25]  [480/1724] loss: 0.388, ave_loss: 0.397
[26]  [500/1724] loss: 0.349, ave_loss: 0.395
[27]  [520/1724] loss: 0.332, ave_loss: 0.392
[28]  [540/1724] loss: 0.506, ave_loss: 0.397
[29]  [560/1724] loss: 0.319, ave_loss: 0.394
[30]  [580/1724] loss: 0.486, ave_loss: 0.397
[31]  [600/1724] loss: 0.333, ave_loss: 0.395
[32]  [620/1724] loss: 0.361, ave_loss: 0.394
[33]  [640/1724] loss: 0.543, ave_loss: 0.398
[34]  [660/1724] loss: 0.468, ave_loss: 0.400
[35]  [680/1724] loss: 0.264, ave_loss: 0.396
[36]  [700/1724] loss: 0.322, ave_loss: 0.394
[37]  [720/1724] loss: 0.350, ave_loss: 0.393
[38]  [740/1724] loss: 0.317, ave_loss: 0.391
[39]  [760/1724] loss: 0.323, ave_loss: 0.389
[40]  [780/1724] loss: 0.352, ave_loss: 0.389
[41]  [800/1724] loss: 0.389, ave_loss: 0.389
[42]  [820/1724] loss: 0.393, ave_loss: 0.389
[43]  [840/1724] loss: 0.465, ave_loss: 0.390
[44]  [860/1724] loss: 0.417, ave_loss: 0.391
[45]  [880/1724] loss: 0.424, ave_loss: 0.392
[46]  [900/1724] loss: 0.431, ave_loss: 0.393
[47]  [920/1724] loss: 0.415, ave_loss: 0.393
[48]  [940/1724] loss: 0.342, ave_loss: 0.392
[49]  [960/1724] loss: 0.246, ave_loss: 0.389
[50]  [980/1724] loss: 0.251, ave_loss: 0.386
[51]  [1000/1724] loss: 0.206, ave_loss: 0.383
[52]  [1020/1724] loss: 0.471, ave_loss: 0.385
[53]  [1040/1724] loss: 0.302, ave_loss: 0.383
[54]  [1060/1724] loss: 0.503, ave_loss: 0.385
[55]  [1080/1724] loss: 0.434, ave_loss: 0.386
[56]  [1100/1724] loss: 0.383, ave_loss: 0.386
[57]  [1120/1724] loss: 0.418, ave_loss: 0.387
[58]  [1140/1724] loss: 0.257, ave_loss: 0.384
[59]  [1160/1724] loss: 0.293, ave_loss: 0.383
[60]  [1180/1724] loss: 0.333, ave_loss: 0.382
[61]  [1200/1724] loss: 0.323, ave_loss: 0.381
[62]  [1220/1724] loss: 0.389, ave_loss: 0.381
[63]  [1240/1724] loss: 0.298, ave_loss: 0.380
[64]  [1260/1724] loss: 0.387, ave_loss: 0.380
[65]  [1280/1724] loss: 0.235, ave_loss: 0.378
[66]  [1300/1724] loss: 0.371, ave_loss: 0.378
[67]  [1320/1724] loss: 0.267, ave_loss: 0.376
[68]  [1340/1724] loss: 0.374, ave_loss: 0.376
[69]  [1360/1724] loss: 0.373, ave_loss: 0.376
[70]  [1380/1724] loss: 0.305, ave_loss: 0.375
[71]  [1400/1724] loss: 0.391, ave_loss: 0.375
[72]  [1420/1724] loss: 0.363, ave_loss: 0.375
[73]  [1440/1724] loss: 0.459, ave_loss: 0.376
[74]  [1460/1724] loss: 0.341, ave_loss: 0.376
[75]  [1480/1724] loss: 0.371, ave_loss: 0.376
[76]  [1500/1724] loss: 0.460, ave_loss: 0.377
[77]  [1520/1724] loss: 0.422, ave_loss: 0.377
[78]  [1540/1724] loss: 0.480, ave_loss: 0.379
[79]  [1560/1724] loss: 0.287, ave_loss: 0.377
[80]  [1580/1724] loss: 0.418, ave_loss: 0.378
[81]  [1600/1724] loss: 0.320, ave_loss: 0.377
[82]  [1620/1724] loss: 0.195, ave_loss: 0.375
[83]  [1640/1724] loss: 0.404, ave_loss: 0.375
[84]  [1660/1724] loss: 0.238, ave_loss: 0.374
[85]  [1680/1724] loss: 0.281, ave_loss: 0.373
[86]  [1700/1724] loss: 0.325, ave_loss: 0.372
[87]  [1720/1724] loss: 0.241, ave_loss: 0.371
[88]  [1740/1724] loss: 0.271, ave_loss: 0.369

Finished Training finishing at 2021-08-24 20:34:23.795102
printing_out epoch  31.647331786542924 learning rate: 0.0001492803122429327
0.00014045784578937536
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.694e-01
Validation Loss: 1.340e+03
Validation ROC: 0.7764
No improvement, still saving model
67.35266821345708 epochs left to go

Training Epoch 31.647331786542924/100 starting at 2021-08-24 20:35:18.594232
[1]  [0/1724] loss: 0.426, ave_loss: 0.426
[2]  [20/1724] loss: 0.314, ave_loss: 0.370
[3]  [40/1724] loss: 0.242, ave_loss: 0.328
[4]  [60/1724] loss: 0.424, ave_loss: 0.352
[5]  [80/1724] loss: 0.355, ave_loss: 0.352
[6]  [100/1724] loss: 0.312, ave_loss: 0.346
[7]  [120/1724] loss: 0.283, ave_loss: 0.337
[8]  [140/1724] loss: 0.389, ave_loss: 0.343
[9]  [160/1724] loss: 0.284, ave_loss: 0.337
[10]  [180/1724] loss: 0.668, ave_loss: 0.370
[11]  [200/1724] loss: 0.384, ave_loss: 0.371
[12]  [220/1724] loss: 0.348, ave_loss: 0.369
[13]  [240/1724] loss: 0.390, ave_loss: 0.371
[14]  [260/1724] loss: 0.316, ave_loss: 0.367
[15]  [280/1724] loss: 0.445, ave_loss: 0.372
[16]  [300/1724] loss: 0.424, ave_loss: 0.375
[17]  [320/1724] loss: 0.392, ave_loss: 0.376
[18]  [340/1724] loss: 0.337, ave_loss: 0.374
[19]  [360/1724] loss: 0.306, ave_loss: 0.371
[20]  [380/1724] loss: 0.418, ave_loss: 0.373
[21]  [400/1724] loss: 0.328, ave_loss: 0.371
[22]  [420/1724] loss: 0.300, ave_loss: 0.368
[23]  [440/1724] loss: 0.425, ave_loss: 0.370
[24]  [460/1724] loss: 0.605, ave_loss: 0.380
[25]  [480/1724] loss: 0.255, ave_loss: 0.375
[26]  [500/1724] loss: 0.367, ave_loss: 0.375
[27]  [520/1724] loss: 0.237, ave_loss: 0.369
[28]  [540/1724] loss: 0.270, ave_loss: 0.366
[29]  [560/1724] loss: 0.315, ave_loss: 0.364
[30]  [580/1724] loss: 0.287, ave_loss: 0.362
[31]  [600/1724] loss: 0.292, ave_loss: 0.359
[32]  [620/1724] loss: 0.466, ave_loss: 0.363
[33]  [640/1724] loss: 0.441, ave_loss: 0.365
[34]  [660/1724] loss: 0.352, ave_loss: 0.365
[35]  [680/1724] loss: 0.584, ave_loss: 0.371
[36]  [700/1724] loss: 0.364, ave_loss: 0.371
[37]  [720/1724] loss: 0.422, ave_loss: 0.372
[38]  [740/1724] loss: 0.351, ave_loss: 0.372
[39]  [760/1724] loss: 0.393, ave_loss: 0.372
[40]  [780/1724] loss: 0.384, ave_loss: 0.372
[41]  [800/1724] loss: 0.385, ave_loss: 0.373
[42]  [820/1724] loss: 0.416, ave_loss: 0.374
[43]  [840/1724] loss: 0.249, ave_loss: 0.371
[44]  [860/1724] loss: 0.328, ave_loss: 0.370
[45]  [880/1724] loss: 0.559, ave_loss: 0.374
[46]  [900/1724] loss: 0.386, ave_loss: 0.374
[47]  [920/1724] loss: 0.339, ave_loss: 0.374
[48]  [940/1724] loss: 0.458, ave_loss: 0.375
[49]  [960/1724] loss: 0.369, ave_loss: 0.375
[50]  [980/1724] loss: 0.431, ave_loss: 0.376
[51]  [1000/1724] loss: 0.380, ave_loss: 0.376
[52]  [1020/1724] loss: 0.315, ave_loss: 0.375
[53]  [1040/1724] loss: 0.444, ave_loss: 0.377
[54]  [1060/1724] loss: 0.370, ave_loss: 0.376
[55]  [1080/1724] loss: 0.347, ave_loss: 0.376
[56]  [1100/1724] loss: 0.317, ave_loss: 0.375
[57]  [1120/1724] loss: 0.345, ave_loss: 0.374
[58]  [1140/1724] loss: 0.293, ave_loss: 0.373
[59]  [1160/1724] loss: 0.421, ave_loss: 0.374
[60]  [1180/1724] loss: 0.544, ave_loss: 0.377
[61]  [1200/1724] loss: 0.403, ave_loss: 0.377
[62]  [1220/1724] loss: 0.352, ave_loss: 0.377
[63]  [1240/1724] loss: 0.314, ave_loss: 0.376
[64]  [1260/1724] loss: 0.531, ave_loss: 0.378
[65]  [1280/1724] loss: 0.451, ave_loss: 0.379
[66]  [1300/1724] loss: 0.393, ave_loss: 0.379
[67]  [1320/1724] loss: 0.432, ave_loss: 0.380
[68]  [1340/1724] loss: 0.286, ave_loss: 0.379
[69]  [1360/1724] loss: 0.316, ave_loss: 0.378
[70]  [1380/1724] loss: 0.307, ave_loss: 0.377
[71]  [1400/1724] loss: 0.664, ave_loss: 0.381
[72]  [1420/1724] loss: 0.207, ave_loss: 0.378
[73]  [1440/1724] loss: 0.330, ave_loss: 0.378
[74]  [1460/1724] loss: 0.334, ave_loss: 0.377
[75]  [1480/1724] loss: 0.736, ave_loss: 0.382
[76]  [1500/1724] loss: 0.413, ave_loss: 0.382
[77]  [1520/1724] loss: 0.245, ave_loss: 0.381
[78]  [1540/1724] loss: 0.498, ave_loss: 0.382
[79]  [1560/1724] loss: 0.492, ave_loss: 0.384
[80]  [1580/1724] loss: 0.300, ave_loss: 0.382
[81]  [1600/1724] loss: 0.294, ave_loss: 0.381
[82]  [1620/1724] loss: 0.310, ave_loss: 0.380
[83]  [1640/1724] loss: 0.325, ave_loss: 0.380
[84]  [1660/1724] loss: 0.428, ave_loss: 0.380
[85]  [1680/1724] loss: 0.383, ave_loss: 0.380
[86]  [1700/1724] loss: 0.488, ave_loss: 0.382
[87]  [1720/1724] loss: 0.360, ave_loss: 0.381
[88]  [1740/1724] loss: 0.451, ave_loss: 0.382

Finished Training finishing at 2021-08-24 20:37:19.261510
printing_out epoch  32.66821345707657 learning rate: 0.00013570937476630243
0.00013163809352331336
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.822e-01
Validation Loss: 1.434e+03
Validation ROC: 0.7790
Saving model
66.33178654292342 epochs left to go

Training Epoch 32.66821345707657/100 starting at 2021-08-24 20:38:34.631586
[1]  [0/1724] loss: 0.287, ave_loss: 0.287
[2]  [20/1724] loss: 0.439, ave_loss: 0.363
[3]  [40/1724] loss: 0.314, ave_loss: 0.347
[4]  [60/1724] loss: 0.369, ave_loss: 0.352
[5]  [80/1724] loss: 0.199, ave_loss: 0.322
[6]  [100/1724] loss: 0.368, ave_loss: 0.329
[7]  [120/1724] loss: 0.425, ave_loss: 0.343
[8]  [140/1724] loss: 0.325, ave_loss: 0.341
[9]  [160/1724] loss: 0.380, ave_loss: 0.345
[10]  [180/1724] loss: 0.463, ave_loss: 0.357
[11]  [200/1724] loss: 0.292, ave_loss: 0.351
[12]  [220/1724] loss: 0.357, ave_loss: 0.352
[13]  [240/1724] loss: 0.299, ave_loss: 0.347
[14]  [260/1724] loss: 0.326, ave_loss: 0.346
[15]  [280/1724] loss: 0.286, ave_loss: 0.342
[16]  [300/1724] loss: 0.270, ave_loss: 0.338
[17]  [320/1724] loss: 0.439, ave_loss: 0.343
[18]  [340/1724] loss: 0.413, ave_loss: 0.347
[19]  [360/1724] loss: 0.341, ave_loss: 0.347
[20]  [380/1724] loss: 0.426, ave_loss: 0.351
[21]  [400/1724] loss: 0.305, ave_loss: 0.349
[22]  [420/1724] loss: 0.427, ave_loss: 0.352
[23]  [440/1724] loss: 0.240, ave_loss: 0.347
[24]  [460/1724] loss: 0.286, ave_loss: 0.345
[25]  [480/1724] loss: 0.326, ave_loss: 0.344
[26]  [500/1724] loss: 0.478, ave_loss: 0.349
[27]  [520/1724] loss: 0.408, ave_loss: 0.351
[28]  [540/1724] loss: 0.333, ave_loss: 0.351
[29]  [560/1724] loss: 0.442, ave_loss: 0.354
[30]  [580/1724] loss: 0.345, ave_loss: 0.354
[31]  [600/1724] loss: 0.420, ave_loss: 0.356
[32]  [620/1724] loss: 0.317, ave_loss: 0.355
[33]  [640/1724] loss: 0.463, ave_loss: 0.358
[34]  [660/1724] loss: 0.317, ave_loss: 0.357
[35]  [680/1724] loss: 0.380, ave_loss: 0.357
[36]  [700/1724] loss: 0.536, ave_loss: 0.362
[37]  [720/1724] loss: 0.380, ave_loss: 0.363
[38]  [740/1724] loss: 0.485, ave_loss: 0.366
[39]  [760/1724] loss: 0.302, ave_loss: 0.364
[40]  [780/1724] loss: 0.286, ave_loss: 0.362
[41]  [800/1724] loss: 0.258, ave_loss: 0.360
[42]  [820/1724] loss: 0.201, ave_loss: 0.356
[43]  [840/1724] loss: 0.327, ave_loss: 0.355
[44]  [860/1724] loss: 0.346, ave_loss: 0.355
[45]  [880/1724] loss: 0.454, ave_loss: 0.357
[46]  [900/1724] loss: 0.397, ave_loss: 0.358
[47]  [920/1724] loss: 0.307, ave_loss: 0.357
[48]  [940/1724] loss: 0.267, ave_loss: 0.355
[49]  [960/1724] loss: 0.368, ave_loss: 0.356
[50]  [980/1724] loss: 0.316, ave_loss: 0.355
[51]  [1000/1724] loss: 0.357, ave_loss: 0.355
[52]  [1020/1724] loss: 0.232, ave_loss: 0.352
[53]  [1040/1724] loss: 0.442, ave_loss: 0.354
[54]  [1060/1724] loss: 0.359, ave_loss: 0.354
[55]  [1080/1724] loss: 0.405, ave_loss: 0.355
[56]  [1100/1724] loss: 0.336, ave_loss: 0.355
[57]  [1120/1724] loss: 0.179, ave_loss: 0.352
[58]  [1140/1724] loss: 0.326, ave_loss: 0.351
[59]  [1160/1724] loss: 0.241, ave_loss: 0.349
[60]  [1180/1724] loss: 0.387, ave_loss: 0.350
[61]  [1200/1724] loss: 0.303, ave_loss: 0.349
[62]  [1220/1724] loss: 0.369, ave_loss: 0.350
[63]  [1240/1724] loss: 0.400, ave_loss: 0.350
[64]  [1260/1724] loss: 0.380, ave_loss: 0.351
[65]  [1280/1724] loss: 0.332, ave_loss: 0.351
[66]  [1300/1724] loss: 0.283, ave_loss: 0.349
[67]  [1320/1724] loss: 0.323, ave_loss: 0.349
[68]  [1340/1724] loss: 0.397, ave_loss: 0.350
[69]  [1360/1724] loss: 0.428, ave_loss: 0.351
[70]  [1380/1724] loss: 0.517, ave_loss: 0.353
[71]  [1400/1724] loss: 0.401, ave_loss: 0.354
[72]  [1420/1724] loss: 0.358, ave_loss: 0.354
[73]  [1440/1724] loss: 0.338, ave_loss: 0.354
[74]  [1460/1724] loss: 0.517, ave_loss: 0.356
[75]  [1480/1724] loss: 0.526, ave_loss: 0.358
[76]  [1500/1724] loss: 0.416, ave_loss: 0.359
[77]  [1520/1724] loss: 0.285, ave_loss: 0.358
[78]  [1540/1724] loss: 0.369, ave_loss: 0.358
[79]  [1560/1724] loss: 0.358, ave_loss: 0.358
[80]  [1580/1724] loss: 0.271, ave_loss: 0.357
[81]  [1600/1724] loss: 0.388, ave_loss: 0.358
[82]  [1620/1724] loss: 0.525, ave_loss: 0.360
[83]  [1640/1724] loss: 0.440, ave_loss: 0.361
[84]  [1660/1724] loss: 0.389, ave_loss: 0.361
[85]  [1680/1724] loss: 0.277, ave_loss: 0.360
[86]  [1700/1724] loss: 0.406, ave_loss: 0.360
[87]  [1720/1724] loss: 0.356, ave_loss: 0.360
[88]  [1740/1724] loss: 0.342, ave_loss: 0.360

Finished Training finishing at 2021-08-24 20:40:47.515169
printing_out epoch  33.68909512761021 learning rate: 0.00013570937476630243
0.00012768895071761397
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.602e-01
Validation Loss: 1.202e+03
Validation ROC: 0.7763
No improvement, still saving model
65.31090487238978 epochs left to go

Training Epoch 33.68909512761021/100 starting at 2021-08-24 20:41:16.860333
[1]  [0/1724] loss: 0.301, ave_loss: 0.301
[2]  [20/1724] loss: 0.332, ave_loss: 0.317
[3]  [40/1724] loss: 0.270, ave_loss: 0.301
[4]  [60/1724] loss: 0.261, ave_loss: 0.291
[5]  [80/1724] loss: 0.329, ave_loss: 0.299
[6]  [100/1724] loss: 0.457, ave_loss: 0.325
[7]  [120/1724] loss: 0.407, ave_loss: 0.337
[8]  [140/1724] loss: 0.285, ave_loss: 0.330
[9]  [160/1724] loss: 0.289, ave_loss: 0.326
[10]  [180/1724] loss: 0.509, ave_loss: 0.344
[11]  [200/1724] loss: 0.404, ave_loss: 0.349
[12]  [220/1724] loss: 0.323, ave_loss: 0.347
[13]  [240/1724] loss: 0.381, ave_loss: 0.350
[14]  [260/1724] loss: 0.393, ave_loss: 0.353
[15]  [280/1724] loss: 0.397, ave_loss: 0.356
[16]  [300/1724] loss: 0.387, ave_loss: 0.358
[17]  [320/1724] loss: 0.369, ave_loss: 0.359
[18]  [340/1724] loss: 0.190, ave_loss: 0.349
[19]  [360/1724] loss: 0.324, ave_loss: 0.348
[20]  [380/1724] loss: 0.306, ave_loss: 0.346
[21]  [400/1724] loss: 0.350, ave_loss: 0.346
[22]  [420/1724] loss: 0.341, ave_loss: 0.346
[23]  [440/1724] loss: 0.462, ave_loss: 0.351
[24]  [460/1724] loss: 0.500, ave_loss: 0.357
[25]  [480/1724] loss: 0.240, ave_loss: 0.352
[26]  [500/1724] loss: 0.304, ave_loss: 0.350
[27]  [520/1724] loss: 0.440, ave_loss: 0.354
[28]  [540/1724] loss: 0.281, ave_loss: 0.351
[29]  [560/1724] loss: 0.584, ave_loss: 0.359
[30]  [580/1724] loss: 0.356, ave_loss: 0.359
[31]  [600/1724] loss: 0.370, ave_loss: 0.359
[32]  [620/1724] loss: 0.198, ave_loss: 0.354
[33]  [640/1724] loss: 0.395, ave_loss: 0.356
[34]  [660/1724] loss: 0.295, ave_loss: 0.354
[35]  [680/1724] loss: 0.430, ave_loss: 0.356
[36]  [700/1724] loss: 0.354, ave_loss: 0.356
[37]  [720/1724] loss: 0.524, ave_loss: 0.361
[38]  [740/1724] loss: 0.289, ave_loss: 0.359
[39]  [760/1724] loss: 0.505, ave_loss: 0.362
[40]  [780/1724] loss: 0.435, ave_loss: 0.364
[41]  [800/1724] loss: 0.332, ave_loss: 0.363
[42]  [820/1724] loss: 0.262, ave_loss: 0.361
[43]  [840/1724] loss: 0.451, ave_loss: 0.363
[44]  [860/1724] loss: 0.409, ave_loss: 0.364
[45]  [880/1724] loss: 0.189, ave_loss: 0.360
[46]  [900/1724] loss: 0.262, ave_loss: 0.358
[47]  [920/1724] loss: 0.318, ave_loss: 0.357
[48]  [940/1724] loss: 0.406, ave_loss: 0.358
[49]  [960/1724] loss: 0.457, ave_loss: 0.360
[50]  [980/1724] loss: 0.348, ave_loss: 0.360
[51]  [1000/1724] loss: 0.290, ave_loss: 0.359
[52]  [1020/1724] loss: 0.416, ave_loss: 0.360
[53]  [1040/1724] loss: 0.301, ave_loss: 0.359
[54]  [1060/1724] loss: 0.291, ave_loss: 0.357
[55]  [1080/1724] loss: 0.348, ave_loss: 0.357
[56]  [1100/1724] loss: 0.416, ave_loss: 0.358
[57]  [1120/1724] loss: 0.293, ave_loss: 0.357
[58]  [1140/1724] loss: 0.266, ave_loss: 0.356
[59]  [1160/1724] loss: 0.480, ave_loss: 0.358
[60]  [1180/1724] loss: 0.263, ave_loss: 0.356
[61]  [1200/1724] loss: 0.272, ave_loss: 0.355
[62]  [1220/1724] loss: 0.573, ave_loss: 0.358
[63]  [1240/1724] loss: 0.523, ave_loss: 0.361
[64]  [1260/1724] loss: 0.282, ave_loss: 0.360
[65]  [1280/1724] loss: 0.388, ave_loss: 0.360
[66]  [1300/1724] loss: 0.276, ave_loss: 0.359
[67]  [1320/1724] loss: 0.404, ave_loss: 0.359
[68]  [1340/1724] loss: 0.432, ave_loss: 0.361
[69]  [1360/1724] loss: 0.295, ave_loss: 0.360
[70]  [1380/1724] loss: 0.391, ave_loss: 0.360
[71]  [1400/1724] loss: 0.420, ave_loss: 0.361
[72]  [1420/1724] loss: 0.311, ave_loss: 0.360
[73]  [1440/1724] loss: 0.362, ave_loss: 0.360
[74]  [1460/1724] loss: 0.392, ave_loss: 0.361
[75]  [1480/1724] loss: 0.293, ave_loss: 0.360
[76]  [1500/1724] loss: 0.218, ave_loss: 0.358
[77]  [1520/1724] loss: 0.493, ave_loss: 0.360
[78]  [1540/1724] loss: 0.272, ave_loss: 0.358
[79]  [1560/1724] loss: 0.340, ave_loss: 0.358
[80]  [1580/1724] loss: 0.341, ave_loss: 0.358
[81]  [1600/1724] loss: 0.382, ave_loss: 0.358
[82]  [1620/1724] loss: 0.438, ave_loss: 0.359
[83]  [1640/1724] loss: 0.371, ave_loss: 0.359
[84]  [1660/1724] loss: 0.485, ave_loss: 0.361
[85]  [1680/1724] loss: 0.268, ave_loss: 0.360
[86]  [1700/1724] loss: 0.330, ave_loss: 0.360
[87]  [1720/1724] loss: 0.366, ave_loss: 0.360
[88]  [1740/1724] loss: 0.296, ave_loss: 0.359

Finished Training finishing at 2021-08-24 20:43:19.503301
printing_out epoch  34.70997679814385 learning rate: 0.00012337215887845676
0.00011967099411210306
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.589e-01
Validation Loss: 1.226e+03
Validation ROC: 0.7782
No improvement, still saving model
64.29002320185614 epochs left to go

Training Epoch 34.70997679814385/100 starting at 2021-08-24 20:43:57.793570
[1]  [0/1724] loss: 0.777, ave_loss: 0.777
[2]  [20/1724] loss: 0.412, ave_loss: 0.595
[3]  [40/1724] loss: 0.519, ave_loss: 0.570
[4]  [60/1724] loss: 0.479, ave_loss: 0.547
[5]  [80/1724] loss: 0.332, ave_loss: 0.504
[6]  [100/1724] loss: 0.347, ave_loss: 0.478
[7]  [120/1724] loss: 0.223, ave_loss: 0.441
[8]  [140/1724] loss: 0.371, ave_loss: 0.433
[9]  [160/1724] loss: 0.406, ave_loss: 0.430
[10]  [180/1724] loss: 0.507, ave_loss: 0.437
[11]  [200/1724] loss: 0.591, ave_loss: 0.451
[12]  [220/1724] loss: 0.520, ave_loss: 0.457
[13]  [240/1724] loss: 0.502, ave_loss: 0.460
[14]  [260/1724] loss: 0.254, ave_loss: 0.446
[15]  [280/1724] loss: 0.253, ave_loss: 0.433
[16]  [300/1724] loss: 0.266, ave_loss: 0.422
[17]  [320/1724] loss: 0.293, ave_loss: 0.415
[18]  [340/1724] loss: 0.281, ave_loss: 0.407
[19]  [360/1724] loss: 0.295, ave_loss: 0.401
[20]  [380/1724] loss: 0.255, ave_loss: 0.394
[21]  [400/1724] loss: 0.530, ave_loss: 0.401
[22]  [420/1724] loss: 0.264, ave_loss: 0.394
[23]  [440/1724] loss: 0.486, ave_loss: 0.398
[24]  [460/1724] loss: 0.323, ave_loss: 0.395
[25]  [480/1724] loss: 0.238, ave_loss: 0.389
[26]  [500/1724] loss: 0.308, ave_loss: 0.386
[27]  [520/1724] loss: 0.377, ave_loss: 0.385
[28]  [540/1724] loss: 0.319, ave_loss: 0.383
[29]  [560/1724] loss: 0.411, ave_loss: 0.384
[30]  [580/1724] loss: 0.282, ave_loss: 0.381
[31]  [600/1724] loss: 0.258, ave_loss: 0.377
[32]  [620/1724] loss: 0.332, ave_loss: 0.375
[33]  [640/1724] loss: 0.305, ave_loss: 0.373
[34]  [660/1724] loss: 0.453, ave_loss: 0.376
[35]  [680/1724] loss: 0.378, ave_loss: 0.376
[36]  [700/1724] loss: 0.362, ave_loss: 0.375
[37]  [720/1724] loss: 0.471, ave_loss: 0.378
[38]  [740/1724] loss: 0.373, ave_loss: 0.378
[39]  [760/1724] loss: 0.357, ave_loss: 0.377
[40]  [780/1724] loss: 0.421, ave_loss: 0.378
[41]  [800/1724] loss: 0.467, ave_loss: 0.380
[42]  [820/1724] loss: 0.519, ave_loss: 0.384
[43]  [840/1724] loss: 0.375, ave_loss: 0.384
[44]  [860/1724] loss: 0.289, ave_loss: 0.381
[45]  [880/1724] loss: 0.278, ave_loss: 0.379
[46]  [900/1724] loss: 0.341, ave_loss: 0.378
[47]  [920/1724] loss: 0.471, ave_loss: 0.380
[48]  [940/1724] loss: 0.500, ave_loss: 0.383
[49]  [960/1724] loss: 0.556, ave_loss: 0.386
[50]  [980/1724] loss: 0.526, ave_loss: 0.389
[51]  [1000/1724] loss: 0.452, ave_loss: 0.390
[52]  [1020/1724] loss: 0.325, ave_loss: 0.389
[53]  [1040/1724] loss: 0.302, ave_loss: 0.387
[54]  [1060/1724] loss: 0.257, ave_loss: 0.385
[55]  [1080/1724] loss: 0.411, ave_loss: 0.385
[56]  [1100/1724] loss: 0.330, ave_loss: 0.384
[57]  [1120/1724] loss: 0.412, ave_loss: 0.385
[58]  [1140/1724] loss: 0.457, ave_loss: 0.386
[59]  [1160/1724] loss: 0.366, ave_loss: 0.386
[60]  [1180/1724] loss: 0.257, ave_loss: 0.384
[61]  [1200/1724] loss: 0.402, ave_loss: 0.384
[62]  [1220/1724] loss: 0.413, ave_loss: 0.384
[63]  [1240/1724] loss: 0.425, ave_loss: 0.385
[64]  [1260/1724] loss: 0.379, ave_loss: 0.385
[65]  [1280/1724] loss: 0.299, ave_loss: 0.384
[66]  [1300/1724] loss: 0.371, ave_loss: 0.383
[67]  [1320/1724] loss: 0.344, ave_loss: 0.383
[68]  [1340/1724] loss: 0.232, ave_loss: 0.381
[69]  [1360/1724] loss: 0.349, ave_loss: 0.380
[70]  [1380/1724] loss: 0.390, ave_loss: 0.380
[71]  [1400/1724] loss: 0.260, ave_loss: 0.379
[72]  [1420/1724] loss: 0.307, ave_loss: 0.378
[73]  [1440/1724] loss: 0.487, ave_loss: 0.379
[74]  [1460/1724] loss: 0.512, ave_loss: 0.381
[75]  [1480/1724] loss: 0.275, ave_loss: 0.380
[76]  [1500/1724] loss: 0.343, ave_loss: 0.379
[77]  [1520/1724] loss: 0.379, ave_loss: 0.379
[78]  [1540/1724] loss: 0.467, ave_loss: 0.380
[79]  [1560/1724] loss: 0.228, ave_loss: 0.378
[80]  [1580/1724] loss: 0.317, ave_loss: 0.377
[81]  [1600/1724] loss: 0.318, ave_loss: 0.377
[82]  [1620/1724] loss: 0.399, ave_loss: 0.377
[83]  [1640/1724] loss: 0.547, ave_loss: 0.379
[84]  [1660/1724] loss: 0.374, ave_loss: 0.379
[85]  [1680/1724] loss: 0.448, ave_loss: 0.380
[86]  [1700/1724] loss: 0.419, ave_loss: 0.380
[87]  [1720/1724] loss: 0.448, ave_loss: 0.381
[88]  [1740/1724] loss: 0.385, ave_loss: 0.381

Finished Training finishing at 2021-08-24 20:46:03.530685
printing_out epoch  35.730858468677496 learning rate: 0.00011215650807132433
0.0001087918128291846
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.811e-01
Validation Loss: 1.241e+03
Validation ROC: 0.7780
No improvement, still saving model
63.269141531322504 epochs left to go

Training Epoch 35.730858468677496/100 starting at 2021-08-24 20:46:40.430885
[1]  [0/1724] loss: 0.557, ave_loss: 0.557
[2]  [20/1724] loss: 0.264, ave_loss: 0.411
[3]  [40/1724] loss: 0.383, ave_loss: 0.401
[4]  [60/1724] loss: 0.293, ave_loss: 0.374
[5]  [80/1724] loss: 0.416, ave_loss: 0.383
[6]  [100/1724] loss: 0.513, ave_loss: 0.404
[7]  [120/1724] loss: 0.357, ave_loss: 0.398
[8]  [140/1724] loss: 0.379, ave_loss: 0.395
[9]  [160/1724] loss: 0.353, ave_loss: 0.390
[10]  [180/1724] loss: 0.362, ave_loss: 0.388
[11]  [200/1724] loss: 0.292, ave_loss: 0.379
[12]  [220/1724] loss: 0.270, ave_loss: 0.370
[13]  [240/1724] loss: 0.438, ave_loss: 0.375
[14]  [260/1724] loss: 0.266, ave_loss: 0.367
[15]  [280/1724] loss: 0.307, ave_loss: 0.363
[16]  [300/1724] loss: 0.296, ave_loss: 0.359
[17]  [320/1724] loss: 0.372, ave_loss: 0.360
[18]  [340/1724] loss: 0.594, ave_loss: 0.373
[19]  [360/1724] loss: 0.340, ave_loss: 0.371
[20]  [380/1724] loss: 0.506, ave_loss: 0.378
[21]  [400/1724] loss: 0.407, ave_loss: 0.379
[22]  [420/1724] loss: 0.384, ave_loss: 0.379
[23]  [440/1724] loss: 0.421, ave_loss: 0.381
[24]  [460/1724] loss: 0.449, ave_loss: 0.384
[25]  [480/1724] loss: 0.331, ave_loss: 0.382
[26]  [500/1724] loss: 0.279, ave_loss: 0.378
[27]  [520/1724] loss: 0.266, ave_loss: 0.374
[28]  [540/1724] loss: 0.281, ave_loss: 0.371
[29]  [560/1724] loss: 0.400, ave_loss: 0.372
[30]  [580/1724] loss: 0.467, ave_loss: 0.375
[31]  [600/1724] loss: 0.389, ave_loss: 0.375
[32]  [620/1724] loss: 0.445, ave_loss: 0.377
[33]  [640/1724] loss: 0.246, ave_loss: 0.373
[34]  [660/1724] loss: 0.486, ave_loss: 0.377
[35]  [680/1724] loss: 0.516, ave_loss: 0.381
[36]  [700/1724] loss: 0.254, ave_loss: 0.377
[37]  [720/1724] loss: 0.444, ave_loss: 0.379
[38]  [740/1724] loss: 0.273, ave_loss: 0.376
[39]  [760/1724] loss: 0.387, ave_loss: 0.377
[40]  [780/1724] loss: 0.320, ave_loss: 0.375
[41]  [800/1724] loss: 0.316, ave_loss: 0.374
[42]  [820/1724] loss: 0.477, ave_loss: 0.376
[43]  [840/1724] loss: 0.370, ave_loss: 0.376
[44]  [860/1724] loss: 0.296, ave_loss: 0.374
[45]  [880/1724] loss: 0.404, ave_loss: 0.375
[46]  [900/1724] loss: 0.311, ave_loss: 0.373
[47]  [920/1724] loss: 0.242, ave_loss: 0.371
[48]  [940/1724] loss: 0.269, ave_loss: 0.369
[49]  [960/1724] loss: 0.410, ave_loss: 0.369
[50]  [980/1724] loss: 0.230, ave_loss: 0.367
[51]  [1000/1724] loss: 0.477, ave_loss: 0.369
[52]  [1020/1724] loss: 0.449, ave_loss: 0.370
[53]  [1040/1724] loss: 0.334, ave_loss: 0.370
[54]  [1060/1724] loss: 0.339, ave_loss: 0.369
[55]  [1080/1724] loss: 0.382, ave_loss: 0.369
[56]  [1100/1724] loss: 0.340, ave_loss: 0.369
[57]  [1120/1724] loss: 0.438, ave_loss: 0.370
[58]  [1140/1724] loss: 0.368, ave_loss: 0.370
[59]  [1160/1724] loss: 0.303, ave_loss: 0.369
[60]  [1180/1724] loss: 0.314, ave_loss: 0.368
[61]  [1200/1724] loss: 0.287, ave_loss: 0.367
[62]  [1220/1724] loss: 0.471, ave_loss: 0.368
[63]  [1240/1724] loss: 0.490, ave_loss: 0.370
[64]  [1260/1724] loss: 0.195, ave_loss: 0.367
[65]  [1280/1724] loss: 0.395, ave_loss: 0.368
[66]  [1300/1724] loss: 0.385, ave_loss: 0.368
[67]  [1320/1724] loss: 0.399, ave_loss: 0.369
[68]  [1340/1724] loss: 0.333, ave_loss: 0.368
[69]  [1360/1724] loss: 0.358, ave_loss: 0.368
[70]  [1380/1724] loss: 0.375, ave_loss: 0.368
[71]  [1400/1724] loss: 0.393, ave_loss: 0.368
[72]  [1420/1724] loss: 0.340, ave_loss: 0.368
[73]  [1440/1724] loss: 0.414, ave_loss: 0.369
[74]  [1460/1724] loss: 0.451, ave_loss: 0.370
[75]  [1480/1724] loss: 0.390, ave_loss: 0.370
[76]  [1500/1724] loss: 0.425, ave_loss: 0.371
[77]  [1520/1724] loss: 0.466, ave_loss: 0.372
[78]  [1540/1724] loss: 0.484, ave_loss: 0.373
[79]  [1560/1724] loss: 0.261, ave_loss: 0.372
[80]  [1580/1724] loss: 0.326, ave_loss: 0.371
[81]  [1600/1724] loss: 0.364, ave_loss: 0.371
[82]  [1620/1724] loss: 0.516, ave_loss: 0.373
[83]  [1640/1724] loss: 0.374, ave_loss: 0.373
[84]  [1660/1724] loss: 0.508, ave_loss: 0.375
[85]  [1680/1724] loss: 0.348, ave_loss: 0.374
[86]  [1700/1724] loss: 0.429, ave_loss: 0.375
[87]  [1720/1724] loss: 0.398, ave_loss: 0.375
[88]  [1740/1724] loss: 0.218, ave_loss: 0.373

Finished Training finishing at 2021-08-24 20:48:40.738220
printing_out epoch  36.75174013921114 learning rate: 0.00010196046188302211
9.890164802653145e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.735e-01
Validation Loss: 1.179e+03
Validation ROC: 0.7784
No improvement, still saving model
62.24825986078886 epochs left to go

Training Epoch 36.75174013921114/100 starting at 2021-08-24 20:49:30.718512
[1]  [0/1724] loss: 0.540, ave_loss: 0.540
[2]  [20/1724] loss: 0.369, ave_loss: 0.454
[3]  [40/1724] loss: 0.293, ave_loss: 0.401
[4]  [60/1724] loss: 0.287, ave_loss: 0.372
[5]  [80/1724] loss: 0.358, ave_loss: 0.369
[6]  [100/1724] loss: 0.461, ave_loss: 0.384
[7]  [120/1724] loss: 0.292, ave_loss: 0.371
[8]  [140/1724] loss: 0.416, ave_loss: 0.377
[9]  [160/1724] loss: 0.467, ave_loss: 0.387
[10]  [180/1724] loss: 0.306, ave_loss: 0.379
[11]  [200/1724] loss: 0.284, ave_loss: 0.370
[12]  [220/1724] loss: 0.289, ave_loss: 0.363
[13]  [240/1724] loss: 0.289, ave_loss: 0.358
[14]  [260/1724] loss: 0.280, ave_loss: 0.352
[15]  [280/1724] loss: 0.251, ave_loss: 0.345
[16]  [300/1724] loss: 0.282, ave_loss: 0.341
[17]  [320/1724] loss: 0.459, ave_loss: 0.348
[18]  [340/1724] loss: 0.300, ave_loss: 0.346
[19]  [360/1724] loss: 0.305, ave_loss: 0.344
[20]  [380/1724] loss: 0.478, ave_loss: 0.350
[21]  [400/1724] loss: 0.394, ave_loss: 0.352
[22]  [420/1724] loss: 0.417, ave_loss: 0.355
[23]  [440/1724] loss: 0.524, ave_loss: 0.363
[24]  [460/1724] loss: 0.328, ave_loss: 0.361
[25]  [480/1724] loss: 0.441, ave_loss: 0.364
[26]  [500/1724] loss: 0.426, ave_loss: 0.367
[27]  [520/1724] loss: 0.320, ave_loss: 0.365
[28]  [540/1724] loss: 0.568, ave_loss: 0.372
[29]  [560/1724] loss: 0.330, ave_loss: 0.371
[30]  [580/1724] loss: 0.293, ave_loss: 0.368
[31]  [600/1724] loss: 0.292, ave_loss: 0.366
[32]  [620/1724] loss: 0.275, ave_loss: 0.363
[33]  [640/1724] loss: 0.339, ave_loss: 0.362
[34]  [660/1724] loss: 0.434, ave_loss: 0.364
[35]  [680/1724] loss: 0.370, ave_loss: 0.364
[36]  [700/1724] loss: 0.333, ave_loss: 0.364
[37]  [720/1724] loss: 0.358, ave_loss: 0.363
[38]  [740/1724] loss: 0.418, ave_loss: 0.365
[39]  [760/1724] loss: 0.357, ave_loss: 0.365
[40]  [780/1724] loss: 0.326, ave_loss: 0.364
[41]  [800/1724] loss: 0.300, ave_loss: 0.362
[42]  [820/1724] loss: 0.228, ave_loss: 0.359
[43]  [840/1724] loss: 0.368, ave_loss: 0.359
[44]  [860/1724] loss: 0.361, ave_loss: 0.359
[45]  [880/1724] loss: 0.211, ave_loss: 0.356
[46]  [900/1724] loss: 0.341, ave_loss: 0.356
[47]  [920/1724] loss: 0.369, ave_loss: 0.356
[48]  [940/1724] loss: 0.371, ave_loss: 0.356
[49]  [960/1724] loss: 0.366, ave_loss: 0.356
[50]  [980/1724] loss: 0.340, ave_loss: 0.356
[51]  [1000/1724] loss: 0.299, ave_loss: 0.355
[52]  [1020/1724] loss: 0.379, ave_loss: 0.355
[53]  [1040/1724] loss: 0.329, ave_loss: 0.355
[54]  [1060/1724] loss: 0.302, ave_loss: 0.354
[55]  [1080/1724] loss: 0.365, ave_loss: 0.354
[56]  [1100/1724] loss: 0.328, ave_loss: 0.354
[57]  [1120/1724] loss: 0.409, ave_loss: 0.355
[58]  [1140/1724] loss: 0.262, ave_loss: 0.353
[59]  [1160/1724] loss: 0.451, ave_loss: 0.355
[60]  [1180/1724] loss: 0.414, ave_loss: 0.356
[61]  [1200/1724] loss: 0.357, ave_loss: 0.356
[62]  [1220/1724] loss: 0.350, ave_loss: 0.356
[63]  [1240/1724] loss: 0.378, ave_loss: 0.356
[64]  [1260/1724] loss: 0.333, ave_loss: 0.356
[65]  [1280/1724] loss: 0.425, ave_loss: 0.357
[66]  [1300/1724] loss: 0.383, ave_loss: 0.357
[67]  [1320/1724] loss: 0.366, ave_loss: 0.357
[68]  [1340/1724] loss: 0.564, ave_loss: 0.360
[69]  [1360/1724] loss: 0.400, ave_loss: 0.361
[70]  [1380/1724] loss: 0.575, ave_loss: 0.364
[71]  [1400/1724] loss: 0.315, ave_loss: 0.363
[72]  [1420/1724] loss: 0.391, ave_loss: 0.364
[73]  [1440/1724] loss: 0.369, ave_loss: 0.364
[74]  [1460/1724] loss: 0.364, ave_loss: 0.364
[75]  [1480/1724] loss: 0.247, ave_loss: 0.362
[76]  [1500/1724] loss: 0.261, ave_loss: 0.361
[77]  [1520/1724] loss: 0.211, ave_loss: 0.359
[78]  [1540/1724] loss: 0.387, ave_loss: 0.359
[79]  [1560/1724] loss: 0.365, ave_loss: 0.359
[80]  [1580/1724] loss: 0.308, ave_loss: 0.359
[81]  [1600/1724] loss: 0.338, ave_loss: 0.358
[82]  [1620/1724] loss: 0.556, ave_loss: 0.361
[83]  [1640/1724] loss: 0.457, ave_loss: 0.362
[84]  [1660/1724] loss: 0.478, ave_loss: 0.363
[85]  [1680/1724] loss: 0.393, ave_loss: 0.364
[86]  [1700/1724] loss: 0.326, ave_loss: 0.363
[87]  [1720/1724] loss: 0.436, ave_loss: 0.364
[88]  [1740/1724] loss: 0.272, ave_loss: 0.363

Finished Training finishing at 2021-08-24 20:51:38.071460
printing_out epoch  37.77262180974478 learning rate: 9.269132898456555e-05
8.991058911502858e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.630e-01
Validation Loss: 1.004e+03
Validation ROC: 0.7775
No improvement, still saving model
61.22737819025522 epochs left to go

Training Epoch 37.77262180974478/100 starting at 2021-08-24 20:52:55.738825
[1]  [0/1724] loss: 0.434, ave_loss: 0.434
[2]  [20/1724] loss: 0.497, ave_loss: 0.466
[3]  [40/1724] loss: 0.366, ave_loss: 0.432
[4]  [60/1724] loss: 0.397, ave_loss: 0.423
[5]  [80/1724] loss: 0.328, ave_loss: 0.404
[6]  [100/1724] loss: 0.221, ave_loss: 0.374
[7]  [120/1724] loss: 0.233, ave_loss: 0.354
[8]  [140/1724] loss: 0.497, ave_loss: 0.372
[9]  [160/1724] loss: 0.506, ave_loss: 0.386
[10]  [180/1724] loss: 0.467, ave_loss: 0.394
[11]  [200/1724] loss: 0.221, ave_loss: 0.379
[12]  [220/1724] loss: 0.419, ave_loss: 0.382
[13]  [240/1724] loss: 0.314, ave_loss: 0.377
[14]  [260/1724] loss: 0.404, ave_loss: 0.379
[15]  [280/1724] loss: 0.353, ave_loss: 0.377
[16]  [300/1724] loss: 0.466, ave_loss: 0.383
[17]  [320/1724] loss: 0.376, ave_loss: 0.382
[18]  [340/1724] loss: 0.348, ave_loss: 0.380
[19]  [360/1724] loss: 0.477, ave_loss: 0.385
[20]  [380/1724] loss: 0.269, ave_loss: 0.379
[21]  [400/1724] loss: 0.268, ave_loss: 0.374
[22]  [420/1724] loss: 0.409, ave_loss: 0.376
[23]  [440/1724] loss: 0.578, ave_loss: 0.385
[24]  [460/1724] loss: 0.298, ave_loss: 0.381
[25]  [480/1724] loss: 0.468, ave_loss: 0.384
[26]  [500/1724] loss: 0.390, ave_loss: 0.385
[27]  [520/1724] loss: 0.320, ave_loss: 0.382
[28]  [540/1724] loss: 0.371, ave_loss: 0.382
[29]  [560/1724] loss: 0.428, ave_loss: 0.383
[30]  [580/1724] loss: 0.423, ave_loss: 0.385
[31]  [600/1724] loss: 0.339, ave_loss: 0.383
[32]  [620/1724] loss: 0.446, ave_loss: 0.385
[33]  [640/1724] loss: 0.209, ave_loss: 0.380
[34]  [660/1724] loss: 0.314, ave_loss: 0.378
[35]  [680/1724] loss: 0.472, ave_loss: 0.381
[36]  [700/1724] loss: 0.362, ave_loss: 0.380
[37]  [720/1724] loss: 0.426, ave_loss: 0.381
[38]  [740/1724] loss: 0.217, ave_loss: 0.377
[39]  [760/1724] loss: 0.383, ave_loss: 0.377
[40]  [780/1724] loss: 0.366, ave_loss: 0.377
[41]  [800/1724] loss: 0.414, ave_loss: 0.378
[42]  [820/1724] loss: 0.347, ave_loss: 0.377
[43]  [840/1724] loss: 0.243, ave_loss: 0.374
[44]  [860/1724] loss: 0.411, ave_loss: 0.375
[45]  [880/1724] loss: 0.488, ave_loss: 0.377
[46]  [900/1724] loss: 0.453, ave_loss: 0.379
[47]  [920/1724] loss: 0.339, ave_loss: 0.378
[48]  [940/1724] loss: 0.359, ave_loss: 0.378
[49]  [960/1724] loss: 0.284, ave_loss: 0.376
[50]  [980/1724] loss: 0.347, ave_loss: 0.375
[51]  [1000/1724] loss: 0.321, ave_loss: 0.374
[52]  [1020/1724] loss: 0.450, ave_loss: 0.376
[53]  [1040/1724] loss: 0.274, ave_loss: 0.374
[54]  [1060/1724] loss: 0.410, ave_loss: 0.374
[55]  [1080/1724] loss: 0.499, ave_loss: 0.377
[56]  [1100/1724] loss: 0.443, ave_loss: 0.378
[57]  [1120/1724] loss: 0.271, ave_loss: 0.376
[58]  [1140/1724] loss: 0.274, ave_loss: 0.374
[59]  [1160/1724] loss: 0.418, ave_loss: 0.375
[60]  [1180/1724] loss: 0.292, ave_loss: 0.374
[61]  [1200/1724] loss: 0.389, ave_loss: 0.374
[62]  [1220/1724] loss: 0.514, ave_loss: 0.376
[63]  [1240/1724] loss: 0.406, ave_loss: 0.377
[64]  [1260/1724] loss: 0.382, ave_loss: 0.377
[65]  [1280/1724] loss: 0.288, ave_loss: 0.375
[66]  [1300/1724] loss: 0.381, ave_loss: 0.375
[67]  [1320/1724] loss: 0.461, ave_loss: 0.377
[68]  [1340/1724] loss: 0.412, ave_loss: 0.377
[69]  [1360/1724] loss: 0.462, ave_loss: 0.378
[70]  [1380/1724] loss: 0.447, ave_loss: 0.379
[71]  [1400/1724] loss: 0.299, ave_loss: 0.378
[72]  [1420/1724] loss: 0.418, ave_loss: 0.379
[73]  [1440/1724] loss: 0.456, ave_loss: 0.380
[74]  [1460/1724] loss: 0.266, ave_loss: 0.378
[75]  [1480/1724] loss: 0.449, ave_loss: 0.379
[76]  [1500/1724] loss: 0.372, ave_loss: 0.379
[77]  [1520/1724] loss: 0.284, ave_loss: 0.378
[78]  [1540/1724] loss: 0.276, ave_loss: 0.377
[79]  [1560/1724] loss: 0.333, ave_loss: 0.376
[80]  [1580/1724] loss: 0.345, ave_loss: 0.376
[81]  [1600/1724] loss: 0.462, ave_loss: 0.377
[82]  [1620/1724] loss: 0.599, ave_loss: 0.379
[83]  [1640/1724] loss: 0.239, ave_loss: 0.378
[84]  [1660/1724] loss: 0.398, ave_loss: 0.378
[85]  [1680/1724] loss: 0.381, ave_loss: 0.378
[86]  [1700/1724] loss: 0.499, ave_loss: 0.379
[87]  [1720/1724] loss: 0.291, ave_loss: 0.378
[88]  [1740/1724] loss: 0.402, ave_loss: 0.379

Finished Training finishing at 2021-08-24 20:54:42.113034
printing_out epoch  38.793503480278424 learning rate: 8.426484453142322e-05
8.173689919548052e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.787e-01
Validation Loss: 1.014e+03
Validation ROC: 0.7795
Saving model
60.206496519721576 epochs left to go

Training Epoch 38.793503480278424/100 starting at 2021-08-24 20:55:07.288849
[1]  [0/1724] loss: 0.571, ave_loss: 0.571
[2]  [20/1724] loss: 0.240, ave_loss: 0.405
[3]  [40/1724] loss: 0.363, ave_loss: 0.391
[4]  [60/1724] loss: 0.365, ave_loss: 0.385
[5]  [80/1724] loss: 0.343, ave_loss: 0.376
[6]  [100/1724] loss: 0.330, ave_loss: 0.368
[7]  [120/1724] loss: 0.320, ave_loss: 0.362
[8]  [140/1724] loss: 0.349, ave_loss: 0.360
[9]  [160/1724] loss: 0.319, ave_loss: 0.355
[10]  [180/1724] loss: 0.487, ave_loss: 0.369
[11]  [200/1724] loss: 0.549, ave_loss: 0.385
[12]  [220/1724] loss: 0.336, ave_loss: 0.381
[13]  [240/1724] loss: 0.241, ave_loss: 0.370
[14]  [260/1724] loss: 0.495, ave_loss: 0.379
[15]  [280/1724] loss: 0.401, ave_loss: 0.381
[16]  [300/1724] loss: 0.332, ave_loss: 0.377
[17]  [320/1724] loss: 0.458, ave_loss: 0.382
[18]  [340/1724] loss: 0.368, ave_loss: 0.381
[19]  [360/1724] loss: 0.294, ave_loss: 0.377
[20]  [380/1724] loss: 0.357, ave_loss: 0.376
[21]  [400/1724] loss: 0.356, ave_loss: 0.375
[22]  [420/1724] loss: 0.195, ave_loss: 0.367
[23]  [440/1724] loss: 0.313, ave_loss: 0.364
[24]  [460/1724] loss: 0.307, ave_loss: 0.362
[25]  [480/1724] loss: 0.307, ave_loss: 0.360
[26]  [500/1724] loss: 0.276, ave_loss: 0.357
[27]  [520/1724] loss: 0.305, ave_loss: 0.355
[28]  [540/1724] loss: 0.407, ave_loss: 0.357
[29]  [560/1724] loss: 0.323, ave_loss: 0.355
[30]  [580/1724] loss: 0.473, ave_loss: 0.359
[31]  [600/1724] loss: 0.405, ave_loss: 0.361
[32]  [620/1724] loss: 0.408, ave_loss: 0.362
[33]  [640/1724] loss: 0.422, ave_loss: 0.364
[34]  [660/1724] loss: 0.282, ave_loss: 0.362
[35]  [680/1724] loss: 0.344, ave_loss: 0.361
[36]  [700/1724] loss: 0.389, ave_loss: 0.362
[37]  [720/1724] loss: 0.332, ave_loss: 0.361
[38]  [740/1724] loss: 0.460, ave_loss: 0.364
[39]  [760/1724] loss: 0.538, ave_loss: 0.368
[40]  [780/1724] loss: 0.459, ave_loss: 0.370
[41]  [800/1724] loss: 0.551, ave_loss: 0.375
[42]  [820/1724] loss: 0.397, ave_loss: 0.375
[43]  [840/1724] loss: 0.426, ave_loss: 0.377
[44]  [860/1724] loss: 0.358, ave_loss: 0.376
[45]  [880/1724] loss: 0.358, ave_loss: 0.376
[46]  [900/1724] loss: 0.338, ave_loss: 0.375
[47]  [920/1724] loss: 0.321, ave_loss: 0.374
[48]  [940/1724] loss: 0.320, ave_loss: 0.373
[49]  [960/1724] loss: 0.320, ave_loss: 0.372
[50]  [980/1724] loss: 0.465, ave_loss: 0.373
[51]  [1000/1724] loss: 0.355, ave_loss: 0.373
[52]  [1020/1724] loss: 0.471, ave_loss: 0.375
[53]  [1040/1724] loss: 0.258, ave_loss: 0.373
[54]  [1060/1724] loss: 0.304, ave_loss: 0.372
[55]  [1080/1724] loss: 0.434, ave_loss: 0.373
[56]  [1100/1724] loss: 0.305, ave_loss: 0.371
[57]  [1120/1724] loss: 0.438, ave_loss: 0.373
[58]  [1140/1724] loss: 0.319, ave_loss: 0.372
[59]  [1160/1724] loss: 0.358, ave_loss: 0.371
[60]  [1180/1724] loss: 0.208, ave_loss: 0.369
[61]  [1200/1724] loss: 0.320, ave_loss: 0.368
[62]  [1220/1724] loss: 0.415, ave_loss: 0.369
[63]  [1240/1724] loss: 0.259, ave_loss: 0.367
[64]  [1260/1724] loss: 0.306, ave_loss: 0.366
[65]  [1280/1724] loss: 0.364, ave_loss: 0.366
[66]  [1300/1724] loss: 0.377, ave_loss: 0.366
[67]  [1320/1724] loss: 0.341, ave_loss: 0.366
[68]  [1340/1724] loss: 0.341, ave_loss: 0.365
[69]  [1360/1724] loss: 0.344, ave_loss: 0.365
[70]  [1380/1724] loss: 0.376, ave_loss: 0.365
[71]  [1400/1724] loss: 0.330, ave_loss: 0.365
[72]  [1420/1724] loss: 0.403, ave_loss: 0.365
[73]  [1440/1724] loss: 0.284, ave_loss: 0.364
[74]  [1460/1724] loss: 0.260, ave_loss: 0.363
[75]  [1480/1724] loss: 0.306, ave_loss: 0.362
[76]  [1500/1724] loss: 0.394, ave_loss: 0.362
[77]  [1520/1724] loss: 0.278, ave_loss: 0.361
[78]  [1540/1724] loss: 0.433, ave_loss: 0.362
[79]  [1560/1724] loss: 0.348, ave_loss: 0.362
[80]  [1580/1724] loss: 0.350, ave_loss: 0.362
[81]  [1600/1724] loss: 0.335, ave_loss: 0.362
[82]  [1620/1724] loss: 0.309, ave_loss: 0.361
[83]  [1640/1724] loss: 0.517, ave_loss: 0.363
[84]  [1660/1724] loss: 0.226, ave_loss: 0.361
[85]  [1680/1724] loss: 0.401, ave_loss: 0.362
[86]  [1700/1724] loss: 0.279, ave_loss: 0.361
[87]  [1720/1724] loss: 0.222, ave_loss: 0.359
[88]  [1740/1724] loss: 0.410, ave_loss: 0.360

Finished Training finishing at 2021-08-24 20:57:06.619901
printing_out epoch  39.814385150812065 learning rate: 8.426484453142322e-05
7.92847922196161e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.597e-01
Validation Loss: 1.105e+03
Validation ROC: 0.7807
Saving model
59.185614849187935 epochs left to go

Training Epoch 39.814385150812065/100 starting at 2021-08-24 20:57:44.282580
[1]  [0/1724] loss: 0.441, ave_loss: 0.441
[2]  [20/1724] loss: 0.312, ave_loss: 0.376
[3]  [40/1724] loss: 0.449, ave_loss: 0.400
[4]  [60/1724] loss: 0.544, ave_loss: 0.436
[5]  [80/1724] loss: 0.417, ave_loss: 0.432
[6]  [100/1724] loss: 0.366, ave_loss: 0.421
[7]  [120/1724] loss: 0.255, ave_loss: 0.398
[8]  [140/1724] loss: 0.253, ave_loss: 0.379
[9]  [160/1724] loss: 0.313, ave_loss: 0.372
[10]  [180/1724] loss: 0.271, ave_loss: 0.362
[11]  [200/1724] loss: 0.407, ave_loss: 0.366
[12]  [220/1724] loss: 0.352, ave_loss: 0.365
[13]  [240/1724] loss: 0.389, ave_loss: 0.367
[14]  [260/1724] loss: 0.444, ave_loss: 0.372
[15]  [280/1724] loss: 0.323, ave_loss: 0.369
[16]  [300/1724] loss: 0.411, ave_loss: 0.371
[17]  [320/1724] loss: 0.276, ave_loss: 0.366
[18]  [340/1724] loss: 0.414, ave_loss: 0.369
[19]  [360/1724] loss: 0.283, ave_loss: 0.364
[20]  [380/1724] loss: 0.354, ave_loss: 0.364
[21]  [400/1724] loss: 0.508, ave_loss: 0.370
[22]  [420/1724] loss: 0.374, ave_loss: 0.371
[23]  [440/1724] loss: 0.293, ave_loss: 0.367
[24]  [460/1724] loss: 0.380, ave_loss: 0.368
[25]  [480/1724] loss: 0.329, ave_loss: 0.366
[26]  [500/1724] loss: 0.443, ave_loss: 0.369
[27]  [520/1724] loss: 0.245, ave_loss: 0.365
[28]  [540/1724] loss: 0.255, ave_loss: 0.361
[29]  [560/1724] loss: 0.395, ave_loss: 0.362
[30]  [580/1724] loss: 0.275, ave_loss: 0.359
[31]  [600/1724] loss: 0.372, ave_loss: 0.359
[32]  [620/1724] loss: 0.342, ave_loss: 0.359
[33]  [640/1724] loss: 0.321, ave_loss: 0.358
[34]  [660/1724] loss: 0.291, ave_loss: 0.356
[35]  [680/1724] loss: 0.495, ave_loss: 0.360
[36]  [700/1724] loss: 0.293, ave_loss: 0.358
[37]  [720/1724] loss: 0.306, ave_loss: 0.356
[38]  [740/1724] loss: 0.270, ave_loss: 0.354
[39]  [760/1724] loss: 0.294, ave_loss: 0.353
[40]  [780/1724] loss: 0.174, ave_loss: 0.348
[41]  [800/1724] loss: 0.451, ave_loss: 0.351
[42]  [820/1724] loss: 0.282, ave_loss: 0.349
[43]  [840/1724] loss: 0.538, ave_loss: 0.353
[44]  [860/1724] loss: 0.458, ave_loss: 0.356
[45]  [880/1724] loss: 0.419, ave_loss: 0.357
[46]  [900/1724] loss: 0.403, ave_loss: 0.358
[47]  [920/1724] loss: 0.430, ave_loss: 0.360
[48]  [940/1724] loss: 0.212, ave_loss: 0.357
[49]  [960/1724] loss: 0.363, ave_loss: 0.357
[50]  [980/1724] loss: 0.462, ave_loss: 0.359
[51]  [1000/1724] loss: 0.336, ave_loss: 0.358
[52]  [1020/1724] loss: 0.293, ave_loss: 0.357
[53]  [1040/1724] loss: 0.541, ave_loss: 0.361
[54]  [1060/1724] loss: 0.409, ave_loss: 0.362
[55]  [1080/1724] loss: 0.605, ave_loss: 0.366
[56]  [1100/1724] loss: 0.339, ave_loss: 0.365
[57]  [1120/1724] loss: 0.511, ave_loss: 0.368
[58]  [1140/1724] loss: 0.361, ave_loss: 0.368
[59]  [1160/1724] loss: 0.398, ave_loss: 0.368
[60]  [1180/1724] loss: 0.310, ave_loss: 0.367
[61]  [1200/1724] loss: 0.367, ave_loss: 0.367
[62]  [1220/1724] loss: 0.246, ave_loss: 0.365
[63]  [1240/1724] loss: 0.293, ave_loss: 0.364
[64]  [1260/1724] loss: 0.500, ave_loss: 0.366
[65]  [1280/1724] loss: 0.392, ave_loss: 0.367
[66]  [1300/1724] loss: 0.462, ave_loss: 0.368
[67]  [1320/1724] loss: 0.237, ave_loss: 0.366
[68]  [1340/1724] loss: 0.327, ave_loss: 0.366
[69]  [1360/1724] loss: 0.218, ave_loss: 0.364
[70]  [1380/1724] loss: 0.254, ave_loss: 0.362
[71]  [1400/1724] loss: 0.463, ave_loss: 0.363
[72]  [1420/1724] loss: 0.340, ave_loss: 0.363
[73]  [1440/1724] loss: 0.433, ave_loss: 0.364
[74]  [1460/1724] loss: 0.491, ave_loss: 0.366
[75]  [1480/1724] loss: 0.390, ave_loss: 0.366
[76]  [1500/1724] loss: 0.368, ave_loss: 0.366
[77]  [1520/1724] loss: 0.278, ave_loss: 0.365
[78]  [1540/1724] loss: 0.343, ave_loss: 0.365
[79]  [1560/1724] loss: 0.228, ave_loss: 0.363
[80]  [1580/1724] loss: 0.321, ave_loss: 0.362
[81]  [1600/1724] loss: 0.307, ave_loss: 0.362
[82]  [1620/1724] loss: 0.372, ave_loss: 0.362
[83]  [1640/1724] loss: 0.356, ave_loss: 0.362
[84]  [1660/1724] loss: 0.298, ave_loss: 0.361
[85]  [1680/1724] loss: 0.353, ave_loss: 0.361
[86]  [1700/1724] loss: 0.253, ave_loss: 0.360
[87]  [1720/1724] loss: 0.462, ave_loss: 0.361
[88]  [1740/1724] loss: 0.320, ave_loss: 0.360

Finished Training finishing at 2021-08-24 20:59:42.704216
printing_out epoch  40.835266821345705 learning rate: 8.426484453142322e-05
7.690624845302761e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.604e-01
Validation Loss: 1.127e+03
Validation ROC: 0.7819
Saving model
58.164733178654295 epochs left to go

Training Epoch 40.835266821345705/100 starting at 2021-08-24 21:00:17.345039
[1]  [0/1724] loss: 0.614, ave_loss: 0.614
[2]  [20/1724] loss: 0.473, ave_loss: 0.543
[3]  [40/1724] loss: 0.289, ave_loss: 0.459
[4]  [60/1724] loss: 0.525, ave_loss: 0.475
[5]  [80/1724] loss: 0.286, ave_loss: 0.437
[6]  [100/1724] loss: 0.336, ave_loss: 0.420
[7]  [120/1724] loss: 0.262, ave_loss: 0.398
[8]  [140/1724] loss: 0.186, ave_loss: 0.371
[9]  [160/1724] loss: 0.324, ave_loss: 0.366
[10]  [180/1724] loss: 0.313, ave_loss: 0.361
[11]  [200/1724] loss: 0.506, ave_loss: 0.374
[12]  [220/1724] loss: 0.377, ave_loss: 0.374
[13]  [240/1724] loss: 0.249, ave_loss: 0.364
[14]  [260/1724] loss: 0.469, ave_loss: 0.372
[15]  [280/1724] loss: 0.350, ave_loss: 0.371
[16]  [300/1724] loss: 0.246, ave_loss: 0.363
[17]  [320/1724] loss: 0.362, ave_loss: 0.363
[18]  [340/1724] loss: 0.290, ave_loss: 0.359
[19]  [360/1724] loss: 0.401, ave_loss: 0.361
[20]  [380/1724] loss: 0.377, ave_loss: 0.362
[21]  [400/1724] loss: 0.203, ave_loss: 0.354
[22]  [420/1724] loss: 0.736, ave_loss: 0.371
[23]  [440/1724] loss: 0.413, ave_loss: 0.373
[24]  [460/1724] loss: 0.339, ave_loss: 0.372
[25]  [480/1724] loss: 0.361, ave_loss: 0.371
[26]  [500/1724] loss: 0.377, ave_loss: 0.372
[27]  [520/1724] loss: 0.378, ave_loss: 0.372
[28]  [540/1724] loss: 0.325, ave_loss: 0.370
[29]  [560/1724] loss: 0.414, ave_loss: 0.372
[30]  [580/1724] loss: 0.400, ave_loss: 0.373
[31]  [600/1724] loss: 0.372, ave_loss: 0.373
[32]  [620/1724] loss: 0.160, ave_loss: 0.366
[33]  [640/1724] loss: 0.259, ave_loss: 0.363
[34]  [660/1724] loss: 0.252, ave_loss: 0.359
[35]  [680/1724] loss: 0.277, ave_loss: 0.357
[36]  [700/1724] loss: 0.313, ave_loss: 0.356
[37]  [720/1724] loss: 0.362, ave_loss: 0.356
[38]  [740/1724] loss: 0.363, ave_loss: 0.356
[39]  [760/1724] loss: 0.290, ave_loss: 0.355
[40]  [780/1724] loss: 0.249, ave_loss: 0.352
[41]  [800/1724] loss: 0.355, ave_loss: 0.352
[42]  [820/1724] loss: 0.426, ave_loss: 0.354
[43]  [840/1724] loss: 0.481, ave_loss: 0.357
[44]  [860/1724] loss: 0.283, ave_loss: 0.355
[45]  [880/1724] loss: 0.371, ave_loss: 0.355
[46]  [900/1724] loss: 0.350, ave_loss: 0.355
[47]  [920/1724] loss: 0.566, ave_loss: 0.360
[48]  [940/1724] loss: 0.507, ave_loss: 0.363
[49]  [960/1724] loss: 0.317, ave_loss: 0.362
[50]  [980/1724] loss: 0.265, ave_loss: 0.360
[51]  [1000/1724] loss: 0.422, ave_loss: 0.361
[52]  [1020/1724] loss: 0.413, ave_loss: 0.362
[53]  [1040/1724] loss: 0.320, ave_loss: 0.361
[54]  [1060/1724] loss: 0.358, ave_loss: 0.361
[55]  [1080/1724] loss: 0.321, ave_loss: 0.361
[56]  [1100/1724] loss: 0.396, ave_loss: 0.361
[57]  [1120/1724] loss: 0.417, ave_loss: 0.362
[58]  [1140/1724] loss: 0.216, ave_loss: 0.360
[59]  [1160/1724] loss: 0.468, ave_loss: 0.361
[60]  [1180/1724] loss: 0.421, ave_loss: 0.362
[61]  [1200/1724] loss: 0.479, ave_loss: 0.364
[62]  [1220/1724] loss: 0.320, ave_loss: 0.364
[63]  [1240/1724] loss: 0.320, ave_loss: 0.363
[64]  [1260/1724] loss: 0.273, ave_loss: 0.362
[65]  [1280/1724] loss: 0.331, ave_loss: 0.361
[66]  [1300/1724] loss: 0.266, ave_loss: 0.360
[67]  [1320/1724] loss: 0.418, ave_loss: 0.361
[68]  [1340/1724] loss: 0.462, ave_loss: 0.362
[69]  [1360/1724] loss: 0.504, ave_loss: 0.364
[70]  [1380/1724] loss: 0.389, ave_loss: 0.364
[71]  [1400/1724] loss: 0.478, ave_loss: 0.366
[72]  [1420/1724] loss: 0.348, ave_loss: 0.366
[73]  [1440/1724] loss: 0.287, ave_loss: 0.365
[74]  [1460/1724] loss: 0.415, ave_loss: 0.365
[75]  [1480/1724] loss: 0.235, ave_loss: 0.364
[76]  [1500/1724] loss: 0.256, ave_loss: 0.362
[77]  [1520/1724] loss: 0.294, ave_loss: 0.361
[78]  [1540/1724] loss: 0.420, ave_loss: 0.362
[79]  [1560/1724] loss: 0.289, ave_loss: 0.361
[80]  [1580/1724] loss: 0.347, ave_loss: 0.361
[81]  [1600/1724] loss: 0.345, ave_loss: 0.361
[82]  [1620/1724] loss: 0.278, ave_loss: 0.360
[83]  [1640/1724] loss: 0.251, ave_loss: 0.358
[84]  [1660/1724] loss: 0.592, ave_loss: 0.361
[85]  [1680/1724] loss: 0.468, ave_loss: 0.363
[86]  [1700/1724] loss: 0.340, ave_loss: 0.362
[87]  [1720/1724] loss: 0.765, ave_loss: 0.367
[88]  [1740/1724] loss: 0.353, ave_loss: 0.367

Finished Training finishing at 2021-08-24 21:02:24.608461
printing_out epoch  41.85614849187935 learning rate: 8.426484453142322e-05
7.459906099943678e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.667e-01
Validation Loss: 9.396e+02
Validation ROC: 0.7801
No improvement, still saving model
57.14385150812065 epochs left to go

Training Epoch 41.85614849187935/100 starting at 2021-08-24 21:03:19.082872
[1]  [0/1724] loss: 0.485, ave_loss: 0.485
[2]  [20/1724] loss: 0.283, ave_loss: 0.384
[3]  [40/1724] loss: 0.301, ave_loss: 0.357
[4]  [60/1724] loss: 0.377, ave_loss: 0.362
[5]  [80/1724] loss: 0.562, ave_loss: 0.402
[6]  [100/1724] loss: 0.339, ave_loss: 0.391
[7]  [120/1724] loss: 0.352, ave_loss: 0.386
[8]  [140/1724] loss: 0.353, ave_loss: 0.382
[9]  [160/1724] loss: 0.341, ave_loss: 0.377
[10]  [180/1724] loss: 0.519, ave_loss: 0.391
[11]  [200/1724] loss: 0.338, ave_loss: 0.387
[12]  [220/1724] loss: 0.368, ave_loss: 0.385
[13]  [240/1724] loss: 0.499, ave_loss: 0.394
[14]  [260/1724] loss: 0.414, ave_loss: 0.395
[15]  [280/1724] loss: 0.369, ave_loss: 0.393
[16]  [300/1724] loss: 0.208, ave_loss: 0.382
[17]  [320/1724] loss: 0.309, ave_loss: 0.378
[18]  [340/1724] loss: 0.329, ave_loss: 0.375
[19]  [360/1724] loss: 0.386, ave_loss: 0.375
[20]  [380/1724] loss: 0.275, ave_loss: 0.370
[21]  [400/1724] loss: 0.249, ave_loss: 0.365
[22]  [420/1724] loss: 0.459, ave_loss: 0.369
[23]  [440/1724] loss: 0.345, ave_loss: 0.368
[24]  [460/1724] loss: 0.356, ave_loss: 0.367
[25]  [480/1724] loss: 0.501, ave_loss: 0.373
[26]  [500/1724] loss: 0.444, ave_loss: 0.375
[27]  [520/1724] loss: 0.349, ave_loss: 0.374
[28]  [540/1724] loss: 0.467, ave_loss: 0.378
[29]  [560/1724] loss: 0.249, ave_loss: 0.373
[30]  [580/1724] loss: 0.361, ave_loss: 0.373
[31]  [600/1724] loss: 0.212, ave_loss: 0.368
[32]  [620/1724] loss: 0.489, ave_loss: 0.372
[33]  [640/1724] loss: 0.503, ave_loss: 0.375
[34]  [660/1724] loss: 0.375, ave_loss: 0.375
[35]  [680/1724] loss: 0.392, ave_loss: 0.376
[36]  [700/1724] loss: 0.341, ave_loss: 0.375
[37]  [720/1724] loss: 0.300, ave_loss: 0.373
[38]  [740/1724] loss: 0.396, ave_loss: 0.374
[39]  [760/1724] loss: 0.394, ave_loss: 0.374
[40]  [780/1724] loss: 0.319, ave_loss: 0.373
[41]  [800/1724] loss: 0.419, ave_loss: 0.374
[42]  [820/1724] loss: 0.442, ave_loss: 0.375
[43]  [840/1724] loss: 0.398, ave_loss: 0.376
[44]  [860/1724] loss: 0.325, ave_loss: 0.375
[45]  [880/1724] loss: 0.294, ave_loss: 0.373
[46]  [900/1724] loss: 0.262, ave_loss: 0.371
[47]  [920/1724] loss: 0.291, ave_loss: 0.369
[48]  [940/1724] loss: 0.314, ave_loss: 0.368
[49]  [960/1724] loss: 0.460, ave_loss: 0.370
[50]  [980/1724] loss: 0.238, ave_loss: 0.367
[51]  [1000/1724] loss: 0.481, ave_loss: 0.369
[52]  [1020/1724] loss: 0.434, ave_loss: 0.371
[53]  [1040/1724] loss: 0.270, ave_loss: 0.369
[54]  [1060/1724] loss: 0.412, ave_loss: 0.369
[55]  [1080/1724] loss: 0.358, ave_loss: 0.369
[56]  [1100/1724] loss: 0.392, ave_loss: 0.370
[57]  [1120/1724] loss: 0.374, ave_loss: 0.370
[58]  [1140/1724] loss: 0.343, ave_loss: 0.369
[59]  [1160/1724] loss: 0.277, ave_loss: 0.368
[60]  [1180/1724] loss: 0.481, ave_loss: 0.370
[61]  [1200/1724] loss: 0.307, ave_loss: 0.369
[62]  [1220/1724] loss: 0.431, ave_loss: 0.370
[63]  [1240/1724] loss: 0.336, ave_loss: 0.369
[64]  [1260/1724] loss: 0.260, ave_loss: 0.367
[65]  [1280/1724] loss: 0.443, ave_loss: 0.368
[66]  [1300/1724] loss: 0.287, ave_loss: 0.367
[67]  [1320/1724] loss: 0.257, ave_loss: 0.366
[68]  [1340/1724] loss: 0.310, ave_loss: 0.365
[69]  [1360/1724] loss: 0.425, ave_loss: 0.366
[70]  [1380/1724] loss: 0.411, ave_loss: 0.366
[71]  [1400/1724] loss: 0.376, ave_loss: 0.366
[72]  [1420/1724] loss: 0.364, ave_loss: 0.366
[73]  [1440/1724] loss: 0.366, ave_loss: 0.366
[74]  [1460/1724] loss: 0.538, ave_loss: 0.369
[75]  [1480/1724] loss: 0.332, ave_loss: 0.368
[76]  [1500/1724] loss: 0.454, ave_loss: 0.369
[77]  [1520/1724] loss: 0.388, ave_loss: 0.370
[78]  [1540/1724] loss: 0.476, ave_loss: 0.371
[79]  [1560/1724] loss: 0.316, ave_loss: 0.370
[80]  [1580/1724] loss: 0.408, ave_loss: 0.371
[81]  [1600/1724] loss: 0.312, ave_loss: 0.370
[82]  [1620/1724] loss: 0.355, ave_loss: 0.370
[83]  [1640/1724] loss: 0.260, ave_loss: 0.368
[84]  [1660/1724] loss: 0.349, ave_loss: 0.368
[85]  [1680/1724] loss: 0.462, ave_loss: 0.369
[86]  [1700/1724] loss: 0.261, ave_loss: 0.368
[87]  [1720/1724] loss: 0.350, ave_loss: 0.368
[88]  [1740/1724] loss: 0.202, ave_loss: 0.366

Finished Training finishing at 2021-08-24 21:05:19.839244
printing_out epoch  42.87703016241299 learning rate: 7.660440411947565e-05
7.430627199589138e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.660e-01
Validation Loss: 9.002e+02
Validation ROC: 0.7813
No improvement, still saving model
56.12296983758701 epochs left to go

Training Epoch 42.87703016241299/100 starting at 2021-08-24 21:07:07.836962
[1]  [0/1724] loss: 0.606, ave_loss: 0.606
[2]  [20/1724] loss: 0.436, ave_loss: 0.521
[3]  [40/1724] loss: 0.431, ave_loss: 0.491
[4]  [60/1724] loss: 0.305, ave_loss: 0.444
[5]  [80/1724] loss: 0.256, ave_loss: 0.407
[6]  [100/1724] loss: 0.330, ave_loss: 0.394
[7]  [120/1724] loss: 0.312, ave_loss: 0.382
[8]  [140/1724] loss: 0.483, ave_loss: 0.395
[9]  [160/1724] loss: 0.348, ave_loss: 0.390
[10]  [180/1724] loss: 0.242, ave_loss: 0.375
[11]  [200/1724] loss: 0.291, ave_loss: 0.367
[12]  [220/1724] loss: 0.362, ave_loss: 0.367
[13]  [240/1724] loss: 0.302, ave_loss: 0.362
[14]  [260/1724] loss: 0.376, ave_loss: 0.363
[15]  [280/1724] loss: 0.536, ave_loss: 0.374
[16]  [300/1724] loss: 0.378, ave_loss: 0.375
[17]  [320/1724] loss: 0.440, ave_loss: 0.378
[18]  [340/1724] loss: 0.355, ave_loss: 0.377
[19]  [360/1724] loss: 0.225, ave_loss: 0.369
[20]  [380/1724] loss: 0.299, ave_loss: 0.366
[21]  [400/1724] loss: 0.294, ave_loss: 0.362
[22]  [420/1724] loss: 0.395, ave_loss: 0.364
[23]  [440/1724] loss: 0.288, ave_loss: 0.360
[24]  [460/1724] loss: 0.147, ave_loss: 0.351
[25]  [480/1724] loss: 0.490, ave_loss: 0.357
[26]  [500/1724] loss: 0.528, ave_loss: 0.364
[27]  [520/1724] loss: 0.473, ave_loss: 0.368
[28]  [540/1724] loss: 0.315, ave_loss: 0.366
[29]  [560/1724] loss: 0.475, ave_loss: 0.370
[30]  [580/1724] loss: 0.390, ave_loss: 0.370
[31]  [600/1724] loss: 0.328, ave_loss: 0.369
[32]  [620/1724] loss: 0.371, ave_loss: 0.369
[33]  [640/1724] loss: 0.323, ave_loss: 0.368
[34]  [660/1724] loss: 0.469, ave_loss: 0.371
[35]  [680/1724] loss: 0.419, ave_loss: 0.372
[36]  [700/1724] loss: 0.335, ave_loss: 0.371
[37]  [720/1724] loss: 0.312, ave_loss: 0.369
[38]  [740/1724] loss: 0.340, ave_loss: 0.369
[39]  [760/1724] loss: 0.286, ave_loss: 0.366
[40]  [780/1724] loss: 0.299, ave_loss: 0.365
[41]  [800/1724] loss: 0.319, ave_loss: 0.364
[42]  [820/1724] loss: 0.635, ave_loss: 0.370
[43]  [840/1724] loss: 0.392, ave_loss: 0.371
[44]  [860/1724] loss: 0.302, ave_loss: 0.369
[45]  [880/1724] loss: 0.502, ave_loss: 0.372
[46]  [900/1724] loss: 0.506, ave_loss: 0.375
[47]  [920/1724] loss: 0.259, ave_loss: 0.372
[48]  [940/1724] loss: 0.337, ave_loss: 0.372
[49]  [960/1724] loss: 0.210, ave_loss: 0.368
[50]  [980/1724] loss: 0.349, ave_loss: 0.368
[51]  [1000/1724] loss: 0.287, ave_loss: 0.366
[52]  [1020/1724] loss: 0.310, ave_loss: 0.365
[53]  [1040/1724] loss: 0.409, ave_loss: 0.366
[54]  [1060/1724] loss: 0.319, ave_loss: 0.365
[55]  [1080/1724] loss: 0.492, ave_loss: 0.368
[56]  [1100/1724] loss: 0.241, ave_loss: 0.365
[57]  [1120/1724] loss: 0.451, ave_loss: 0.367
[58]  [1140/1724] loss: 0.419, ave_loss: 0.368
[59]  [1160/1724] loss: 0.267, ave_loss: 0.366
[60]  [1180/1724] loss: 0.464, ave_loss: 0.368
[61]  [1200/1724] loss: 0.318, ave_loss: 0.367
[62]  [1220/1724] loss: 0.275, ave_loss: 0.365
[63]  [1240/1724] loss: 0.304, ave_loss: 0.364
[64]  [1260/1724] loss: 0.307, ave_loss: 0.364
[65]  [1280/1724] loss: 0.528, ave_loss: 0.366
[66]  [1300/1724] loss: 0.365, ave_loss: 0.366
[67]  [1320/1724] loss: 0.274, ave_loss: 0.365
[68]  [1340/1724] loss: 0.598, ave_loss: 0.368
[69]  [1360/1724] loss: 0.324, ave_loss: 0.367
[70]  [1380/1724] loss: 0.387, ave_loss: 0.368
[71]  [1400/1724] loss: 0.309, ave_loss: 0.367
[72]  [1420/1724] loss: 0.332, ave_loss: 0.366
[73]  [1440/1724] loss: 0.245, ave_loss: 0.365
[74]  [1460/1724] loss: 0.304, ave_loss: 0.364
[75]  [1480/1724] loss: 0.526, ave_loss: 0.366
[76]  [1500/1724] loss: 0.344, ave_loss: 0.366
[77]  [1520/1724] loss: 0.449, ave_loss: 0.367
[78]  [1540/1724] loss: 0.319, ave_loss: 0.366
[79]  [1560/1724] loss: 0.276, ave_loss: 0.365
[80]  [1580/1724] loss: 0.323, ave_loss: 0.365
[81]  [1600/1724] loss: 0.387, ave_loss: 0.365
[82]  [1620/1724] loss: 0.426, ave_loss: 0.366
[83]  [1640/1724] loss: 0.249, ave_loss: 0.364
[84]  [1660/1724] loss: 0.430, ave_loss: 0.365
[85]  [1680/1724] loss: 0.453, ave_loss: 0.366
[86]  [1700/1724] loss: 0.403, ave_loss: 0.366
[87]  [1720/1724] loss: 0.256, ave_loss: 0.365
[88]  [1740/1724] loss: 0.377, ave_loss: 0.365

Finished Training finishing at 2021-08-24 21:09:18.478500
printing_out epoch  43.89791183294663 learning rate: 6.96403673813415e-05
6.755115635990125e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.653e-01
Validation Loss: 8.787e+02
Validation ROC: 0.7812
No improvement, still saving model
55.10208816705337 epochs left to go

Training Epoch 43.89791183294663/100 starting at 2021-08-24 21:09:44.510313
[1]  [0/1724] loss: 0.658, ave_loss: 0.658
[2]  [20/1724] loss: 0.386, ave_loss: 0.522
[3]  [40/1724] loss: 0.264, ave_loss: 0.436
[4]  [60/1724] loss: 0.392, ave_loss: 0.425
[5]  [80/1724] loss: 0.280, ave_loss: 0.396
[6]  [100/1724] loss: 0.309, ave_loss: 0.381
[7]  [120/1724] loss: 0.357, ave_loss: 0.378
[8]  [140/1724] loss: 0.454, ave_loss: 0.387
[9]  [160/1724] loss: 0.418, ave_loss: 0.391
[10]  [180/1724] loss: 0.350, ave_loss: 0.387
[11]  [200/1724] loss: 0.363, ave_loss: 0.385
[12]  [220/1724] loss: 0.501, ave_loss: 0.394
[13]  [240/1724] loss: 0.310, ave_loss: 0.388
[14]  [260/1724] loss: 0.470, ave_loss: 0.394
[15]  [280/1724] loss: 0.251, ave_loss: 0.384
[16]  [300/1724] loss: 0.216, ave_loss: 0.374
[17]  [320/1724] loss: 0.258, ave_loss: 0.367
[18]  [340/1724] loss: 0.335, ave_loss: 0.365
[19]  [360/1724] loss: 0.461, ave_loss: 0.370
[20]  [380/1724] loss: 0.244, ave_loss: 0.364
[21]  [400/1724] loss: 0.255, ave_loss: 0.359
[22]  [420/1724] loss: 0.322, ave_loss: 0.357
[23]  [440/1724] loss: 0.308, ave_loss: 0.355
[24]  [460/1724] loss: 0.398, ave_loss: 0.357
[25]  [480/1724] loss: 0.305, ave_loss: 0.355
[26]  [500/1724] loss: 0.347, ave_loss: 0.354
[27]  [520/1724] loss: 0.343, ave_loss: 0.354
[28]  [540/1724] loss: 0.250, ave_loss: 0.350
[29]  [560/1724] loss: 0.437, ave_loss: 0.353
[30]  [580/1724] loss: 0.450, ave_loss: 0.356
[31]  [600/1724] loss: 0.449, ave_loss: 0.359
[32]  [620/1724] loss: 0.410, ave_loss: 0.361
[33]  [640/1724] loss: 0.501, ave_loss: 0.365
[34]  [660/1724] loss: 0.400, ave_loss: 0.366
[35]  [680/1724] loss: 0.266, ave_loss: 0.363
[36]  [700/1724] loss: 0.264, ave_loss: 0.361
[37]  [720/1724] loss: 0.468, ave_loss: 0.364
[38]  [740/1724] loss: 0.320, ave_loss: 0.362
[39]  [760/1724] loss: 0.351, ave_loss: 0.362
[40]  [780/1724] loss: 0.408, ave_loss: 0.363
[41]  [800/1724] loss: 0.260, ave_loss: 0.361
[42]  [820/1724] loss: 0.440, ave_loss: 0.363
[43]  [840/1724] loss: 0.484, ave_loss: 0.365
[44]  [860/1724] loss: 0.261, ave_loss: 0.363
[45]  [880/1724] loss: 0.280, ave_loss: 0.361
[46]  [900/1724] loss: 0.334, ave_loss: 0.361
[47]  [920/1724] loss: 0.347, ave_loss: 0.360
[48]  [940/1724] loss: 0.336, ave_loss: 0.360
[49]  [960/1724] loss: 0.309, ave_loss: 0.359
[50]  [980/1724] loss: 0.317, ave_loss: 0.358
[51]  [1000/1724] loss: 0.415, ave_loss: 0.359
[52]  [1020/1724] loss: 0.453, ave_loss: 0.361
[53]  [1040/1724] loss: 0.310, ave_loss: 0.360
[54]  [1060/1724] loss: 0.415, ave_loss: 0.361
[55]  [1080/1724] loss: 0.338, ave_loss: 0.361
[56]  [1100/1724] loss: 0.379, ave_loss: 0.361
[57]  [1120/1724] loss: 0.365, ave_loss: 0.361
[58]  [1140/1724] loss: 0.540, ave_loss: 0.364
[59]  [1160/1724] loss: 0.248, ave_loss: 0.362
[60]  [1180/1724] loss: 0.280, ave_loss: 0.361
[61]  [1200/1724] loss: 0.519, ave_loss: 0.363
[62]  [1220/1724] loss: 0.456, ave_loss: 0.365
[63]  [1240/1724] loss: 0.257, ave_loss: 0.363
[64]  [1260/1724] loss: 0.301, ave_loss: 0.362
[65]  [1280/1724] loss: 0.658, ave_loss: 0.367
[66]  [1300/1724] loss: 0.261, ave_loss: 0.365
[67]  [1320/1724] loss: 0.304, ave_loss: 0.364
[68]  [1340/1724] loss: 0.525, ave_loss: 0.366
[69]  [1360/1724] loss: 0.177, ave_loss: 0.364
[70]  [1380/1724] loss: 0.212, ave_loss: 0.362
[71]  [1400/1724] loss: 0.206, ave_loss: 0.359
[72]  [1420/1724] loss: 0.195, ave_loss: 0.357
[73]  [1440/1724] loss: 0.465, ave_loss: 0.359
[74]  [1460/1724] loss: 0.342, ave_loss: 0.358
[75]  [1480/1724] loss: 0.264, ave_loss: 0.357
[76]  [1500/1724] loss: 0.281, ave_loss: 0.356
[77]  [1520/1724] loss: 0.370, ave_loss: 0.356
[78]  [1540/1724] loss: 0.258, ave_loss: 0.355
[79]  [1560/1724] loss: 0.359, ave_loss: 0.355
[80]  [1580/1724] loss: 0.277, ave_loss: 0.354
[81]  [1600/1724] loss: 0.370, ave_loss: 0.354
[82]  [1620/1724] loss: 0.317, ave_loss: 0.354
[83]  [1640/1724] loss: 0.474, ave_loss: 0.355
[84]  [1660/1724] loss: 0.212, ave_loss: 0.354
[85]  [1680/1724] loss: 0.216, ave_loss: 0.352
[86]  [1700/1724] loss: 0.380, ave_loss: 0.352
[87]  [1720/1724] loss: 0.363, ave_loss: 0.352
[88]  [1740/1724] loss: 0.354, ave_loss: 0.352

Finished Training finishing at 2021-08-24 21:11:51.549401
printing_out epoch  44.91879350348028 learning rate: 6.330942489212863e-05
6.141014214536477e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.524e-01
Validation Loss: 9.935e+02
Validation ROC: 0.7806
No improvement, still saving model
54.08120649651972 epochs left to go

Training Epoch 44.91879350348028/100 starting at 2021-08-24 21:12:31.177344
[1]  [0/1724] loss: 0.383, ave_loss: 0.383
[2]  [20/1724] loss: 0.368, ave_loss: 0.375
[3]  [40/1724] loss: 0.405, ave_loss: 0.385
[4]  [60/1724] loss: 0.324, ave_loss: 0.370
[5]  [80/1724] loss: 0.298, ave_loss: 0.355
[6]  [100/1724] loss: 0.286, ave_loss: 0.344
[7]  [120/1724] loss: 0.307, ave_loss: 0.339
[8]  [140/1724] loss: 0.321, ave_loss: 0.336
[9]  [160/1724] loss: 0.444, ave_loss: 0.348
[10]  [180/1724] loss: 0.305, ave_loss: 0.344
[11]  [200/1724] loss: 0.432, ave_loss: 0.352
[12]  [220/1724] loss: 0.358, ave_loss: 0.353
[13]  [240/1724] loss: 0.296, ave_loss: 0.348
[14]  [260/1724] loss: 0.272, ave_loss: 0.343
[15]  [280/1724] loss: 0.441, ave_loss: 0.349
[16]  [300/1724] loss: 0.377, ave_loss: 0.351
[17]  [320/1724] loss: 0.272, ave_loss: 0.346
[18]  [340/1724] loss: 0.386, ave_loss: 0.349
[19]  [360/1724] loss: 0.413, ave_loss: 0.352
[20]  [380/1724] loss: 0.503, ave_loss: 0.360
[21]  [400/1724] loss: 0.311, ave_loss: 0.357
[22]  [420/1724] loss: 0.434, ave_loss: 0.361
[23]  [440/1724] loss: 0.429, ave_loss: 0.364
[24]  [460/1724] loss: 0.326, ave_loss: 0.362
[25]  [480/1724] loss: 0.299, ave_loss: 0.360
[26]  [500/1724] loss: 0.302, ave_loss: 0.357
[27]  [520/1724] loss: 0.473, ave_loss: 0.362
[28]  [540/1724] loss: 0.295, ave_loss: 0.359
[29]  [560/1724] loss: 0.353, ave_loss: 0.359
[30]  [580/1724] loss: 0.337, ave_loss: 0.358
[31]  [600/1724] loss: 0.405, ave_loss: 0.360
[32]  [620/1724] loss: 0.247, ave_loss: 0.356
[33]  [640/1724] loss: 0.316, ave_loss: 0.355
[34]  [660/1724] loss: 0.410, ave_loss: 0.357
[35]  [680/1724] loss: 0.371, ave_loss: 0.357
[36]  [700/1724] loss: 0.464, ave_loss: 0.360
[37]  [720/1724] loss: 0.319, ave_loss: 0.359
[38]  [740/1724] loss: 0.387, ave_loss: 0.360
[39]  [760/1724] loss: 0.395, ave_loss: 0.361
[40]  [780/1724] loss: 0.398, ave_loss: 0.362
[41]  [800/1724] loss: 0.314, ave_loss: 0.360
[42]  [820/1724] loss: 0.240, ave_loss: 0.358
[43]  [840/1724] loss: 0.359, ave_loss: 0.358
[44]  [860/1724] loss: 0.382, ave_loss: 0.358
[45]  [880/1724] loss: 0.291, ave_loss: 0.357
[46]  [900/1724] loss: 0.340, ave_loss: 0.356
[47]  [920/1724] loss: 0.375, ave_loss: 0.357
[48]  [940/1724] loss: 0.562, ave_loss: 0.361
[49]  [960/1724] loss: 0.422, ave_loss: 0.362
[50]  [980/1724] loss: 0.332, ave_loss: 0.362
[51]  [1000/1724] loss: 0.315, ave_loss: 0.361
[52]  [1020/1724] loss: 0.362, ave_loss: 0.361
[53]  [1040/1724] loss: 0.180, ave_loss: 0.357
[54]  [1060/1724] loss: 0.275, ave_loss: 0.356
[55]  [1080/1724] loss: 0.358, ave_loss: 0.356
[56]  [1100/1724] loss: 0.336, ave_loss: 0.355
[57]  [1120/1724] loss: 0.352, ave_loss: 0.355
[58]  [1140/1724] loss: 0.261, ave_loss: 0.354
[59]  [1160/1724] loss: 0.277, ave_loss: 0.352
[60]  [1180/1724] loss: 0.258, ave_loss: 0.351
[61]  [1200/1724] loss: 0.244, ave_loss: 0.349
[62]  [1220/1724] loss: 0.467, ave_loss: 0.351
[63]  [1240/1724] loss: 0.444, ave_loss: 0.352
[64]  [1260/1724] loss: 0.304, ave_loss: 0.352
[65]  [1280/1724] loss: 0.499, ave_loss: 0.354
[66]  [1300/1724] loss: 0.361, ave_loss: 0.354
[67]  [1320/1724] loss: 0.424, ave_loss: 0.355
[68]  [1340/1724] loss: 0.589, ave_loss: 0.359
[69]  [1360/1724] loss: 0.402, ave_loss: 0.359
[70]  [1380/1724] loss: 0.362, ave_loss: 0.359
[71]  [1400/1724] loss: 0.316, ave_loss: 0.359
[72]  [1420/1724] loss: 0.275, ave_loss: 0.357
[73]  [1440/1724] loss: 0.280, ave_loss: 0.356
[74]  [1460/1724] loss: 0.337, ave_loss: 0.356
[75]  [1480/1724] loss: 0.317, ave_loss: 0.356
[76]  [1500/1724] loss: 0.372, ave_loss: 0.356
[77]  [1520/1724] loss: 0.309, ave_loss: 0.355
[78]  [1540/1724] loss: 0.371, ave_loss: 0.355
[79]  [1560/1724] loss: 0.379, ave_loss: 0.356
[80]  [1580/1724] loss: 0.282, ave_loss: 0.355
[81]  [1600/1724] loss: 0.400, ave_loss: 0.355
[82]  [1620/1724] loss: 0.362, ave_loss: 0.355
[83]  [1640/1724] loss: 0.291, ave_loss: 0.355
[84]  [1660/1724] loss: 0.429, ave_loss: 0.356
[85]  [1680/1724] loss: 0.511, ave_loss: 0.357
[86]  [1700/1724] loss: 0.298, ave_loss: 0.357
[87]  [1720/1724] loss: 0.353, ave_loss: 0.357
[88]  [1740/1724] loss: 0.453, ave_loss: 0.358

Finished Training finishing at 2021-08-24 21:14:51.836897
printing_out epoch  45.93967517401392 learning rate: 5.755402262920784e-05
5.58274019503316e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.578e-01
Validation Loss: 1.023e+03
Validation ROC: 0.7825
Saving model
53.06032482598608 epochs left to go

Training Epoch 45.93967517401392/100 starting at 2021-08-24 21:15:28.859788
[1]  [0/1724] loss: 0.409, ave_loss: 0.409
[2]  [20/1724] loss: 0.334, ave_loss: 0.372
[3]  [40/1724] loss: 0.400, ave_loss: 0.381
[4]  [60/1724] loss: 0.444, ave_loss: 0.397
[5]  [80/1724] loss: 0.394, ave_loss: 0.396
[6]  [100/1724] loss: 0.381, ave_loss: 0.394
[7]  [120/1724] loss: 0.388, ave_loss: 0.393
[8]  [140/1724] loss: 0.329, ave_loss: 0.385
[9]  [160/1724] loss: 0.395, ave_loss: 0.386
[10]  [180/1724] loss: 0.366, ave_loss: 0.384
[11]  [200/1724] loss: 0.276, ave_loss: 0.374
[12]  [220/1724] loss: 0.258, ave_loss: 0.365
[13]  [240/1724] loss: 0.319, ave_loss: 0.361
[14]  [260/1724] loss: 0.240, ave_loss: 0.352
[15]  [280/1724] loss: 0.332, ave_loss: 0.351
[16]  [300/1724] loss: 0.423, ave_loss: 0.355
[17]  [320/1724] loss: 0.290, ave_loss: 0.352
[18]  [340/1724] loss: 0.282, ave_loss: 0.348
[19]  [360/1724] loss: 0.293, ave_loss: 0.345
[20]  [380/1724] loss: 0.285, ave_loss: 0.342
[21]  [400/1724] loss: 0.366, ave_loss: 0.343
[22]  [420/1724] loss: 0.472, ave_loss: 0.349
[23]  [440/1724] loss: 0.467, ave_loss: 0.354
[24]  [460/1724] loss: 0.298, ave_loss: 0.352
[25]  [480/1724] loss: 0.329, ave_loss: 0.351
[26]  [500/1724] loss: 0.322, ave_loss: 0.350
[27]  [520/1724] loss: 0.395, ave_loss: 0.351
[28]  [540/1724] loss: 0.336, ave_loss: 0.351
[29]  [560/1724] loss: 0.374, ave_loss: 0.352
[30]  [580/1724] loss: 0.380, ave_loss: 0.353
[31]  [600/1724] loss: 0.298, ave_loss: 0.351
[32]  [620/1724] loss: 0.434, ave_loss: 0.353
[33]  [640/1724] loss: 0.208, ave_loss: 0.349
[34]  [660/1724] loss: 0.413, ave_loss: 0.351
[35]  [680/1724] loss: 0.308, ave_loss: 0.350
[36]  [700/1724] loss: 0.375, ave_loss: 0.350
[37]  [720/1724] loss: 0.529, ave_loss: 0.355
[38]  [740/1724] loss: 0.589, ave_loss: 0.361
[39]  [760/1724] loss: 0.281, ave_loss: 0.359
[40]  [780/1724] loss: 0.438, ave_loss: 0.361
[41]  [800/1724] loss: 0.298, ave_loss: 0.360
[42]  [820/1724] loss: 0.456, ave_loss: 0.362
[43]  [840/1724] loss: 0.248, ave_loss: 0.359
[44]  [860/1724] loss: 0.223, ave_loss: 0.356
[45]  [880/1724] loss: 0.464, ave_loss: 0.359
[46]  [900/1724] loss: 0.472, ave_loss: 0.361
[47]  [920/1724] loss: 0.424, ave_loss: 0.362
[48]  [940/1724] loss: 0.331, ave_loss: 0.362
[49]  [960/1724] loss: 0.325, ave_loss: 0.361
[50]  [980/1724] loss: 0.250, ave_loss: 0.359
[51]  [1000/1724] loss: 0.343, ave_loss: 0.358
[52]  [1020/1724] loss: 0.535, ave_loss: 0.362
[53]  [1040/1724] loss: 0.294, ave_loss: 0.361
[54]  [1060/1724] loss: 0.459, ave_loss: 0.362
[55]  [1080/1724] loss: 0.295, ave_loss: 0.361
[56]  [1100/1724] loss: 0.271, ave_loss: 0.360
[57]  [1120/1724] loss: 0.418, ave_loss: 0.361
[58]  [1140/1724] loss: 0.225, ave_loss: 0.358
[59]  [1160/1724] loss: 0.431, ave_loss: 0.359
[60]  [1180/1724] loss: 0.228, ave_loss: 0.357
[61]  [1200/1724] loss: 0.417, ave_loss: 0.358
[62]  [1220/1724] loss: 0.326, ave_loss: 0.358
[63]  [1240/1724] loss: 0.362, ave_loss: 0.358
[64]  [1260/1724] loss: 0.387, ave_loss: 0.358
[65]  [1280/1724] loss: 0.319, ave_loss: 0.358
[66]  [1300/1724] loss: 0.486, ave_loss: 0.360
[67]  [1320/1724] loss: 0.453, ave_loss: 0.361
[68]  [1340/1724] loss: 0.442, ave_loss: 0.362
[69]  [1360/1724] loss: 0.322, ave_loss: 0.362
[70]  [1380/1724] loss: 0.403, ave_loss: 0.362
[71]  [1400/1724] loss: 0.512, ave_loss: 0.364
[72]  [1420/1724] loss: 0.370, ave_loss: 0.364
[73]  [1440/1724] loss: 0.365, ave_loss: 0.364
[74]  [1460/1724] loss: 0.230, ave_loss: 0.363
[75]  [1480/1724] loss: 0.330, ave_loss: 0.362
[76]  [1500/1724] loss: 0.333, ave_loss: 0.362
[77]  [1520/1724] loss: 0.557, ave_loss: 0.364
[78]  [1540/1724] loss: 0.294, ave_loss: 0.363
[79]  [1560/1724] loss: 0.412, ave_loss: 0.364
[80]  [1580/1724] loss: 0.381, ave_loss: 0.364
[81]  [1600/1724] loss: 0.363, ave_loss: 0.364
[82]  [1620/1724] loss: 0.458, ave_loss: 0.365
[83]  [1640/1724] loss: 0.406, ave_loss: 0.366
[84]  [1660/1724] loss: 0.334, ave_loss: 0.365
[85]  [1680/1724] loss: 0.360, ave_loss: 0.365
[86]  [1700/1724] loss: 0.456, ave_loss: 0.366
[87]  [1720/1724] loss: 0.317, ave_loss: 0.366
[88]  [1740/1724] loss: 0.260, ave_loss: 0.365

Finished Training finishing at 2021-08-24 21:17:36.230213
printing_out epoch  46.96055684454756 learning rate: 5.755402262920784e-05
5.415257989182165e-05
y_prime, 849 434
y_gold, 849 434
disruptive, 849
=========Summary======== for epoch88
Training Loss numpy: 3.647e-01
Validation Loss: 9.871e+02
Validation ROC: 0.7826
Saving model
52.03944315545244 epochs left to go

Training Epoch 46.96055684454756/100 starting at 2021-08-24 21:18:28.887624
[1]  [0/1724] loss: 0.284, ave_loss: 0.284
[2]  [20/1724] loss: 0.284, ave_loss: 0.284
[3]  [40/1724] loss: 0.444, ave_loss: 0.337
[4]  [60/1724] loss: 0.393, ave_loss: 0.351
[5]  [80/1724] loss: 0.644, ave_loss: 0.410
[6]  [100/1724] loss: 0.438, ave_loss: 0.414
[7]  [120/1724] loss: 0.203, ave_loss: 0.384
[8]  [140/1724] loss: 0.417, ave_loss: 0.388
[9]  [160/1724] loss: 0.374, ave_loss: 0.387
[10]  [180/1724] loss: 0.324, ave_loss: 0.380
[11]  [200/1724] loss: 0.336, ave_loss: 0.376
[12]  [220/1724] loss: 0.402, ave_loss: 0.379
[13]  [240/1724] loss: 0.384, ave_loss: 0.379
[14]  [260/1724] loss: 0.386, ave_loss: 0.379
[15]  [280/1724] loss: 0.366, ave_loss: 0.379
[16]  [300/1724] loss: 0.265, ave_loss: 0.371
[17]  [320/1724] loss: 0.362, ave_loss: 0.371
[18]  [340/1724] loss: 0.384, ave_loss: 0.372
[19]  [360/1724] loss: 0.303, ave_loss: 0.368
[20]  [380/1724] loss: 0.351, ave_loss: 0.367
[21]  [400/1724] loss: 0.414, ave_loss: 0.369
[22]  [420/1724] loss: 0.342, ave_loss: 0.368
[23]  [440/1724] loss: 0.407, ave_loss: 0.370
[24]  [460/1724] loss: 0.495, ave_loss: 0.375
[25]  [480/1724] loss: 0.247, ave_loss: 0.370
[26]  [500/1724] loss: 0.363, ave_loss: 0.370
[27]  [520/1724] loss: 0.389, ave_loss: 0.370
[28]  [540/1724] loss: 0.230, ave_loss: 0.365
[29]  [560/1724] loss: 0.311, ave_loss: 0.364
[30]  [580/1724] loss: 0.358, ave_loss: 0.363
[31]  [600/1724] loss: 0.444, ave_loss: 0.366
[32]  [620/1724] loss: 0.333, ave_loss: 0.365
[33]  [640/1724] loss: 0.345, ave_loss: 0.364
[34]  [660/1724] loss: 0.322, ave_loss: 0.363
[35]  [680/1724] loss: 0.291, ave_loss: 0.361
[36]  [700/1724] loss: 0.252, ave_loss: 0.358
[37]  [720/1724] loss: 0.353, ave_loss: 0.358
[38]  [740/1724] loss: 0.292, ave_loss: 0.356
[39]  [760/1724] loss: 0.435, ave_loss: 0.358
[40]  [780/1724] loss: 0.256, ave_loss: 0.356
[41]  [800/1724] loss: 0.342, ave_loss: 0.355
[42]  [820/1724] loss: 0.242, ave_loss: 0.353
[43]  [840/1724] loss: 0.295, ave_loss: 0.351
[44]  [860/1724] loss: 0.235, ave_loss: 0.349
[45]  [880/1724] loss: 0.316, ave_loss: 0.348
[46]  [900/1724] loss: 0.457, ave_loss: 0.350
[47]  [920/1724] loss: 0.183, ave_loss: 0.347
[48]  [940/1724] loss: 0.415, ave_loss: 0.348
[49]  [960/1724] loss: 0.315, ave_loss: 0.347
[50]  [980/1724] loss: 0.416, ave_loss: 0.349
[51]  [1000/1724] loss: 0.426, ave_loss: 0.350
[52]  [1020/1724] loss: 0.483, ave_loss: 0.353
[53]  [1040/1724] loss: 0.393, ave_loss: 0.354
[54]  [1060/1724] loss: 0.316, ave_loss: 0.353
[55]  [1080/1724] loss: 0.342, ave_loss: 0.353
[56]  [1100/1724] loss: 0.371, ave_loss: 0.353
[57]  [1120/1724] loss: 0.329, ave_loss: 0.353
[58]  [1140/1724] loss: 0.306, ave_loss: 0.352
[59]  [1160/1724] loss: 0.259, ave_loss: 0.350
[60]  [1180/1724] loss: 0.246, ave_loss: 0.349
[61]  [1200/1724] loss: 0.389, ave_loss: 0.349
[62]  [1220/1724] loss: 0.200, ave_loss: 0.347
[63]  [1240/1724] loss: 0.277, ave_loss: 0.346
[64]  [1260/1724] loss: 0.228, ave_loss: 0.344
[65]  [1280/1724] loss: 0.318, ave_loss: 0.343
[66]  [1300/1724] loss: 0.424, ave_loss: 0.345
[67]  [1320/1724] loss: 0.283, ave_loss: 0.344
[68]  [1340/1724] loss: 0.357, ave_loss: 0.344
[69]  [1360/1724] loss: 0.195, ave_loss: 0.342
[70]  [1380/1724] loss: 0.354, ave_loss: 0.342
[71]  [1400/1724] loss: 0.229, ave_loss: 0.340
[72]  [1420/1724] loss: 0.359, ave_loss: 0.341
[73]  [1440/1724] loss: 0.230, ave_loss: 0.339
[74]  [1460/1724] loss: 0.348, ave_loss: 0.339
[75]  [1480/1724] loss: 0.253, ave_loss: 0.338
[76]  [1500/1724] loss: 0.312, ave_loss: 0.338
[77]  [1520/1724] loss: 0.518, ave_loss: 0.340
[78]  [1540/1724] loss: 0.295, ave_loss: 0.339
[79]  [1560/1724] loss: 0.324, ave_loss: 0.339
[80]  [1580/1724] loss: 0.262, ave_loss: 0.338
[81]  [1600/1724] loss: 0.418, ave_loss: 0.339
[82]  [1620/1724] loss: 0.291, ave_loss: 0.339
[83]  [1640/1724] loss: 0.291, ave_loss: 0.338
[84]  [1660/1724] loss: 0.303, ave_loss: 0.338
[85]  [1680/1724] loss: 0.333, ave_loss: 0.338
[86]  [1700/1724] loss: 0.476, ave_loss: 0.339
